<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  border: 1px solid #ddd;
  border-radius: 3px;
  height: 97%;
}

#side-bar {
  overflow: auto;
}

#editor-wrapper {
  overflow: hidden;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijn@haverbeke.berlin> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report.events;
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(report.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report.events;
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setChecker(report.checker);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.fileId]);
    this.drawBugPath();

    this.jumpTo(event.line, 0);
    this.highlightBugEvent(idx);
  },

  highlightBugEvent : function (idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setChecker : function (checker) {
    var content = checker.name;
    if (checker.url) {
      content = '<a href="' + checker.url + '" target="_blank">' +
        checker.name + '</a>';
    }

    this._checkerName.innerHTML = content;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.filePath;
    let e = document.createElement('div');
    e.innerHTML = file.content;
    this._codeMirror.doc.setValue(e.innerText);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.fileId !== that._currentBugEvent.fileId) {
        return;
      }

      var left = that._codeMirror.defaultCharWidth() * event.column + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.fileId !== that._currentBugEvent.fileId)
        return;

      var left = that._codeMirror.defaultCharWidth() * event.column + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.line - 1, element));
    });
    // If there are no events, or the last event does not match
    // the main warning message we print the warning message as a separate
    // error node.
    var lastEvent = null
    if (currentEvents.length > 0)
      lastEvent =currentEvents[currentEvents.length - 1];
    if (!lastEvent ||
          lastEvent.message != this._currentReport.message ||
          lastEvent.line != this._currentReport.line){
        var element = document.createElement('div');
        var left = that._codeMirror.defaultCharWidth() * lastEvent.column + 'px';
        element.setAttribute('style', 'margin-left: ' + left);
        element.setAttribute('class', 'check-msg ' + "error");
        var error_tag = document.createElement('span');
        error_tag.setAttribute('class', 'checker-enum error');
        error_tag.innerHTML = "E";
        element.appendChild(error_tag);
        var msg = document.createElement('span');
        msg.innerHTML = that.escapeHTML(this._currentReport.message)
          .replace(/(?:\r\n|\r|\n)/g, '<br>');
        element.appendChild(msg);
        that._lineWidgets.push(that._codeMirror.addLineWidget(
          this._currentReport.line - 1, element));
      }
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc", "content": "\n#ifdef EIGEN_PARSED_BY_DOXYGEN\n\n/// \\returns an expression of \\c *this with reshaped sizes.\n///\n/// \\param nRows the number of rows in the reshaped expression, specified at either run-time or compile-time, or\n/// AutoSize \\param nCols the number of columns in the reshaped expression, specified at either run-time or\n/// compile-time, or AutoSize \\tparam Order specifies whether the coefficients should be processed in column-major-order\n/// (ColMajor), in row-major-order (RowMajor),\n///               or follows the \\em natural order of the nested expression (AutoOrder). The default is ColMajor.\n/// \\tparam NRowsType the type of the value handling the number of rows, typically Index.\n/// \\tparam NColsType the type of the value handling the number of columns, typically Index.\n///\n/// Dynamic size example: \\include MatrixBase_reshaped_int_int.cpp\n/// Output: \\verbinclude MatrixBase_reshaped_int_int.out\n///\n/// The number of rows \\a nRows and columns \\a nCols can also be specified at compile-time by passing Eigen::fix&lt;N&gt;,\n/// or Eigen::fix&lt;N&gt;(n) as arguments. In the later case, \\c n plays the role of a runtime fallback value in case \\c N\n/// equals Eigen::Dynamic. Here is an example with a fixed number of rows and columns: \\include\n/// MatrixBase_reshaped_fixed.cpp Output: \\verbinclude MatrixBase_reshaped_fixed.out\n///\n/// Finally, one of the sizes parameter can be automatically deduced from the other one by passing AutoSize as in the\n/// following example: \\include MatrixBase_reshaped_auto.cpp Output: \\verbinclude MatrixBase_reshaped_auto.out AutoSize\n/// does preserve compile-time sizes when possible, i.e., when the sizes of the input are known at compile time \\b and\n/// that the other size is passed at compile-time using Eigen::fix&lt;N&gt; as above.\n///\n/// \\sa class Reshaped, fix, fix&lt;N&gt;(int)\n///\ntemplate &lt;int Order = ColMajor, typename NRowsType, typename NColsType&gt;\nEIGEN_DEVICE_FUNC inline Reshaped&lt;Derived, ...&gt; reshaped(NRowsType nRows, NColsType nCols);\n\n/// This is the const version of reshaped(NRowsType,NColsType).\ntemplate &lt;int Order = ColMajor, typename NRowsType, typename NColsType&gt;\nEIGEN_DEVICE_FUNC inline const Reshaped&lt;const Derived, ...&gt; reshaped(NRowsType nRows, NColsType nCols) const;\n\n/// \\returns an expression of \\c *this with columns (or rows) stacked to a linear column vector\n///\n/// \\tparam Order specifies whether the coefficients should be processed in column-major-order (ColMajor), in\n/// row-major-order (RowMajor),\n///               or follows the \\em natural order of the nested expression (AutoOrder). The default is ColMajor.\n///\n/// This overloads is essentially a shortcut for `A.reshaped&lt;Order&gt;(AutoSize,fix&lt;1&gt;)`.\n///\n/// - If `Order==ColMajor` (the default), then it returns a column-vector from the stacked columns of \\c *this.\n/// - If `Order==RowMajor`, then it returns a column-vector from the stacked rows of \\c *this.\n/// - If `Order==AutoOrder`, then it returns a column-vector with elements stacked following the storage order of \\c\n/// *this.\n///   This mode is the recommended one when the particular ordering of the element is not relevant.\n///\n/// Example:\n/// \\include MatrixBase_reshaped_to_vector.cpp\n/// Output: \\verbinclude MatrixBase_reshaped_to_vector.out\n///\n/// If you want more control, you can still fall back to reshaped(NRowsType,NColsType).\n///\n/// \\sa reshaped(NRowsType,NColsType), class Reshaped\n///\ntemplate &lt;int Order = ColMajor&gt;\nEIGEN_DEVICE_FUNC inline Reshaped&lt;Derived, ...&gt; reshaped();\n\n/// This is the const version of reshaped().\ntemplate &lt;int Order = ColMajor&gt;\nEIGEN_DEVICE_FUNC inline const Reshaped&lt;const Derived, ...&gt; reshaped() const;\n\n#else\n\n// This file is automatically included twice to generate const and non-const versions\n\n#ifndef EIGEN_RESHAPED_METHOD_2ND_PASS\n#define EIGEN_RESHAPED_METHOD_CONST const\n#else\n#define EIGEN_RESHAPED_METHOD_CONST\n#endif\n\n#ifndef EIGEN_RESHAPED_METHOD_2ND_PASS\n\n// This part is included once\n\n#endif\n\ntemplate &lt;typename NRowsType, typename NColsType&gt;\nEIGEN_DEVICE_FUNC inline Reshaped&lt;\n    EIGEN_RESHAPED_METHOD_CONST Derived,\n    internal::get_compiletime_reshape_size&lt;NRowsType, NColsType, SizeAtCompileTime&gt;::value,\n    internal::get_compiletime_reshape_size&lt;NColsType, NRowsType, SizeAtCompileTime&gt;::value&gt;\nreshaped(NRowsType nRows, NColsType nCols) EIGEN_RESHAPED_METHOD_CONST {\n  return Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived,\n                  internal::get_compiletime_reshape_size&lt;NRowsType, NColsType, SizeAtCompileTime&gt;::value,\n                  internal::get_compiletime_reshape_size&lt;NColsType, NRowsType, SizeAtCompileTime&gt;::value&gt;(\n      derived(), internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),\n      internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));\n}\n\ntemplate &lt;int Order, typename NRowsType, typename NColsType&gt;\nEIGEN_DEVICE_FUNC inline Reshaped&lt;\n    EIGEN_RESHAPED_METHOD_CONST Derived,\n    internal::get_compiletime_reshape_size&lt;NRowsType, NColsType, SizeAtCompileTime&gt;::value,\n    internal::get_compiletime_reshape_size&lt;NColsType, NRowsType, SizeAtCompileTime&gt;::value,\n    internal::get_compiletime_reshape_order(Flags, Order)&gt;\nreshaped(NRowsType nRows, NColsType nCols) EIGEN_RESHAPED_METHOD_CONST {\n  return Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived,\n                  internal::get_compiletime_reshape_size&lt;NRowsType, NColsType, SizeAtCompileTime&gt;::value,\n                  internal::get_compiletime_reshape_size&lt;NColsType, NRowsType, SizeAtCompileTime&gt;::value,\n                  internal::get_compiletime_reshape_order(Flags, Order)&gt;(\n      derived(), internal::get_runtime_reshape_size(nRows, internal::get_runtime_value(nCols), size()),\n      internal::get_runtime_reshape_size(nCols, internal::get_runtime_value(nRows), size()));\n}\n\n// Views as linear vectors\n\nEIGEN_DEVICE_FUNC inline Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived, SizeAtCompileTime, 1&gt; reshaped()\n    EIGEN_RESHAPED_METHOD_CONST {\n  return Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived, SizeAtCompileTime, 1&gt;(derived(), size(), 1);\n}\n\ntemplate &lt;int Order&gt;\nEIGEN_DEVICE_FUNC inline Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived, SizeAtCompileTime, 1,\n                                  internal::get_compiletime_reshape_order(Flags, Order)&gt;\nreshaped() EIGEN_RESHAPED_METHOD_CONST {\n  EIGEN_STATIC_ASSERT(Order == RowMajor || Order == ColMajor || Order == AutoOrder, INVALID_TEMPLATE_PARAMETER);\n  return Reshaped&lt;EIGEN_RESHAPED_METHOD_CONST Derived, SizeAtCompileTime, 1,\n                  internal::get_compiletime_reshape_order(Flags, Order)&gt;(derived(), size(), 1);\n}\n\n#undef EIGEN_RESHAPED_METHOD_CONST\n\n#ifndef EIGEN_RESHAPED_METHOD_2ND_PASS\n#define EIGEN_RESHAPED_METHOD_2ND_PASS\n#include &quot;ReshapedMethods.inc&quot;\n#undef EIGEN_RESHAPED_METHOD_2ND_PASS\n#endif\n\n#endif  // EIGEN_PARSED_BY_DOXYGEN\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ARRAY_H\n#define EIGEN_ARRAY_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_&gt;\nstruct traits&lt;Array&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt;\n    : traits&lt;Matrix&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt; {\n  typedef ArrayXpr XprKind;\n  typedef ArrayBase&lt;Array&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt; XprBase;\n};\n}  // namespace internal\n\n/** \\class Array\n * \\ingroup Core_Module\n *\n * \\brief General-purpose arrays with easy API for coefficient-wise operations\n *\n * The %Array class is very similar to the Matrix class. It provides\n * general-purpose one- and two-dimensional arrays. The difference between the\n * %Array and the %Matrix class is primarily in the API: the API for the\n * %Array class provides easy access to coefficient-wise operations, while the\n * API for the %Matrix class provides easy access to linear-algebra\n * operations.\n *\n * See documentation of class Matrix for detailed information on the template parameters\n * storage layout.\n *\n * This class can be extended with the help of the plugin mechanism described on the page\n * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_ARRAY_PLUGIN.\n *\n * \\sa \\blank \\ref TutorialArrayClass, \\ref TopicClassHierarchy\n */\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_&gt;\nclass Array : public PlainObjectBase&lt;Array&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt; {\n public:\n  typedef PlainObjectBase&lt;Array&gt; Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(Array)\n\n  enum { Options = Options_ };\n  typedef typename Base::PlainObject PlainObject;\n\n protected:\n  template &lt;typename Derived, typename OtherDerived, bool IsVector&gt;\n  friend struct internal::conservative_resize_like_impl;\n\n  using Base::m_storage;\n\n public:\n  using Base::base;\n  using Base::coeff;\n  using Base::coeffRef;\n\n  /**\n   * The usage of\n   *   using Base::operator=;\n   * fails on MSVC. Since the code below is working with GCC and MSVC, we skipped\n   * the usage of &#x27;using&#x27;. This should be done only for operator=.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::operator=(other);\n  }\n\n  /** Set all the entries to \\a value.\n   * \\sa DenseBase::setConstant(), DenseBase::fill()\n   */\n  /* This overload is needed because the usage of\n   *   using Base::operator=;\n   * fails on MSVC. Since the code below is working with GCC and MSVC, we skipped\n   * the usage of &#x27;using&#x27;. This should be done only for operator=.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array&amp; operator=(const Scalar&amp; value) {\n    Base::setConstant(value);\n    return *this;\n  }\n\n  /** Copies the value of the expression \\a other into \\c *this with automatic resizing.\n   *\n   * *this might be resized to match the dimensions of \\a other. If *this was a null matrix (not already initialized),\n   * it will be initialized.\n   *\n   * Note that copying a row-vector into a vector (and conversely) is allowed.\n   * The resizing, if any, is then done in the appropriate way so that row-vectors\n   * remain row-vectors and vectors remain vectors.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::_set(other);\n  }\n\n  /**\n   * \\brief Assigns arrays to each other.\n   *\n   * \\note This is a special case of the templated operator=. Its purpose is\n   * to prevent a default operator= from hiding the templated operator=.\n   *\n   * \\callgraph\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array&amp; operator=(const Array&amp; other) { return Base::_set(other); }\n\n  /** Default constructor.\n   *\n   * For fixed-size matrices, does nothing.\n   *\n   * For dynamic-size matrices, creates an empty matrix of size 0. Does not allocate any array. Such a matrix\n   * is called a null matrix. This constructor is the unique way to create null matrices: resizing\n   * a matrix to 0 is not supported.\n   *\n   * \\sa resize(Index,Index)\n   */\n#ifdef EIGEN_INITIALIZE_COEFFS\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Array() : Base() { EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED }\n#else\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Array() = default;\n#endif\n  /** \\brief Move constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Array(Array&amp;&amp;) = default;\n  EIGEN_DEVICE_FUNC Array&amp; operator=(Array&amp;&amp; other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable&lt;Scalar&gt;::value) {\n    Base::operator=(std::move(other));\n    return *this;\n  }\n\n  /** \\brief Construct a row of column vector with fixed size from an arbitrary number of coefficients.\n   *\n   * \\only_for_vectors\n   *\n   * This constructor is for 1D array or vectors with more than 4 coefficients.\n   *\n   * \\warning To construct a column (resp. row) vector of fixed length, the number of values passed to this\n   * constructor must match the the fixed number of rows (resp. columns) of \\c *this.\n   *\n   *\n   * Example: \\include Array_variadic_ctor_cxx11.cpp\n   * Output: \\verbinclude Array_variadic_ctor_cxx11.out\n   *\n   * \\sa Array(const std::initializer_list&lt;std::initializer_list&lt;Scalar&gt;&gt;&amp;)\n   * \\sa Array(const Scalar&amp;), Array(const Scalar&amp;,const Scalar&amp;)\n   */\n  template &lt;typename... ArgTypes&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3,\n                                              const ArgTypes&amp;... args)\n      : Base(a0, a1, a2, a3, args...) {}\n\n  /** \\brief Constructs an array and initializes it from the coefficients given as initializer-lists grouped by row.\n   * \\cpp11\n   *\n   * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:\n   *\n   * Example: \\include Array_initializer_list_23_cxx11.cpp\n   * Output: \\verbinclude Array_initializer_list_23_cxx11.out\n   *\n   * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is\n   * triggered.\n   *\n   * In the case of a compile-time column 1D array, implicit transposition from a single row is allowed.\n   * Therefore &lt;code&gt; Array&lt;int,Dynamic,1&gt;{{1,2,3,4,5}}&lt;/code&gt; is legal and the more verbose syntax\n   * &lt;code&gt;Array&lt;int,Dynamic,1&gt;{{1},{2},{3},{4},{5}}&lt;/code&gt; can be avoided:\n   *\n   * Example: \\include Array_initializer_list_vector_cxx11.cpp\n   * Output: \\verbinclude Array_initializer_list_vector_cxx11.out\n   *\n   * In the case of fixed-sized arrays, the initializer list sizes must exactly match the array sizes,\n   * and implicit transposition is allowed for compile-time 1D arrays only.\n   *\n   * \\sa  Array(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3, const ArgTypes&amp;... args)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Array(\n      const std::initializer_list&lt;std::initializer_list&lt;Scalar&gt;&gt;&amp; list)\n      : Base(list) {}\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Array(const T&amp; x) {\n    Base::template _init1&lt;T&gt;(x);\n  }\n\n  template &lt;typename T0, typename T1&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array(const T0&amp; val0, const T1&amp; val1) {\n    this-&gt;template _init2&lt;T0, T1&gt;(val0, val1);\n  }\n\n#else\n  /** \\brief Constructs a fixed-sized array initialized with coefficients starting at \\a data */\n  EIGEN_DEVICE_FUNC explicit Array(const Scalar* data);\n  /** Constructs a vector or row-vector with given dimension. \\only_for_vectors\n   *\n   * Note that this is only useful for dynamic-size vectors. For fixed-size vectors,\n   * it is redundant to pass the dimension here, so it makes more sense to use the default\n   * constructor Array() instead.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Array(Index dim);\n  /** constructs an initialized 1x1 Array with the given coefficient\n   * \\sa const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3, const ArgTypes&amp;... args */\n  Array(const Scalar&amp; value);\n  /** constructs an uninitialized array with \\a rows rows and \\a cols columns.\n   *\n   * This is useful for dynamic-size arrays. For fixed-size arrays,\n   * it is redundant to pass these parameters, so one should use the default constructor\n   * Array() instead. */\n  Array(Index rows, Index cols);\n  /** constructs an initialized 2D vector with given coefficients\n   * \\sa Array(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3, const ArgTypes&amp;... args) */\n  Array(const Scalar&amp; val0, const Scalar&amp; val1);\n#endif  // end EIGEN_PARSED_BY_DOXYGEN\n\n  /** constructs an initialized 3D vector with given coefficients\n   * \\sa Array(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3, const ArgTypes&amp;... args)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array(const Scalar&amp; val0, const Scalar&amp; val1, const Scalar&amp; val2) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Array, 3)\n    m_storage.data()[0] = val0;\n    m_storage.data()[1] = val1;\n    m_storage.data()[2] = val2;\n  }\n  /** constructs an initialized 4D vector with given coefficients\n   * \\sa Array(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3, const ArgTypes&amp;... args)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array(const Scalar&amp; val0, const Scalar&amp; val1, const Scalar&amp; val2,\n                                              const Scalar&amp; val3) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Array, 4)\n    m_storage.data()[0] = val0;\n    m_storage.data()[1] = val1;\n    m_storage.data()[2] = val2;\n    m_storage.data()[3] = val3;\n  }\n\n  /** Copy constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Array(const Array&amp;) = default;\n\n private:\n  struct PrivateType {};\n\n public:\n  /** \\sa MatrixBase::operator=(const EigenBase&lt;OtherDerived&gt;&amp;) */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Array(\n      const EigenBase&lt;OtherDerived&gt;&amp; other,\n      std::enable_if_t&lt;internal::is_convertible&lt;typename OtherDerived::Scalar, Scalar&gt;::value, PrivateType&gt; =\n          PrivateType())\n      : Base(other.derived()) {}\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return this-&gt;innerSize(); }\n\n#ifdef EIGEN_ARRAY_PLUGIN\n#include EIGEN_ARRAY_PLUGIN\n#endif\n\n private:\n  template &lt;typename MatrixType, typename OtherDerived, bool SwapPointers&gt;\n  friend struct internal::matrix_swap_impl;\n};\n\n/** \\defgroup arraytypedefs Global array typedefs\n * \\ingroup Core_Module\n *\n * %Eigen defines several typedef shortcuts for most common 1D and 2D array types.\n *\n * The general patterns are the following:\n *\n * \\c ArrayRowsColsType where \\c Rows and \\c Cols can be \\c 2,\\c 3,\\c 4 for fixed size square matrices or \\c X for\n * dynamic size, and where \\c Type can be \\c i for integer, \\c f for float, \\c d for double, \\c cf for complex float, \\c\n * cd for complex double.\n *\n * For example, \\c Array33d is a fixed-size 3x3 array type of doubles, and \\c ArrayXXf is a dynamic-size matrix of\n * floats.\n *\n * There are also \\c ArraySizeType which are self-explanatory. For example, \\c Array4cf is\n * a fixed-size 1D array of 4 complex floats.\n *\n * With \\cpp11, template alias are also defined for common sizes.\n * They follow the same pattern as above except that the scalar type suffix is replaced by a\n * template parameter, i.e.:\n *   - `ArrayRowsCols&lt;Type&gt;` where `Rows` and `Cols` can be \\c 2,\\c 3,\\c 4, or \\c X for fixed or dynamic size.\n *   - `ArraySize&lt;Type&gt;` where `Size` can be \\c 2,\\c 3,\\c 4 or \\c X for fixed or dynamic size 1D arrays.\n *\n * \\sa class Array\n */\n\n#define EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)        \\\n  /** \\ingroup arraytypedefs */                                              \\\n  typedef Array&lt;Type, Size, Size&gt; Array##SizeSuffix##SizeSuffix##TypeSuffix; \\\n  /** \\ingroup arraytypedefs */                                              \\\n  typedef Array&lt;Type, Size, 1&gt; Array##SizeSuffix##TypeSuffix;\n\n#define EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Type, TypeSuffix, Size)  \\\n  /** \\ingroup arraytypedefs */                                  \\\n  typedef Array&lt;Type, Size, Dynamic&gt; Array##Size##X##TypeSuffix; \\\n  /** \\ingroup arraytypedefs */                                  \\\n  typedef Array&lt;Type, Dynamic, Size&gt; Array##X##Size##TypeSuffix;\n\n#define EIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(Type, TypeSuffix) \\\n  EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, 2, 2)           \\\n  EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, 3, 3)           \\\n  EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, 4, 4)           \\\n  EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, Dynamic, X)     \\\n  EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Type, TypeSuffix, 2)        \\\n  EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Type, TypeSuffix, 3)        \\\n  EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Type, TypeSuffix, 4)\n\nEIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(int, i)\nEIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(float, f)\nEIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(double, d)\nEIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(std::complex&lt;float&gt;, cf)\nEIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES(std::complex&lt;double&gt;, cd)\n\n#undef EIGEN_MAKE_ARRAY_TYPEDEFS_ALL_SIZES\n#undef EIGEN_MAKE_ARRAY_TYPEDEFS\n#undef EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS\n\n#define EIGEN_MAKE_ARRAY_TYPEDEFS(Size, SizeSuffix)              \\\n  /** \\ingroup arraytypedefs */                                  \\\n  /** \\brief \\cpp11 */                                           \\\n  template &lt;typename Type&gt;                                       \\\n  using Array##SizeSuffix##SizeSuffix = Array&lt;Type, Size, Size&gt;; \\\n  /** \\ingroup arraytypedefs */                                  \\\n  /** \\brief \\cpp11 */                                           \\\n  template &lt;typename Type&gt;                                       \\\n  using Array##SizeSuffix = Array&lt;Type, Size, 1&gt;;\n\n#define EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Size)        \\\n  /** \\ingroup arraytypedefs */                      \\\n  /** \\brief \\cpp11 */                               \\\n  template &lt;typename Type&gt;                           \\\n  using Array##Size##X = Array&lt;Type, Size, Dynamic&gt;; \\\n  /** \\ingroup arraytypedefs */                      \\\n  /** \\brief \\cpp11 */                               \\\n  template &lt;typename Type&gt;                           \\\n  using Array##X##Size = Array&lt;Type, Dynamic, Size&gt;;\n\nEIGEN_MAKE_ARRAY_TYPEDEFS(2, 2)\nEIGEN_MAKE_ARRAY_TYPEDEFS(3, 3)\nEIGEN_MAKE_ARRAY_TYPEDEFS(4, 4)\nEIGEN_MAKE_ARRAY_TYPEDEFS(Dynamic, X)\nEIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(2)\nEIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(3)\nEIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(4)\n\n#undef EIGEN_MAKE_ARRAY_TYPEDEFS\n#undef EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS\n\n#define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, SizeSuffix) \\\n  using Eigen::Matrix##SizeSuffix##TypeSuffix;                               \\\n  using Eigen::Vector##SizeSuffix##TypeSuffix;                               \\\n  using Eigen::RowVector##SizeSuffix##TypeSuffix;\n\n#define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(TypeSuffix)       \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, 2) \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, 3) \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, 4) \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, X)\n\n#define EIGEN_USING_ARRAY_TYPEDEFS        \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(i)  \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(f)  \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(d)  \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(cf) \\\n  EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(cd)\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ARRAY_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ARRAYBASE_H\n#define EIGEN_ARRAYBASE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\ntemplate &lt;typename ExpressionType&gt;\nclass MatrixWrapper;\n\n/** \\class ArrayBase\n * \\ingroup Core_Module\n *\n * \\brief Base class for all 1D and 2D array, and related expressions\n *\n * An array is similar to a dense vector or matrix. While matrices are mathematical\n * objects with well defined linear algebra operators, an array is just a collection\n * of scalar values arranged in a one or two dimensional fashion. As the main consequence,\n * all operations applied to an array are performed coefficient wise. Furthermore,\n * arrays support scalar math functions of the c++ standard library (e.g., std::sin(x)), and convenient\n * constructors allowing to easily write generic code working for both scalar values\n * and arrays.\n *\n * This class is the base that is inherited by all array expression types.\n *\n * \\tparam Derived is the derived type, e.g., an array or an expression type.\n *\n * This class can be extended with the help of the plugin mechanism described on the page\n * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_ARRAYBASE_PLUGIN.\n *\n * \\sa class MatrixBase, \\ref TopicClassHierarchy\n */\ntemplate &lt;typename Derived&gt;\nclass ArrayBase : public DenseBase&lt;Derived&gt; {\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** The base class for a given storage type. */\n  typedef ArrayBase StorageBaseType;\n\n  typedef ArrayBase Eigen_BaseClassForSpecializationOfGlobalMathFuncImpl;\n\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n  typedef typename internal::packet_traits&lt;Scalar&gt;::type PacketScalar;\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n\n  typedef DenseBase&lt;Derived&gt; Base;\n  using Base::ColsAtCompileTime;\n  using Base::Flags;\n  using Base::IsVectorAtCompileTime;\n  using Base::MaxColsAtCompileTime;\n  using Base::MaxRowsAtCompileTime;\n  using Base::MaxSizeAtCompileTime;\n  using Base::RowsAtCompileTime;\n  using Base::SizeAtCompileTime;\n\n  using Base::coeff;\n  using Base::coeffRef;\n  using Base::cols;\n  using Base::const_cast_derived;\n  using Base::derived;\n  using Base::lazyAssign;\n  using Base::rows;\n  using Base::size;\n  using Base::operator-;\n  using Base::operator=;\n  using Base::operator+=;\n  using Base::operator-=;\n  using Base::operator*=;\n  using Base::operator/=;\n\n  typedef typename Base::CoeffReturnType CoeffReturnType;\n\n  typedef typename Base::PlainObject PlainObject;\n\n  /** \\internal Represents a matrix with all coefficients equal to one another*/\n  typedef CwiseNullaryOp&lt;internal::scalar_constant_op&lt;Scalar&gt;, PlainObject&gt; ConstantReturnType;\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n#define EIGEN_CURRENT_STORAGE_BASE_CLASS Eigen::ArrayBase\n#define EIGEN_DOC_UNARY_ADDONS(X, Y)\n#include &quot;../plugins/MatrixCwiseUnaryOps.inc&quot;\n#include &quot;../plugins/ArrayCwiseUnaryOps.inc&quot;\n#include &quot;../plugins/CommonCwiseBinaryOps.inc&quot;\n#include &quot;../plugins/MatrixCwiseBinaryOps.inc&quot;\n#include &quot;../plugins/ArrayCwiseBinaryOps.inc&quot;\n#ifdef EIGEN_ARRAYBASE_PLUGIN\n#include EIGEN_ARRAYBASE_PLUGIN\n#endif\n#undef EIGEN_CURRENT_STORAGE_BASE_CLASS\n#undef EIGEN_DOC_UNARY_ADDONS\n\n  /** Special case of the template operator=, in order to prevent the compiler\n   * from generating a default operator= (issue hit with g++ 4.1)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const ArrayBase&amp; other) {\n    internal::call_assignment(derived(), other.derived());\n    return derived();\n  }\n\n  /** Set all the entries to \\a value.\n   * \\sa DenseBase::setConstant(), DenseBase::fill() */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const Scalar&amp; value) {\n    Base::setConstant(value);\n    return derived();\n  }\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator+=(const Scalar&amp; other) {\n    internal::call_assignment(this-&gt;derived(), PlainObject::Constant(rows(), cols(), other),\n                              internal::add_assign_op&lt;Scalar, Scalar&gt;());\n    return derived();\n  }\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator-=(const Scalar&amp; other) {\n    internal::call_assignment(this-&gt;derived(), PlainObject::Constant(rows(), cols(), other),\n                              internal::sub_assign_op&lt;Scalar, Scalar&gt;());\n    return derived();\n  }\n\n  /** replaces \\c *this by \\c *this + \\a other.\n   *\n   * \\returns a reference to \\c *this\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator+=(const ArrayBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment(derived(), other.derived(), internal::add_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return derived();\n  }\n\n  /** replaces \\c *this by \\c *this - \\a other.\n   *\n   * \\returns a reference to \\c *this\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator-=(const ArrayBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment(derived(), other.derived(), internal::sub_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return derived();\n  }\n\n  /** replaces \\c *this by \\c *this * \\a other coefficient wise.\n   *\n   * \\returns a reference to \\c *this\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator*=(const ArrayBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment(derived(), other.derived(), internal::mul_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return derived();\n  }\n\n  /** replaces \\c *this by \\c *this / \\a other coefficient wise.\n   *\n   * \\returns a reference to \\c *this\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator/=(const ArrayBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment(derived(), other.derived(), internal::div_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return derived();\n  }\n\n public:\n  EIGEN_DEVICE_FUNC ArrayBase&lt;Derived&gt;&amp; array() { return *this; }\n  EIGEN_DEVICE_FUNC const ArrayBase&lt;Derived&gt;&amp; array() const { return *this; }\n\n  /** \\returns an \\link Eigen::MatrixBase Matrix \\endlink expression of this array\n   * \\sa MatrixBase::array() */\n  EIGEN_DEVICE_FUNC MatrixWrapper&lt;Derived&gt; matrix() { return MatrixWrapper&lt;Derived&gt;(derived()); }\n  EIGEN_DEVICE_FUNC const MatrixWrapper&lt;const Derived&gt; matrix() const {\n    return MatrixWrapper&lt;const Derived&gt;(derived());\n  }\n\n  //     template&lt;typename Dest&gt;\n  //     inline void evalTo(Dest&amp; dst) const { dst = matrix(); }\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(ArrayBase)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(ArrayBase)\n\n private:\n  explicit ArrayBase(Index);\n  ArrayBase(Index, Index);\n  template &lt;typename OtherDerived&gt;\n  explicit ArrayBase(const ArrayBase&lt;OtherDerived&gt;&amp;);\n\n protected:\n  // mixing arrays and matrices is not legal\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator+=(const MatrixBase&lt;OtherDerived&gt;&amp;) {\n    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,\n                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);\n    return *this;\n  }\n  // mixing arrays and matrices is not legal\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator-=(const MatrixBase&lt;OtherDerived&gt;&amp;) {\n    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,\n                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);\n    return *this;\n  }\n};\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ARRAYBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2015 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_MACROS_H\n#define EIGEN_MACROS_H\n// IWYU pragma: private\n#include &quot;../InternalHeaderCheck.h&quot;\n\n//------------------------------------------------------------------------------------------\n// Eigen version and basic defaults\n//------------------------------------------------------------------------------------------\n\n#define EIGEN_WORLD_VERSION 3\n#define EIGEN_MAJOR_VERSION 4\n#define EIGEN_MINOR_VERSION 90\n\n#define EIGEN_VERSION_AT_LEAST(x, y, z) \\\n  (EIGEN_WORLD_VERSION &gt; x ||           \\\n   (EIGEN_WORLD_VERSION &gt;= x &amp;&amp; (EIGEN_MAJOR_VERSION &gt; y || (EIGEN_MAJOR_VERSION &gt;= y &amp;&amp; EIGEN_MINOR_VERSION &gt;= z))))\n\n#ifdef EIGEN_DEFAULT_TO_ROW_MAJOR\n#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::RowMajor\n#else\n#define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::ColMajor\n#endif\n\n#ifndef EIGEN_DEFAULT_DENSE_INDEX_TYPE\n#define EIGEN_DEFAULT_DENSE_INDEX_TYPE std::ptrdiff_t\n#endif\n\n// Upperbound on the C++ version to use.\n// Expected values are 03, 11, 14, 17, etc.\n// By default, let&#x27;s use an arbitrarily large C++ version.\n#ifndef EIGEN_MAX_CPP_VER\n#define EIGEN_MAX_CPP_VER 99\n#endif\n\n/** Allows to disable some optimizations which might affect the accuracy of the result.\n * Such optimization are enabled by default, and set EIGEN_FAST_MATH to 0 to disable them.\n * They currently include:\n *   - single precision ArrayBase::sin() and ArrayBase::cos() for SSE and AVX vectorization.\n */\n#ifndef EIGEN_FAST_MATH\n#define EIGEN_FAST_MATH 1\n#endif\n\n#ifndef EIGEN_STACK_ALLOCATION_LIMIT\n// 131072 == 128 KB\n#define EIGEN_STACK_ALLOCATION_LIMIT 131072\n#endif\n\n//------------------------------------------------------------------------------------------\n// Compiler identification, EIGEN_COMP_*\n//------------------------------------------------------------------------------------------\n\n/// \\internal EIGEN_COMP_GNUC set to version (e.g., 951 for GCC 9.5.1) for all compilers compatible with GCC\n#ifdef __GNUC__\n#define EIGEN_COMP_GNUC (__GNUC__ * 100 + __GNUC_MINOR__ * 10 + __GNUC_PATCHLEVEL__)\n#else\n#define EIGEN_COMP_GNUC 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANG set to version (e.g., 372 for clang 3.7.2) if the compiler is clang\n#if defined(__clang__)\n#define EIGEN_COMP_CLANG (__clang_major__ * 100 + __clang_minor__ * 10 + __clang_patchlevel__)\n#else\n#define EIGEN_COMP_CLANG 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANGAPPLE set to the version number (e.g. 9000000 for AppleClang 9.0) if the compiler is\n/// AppleClang\n#if defined(__clang__) &amp;&amp; defined(__apple_build_version__)\n#define EIGEN_COMP_CLANGAPPLE __apple_build_version__\n#else\n#define EIGEN_COMP_CLANGAPPLE 0\n#endif\n\n/// \\internal EIGEN_COMP_CASTXML set to 1 if being preprocessed by CastXML\n#if defined(__castxml__)\n#define EIGEN_COMP_CASTXML 1\n#else\n#define EIGEN_COMP_CASTXML 0\n#endif\n\n/// \\internal EIGEN_COMP_LLVM set to 1 if the compiler backend is llvm\n#if defined(__llvm__)\n#define EIGEN_COMP_LLVM 1\n#else\n#define EIGEN_COMP_LLVM 0\n#endif\n\n/// \\internal EIGEN_COMP_ICC set to __INTEL_COMPILER if the compiler is Intel icc compiler, 0 otherwise\n#if defined(__INTEL_COMPILER)\n#define EIGEN_COMP_ICC __INTEL_COMPILER\n#else\n#define EIGEN_COMP_ICC 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANGICC set to __INTEL_CLANG_COMPILER if the compiler is Intel icx compiler, 0 otherwise\n#if defined(__INTEL_CLANG_COMPILER)\n#define EIGEN_COMP_CLANGICC __INTEL_CLANG_COMPILER\n#else\n#define EIGEN_COMP_CLANGICC 0\n#endif\n\n/// \\internal EIGEN_COMP_MINGW set to 1 if the compiler is mingw\n#if defined(__MINGW32__)\n#define EIGEN_COMP_MINGW 1\n#else\n#define EIGEN_COMP_MINGW 0\n#endif\n\n/// \\internal EIGEN_COMP_SUNCC set to 1 if the compiler is Solaris Studio\n#if defined(__SUNPRO_CC)\n#define EIGEN_COMP_SUNCC 1\n#else\n#define EIGEN_COMP_SUNCC 0\n#endif\n\n/// \\internal EIGEN_COMP_MSVC set to _MSC_VER if the compiler is Microsoft Visual C++, 0 otherwise.\n#if defined(_MSC_VER)\n#define EIGEN_COMP_MSVC _MSC_VER\n#else\n#define EIGEN_COMP_MSVC 0\n#endif\n\n#if defined(__NVCC__)\n#if defined(__CUDACC_VER_MAJOR__) &amp;&amp; (__CUDACC_VER_MAJOR__ &gt;= 9)\n#define EIGEN_COMP_NVCC ((__CUDACC_VER_MAJOR__ * 10000) + (__CUDACC_VER_MINOR__ * 100))\n#elif defined(__CUDACC_VER__)\n#define EIGEN_COMP_NVCC __CUDACC_VER__\n#else\n#error &quot;NVCC did not define compiler version.&quot;\n#endif\n#else\n#define EIGEN_COMP_NVCC 0\n#endif\n\n// For the record, here is a table summarizing the possible values for EIGEN_COMP_MSVC:\n//  name        ver   MSC_VER\n//  2015        14      1900\n//  &quot;15&quot;        15      1900\n//  2017-14.1   15.0    1910\n//  2017-14.11  15.3    1911\n//  2017-14.12  15.5    1912\n//  2017-14.13  15.6    1913\n//  2017-14.14  15.7    1914\n//  2017        15.8    1915\n//  2017        15.9    1916\n//  2019 RTW    16.0    1920\n\n/// \\internal EIGEN_COMP_MSVC_LANG set to _MSVC_LANG if the compiler is Microsoft Visual C++, 0 otherwise.\n#if defined(_MSVC_LANG)\n#define EIGEN_COMP_MSVC_LANG _MSVC_LANG\n#else\n#define EIGEN_COMP_MSVC_LANG 0\n#endif\n\n// For the record, here is a table summarizing the possible values for EIGEN_COMP_MSVC_LANG:\n// MSVC option                          Standard  MSVC_LANG\n// /std:c++14 (default as of VS 2019)   C++14     201402L\n// /std:c++17                           C++17     201703L\n// /std:c++latest                       &gt;C++17    &gt;201703L\n\n/// \\internal EIGEN_COMP_MSVC_STRICT set to 1 if the compiler is really Microsoft Visual C++ and not ,e.g., ICC or\n/// clang-cl\n#if EIGEN_COMP_MSVC &amp;&amp; !(EIGEN_COMP_ICC || EIGEN_COMP_LLVM || EIGEN_COMP_CLANG)\n#define EIGEN_COMP_MSVC_STRICT _MSC_VER\n#else\n#define EIGEN_COMP_MSVC_STRICT 0\n#endif\n\n/// \\internal EIGEN_COMP_IBM set to xlc version if the compiler is IBM XL C++\n// XLC   version\n// 3.1   0x0301\n// 4.5   0x0405\n// 5.0   0x0500\n// 12.1  0x0C01\n#if defined(__IBMCPP__) || defined(__xlc__) || defined(__ibmxl__)\n#define EIGEN_COMP_IBM __xlC__\n#else\n#define EIGEN_COMP_IBM 0\n#endif\n\n/// \\internal EIGEN_COMP_PGI set to PGI version if the compiler is Portland Group Compiler\n#if defined(__PGI)\n#define EIGEN_COMP_PGI (__PGIC__ * 100 + __PGIC_MINOR__)\n#else\n#define EIGEN_COMP_PGI 0\n#endif\n\n/// \\internal EIGEN_COMP_NVHPC set to NVHPC version if the compiler is nvc++\n#if defined(__NVCOMPILER)\n#define EIGEN_COMP_NVHPC (__NVCOMPILER_MAJOR__ * 100 + __NVCOMPILER_MINOR__)\n#else\n#define EIGEN_COMP_NVHPC 0\n#endif\n\n/// \\internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler\n#if defined(__CC_ARM) || defined(__ARMCC_VERSION)\n#define EIGEN_COMP_ARM 1\n#else\n#define EIGEN_COMP_ARM 0\n#endif\n\n/// \\internal EIGEN_COMP_EMSCRIPTEN set to 1 if the compiler is Emscripten Compiler\n#if defined(__EMSCRIPTEN__)\n#define EIGEN_COMP_EMSCRIPTEN 1\n#else\n#define EIGEN_COMP_EMSCRIPTEN 0\n#endif\n\n/// \\internal EIGEN_COMP_FCC set to FCC version if the compiler is Fujitsu Compiler (traditional mode)\n/// \\note The Fujitsu C/C++ compiler uses the traditional mode based\n/// on EDG g++ 6.1 by default or if invoked with the -Nnoclang flag\n#if defined(__FUJITSU)\n#define EIGEN_COMP_FCC (__FCC_major__ * 100 + __FCC_minor__ * 10 + __FCC_patchlevel__)\n#else\n#define EIGEN_COMP_FCC 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANGFCC set to FCC version if the compiler is Fujitsu Compiler (Clang mode)\n/// \\note The Fujitsu C/C++ compiler uses the non-traditional mode\n/// based on Clang 7.1.0 if invoked with the -Nclang flag\n#if defined(__CLANG_FUJITSU)\n#define EIGEN_COMP_CLANGFCC (__FCC_major__ * 100 + __FCC_minor__ * 10 + __FCC_patchlevel__)\n#else\n#define EIGEN_COMP_CLANGFCC 0\n#endif\n\n/// \\internal EIGEN_COMP_CPE set to CPE version if the compiler is HPE Cray Compiler (GCC based)\n/// \\note This is the SVE-enabled C/C++ compiler from the HPE Cray\n/// Programming Environment (CPE) based on Cray GCC 8.1\n#if defined(_CRAYC) &amp;&amp; !defined(__clang__)\n#define EIGEN_COMP_CPE (_RELEASE_MAJOR * 100 + _RELEASE_MINOR * 10 + _RELEASE_PATCHLEVEL)\n#else\n#define EIGEN_COMP_CPE 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANGCPE set to CPE version if the compiler is HPE Cray Compiler (Clang based)\n/// \\note This is the C/C++ compiler from the HPE Cray Programming\n/// Environment (CPE) based on Cray Clang 11.0 without SVE-support\n#if defined(_CRAYC) &amp;&amp; defined(__clang__)\n#define EIGEN_COMP_CLANGCPE (_RELEASE_MAJOR * 100 + _RELEASE_MINOR * 10 + _RELEASE_PATCHLEVEL)\n#else\n#define EIGEN_COMP_CLANGCPE 0\n#endif\n\n/// \\internal EIGEN_COMP_LCC set to 1 if the compiler is MCST-LCC (MCST eLbrus Compiler Collection)\n#if defined(__LCC__) &amp;&amp; defined(__MCST__)\n#define EIGEN_COMP_LCC (__LCC__ * 100 + __LCC_MINOR__)\n#else\n#define EIGEN_COMP_LCC 0\n#endif\n\n/// \\internal EIGEN_COMP_GNUC_STRICT set to 1 if the compiler is really GCC and not a compatible compiler (e.g., ICC,\n/// clang, mingw, etc.)\n#if EIGEN_COMP_GNUC &amp;&amp;                                                                                      \\\n    !(EIGEN_COMP_CLANG || EIGEN_COMP_ICC || EIGEN_COMP_CLANGICC || EIGEN_COMP_MINGW || EIGEN_COMP_PGI ||    \\\n      EIGEN_COMP_IBM || EIGEN_COMP_ARM || EIGEN_COMP_EMSCRIPTEN || EIGEN_COMP_FCC || EIGEN_COMP_CLANGFCC || \\\n      EIGEN_COMP_CPE || EIGEN_COMP_CLANGCPE || EIGEN_COMP_LCC)\n#define EIGEN_COMP_GNUC_STRICT 1\n#else\n#define EIGEN_COMP_GNUC_STRICT 0\n#endif\n\n// GCC, and compilers that pretend to be it, have different version schemes, so this only makes sense to use with the\n// real GCC.\n#if EIGEN_COMP_GNUC_STRICT\n#define EIGEN_GNUC_STRICT_AT_LEAST(x, y, z)                   \\\n  ((__GNUC__ &gt; x) || (__GNUC__ == x &amp;&amp; __GNUC_MINOR__ &gt; y) || \\\n   (__GNUC__ == x &amp;&amp; __GNUC_MINOR__ == y &amp;&amp; __GNUC_PATCHLEVEL__ &gt;= z))\n#define EIGEN_GNUC_STRICT_LESS_THAN(x, y, z)                  \\\n  ((__GNUC__ &lt; x) || (__GNUC__ == x &amp;&amp; __GNUC_MINOR__ &lt; y) || \\\n   (__GNUC__ == x &amp;&amp; __GNUC_MINOR__ == y &amp;&amp; __GNUC_PATCHLEVEL__ &lt; z))\n#else\n#define EIGEN_GNUC_STRICT_AT_LEAST(x, y, z) 0\n#define EIGEN_GNUC_STRICT_LESS_THAN(x, y, z) 0\n#endif\n\n/// \\internal EIGEN_COMP_CLANG_STRICT set to 1 if the compiler is really Clang and not a compatible compiler (e.g.,\n/// AppleClang, etc.)\n#if EIGEN_COMP_CLANG &amp;&amp; !(EIGEN_COMP_CLANGAPPLE || EIGEN_COMP_CLANGICC || EIGEN_COMP_CLANGFCC || EIGEN_COMP_CLANGCPE)\n#define EIGEN_COMP_CLANG_STRICT 1\n#else\n#define EIGEN_COMP_CLANG_STRICT 0\n#endif\n\n// Clang, and compilers forked from it, have different version schemes, so this only makes sense to use with the real\n// Clang.\n#if EIGEN_COMP_CLANG_STRICT\n#define EIGEN_CLANG_STRICT_AT_LEAST(x, y, z)                                 \\\n  ((__clang_major__ &gt; x) || (__clang_major__ == x &amp;&amp; __clang_minor__ &gt; y) || \\\n   (__clang_major__ == x &amp;&amp; __clang_minor__ == y &amp;&amp; __clang_patchlevel__ &gt;= z))\n#define EIGEN_CLANG_STRICT_LESS_THAN(x, y, z)                                \\\n  ((__clang_major__ &lt; x) || (__clang_major__ == x &amp;&amp; __clang_minor__ &lt; y) || \\\n   (__clang_major__ == x &amp;&amp; __clang_minor__ == y &amp;&amp; __clang_patchlevel__ &lt; z))\n#else\n#define EIGEN_CLANG_STRICT_AT_LEAST(x, y, z) 0\n#define EIGEN_CLANG_STRICT_LESS_THAN(x, y, z) 0\n#endif\n\n//------------------------------------------------------------------------------------------\n// Architecture identification, EIGEN_ARCH_*\n//------------------------------------------------------------------------------------------\n\n#if defined(__x86_64__) || (defined(_M_X64) &amp;&amp; !defined(_M_ARM64EC)) || defined(__amd64)\n#define EIGEN_ARCH_x86_64 1\n#else\n#define EIGEN_ARCH_x86_64 0\n#endif\n\n#if defined(__i386__) || defined(_M_IX86) || defined(_X86_) || defined(__i386)\n#define EIGEN_ARCH_i386 1\n#else\n#define EIGEN_ARCH_i386 0\n#endif\n\n#if EIGEN_ARCH_x86_64 || EIGEN_ARCH_i386\n#define EIGEN_ARCH_i386_OR_x86_64 1\n#else\n#define EIGEN_ARCH_i386_OR_x86_64 0\n#endif\n\n/// \\internal EIGEN_ARCH_ARM set to 1 if the architecture is ARM\n#if defined(__arm__)\n#define EIGEN_ARCH_ARM 1\n#else\n#define EIGEN_ARCH_ARM 0\n#endif\n\n/// \\internal EIGEN_ARCH_ARM64 set to 1 if the architecture is ARM64\n#if defined(__aarch64__) || defined(_M_ARM64) || defined(_M_ARM64EC)\n#define EIGEN_ARCH_ARM64 1\n#else\n#define EIGEN_ARCH_ARM64 0\n#endif\n\n/// \\internal EIGEN_ARCH_ARM_OR_ARM64 set to 1 if the architecture is ARM or ARM64\n#if EIGEN_ARCH_ARM || EIGEN_ARCH_ARM64\n#define EIGEN_ARCH_ARM_OR_ARM64 1\n#else\n#define EIGEN_ARCH_ARM_OR_ARM64 0\n#endif\n\n/// \\internal EIGEN_ARCH_ARMV8 set to 1 if the architecture is armv8 or greater.\n#if EIGEN_ARCH_ARM_OR_ARM64 &amp;&amp; defined(__ARM_ARCH) &amp;&amp; __ARM_ARCH &gt;= 8\n#define EIGEN_ARCH_ARMV8 1\n#else\n#define EIGEN_ARCH_ARMV8 0\n#endif\n\n/// \\internal EIGEN_HAS_ARM64_FP16 set to 1 if the architecture provides an IEEE\n/// compliant Arm fp16 type\n#if EIGEN_ARCH_ARM_OR_ARM64\n#ifndef EIGEN_HAS_ARM64_FP16\n#if defined(__ARM_FP16_FORMAT_IEEE)\n#define EIGEN_HAS_ARM64_FP16 1\n#else\n#define EIGEN_HAS_ARM64_FP16 0\n#endif\n#endif\n#endif\n\n/// \\internal EIGEN_ARCH_MIPS set to 1 if the architecture is MIPS\n#if defined(__mips__) || defined(__mips)\n#define EIGEN_ARCH_MIPS 1\n#else\n#define EIGEN_ARCH_MIPS 0\n#endif\n\n/// \\internal EIGEN_ARCH_LOONGARCH64 set to 1 if the architecture is LOONGARCH64\n#if defined(__loongarch64)\n#define EIGEN_ARCH_LOONGARCH64 1\n#else\n#define EIGEN_ARCH_LOONGARCH64 0\n#endif\n\n/// \\internal EIGEN_ARCH_SPARC set to 1 if the architecture is SPARC\n#if defined(__sparc__) || defined(__sparc)\n#define EIGEN_ARCH_SPARC 1\n#else\n#define EIGEN_ARCH_SPARC 0\n#endif\n\n/// \\internal EIGEN_ARCH_IA64 set to 1 if the architecture is Intel Itanium\n#if defined(__ia64__)\n#define EIGEN_ARCH_IA64 1\n#else\n#define EIGEN_ARCH_IA64 0\n#endif\n\n/// \\internal EIGEN_ARCH_PPC set to 1 if the architecture is PowerPC\n#if defined(__powerpc__) || defined(__ppc__) || defined(_M_PPC) || defined(__POWERPC__)\n#define EIGEN_ARCH_PPC 1\n#else\n#define EIGEN_ARCH_PPC 0\n#endif\n\n//------------------------------------------------------------------------------------------\n// Operating system identification, EIGEN_OS_*\n//------------------------------------------------------------------------------------------\n\n/// \\internal EIGEN_OS_UNIX set to 1 if the OS is a unix variant\n#if defined(__unix__) || defined(__unix)\n#define EIGEN_OS_UNIX 1\n#else\n#define EIGEN_OS_UNIX 0\n#endif\n\n/// \\internal EIGEN_OS_LINUX set to 1 if the OS is based on Linux kernel\n#if defined(__linux__)\n#define EIGEN_OS_LINUX 1\n#else\n#define EIGEN_OS_LINUX 0\n#endif\n\n/// \\internal EIGEN_OS_ANDROID set to 1 if the OS is Android\n// note: ANDROID is defined when using ndk_build, __ANDROID__ is defined when using a standalone toolchain.\n#if defined(__ANDROID__) || defined(ANDROID)\n#define EIGEN_OS_ANDROID 1\n\n// Since NDK r16, `__NDK_MAJOR__` and `__NDK_MINOR__` are defined in\n// &lt;android/ndk-version.h&gt;. For NDK &lt; r16, users should define these macros,\n// e.g. `-D__NDK_MAJOR__=11 -D__NKD_MINOR__=0` for NDK r11.\n#if defined __has_include\n#if __has_include(&lt;android/ndk-version.h&gt;)\n#include &lt;android/ndk-version.h&gt;\n#endif\n#endif\n\n#else\n#define EIGEN_OS_ANDROID 0\n#endif\n\n/// \\internal EIGEN_OS_GNULINUX set to 1 if the OS is GNU Linux and not Linux-based OS (e.g., not android)\n#if defined(__gnu_linux__) &amp;&amp; !(EIGEN_OS_ANDROID)\n#define EIGEN_OS_GNULINUX 1\n#else\n#define EIGEN_OS_GNULINUX 0\n#endif\n\n/// \\internal EIGEN_OS_BSD set to 1 if the OS is a BSD variant\n#if defined(__FreeBSD__) || defined(__NetBSD__) || defined(__OpenBSD__) || defined(__bsdi__) || defined(__DragonFly__)\n#define EIGEN_OS_BSD 1\n#else\n#define EIGEN_OS_BSD 0\n#endif\n\n/// \\internal EIGEN_OS_MAC set to 1 if the OS is MacOS\n#if defined(__APPLE__)\n#define EIGEN_OS_MAC 1\n#else\n#define EIGEN_OS_MAC 0\n#endif\n\n/// \\internal EIGEN_OS_QNX set to 1 if the OS is QNX\n#if defined(__QNX__)\n#define EIGEN_OS_QNX 1\n#else\n#define EIGEN_OS_QNX 0\n#endif\n\n/// \\internal EIGEN_OS_WIN set to 1 if the OS is Windows based\n#if defined(_WIN32)\n#define EIGEN_OS_WIN 1\n#else\n#define EIGEN_OS_WIN 0\n#endif\n\n/// \\internal EIGEN_OS_WIN64 set to 1 if the OS is Windows 64bits\n#if defined(_WIN64)\n#define EIGEN_OS_WIN64 1\n#else\n#define EIGEN_OS_WIN64 0\n#endif\n\n/// \\internal EIGEN_OS_WINCE set to 1 if the OS is Windows CE\n#if defined(_WIN32_WCE)\n#define EIGEN_OS_WINCE 1\n#else\n#define EIGEN_OS_WINCE 0\n#endif\n\n/// \\internal EIGEN_OS_CYGWIN set to 1 if the OS is Windows/Cygwin\n#if defined(__CYGWIN__)\n#define EIGEN_OS_CYGWIN 1\n#else\n#define EIGEN_OS_CYGWIN 0\n#endif\n\n/// \\internal EIGEN_OS_WIN_STRICT set to 1 if the OS is really Windows and not some variants\n#if EIGEN_OS_WIN &amp;&amp; !(EIGEN_OS_WINCE || EIGEN_OS_CYGWIN)\n#define EIGEN_OS_WIN_STRICT 1\n#else\n#define EIGEN_OS_WIN_STRICT 0\n#endif\n\n/// \\internal EIGEN_OS_SUN set to __SUNPRO_C if the OS is SUN\n// compiler  solaris   __SUNPRO_C\n// version   studio\n// 5.7       10        0x570\n// 5.8       11        0x580\n// 5.9       12        0x590\n// 5.10\t     12.1      0x5100\n// 5.11\t     12.2      0x5110\n// 5.12\t     12.3      0x5120\n#if (defined(sun) || defined(__sun)) &amp;&amp; !(defined(__SVR4) || defined(__svr4__))\n#define EIGEN_OS_SUN __SUNPRO_C\n#else\n#define EIGEN_OS_SUN 0\n#endif\n\n/// \\internal EIGEN_OS_SOLARIS set to 1 if the OS is Solaris\n#if (defined(sun) || defined(__sun)) &amp;&amp; (defined(__SVR4) || defined(__svr4__))\n#define EIGEN_OS_SOLARIS 1\n#else\n#define EIGEN_OS_SOLARIS 0\n#endif\n\n//------------------------------------------------------------------------------------------\n// Detect GPU compilers and architectures\n//------------------------------------------------------------------------------------------\n\n// NVCC is not supported as the target platform for HIPCC\n// Note that this also makes EIGEN_CUDACC and EIGEN_HIPCC mutually exclusive\n#if defined(__NVCC__) &amp;&amp; defined(__HIPCC__)\n#error &quot;NVCC as the target platform for HIPCC is currently not supported.&quot;\n#endif\n\n#if defined(__CUDACC__) &amp;&amp; !defined(EIGEN_NO_CUDA) &amp;&amp; !defined(__SYCL_DEVICE_ONLY__)\n// Means the compiler is either nvcc or clang with CUDA enabled\n#define EIGEN_CUDACC __CUDACC__\n#endif\n\n#if defined(__CUDA_ARCH__) &amp;&amp; !defined(EIGEN_NO_CUDA) &amp;&amp; !defined(__SYCL_DEVICE_ONLY__)\n// Means we are generating code for the device\n#define EIGEN_CUDA_ARCH __CUDA_ARCH__\n#endif\n\n#if defined(EIGEN_CUDACC)\n#include &lt;cuda.h&gt;\n#define EIGEN_CUDA_SDK_VER (CUDA_VERSION * 10)\n#else\n#define EIGEN_CUDA_SDK_VER 0\n#endif\n\n#if defined(__HIPCC__) &amp;&amp; !defined(EIGEN_NO_HIP) &amp;&amp; !defined(__SYCL_DEVICE_ONLY__)\n// Means the compiler is HIPCC (analogous to EIGEN_CUDACC, but for HIP)\n#define EIGEN_HIPCC __HIPCC__\n\n// We need to include hip_runtime.h here because it pulls in\n// ++ hip_common.h which contains the define for  __HIP_DEVICE_COMPILE__\n// ++ host_defines.h which contains the defines for the __host__ and __device__ macros\n#include &lt;hip/hip_runtime.h&gt;\n\n#if defined(__HIP_DEVICE_COMPILE__) &amp;&amp; !defined(__SYCL_DEVICE_ONLY__)\n// analogous to EIGEN_CUDA_ARCH, but for HIP\n#define EIGEN_HIP_DEVICE_COMPILE __HIP_DEVICE_COMPILE__\n#endif\n\n// For HIP (ROCm 3.5 and higher), we need to explicitly set the launch_bounds attribute\n// value to 1024. The compiler assigns a default value of 256 when the attribute is not\n// specified. This results in failures on the HIP platform, for cases when a GPU kernel\n// without an explicit launch_bounds attribute is called with a threads_per_block value\n// greater than 256.\n//\n// This is a regression in functioanlity and is expected to be fixed within the next\n// couple of ROCm releases (compiler will go back to using 1024 value as the default)\n//\n// In the meantime, we will use a &quot;only enabled for HIP&quot; macro to set the launch_bounds\n// attribute.\n\n#define EIGEN_HIP_LAUNCH_BOUNDS_1024 __launch_bounds__(1024)\n\n#endif\n\n#if !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)\n#define EIGEN_HIP_LAUNCH_BOUNDS_1024\n#endif  // !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)\n\n// Unify CUDA/HIPCC\n\n#if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)\n//\n// If either EIGEN_CUDACC or EIGEN_HIPCC is defined, then define EIGEN_GPUCC\n//\n#define EIGEN_GPUCC\n//\n// EIGEN_HIPCC implies the HIP compiler and is used to tweak Eigen code for use in HIP kernels\n// EIGEN_CUDACC implies the CUDA compiler and is used to tweak Eigen code for use in CUDA kernels\n//\n// In most cases the same tweaks are required to the Eigen code to enable in both the HIP and CUDA kernels.\n// For those cases, the corresponding code should be guarded with\n//      #if defined(EIGEN_GPUCC)\n// instead of\n//      #if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)\n//\n// For cases where the tweak is specific to HIP, the code should be guarded with\n//      #if defined(EIGEN_HIPCC)\n//\n// For cases where the tweak is specific to CUDA, the code should be guarded with\n//      #if defined(EIGEN_CUDACC)\n//\n#endif\n\n#if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIP_DEVICE_COMPILE)\n//\n// If either EIGEN_CUDA_ARCH or EIGEN_HIP_DEVICE_COMPILE is defined, then define EIGEN_GPU_COMPILE_PHASE\n//\n#define EIGEN_GPU_COMPILE_PHASE\n//\n// GPU compilers (HIPCC, NVCC) typically do two passes over the source code,\n//   + one to compile the source for the &quot;host&quot; (ie CPU)\n//   + another to compile the source for the &quot;device&quot; (ie. GPU)\n//\n// Code that needs to enabled only during the either the &quot;host&quot; or &quot;device&quot; compilation phase\n// needs to be guarded with a macro that indicates the current compilation phase\n//\n// EIGEN_HIP_DEVICE_COMPILE implies the device compilation phase in HIP\n// EIGEN_CUDA_ARCH implies the device compilation phase in CUDA\n//\n// In most cases, the &quot;host&quot; / &quot;device&quot; specific code is the same for both HIP and CUDA\n// For those cases, the code should be guarded with\n//       #if defined(EIGEN_GPU_COMPILE_PHASE)\n// instead of\n//       #if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIP_DEVICE_COMPILE)\n//\n// For cases where the tweak is specific to HIP, the code should be guarded with\n//      #if defined(EIGEN_HIP_DEVICE_COMPILE)\n//\n// For cases where the tweak is specific to CUDA, the code should be guarded with\n//      #if defined(EIGEN_CUDA_ARCH)\n//\n#endif\n\n/// \\internal EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC set to 1 if the architecture\n/// supports Neon vector intrinsics for fp16.\n#if EIGEN_ARCH_ARM_OR_ARM64\n#ifndef EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC\n// Clang only supports FP16 on aarch64, and not all intrinsics are available\n// on A32 anyways even in GCC (e.g. vdiv_f16, vsqrt_f16).\n#if EIGEN_ARCH_ARM64 &amp;&amp; defined(__ARM_FEATURE_FP16_VECTOR_ARITHMETIC) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 1\n#else\n#define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 0\n#endif\n#endif\n#endif\n\n/// \\internal EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC set to 1 if the architecture\n/// supports Neon scalar intrinsics for fp16.\n#if EIGEN_ARCH_ARM_OR_ARM64\n#ifndef EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC\n// Clang only supports FP16 on aarch64, and not all intrinsics are available\n// on A32 anyways, even in GCC (e.g. vceqh_f16).\n#if EIGEN_ARCH_ARM64 &amp;&amp; defined(__ARM_FEATURE_FP16_SCALAR_ARITHMETIC) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC 1\n#endif\n#endif\n#endif\n\n#if defined(EIGEN_USE_SYCL) &amp;&amp; defined(__SYCL_DEVICE_ONLY__)\n// EIGEN_USE_SYCL is a user-defined macro while __SYCL_DEVICE_ONLY__ is a compiler-defined macro.\n// In most cases we want to check if both macros are defined which can be done using the define below.\n#define SYCL_DEVICE_ONLY\n#endif\n\n//------------------------------------------------------------------------------------------\n// Detect Compiler/Architecture/OS specific features\n//------------------------------------------------------------------------------------------\n\n// Cross compiler wrapper around LLVM&#x27;s __has_builtin\n#ifdef __has_builtin\n#define EIGEN_HAS_BUILTIN(x) __has_builtin(x)\n#else\n#define EIGEN_HAS_BUILTIN(x) 0\n#endif\n\n// A Clang feature extension to determine compiler features.\n// We use it to determine &#x27;cxx_rvalue_references&#x27;\n#ifndef __has_feature\n#define __has_feature(x) 0\n#endif\n\n// The macro EIGEN_CPLUSPLUS is a replacement for __cplusplus/_MSVC_LANG that\n// works for both platforms, indicating the C++ standard version number.\n//\n// With MSVC, without defining /Zc:__cplusplus, the __cplusplus macro will\n// report 199711L regardless of the language standard specified via /std.\n// We need to rely on _MSVC_LANG instead, which is only available after\n// VS2015.3.\n#if EIGEN_COMP_MSVC_LANG &gt; 0\n#define EIGEN_CPLUSPLUS EIGEN_COMP_MSVC_LANG\n#elif EIGEN_COMP_MSVC &gt;= 1900\n#define EIGEN_CPLUSPLUS 201103L\n#elif defined(__cplusplus)\n#define EIGEN_CPLUSPLUS __cplusplus\n#else\n#define EIGEN_CPLUSPLUS 0\n#endif\n\n// The macro EIGEN_COMP_CXXVER defines the c++ version expected by the compiler.\n// For instance, if compiling with gcc and -std=c++17, then EIGEN_COMP_CXXVER\n// is defined to 17.\n#if EIGEN_CPLUSPLUS &gt;= 202002L\n#define EIGEN_COMP_CXXVER 20\n#elif EIGEN_CPLUSPLUS &gt;= 201703L\n#define EIGEN_COMP_CXXVER 17\n#elif EIGEN_CPLUSPLUS &gt;= 201402L\n#define EIGEN_COMP_CXXVER 14\n#elif EIGEN_CPLUSPLUS &gt;= 201103L\n#define EIGEN_COMP_CXXVER 11\n#else\n#define EIGEN_COMP_CXXVER 03\n#endif\n\n// The macros EIGEN_HAS_CXX?? defines a rough estimate of available c++ features\n// but in practice we should not rely on them but rather on the availability of\n// individual features as defined later.\n// This is why there is no EIGEN_HAS_CXX17.\n#if EIGEN_MAX_CPP_VER &lt; 14 || EIGEN_COMP_CXXVER &lt; 14 || (EIGEN_COMP_MSVC &amp;&amp; EIGEN_COMP_MSVC &lt; 1900) || \\\n    (EIGEN_COMP_ICC &amp;&amp; EIGEN_COMP_ICC &lt; 1500) || (EIGEN_COMP_NVCC &amp;&amp; EIGEN_COMP_NVCC &lt; 80000) ||       \\\n    (EIGEN_COMP_CLANG_STRICT &amp;&amp; EIGEN_COMP_CLANG &lt; 390) ||                                             \\\n    (EIGEN_COMP_CLANGAPPLE &amp;&amp; EIGEN_COMP_CLANGAPPLE &lt; 9000000) || (EIGEN_COMP_GNUC_STRICT &amp;&amp; EIGEN_COMP_GNUC &lt; 510)\n#error Eigen requires at least c++14 support.\n#endif\n\n// Does the compiler support C99?\n// Need to include &lt;cmath&gt; to make sure _GLIBCXX_USE_C99 gets defined\n#include &lt;cmath&gt;\n#ifndef EIGEN_HAS_C99_MATH\n#if ((defined(__STDC_VERSION__) &amp;&amp; (__STDC_VERSION__ &gt;= 199901)) ||                                          \\\n     (defined(__GNUC__) &amp;&amp; defined(_GLIBCXX_USE_C99)) || (defined(_LIBCPP_VERSION) &amp;&amp; !defined(_MSC_VER)) || \\\n     (EIGEN_COMP_MSVC) || defined(SYCL_DEVICE_ONLY))\n#define EIGEN_HAS_C99_MATH 1\n#else\n#define EIGEN_HAS_C99_MATH 0\n#endif\n#endif\n\n// Does the compiler support std::hash?\n#ifndef EIGEN_HAS_STD_HASH\n// The std::hash struct is defined in C++11 but is not labelled as a __device__\n// function and is not constexpr, so cannot be used on device.\n#if !defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_HAS_STD_HASH 1\n#else\n#define EIGEN_HAS_STD_HASH 0\n#endif\n#endif  // EIGEN_HAS_STD_HASH\n\n#ifndef EIGEN_HAS_STD_INVOKE_RESULT\n#if EIGEN_MAX_CPP_VER &gt;= 17 &amp;&amp; EIGEN_COMP_CXXVER &gt;= 17\n#define EIGEN_HAS_STD_INVOKE_RESULT 1\n#else\n#define EIGEN_HAS_STD_INVOKE_RESULT 0\n#endif\n#endif\n\n#define EIGEN_CONSTEXPR constexpr\n\n// NOTE: the required Apple&#x27;s clang version is very conservative\n//       and it could be that XCode 9 works just fine.\n// NOTE: the MSVC version is based on https://en.cppreference.com/w/cpp/compiler_support\n//       and not tested.\n// NOTE: Intel C++ Compiler Classic (icc) Version 19.0 and later supports dynamic allocation\n//       for over-aligned data, but not in a manner that is compatible with Eigen.\n//       See https://gitlab.com/libeigen/eigen/-/issues/2575\n#ifndef EIGEN_HAS_CXX17_OVERALIGN\n#if EIGEN_MAX_CPP_VER &gt;= 17 &amp;&amp; EIGEN_COMP_CXXVER &gt;= 17 &amp;&amp;                                                            \\\n    ((EIGEN_COMP_MSVC &gt;= 1912) || (EIGEN_GNUC_STRICT_AT_LEAST(7, 0, 0)) || (EIGEN_CLANG_STRICT_AT_LEAST(5, 0, 0)) || \\\n     (EIGEN_COMP_CLANGAPPLE &amp;&amp; EIGEN_COMP_CLANGAPPLE &gt;= 10000000)) &amp;&amp;                                                \\\n    !EIGEN_COMP_ICC\n#define EIGEN_HAS_CXX17_OVERALIGN 1\n#else\n#define EIGEN_HAS_CXX17_OVERALIGN 0\n#endif\n#endif\n\n#if defined(EIGEN_CUDACC)\n// While available already with c++11, this is useful mostly starting with c++14 and relaxed constexpr rules\n#if defined(__NVCC__)\n// nvcc considers constexpr functions as __host__ __device__ with the option --expt-relaxed-constexpr\n#ifdef __CUDACC_RELAXED_CONSTEXPR__\n#define EIGEN_CONSTEXPR_ARE_DEVICE_FUNC\n#endif\n#elif defined(__clang__) &amp;&amp; defined(__CUDA__) &amp;&amp; __has_feature(cxx_relaxed_constexpr)\n// clang++ always considers constexpr functions as implicitly __host__ __device__\n#define EIGEN_CONSTEXPR_ARE_DEVICE_FUNC\n#endif\n#endif\n\n// Does the compiler support the __int128 and __uint128_t extensions for 128-bit\n// integer arithmetic?\n//\n// Clang and GCC define __SIZEOF_INT128__ when these extensions are supported,\n// but we avoid using them in certain cases:\n//\n// * Building using Clang for Windows, where the Clang runtime library has\n//   128-bit support only on LP64 architectures, but Windows is LLP64.\n#ifndef EIGEN_HAS_BUILTIN_INT128\n#if defined(__SIZEOF_INT128__) &amp;&amp; !(EIGEN_OS_WIN &amp;&amp; EIGEN_COMP_CLANG)\n#define EIGEN_HAS_BUILTIN_INT128 1\n#else\n#define EIGEN_HAS_BUILTIN_INT128 0\n#endif\n#endif\n\n//------------------------------------------------------------------------------------------\n// Preprocessor programming helpers\n//------------------------------------------------------------------------------------------\n\n// This macro can be used to prevent from macro expansion, e.g.:\n//   std::max EIGEN_NOT_A_MACRO(a,b)\n#define EIGEN_NOT_A_MACRO\n\n#define EIGEN_DEBUG_VAR(x) std::cerr &lt;&lt; #x &lt;&lt; &quot; = &quot; &lt;&lt; x &lt;&lt; std::endl;\n\n// concatenate two tokens\n#define EIGEN_CAT2(a, b) a##b\n#define EIGEN_CAT(a, b) EIGEN_CAT2(a, b)\n\n#define EIGEN_COMMA ,\n\n// convert a token to a string\n#define EIGEN_MAKESTRING2(a) #a\n#define EIGEN_MAKESTRING(a) EIGEN_MAKESTRING2(a)\n\n// EIGEN_STRONG_INLINE is a stronger version of the inline, using __forceinline on MSVC,\n// but it still doesn&#x27;t use GCC&#x27;s always_inline. This is useful in (common) situations where MSVC needs forceinline\n// but GCC is still doing fine with just inline.\n#ifndef EIGEN_STRONG_INLINE\n#if (EIGEN_COMP_MSVC || EIGEN_COMP_ICC) &amp;&amp; !defined(EIGEN_GPUCC)\n#define EIGEN_STRONG_INLINE __forceinline\n#else\n#define EIGEN_STRONG_INLINE inline\n#endif\n#endif\n\n// EIGEN_ALWAYS_INLINE is the strongest, it has the effect of making the function inline and adding every possible\n// attribute to maximize inlining. This should only be used when really necessary: in particular,\n// it uses __attribute__((always_inline)) on GCC, which most of the time is useless and can severely harm compile times.\n// FIXME with the always_inline attribute,\n#if EIGEN_COMP_GNUC &amp;&amp; !defined(SYCL_DEVICE_ONLY)\n#define EIGEN_ALWAYS_INLINE __attribute__((always_inline)) inline\n#else\n#define EIGEN_ALWAYS_INLINE EIGEN_STRONG_INLINE\n#endif\n\n#if EIGEN_COMP_GNUC\n#define EIGEN_DONT_INLINE __attribute__((noinline))\n#elif EIGEN_COMP_MSVC\n#define EIGEN_DONT_INLINE __declspec(noinline)\n#else\n#define EIGEN_DONT_INLINE\n#endif\n\n#if EIGEN_COMP_GNUC\n#define EIGEN_PERMISSIVE_EXPR __extension__\n#else\n#define EIGEN_PERMISSIVE_EXPR\n#endif\n\n// GPU stuff\n\n// Disable some features when compiling with GPU compilers (SYCL/HIPCC)\n#if defined(SYCL_DEVICE_ONLY) || defined(EIGEN_HIP_DEVICE_COMPILE)\n// Do not try asserts on device code\n#ifndef EIGEN_NO_DEBUG\n#define EIGEN_NO_DEBUG\n#endif\n\n#ifdef EIGEN_INTERNAL_DEBUGGING\n#undef EIGEN_INTERNAL_DEBUGGING\n#endif\n#endif\n\n// No exceptions on device.\n#if defined(SYCL_DEVICE_ONLY) || defined(EIGEN_GPU_COMPILE_PHASE)\n#ifdef EIGEN_EXCEPTIONS\n#undef EIGEN_EXCEPTIONS\n#endif\n#endif\n\n#if defined(SYCL_DEVICE_ONLY)\n#ifndef EIGEN_DONT_VECTORIZE\n#define EIGEN_DONT_VECTORIZE\n#endif\n#define EIGEN_DEVICE_FUNC __attribute__((flatten)) __attribute__((always_inline))\n// All functions callable from CUDA/HIP code must be qualified with __device__\n#elif defined(EIGEN_GPUCC)\n#define EIGEN_DEVICE_FUNC __host__ __device__\n#else\n#define EIGEN_DEVICE_FUNC\n#endif\n\n// this macro allows to get rid of linking errors about multiply defined functions.\n//  - static is not very good because it prevents definitions from different object files to be merged.\n//           So static causes the resulting linked executable to be bloated with multiple copies of the same function.\n//  - inline is not perfect either as it unwantedly hints the compiler toward inlining the function.\n#define EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC\n#define EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC inline\n\n#ifdef NDEBUG\n#ifndef EIGEN_NO_DEBUG\n#define EIGEN_NO_DEBUG\n#endif\n#endif\n\n// eigen_assert can be overridden\n#ifndef eigen_assert\n#define eigen_assert(x) eigen_plain_assert(x)\n#endif\n\n#ifdef EIGEN_INTERNAL_DEBUGGING\n#define eigen_internal_assert(x) eigen_assert(x)\n#else\n#define eigen_internal_assert(x) ((void)0)\n#endif\n\n#if defined(EIGEN_NO_DEBUG) || (defined(EIGEN_GPU_COMPILE_PHASE) &amp;&amp; defined(EIGEN_NO_DEBUG_GPU))\n#define EIGEN_ONLY_USED_FOR_DEBUG(x) EIGEN_UNUSED_VARIABLE(x)\n#else\n#define EIGEN_ONLY_USED_FOR_DEBUG(x)\n#endif\n\n#ifndef EIGEN_NO_DEPRECATED_WARNING\n#if EIGEN_COMP_GNUC\n#define EIGEN_DEPRECATED __attribute__((deprecated))\n#elif EIGEN_COMP_MSVC\n#define EIGEN_DEPRECATED __declspec(deprecated)\n#else\n#define EIGEN_DEPRECATED\n#endif\n#else\n#define EIGEN_DEPRECATED\n#endif\n\n#if EIGEN_COMP_GNUC\n#define EIGEN_UNUSED __attribute__((unused))\n#else\n#define EIGEN_UNUSED\n#endif\n\n#if EIGEN_COMP_GNUC\n#define EIGEN_PRAGMA(tokens) _Pragma(#tokens)\n#define EIGEN_DIAGNOSTICS(tokens) EIGEN_PRAGMA(GCC diagnostic tokens)\n#define EIGEN_DIAGNOSTICS_OFF(msc, gcc) EIGEN_DIAGNOSTICS(gcc)\n#elif EIGEN_COMP_MSVC\n#define EIGEN_PRAGMA(tokens) __pragma(tokens)\n#define EIGEN_DIAGNOSTICS(tokens) EIGEN_PRAGMA(warning(tokens))\n#define EIGEN_DIAGNOSTICS_OFF(msc, gcc) EIGEN_DIAGNOSTICS(msc)\n#else\n#define EIGEN_PRAGMA(tokens)\n#define EIGEN_DIAGNOSTICS(tokens)\n#define EIGEN_DIAGNOSTICS_OFF(msc, gcc)\n#endif\n\n#define EIGEN_DISABLE_DEPRECATED_WARNING EIGEN_DIAGNOSTICS_OFF(disable : 4996, ignored &quot;-Wdeprecated-declarations&quot;)\n\n// Suppresses &#x27;unused variable&#x27; warnings.\nnamespace Eigen {\nnamespace internal {\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void ignore_unused_variable(const T&amp;) {}\n}  // namespace internal\n}  // namespace Eigen\n#define EIGEN_UNUSED_VARIABLE(var) Eigen::internal::ignore_unused_variable(var);\n\n#if !defined(EIGEN_ASM_COMMENT)\n#if EIGEN_COMP_GNUC &amp;&amp; (EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM_OR_ARM64)\n#define EIGEN_ASM_COMMENT(X) __asm__(&quot;#&quot; X)\n#else\n#define EIGEN_ASM_COMMENT(X)\n#endif\n#endif\n\n// Acts as a barrier preventing operations involving `X` from crossing. This\n// occurs, for example, in the fast rounding trick where a magic constant is\n// added then subtracted, which is otherwise compiled away with -ffast-math.\n//\n// See bug 1674\n#if defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_OPTIMIZATION_BARRIER(X)\n#endif\n\n#if !defined(EIGEN_OPTIMIZATION_BARRIER)\n#if EIGEN_COMP_GNUC\n   // According to https://gcc.gnu.org/onlinedocs/gcc/Constraints.html:\n//   X: Any operand whatsoever.\n//   r: A register operand is allowed provided that it is in a general\n//      register.\n//   g: Any register, memory or immediate integer operand is allowed, except\n//      for registers that are not general registers.\n//   w: (AArch32/AArch64) Floating point register, Advanced SIMD vector\n//      register or SVE vector register.\n//   x: (SSE) Any SSE register.\n//      (AArch64) Like w, but restricted to registers 0 to 15 inclusive.\n//   v: (PowerPC) An Altivec vector register.\n//   wa:(PowerPC) A VSX register.\n//\n// &quot;X&quot; (uppercase) should work for all cases, though this seems to fail for\n// some versions of GCC for arm/aarch64 with\n//   &quot;error: inconsistent operand constraints in an &#x27;asm&#x27;&quot;\n// Clang x86_64/arm/aarch64 seems to require &quot;g&quot; to support both scalars and\n// vectors, otherwise\n//   &quot;error: non-trivial scalar-to-vector conversion, possible invalid\n//    constraint for vector type&quot;\n//\n// GCC for ppc64le generates an internal compiler error with x/X/g.\n// GCC for AVX generates an internal compiler error with X.\n//\n// Tested on icc/gcc/clang for sse, avx, avx2, avx512dq\n//           gcc for arm, aarch64,\n//           gcc for ppc64le,\n// both vectors and scalars.\n//\n// Note that this is restricted to plain types - this will not work\n// directly for std::complex&lt;T&gt;, Eigen::half, Eigen::bfloat16. For these,\n// you will need to apply to the underlying POD type.\n#if EIGEN_ARCH_PPC &amp;&amp; EIGEN_COMP_GNUC_STRICT\n   // This seems to be broken on clang. Packet4f is loaded into a single\n//   register rather than a vector, zeroing out some entries. Integer\n//   types also generate a compile error.\n#if EIGEN_OS_MAC\n   // General, Altivec for Apple (VSX were added in ISA v2.06):\n#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__(&quot;&quot; : &quot;+r,v&quot;(X));\n#else\n   // General, Altivec, VSX otherwise:\n#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__(&quot;&quot; : &quot;+r,v,wa&quot;(X));\n#endif\n#elif EIGEN_ARCH_ARM_OR_ARM64\n#ifdef __ARM_FP\n   // General, VFP or NEON.\n// Clang doesn&#x27;t like &quot;r&quot;,\n//    error: non-trivial scalar-to-vector conversion, possible invalid\n//           constraint for vector typ\n#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__(&quot;&quot; : &quot;+g,w&quot;(X));\n#else\n   // Arm without VFP or NEON.\n// &quot;w&quot; constraint will not compile.\n#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__(&quot;&quot; : &quot;+g&quot;(X));\n#endif\n#elif EIGEN_ARCH_i386_OR_x86_64\n   // General, SSE.\n#define EIGEN_OPTIMIZATION_BARRIER(X) __asm__(&quot;&quot; : &quot;+g,x&quot;(X));\n#else\n   // Not implemented for other architectures.\n#define EIGEN_OPTIMIZATION_BARRIER(X)\n#endif\n#else\n   // Not implemented for other compilers.\n#define EIGEN_OPTIMIZATION_BARRIER(X)\n#endif\n#endif\n\n#if EIGEN_COMP_MSVC\n// NOTE MSVC often gives C4127 warnings with compiletime if statements. See bug 1362.\n// This workaround is ugly, but it does the job.\n#define EIGEN_CONST_CONDITIONAL(cond) (void)0, cond\n#else\n#define EIGEN_CONST_CONDITIONAL(cond) cond\n#endif\n\n#ifdef EIGEN_DONT_USE_RESTRICT_KEYWORD\n#define EIGEN_RESTRICT\n#endif\n#ifndef EIGEN_RESTRICT\n#define EIGEN_RESTRICT __restrict\n#endif\n\n#ifndef EIGEN_DEFAULT_IO_FORMAT\n#ifdef EIGEN_MAKING_DOCS\n// format used in Eigen&#x27;s documentation\n// needed to define it here as escaping characters in CMake add_definition&#x27;s argument seems very problematic.\n#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat(3, 0, &quot; &quot;, &quot;\\n&quot;, &quot;&quot;, &quot;&quot;)\n#else\n#define EIGEN_DEFAULT_IO_FORMAT Eigen::IOFormat()\n#endif\n#endif\n\n// just an empty macro !\n#define EIGEN_EMPTY\n\n// When compiling CUDA/HIP device code with NVCC or HIPCC\n// pull in math functions from the global namespace.\n// In host mode, and when device code is compiled with clang,\n// use the std versions.\n#if (defined(EIGEN_CUDA_ARCH) &amp;&amp; defined(__NVCC__)) || defined(EIGEN_HIP_DEVICE_COMPILE)\n#define EIGEN_USING_STD(FUNC) using ::FUNC;\n#else\n#define EIGEN_USING_STD(FUNC) using std::FUNC;\n#endif\n\n#if EIGEN_COMP_CLANG  // workaround clang bug (see http://forum.kde.org/viewtopic.php?f=74&amp;t=102653)\n#define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)                                           \\\n  using Base::operator=;                                                                           \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const Derived&amp; other) {                 \\\n    Base::operator=(other);                                                                        \\\n    return *this;                                                                                  \\\n  }                                                                                                \\\n  template &lt;typename OtherDerived&gt;                                                                 \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) { \\\n    Base::operator=(other.derived());                                                              \\\n    return *this;                                                                                  \\\n  }\n#else\n#define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)                           \\\n  using Base::operator=;                                                           \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const Derived&amp; other) { \\\n    Base::operator=(other);                                                        \\\n    return *this;                                                                  \\\n  }\n#endif\n\n/**\n * \\internal\n * \\brief Macro to explicitly define the default copy constructor.\n * This is necessary, because the implicit definition is deprecated if the copy-assignment is overridden.\n */\n#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS) EIGEN_DEVICE_FUNC CLASS(const CLASS&amp;) = default;\n\n/** \\internal\n * \\brief Macro to manually inherit assignment operators.\n * This is necessary, because the implicitly defined assignment operator gets deleted when a custom operator= is\n * defined. With C++11 or later this also default-implements the copy-constructor\n */\n#define EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Derived) \\\n  EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)  \\\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(Derived)\n\n/** \\internal\n * \\brief Macro to manually define default constructors and destructors.\n * This is necessary when the copy constructor is re-defined.\n * For empty helper classes this should usually be protected, to avoid accidentally creating empty objects.\n *\n * Hiding the default destructor lead to problems in C++03 mode together with boost::multiprecision\n */\n#define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived) \\\n  EIGEN_DEVICE_FUNC Derived() = default;                        \\\n  EIGEN_DEVICE_FUNC ~Derived() = default;\n\n/**\n * Just a side note. Commenting within defines works only by documenting\n * behind the object (via &#x27;!&lt;&#x27;). Comments cannot be multi-line and thus\n * we have these extra long lines. What is confusing doxygen over here is\n * that we use &#x27;\\&#x27; and basically have a bunch of typedefs with their\n * documentation in a single line.\n **/\n\n#define EIGEN_GENERIC_PUBLIC_INTERFACE(Derived)                                                                        \\\n  typedef typename Eigen::internal::traits&lt;Derived&gt;::Scalar                                                            \\\n      Scalar; /*!&lt; \\brief Numeric type, e.g. float, double, int or std::complex&lt;float&gt;. */                             \\\n  typedef typename Eigen::NumTraits&lt;Scalar&gt;::Real                                                                      \\\n      RealScalar; /*!&lt; \\brief The underlying numeric type for composed scalar types. \\details In cases where Scalar is \\\n                     e.g. std::complex&lt;T&gt;, T were corresponding to RealScalar. */                                      \\\n  typedef typename Base::CoeffReturnType                                                                               \\\n      CoeffReturnType; /*!&lt; \\brief The return type for coefficient access. \\details Depending on whether the object    \\\n                          allows direct coefficient access (e.g. for a MatrixXd), this type is either &#x27;const Scalar&amp;&#x27;  \\\n                          or simply &#x27;Scalar&#x27; for objects that do not allow direct coefficient access. */               \\\n  typedef typename Eigen::internal::ref_selector&lt;Derived&gt;::type Nested;                                                \\\n  typedef typename Eigen::internal::traits&lt;Derived&gt;::StorageKind StorageKind;                                          \\\n  typedef typename Eigen::internal::traits&lt;Derived&gt;::StorageIndex StorageIndex;                                        \\\n  enum CompileTimeTraits {                                                                                             \\\n    RowsAtCompileTime = Eigen::internal::traits&lt;Derived&gt;::RowsAtCompileTime,                                           \\\n    ColsAtCompileTime = Eigen::internal::traits&lt;Derived&gt;::ColsAtCompileTime,                                           \\\n    Flags = Eigen::internal::traits&lt;Derived&gt;::Flags,                                                                   \\\n    SizeAtCompileTime = Base::SizeAtCompileTime,                                                                       \\\n    MaxSizeAtCompileTime = Base::MaxSizeAtCompileTime,                                                                 \\\n    IsVectorAtCompileTime = Base::IsVectorAtCompileTime                                                                \\\n  };                                                                                                                   \\\n  using Base::derived;                                                                                                 \\\n  using Base::const_cast_derived;\n\n// FIXME Maybe the EIGEN_DENSE_PUBLIC_INTERFACE could be removed as importing PacketScalar is rarely needed\n#define EIGEN_DENSE_PUBLIC_INTERFACE(Derived) \\\n  EIGEN_GENERIC_PUBLIC_INTERFACE(Derived)     \\\n  typedef typename Base::PacketScalar PacketScalar;\n\n#if EIGEN_HAS_BUILTIN(__builtin_expect) || EIGEN_COMP_GNUC\n#define EIGEN_PREDICT_FALSE(x) (__builtin_expect(x, false))\n#define EIGEN_PREDICT_TRUE(x) (__builtin_expect(false || (x), true))\n#else\n#define EIGEN_PREDICT_FALSE(x) (x)\n#define EIGEN_PREDICT_TRUE(x) (x)\n#endif\n\n// the expression type of a standard coefficient wise binary operation\n#define EIGEN_CWISE_BINARY_RETURN_TYPE(LHS, RHS, OPNAME)                                                       \\\n  CwiseBinaryOp&lt;EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) &lt; typename internal::traits&lt;LHS&gt;::Scalar, \\\n                typename internal::traits&lt;RHS&gt;::Scalar&gt;,                                                       \\\n      const LHS, const RHS &gt;\n\n#define EIGEN_MAKE_CWISE_BINARY_OP(METHOD, OPNAME)                                                                \\\n  template &lt;typename OtherDerived&gt;                                                                                \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_CWISE_BINARY_RETURN_TYPE(                                     \\\n      Derived, OtherDerived, OPNAME)(METHOD)(const EIGEN_CURRENT_STORAGE_BASE_CLASS&lt;OtherDerived&gt;&amp; other) const { \\\n    return EIGEN_CWISE_BINARY_RETURN_TYPE(Derived, OtherDerived, OPNAME)(derived(), other.derived());             \\\n  }\n\n#define EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, TYPEA, TYPEB)     \\\n  (Eigen::internal::has_ReturnType&lt;Eigen::ScalarBinaryOpTraits&lt; \\\n       TYPEA, TYPEB, EIGEN_CAT(EIGEN_CAT(Eigen::internal::scalar_, OPNAME), _op) &lt; TYPEA, TYPEB&gt; &gt; &gt; ::value)\n\n#define EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(EXPR, SCALAR, OPNAME)                                            \\\n  CwiseBinaryOp&lt;EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) &lt; typename internal::traits&lt;EXPR&gt;::Scalar, \\\n                SCALAR&gt;,                                                                                        \\\n      const EXPR, const typename internal::plain_constant_type&lt;EXPR, SCALAR&gt;::type &gt;\n\n#define EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(SCALAR, EXPR, OPNAME)           \\\n  CwiseBinaryOp&lt;EIGEN_CAT(EIGEN_CAT(internal::scalar_, OPNAME), _op) &lt; SCALAR, \\\n                typename internal::traits&lt;EXPR&gt;::Scalar&gt;,                      \\\n      const typename internal::plain_constant_type&lt;EXPR, SCALAR&gt;::type, const EXPR &gt;\n\n#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD, OPNAME)                                                       \\\n  template &lt;typename T&gt;                                                                                              \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(                                \\\n      Derived,                                                                                                       \\\n      typename internal::promote_scalar_arg&lt;Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(          \\\n          OPNAME, Scalar, T)&gt;::type,                                                                                 \\\n      OPNAME)(METHOD)(const T&amp; scalar) const {                                                                       \\\n    typedef typename internal::promote_scalar_arg&lt;Scalar, T, EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, Scalar, T)&gt;::type \\\n        PromotedT;                                                                                                   \\\n    return EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(Derived, PromotedT, OPNAME)(                                       \\\n        derived(), typename internal::plain_constant_type&lt;Derived, PromotedT&gt;::type(                                 \\\n                       derived().rows(), derived().cols(), internal::scalar_constant_op&lt;PromotedT&gt;(scalar)));        \\\n  }\n\n#define EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD, OPNAME)                                                        \\\n  template &lt;typename T&gt;                                                                                              \\\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE friend const EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(                         \\\n      typename internal::promote_scalar_arg&lt;Scalar EIGEN_COMMA T EIGEN_COMMA EIGEN_SCALAR_BINARY_SUPPORTED(          \\\n          OPNAME, T, Scalar)&gt;::type,                                                                                 \\\n      Derived, OPNAME)(METHOD)(const T&amp; scalar, const StorageBaseType&amp; matrix) {                                     \\\n    typedef typename internal::promote_scalar_arg&lt;Scalar, T, EIGEN_SCALAR_BINARY_SUPPORTED(OPNAME, T, Scalar)&gt;::type \\\n        PromotedT;                                                                                                   \\\n    return EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(PromotedT, Derived, OPNAME)(                                       \\\n        typename internal::plain_constant_type&lt;Derived, PromotedT&gt;::type(                                            \\\n            matrix.derived().rows(), matrix.derived().cols(), internal::scalar_constant_op&lt;PromotedT&gt;(scalar)),      \\\n        matrix.derived());                                                                                           \\\n  }\n\n#define EIGEN_MAKE_SCALAR_BINARY_OP(METHOD, OPNAME)     \\\n  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHELEFT(METHOD, OPNAME) \\\n  EIGEN_MAKE_SCALAR_BINARY_OP_ONTHERIGHT(METHOD, OPNAME)\n\n#if (defined(_CPPUNWIND) || defined(__EXCEPTIONS)) &amp;&amp; !defined(EIGEN_CUDA_ARCH) &amp;&amp; !defined(EIGEN_EXCEPTIONS) &amp;&amp; \\\n    !defined(EIGEN_USE_SYCL) &amp;&amp; !defined(EIGEN_HIP_DEVICE_COMPILE)\n#define EIGEN_EXCEPTIONS\n#endif\n\n#ifdef EIGEN_EXCEPTIONS\n#define EIGEN_THROW_X(X) throw X\n#define EIGEN_THROW throw\n#define EIGEN_TRY try\n#define EIGEN_CATCH(X) catch (X)\n#else\n#if defined(EIGEN_CUDA_ARCH)\n#define EIGEN_THROW_X(X) asm(&quot;trap;&quot;)\n#define EIGEN_THROW asm(&quot;trap;&quot;)\n#elif defined(EIGEN_HIP_DEVICE_COMPILE)\n#define EIGEN_THROW_X(X) asm(&quot;s_trap 0&quot;)\n#define EIGEN_THROW asm(&quot;s_trap 0&quot;)\n#else\n#define EIGEN_THROW_X(X) std::abort()\n#define EIGEN_THROW std::abort()\n#endif\n#define EIGEN_TRY if (true)\n#define EIGEN_CATCH(X) else\n#endif\n\n#define EIGEN_NOEXCEPT noexcept\n#define EIGEN_NOEXCEPT_IF(x) noexcept(x)\n#define EIGEN_NO_THROW noexcept(true)\n#define EIGEN_EXCEPTION_SPEC(X) noexcept(false)\n\n// The all function is used to enable a variadic version of eigen_assert which can take a parameter pack as its input.\nnamespace Eigen {\nnamespace internal {\n\nEIGEN_DEVICE_FUNC inline bool all() { return true; }\n\ntemplate &lt;typename T, typename... Ts&gt;\nEIGEN_DEVICE_FUNC bool all(T t, Ts... ts) {\n  return t &amp;&amp; all(ts...);\n}\n\n}  // namespace internal\n}  // namespace Eigen\n\n// provide override and final specifiers if they are available:\n#define EIGEN_OVERRIDE override\n#define EIGEN_FINAL final\n\n// Wrapping #pragma unroll in a macro since it is required for SYCL\n#if defined(SYCL_DEVICE_ONLY)\n#if defined(_MSC_VER)\n#define EIGEN_UNROLL_LOOP __pragma(unroll)\n#else\n#define EIGEN_UNROLL_LOOP _Pragma(&quot;unroll&quot;)\n#endif\n#else\n#define EIGEN_UNROLL_LOOP\n#endif\n\n// Notice: Use this macro with caution. The code in the if body should still\n// compile with C++14.\n#if defined(EIGEN_HAS_CXX17_IFCONSTEXPR)\n#define EIGEN_IF_CONSTEXPR(X) if constexpr (X)\n#else\n#define EIGEN_IF_CONSTEXPR(X) if (X)\n#endif\n\n#endif  // EIGEN_MACROS_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2007 Michael Olbrich &lt;michael.olbrich@gmx.net&gt;\n// Copyright (C) 2006-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ASSIGN_H\n#define EIGEN_ASSIGN_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; DenseBase&lt;Derived&gt;::lazyAssign(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n  enum { SameType = internal::is_same&lt;typename Derived::Scalar, typename OtherDerived::Scalar&gt;::value };\n\n  EIGEN_STATIC_ASSERT_LVALUE(Derived)\n  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Derived, OtherDerived)\n  EIGEN_STATIC_ASSERT(\n      SameType,\n      YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)\n\n  eigen_assert(rows() == other.rows() &amp;&amp; cols() == other.cols());\n  internal::call_assignment_no_alias(derived(), other.derived());\n\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; DenseBase&lt;Derived&gt;::operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; DenseBase&lt;Derived&gt;::operator=(const DenseBase&amp; other) {\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; MatrixBase&lt;Derived&gt;::operator=(const MatrixBase&amp; other) {\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; MatrixBase&lt;Derived&gt;::operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; MatrixBase&lt;Derived&gt;::operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; MatrixBase&lt;Derived&gt;::operator=(\n    const ReturnByValue&lt;OtherDerived&gt;&amp; other) {\n  other.derived().evalTo(derived());\n  return derived();\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ASSIGN_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2007-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008-2010 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_DENSEBASE_H\n#define EIGEN_DENSEBASE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n// The index type defined by EIGEN_DEFAULT_DENSE_INDEX_TYPE must be a signed type.\nEIGEN_STATIC_ASSERT(NumTraits&lt;DenseIndex&gt;::IsSigned, THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE)\n\n/** \\class DenseBase\n * \\ingroup Core_Module\n *\n * \\brief Base class for all dense matrices, vectors, and arrays\n *\n * This class is the base that is inherited by all dense objects (matrix, vector, arrays,\n * and related expression types). The common Eigen API for dense objects is contained in this class.\n *\n * \\tparam Derived is the derived type, e.g., a matrix type or an expression.\n *\n * This class can be extended with the help of the plugin mechanism described on the page\n * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_DENSEBASE_PLUGIN.\n *\n * \\sa \\blank \\ref TopicClassHierarchy\n */\ntemplate &lt;typename Derived&gt;\nclass DenseBase\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n    : public DenseCoeffsBase&lt;Derived, internal::accessors_level&lt;Derived&gt;::value&gt;\n#else\n    : public DenseCoeffsBase&lt;Derived, DirectWriteAccessors&gt;\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n{\n public:\n  /** Inner iterator type to iterate over the coefficients of a row or column.\n   * \\sa class InnerIterator\n   */\n  typedef Eigen::InnerIterator&lt;Derived&gt; InnerIterator;\n\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n\n  /**\n   * \\brief The type used to store indices\n   * \\details This typedef is relevant for types that store multiple indices such as\n   *          PermutationMatrix or Transpositions, otherwise it defaults to Eigen::Index\n   * \\sa \\blank \\ref TopicPreprocessorDirectives, Eigen::Index, SparseMatrixBase.\n   */\n  typedef typename internal::traits&lt;Derived&gt;::StorageIndex StorageIndex;\n\n  /** The numeric type of the expression&#x27; coefficients, e.g. float, double, int or std::complex&lt;float&gt;, etc. */\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n\n  /** The numeric type of the expression&#x27; coefficients, e.g. float, double, int or std::complex&lt;float&gt;, etc.\n   *\n   * It is an alias for the Scalar type */\n  typedef Scalar value_type;\n\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n  typedef DenseCoeffsBase&lt;Derived, internal::accessors_level&lt;Derived&gt;::value&gt; Base;\n\n  using Base::coeff;\n  using Base::coeffByOuterInner;\n  using Base::colIndexByOuterInner;\n  using Base::cols;\n  using Base::const_cast_derived;\n  using Base::derived;\n  using Base::rowIndexByOuterInner;\n  using Base::rows;\n  using Base::size;\n  using Base::operator();\n  using Base::operator[];\n  using Base::colStride;\n  using Base::innerStride;\n  using Base::outerStride;\n  using Base::rowStride;\n  using Base::stride;\n  using Base::w;\n  using Base::x;\n  using Base::y;\n  using Base::z;\n  typedef typename Base::CoeffReturnType CoeffReturnType;\n\n  enum {\n\n    RowsAtCompileTime = internal::traits&lt;Derived&gt;::RowsAtCompileTime,\n    /**&lt; The number of rows at compile-time. This is just a copy of the value provided\n     * by the \\a Derived type. If a value is not known at compile-time,\n     * it is set to the \\a Dynamic constant.\n     * \\sa MatrixBase::rows(), MatrixBase::cols(), ColsAtCompileTime, SizeAtCompileTime */\n\n    ColsAtCompileTime = internal::traits&lt;Derived&gt;::ColsAtCompileTime,\n    /**&lt; The number of columns at compile-time. This is just a copy of the value provided\n     * by the \\a Derived type. If a value is not known at compile-time,\n     * it is set to the \\a Dynamic constant.\n     * \\sa MatrixBase::rows(), MatrixBase::cols(), RowsAtCompileTime, SizeAtCompileTime */\n\n    SizeAtCompileTime = (internal::size_of_xpr_at_compile_time&lt;Derived&gt;::ret),\n    /**&lt; This is equal to the number of coefficients, i.e. the number of\n     * rows times the number of columns, or to \\a Dynamic if this is not\n     * known at compile-time. \\sa RowsAtCompileTime, ColsAtCompileTime */\n\n    MaxRowsAtCompileTime = internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime,\n    /**&lt; This value is equal to the maximum possible number of rows that this expression\n     * might have. If this expression might have an arbitrarily high number of rows,\n     * this value is set to \\a Dynamic.\n     *\n     * This value is useful to know when evaluating an expression, in order to determine\n     * whether it is possible to avoid doing a dynamic memory allocation.\n     *\n     * \\sa RowsAtCompileTime, MaxColsAtCompileTime, MaxSizeAtCompileTime\n     */\n\n    MaxColsAtCompileTime = internal::traits&lt;Derived&gt;::MaxColsAtCompileTime,\n    /**&lt; This value is equal to the maximum possible number of columns that this expression\n     * might have. If this expression might have an arbitrarily high number of columns,\n     * this value is set to \\a Dynamic.\n     *\n     * This value is useful to know when evaluating an expression, in order to determine\n     * whether it is possible to avoid doing a dynamic memory allocation.\n     *\n     * \\sa ColsAtCompileTime, MaxRowsAtCompileTime, MaxSizeAtCompileTime\n     */\n\n    MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime,\n                                                          internal::traits&lt;Derived&gt;::MaxColsAtCompileTime),\n    /**&lt; This value is equal to the maximum possible number of coefficients that this expression\n     * might have. If this expression might have an arbitrarily high number of coefficients,\n     * this value is set to \\a Dynamic.\n     *\n     * This value is useful to know when evaluating an expression, in order to determine\n     * whether it is possible to avoid doing a dynamic memory allocation.\n     *\n     * \\sa SizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime\n     */\n\n    IsVectorAtCompileTime =\n        internal::traits&lt;Derived&gt;::RowsAtCompileTime == 1 || internal::traits&lt;Derived&gt;::ColsAtCompileTime == 1,\n    /**&lt; This is set to true if either the number of rows or the number of\n     * columns is known at compile-time to be equal to 1. Indeed, in that case,\n     * we are dealing with a column-vector (if there is only one column) or with\n     * a row-vector (if there is only one row). */\n\n    NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0\n                    : bool(IsVectorAtCompileTime)  ? 1\n                                                   : 2,\n    /**&lt; This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors,\n     * and 2 for matrices.\n     */\n\n    Flags = internal::traits&lt;Derived&gt;::Flags,\n    /**&lt; This stores expression \\ref flags flags which may or may not be inherited by new expressions\n     * constructed from this one. See the \\ref flags &quot;list of flags&quot;.\n     */\n\n    IsRowMajor = int(Flags) &amp; RowMajorBit, /**&lt; True if this expression has row-major storage order. */\n\n    InnerSizeAtCompileTime = int(IsVectorAtCompileTime) ? int(SizeAtCompileTime)\n                             : int(IsRowMajor)          ? int(ColsAtCompileTime)\n                                                        : int(RowsAtCompileTime),\n\n    InnerStrideAtCompileTime = internal::inner_stride_at_compile_time&lt;Derived&gt;::ret,\n    OuterStrideAtCompileTime = internal::outer_stride_at_compile_time&lt;Derived&gt;::ret\n  };\n\n  typedef typename internal::find_best_packet&lt;Scalar, SizeAtCompileTime&gt;::type PacketScalar;\n\n  enum { IsPlainObjectBase = 0 };\n\n  /** The plain matrix type corresponding to this expression.\n   * \\sa PlainObject */\n  typedef Matrix&lt;typename internal::traits&lt;Derived&gt;::Scalar, internal::traits&lt;Derived&gt;::RowsAtCompileTime,\n                 internal::traits&lt;Derived&gt;::ColsAtCompileTime,\n                 AutoAlign | (internal::traits&lt;Derived&gt;::Flags &amp; RowMajorBit ? RowMajor : ColMajor),\n                 internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime, internal::traits&lt;Derived&gt;::MaxColsAtCompileTime&gt;\n      PlainMatrix;\n\n  /** The plain array type corresponding to this expression.\n   * \\sa PlainObject */\n  typedef Array&lt;typename internal::traits&lt;Derived&gt;::Scalar, internal::traits&lt;Derived&gt;::RowsAtCompileTime,\n                internal::traits&lt;Derived&gt;::ColsAtCompileTime,\n                AutoAlign | (internal::traits&lt;Derived&gt;::Flags &amp; RowMajorBit ? RowMajor : ColMajor),\n                internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime, internal::traits&lt;Derived&gt;::MaxColsAtCompileTime&gt;\n      PlainArray;\n\n  /** \\brief The plain matrix or array type corresponding to this expression.\n   *\n   * This is not necessarily exactly the return type of eval(). In the case of plain matrices,\n   * the return type of eval() is a const reference to a matrix, not a matrix! It is however guaranteed\n   * that the return type of eval() is either PlainObject or const PlainObject&amp;.\n   */\n  typedef std::conditional_t&lt;internal::is_same&lt;typename internal::traits&lt;Derived&gt;::XprKind, MatrixXpr&gt;::value,\n                             PlainMatrix, PlainArray&gt;\n      PlainObject;\n\n  /** \\returns the outer size.\n   *\n   * \\note For a vector, this returns just 1. For a matrix (non-vector), this is the major dimension\n   * with respect to the \\ref TopicStorageOrders &quot;storage order&quot;, i.e., the number of columns for a\n   * column-major matrix, and the number of rows for a row-major matrix. */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerSize() const {\n    return IsVectorAtCompileTime ? 1 : int(IsRowMajor) ? this-&gt;rows() : this-&gt;cols();\n  }\n\n  /** \\returns the inner size.\n   *\n   * \\note For a vector, this is just the size. For a matrix (non-vector), this is the minor dimension\n   * with respect to the \\ref TopicStorageOrders &quot;storage order&quot;, i.e., the number of rows for a\n   * column-major matrix, and the number of columns for a row-major matrix. */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const {\n    return IsVectorAtCompileTime ? this-&gt;size() : int(IsRowMajor) ? this-&gt;cols() : this-&gt;rows();\n  }\n\n  /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are\n   * Matrix::resize() and Array::resize(). The present method only asserts that the new size equals the old size, and\n   * does nothing else.\n   */\n  EIGEN_DEVICE_FUNC void resize(Index newSize) {\n    EIGEN_ONLY_USED_FOR_DEBUG(newSize);\n    eigen_assert(newSize == this-&gt;size() &amp;&amp; &quot;DenseBase::resize() does not actually allow to resize.&quot;);\n  }\n  /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are\n   * Matrix::resize() and Array::resize(). The present method only asserts that the new size equals the old size, and\n   * does nothing else.\n   */\n  EIGEN_DEVICE_FUNC void resize(Index rows, Index cols) {\n    EIGEN_ONLY_USED_FOR_DEBUG(rows);\n    EIGEN_ONLY_USED_FOR_DEBUG(cols);\n    eigen_assert(rows == this-&gt;rows() &amp;&amp; cols == this-&gt;cols() &amp;&amp;\n                 &quot;DenseBase::resize() does not actually allow to resize.&quot;);\n  }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** \\internal Represents a matrix with all coefficients equal to one another*/\n  typedef CwiseNullaryOp&lt;internal::scalar_constant_op&lt;Scalar&gt;, PlainObject&gt; ConstantReturnType;\n  /** \\internal Represents a matrix with all coefficients equal to zero*/\n  typedef CwiseNullaryOp&lt;internal::scalar_zero_op&lt;Scalar&gt;, PlainObject&gt; ZeroReturnType;\n  /** \\internal \\deprecated Represents a vector with linearly spaced coefficients that allows sequential access only. */\n  EIGEN_DEPRECATED typedef CwiseNullaryOp&lt;internal::linspaced_op&lt;Scalar&gt;, PlainObject&gt; SequentialLinSpacedReturnType;\n  /** \\internal Represents a vector with linearly spaced coefficients that allows random access. */\n  typedef CwiseNullaryOp&lt;internal::linspaced_op&lt;Scalar&gt;, PlainObject&gt; RandomAccessLinSpacedReturnType;\n  /** \\internal Represents a vector with equally spaced coefficients that allows random access. */\n  typedef CwiseNullaryOp&lt;internal::equalspaced_op&lt;Scalar&gt;, PlainObject&gt; RandomAccessEqualSpacedReturnType;\n  /** \\internal the return type of MatrixBase::eigenvalues() */\n  typedef Matrix&lt;typename NumTraits&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt;::Real,\n                 internal::traits&lt;Derived&gt;::ColsAtCompileTime, 1&gt;\n      EigenvaluesReturnType;\n\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n  /** Copies \\a other into *this. \\returns a reference to *this. */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other);\n\n  /** Special case of the template operator=, in order to prevent the compiler\n   * from generating a default operator= (issue hit with g++ 4.1)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const DenseBase&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator+=(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator-=(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const ReturnByValue&lt;OtherDerived&gt;&amp; func);\n\n  /** \\internal\n   * Copies \\a other into *this without evaluating other. \\returns a reference to *this. */\n  template &lt;typename OtherDerived&gt;\n  /** \\deprecated */\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC Derived&amp; lazyAssign(const DenseBase&lt;OtherDerived&gt;&amp; other);\n\n  EIGEN_DEVICE_FUNC CommaInitializer&lt;Derived&gt; operator&lt;&lt;(const Scalar&amp; s);\n\n  template &lt;unsigned int Added, unsigned int Removed&gt;\n  /** \\deprecated it now returns \\c *this */\n  EIGEN_DEPRECATED const Derived&amp; flagged() const {\n    return derived();\n  }\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC CommaInitializer&lt;Derived&gt; operator&lt;&lt;(const DenseBase&lt;OtherDerived&gt;&amp; other);\n\n  typedef Transpose&lt;Derived&gt; TransposeReturnType;\n  EIGEN_DEVICE_FUNC TransposeReturnType transpose();\n  typedef Transpose&lt;const Derived&gt; ConstTransposeReturnType;\n  EIGEN_DEVICE_FUNC const ConstTransposeReturnType transpose() const;\n  EIGEN_DEVICE_FUNC void transposeInPlace();\n\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(Index rows, Index cols, const Scalar&amp; value);\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(Index size, const Scalar&amp; value);\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Constant(const Scalar&amp; value);\n\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t, Index size,\n                                                                                            const Scalar&amp; low,\n                                                                                            const Scalar&amp; high);\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Sequential_t,\n                                                                                            const Scalar&amp; low,\n                                                                                            const Scalar&amp; high);\n\n  EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(Index size, const Scalar&amp; low,\n                                                                           const Scalar&amp; high);\n  EIGEN_DEVICE_FUNC static const RandomAccessLinSpacedReturnType LinSpaced(const Scalar&amp; low, const Scalar&amp; high);\n\n  EIGEN_DEVICE_FUNC static const RandomAccessEqualSpacedReturnType EqualSpaced(Index size, const Scalar&amp; low,\n                                                                               const Scalar&amp; step);\n  EIGEN_DEVICE_FUNC static const RandomAccessEqualSpacedReturnType EqualSpaced(const Scalar&amp; low, const Scalar&amp; step);\n\n  template &lt;typename CustomNullaryOp&gt;\n  EIGEN_DEVICE_FUNC static const CwiseNullaryOp&lt;CustomNullaryOp, PlainObject&gt; NullaryExpr(Index rows, Index cols,\n                                                                                          const CustomNullaryOp&amp; func);\n  template &lt;typename CustomNullaryOp&gt;\n  EIGEN_DEVICE_FUNC static const CwiseNullaryOp&lt;CustomNullaryOp, PlainObject&gt; NullaryExpr(Index size,\n                                                                                          const CustomNullaryOp&amp; func);\n  template &lt;typename CustomNullaryOp&gt;\n  EIGEN_DEVICE_FUNC static const CwiseNullaryOp&lt;CustomNullaryOp, PlainObject&gt; NullaryExpr(const CustomNullaryOp&amp; func);\n\n  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero(Index size);\n  EIGEN_DEVICE_FUNC static const ZeroReturnType Zero();\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones(Index size);\n  EIGEN_DEVICE_FUNC static const ConstantReturnType Ones();\n\n  EIGEN_DEVICE_FUNC void fill(const Scalar&amp; value);\n  EIGEN_DEVICE_FUNC Derived&amp; setConstant(const Scalar&amp; value);\n  EIGEN_DEVICE_FUNC Derived&amp; setLinSpaced(Index size, const Scalar&amp; low, const Scalar&amp; high);\n  EIGEN_DEVICE_FUNC Derived&amp; setLinSpaced(const Scalar&amp; low, const Scalar&amp; high);\n  EIGEN_DEVICE_FUNC Derived&amp; setEqualSpaced(Index size, const Scalar&amp; low, const Scalar&amp; step);\n  EIGEN_DEVICE_FUNC Derived&amp; setEqualSpaced(const Scalar&amp; low, const Scalar&amp; step);\n  EIGEN_DEVICE_FUNC Derived&amp; setZero();\n  EIGEN_DEVICE_FUNC Derived&amp; setOnes();\n  EIGEN_DEVICE_FUNC Derived&amp; setRandom();\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC bool isApprox(const DenseBase&lt;OtherDerived&gt;&amp; other,\n                                  const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  EIGEN_DEVICE_FUNC bool isMuchSmallerThan(const RealScalar&amp; other,\n                                           const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC bool isMuchSmallerThan(const DenseBase&lt;OtherDerived&gt;&amp; other,\n                                           const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  EIGEN_DEVICE_FUNC bool isApproxToConstant(const Scalar&amp; value,\n                                            const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  EIGEN_DEVICE_FUNC bool isConstant(const Scalar&amp; value,\n                                    const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  EIGEN_DEVICE_FUNC bool isZero(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  EIGEN_DEVICE_FUNC bool isOnes(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  EIGEN_DEVICE_FUNC inline bool hasNaN() const;\n  EIGEN_DEVICE_FUNC inline bool allFinite() const;\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator*=(const Scalar&amp; other);\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator/=(const Scalar&amp; other);\n\n  typedef internal::add_const_on_value_type_t&lt;typename internal::eval&lt;Derived&gt;::type&gt; EvalReturnType;\n  /** \\returns the matrix or vector obtained by evaluating this expression.\n   *\n   * Notice that in the case of a plain matrix or vector (not an expression) this function just returns\n   * a const reference, in order to avoid a useless copy.\n   *\n   * \\warning Be careful with eval() and the auto C++ keyword, as detailed in this \\link TopicPitfalls_auto_keyword page\n   * \\endlink.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EvalReturnType eval() const {\n    // Even though MSVC does not honor strong inlining when the return type\n    // is a dynamic matrix, we desperately need strong inlining for fixed\n    // size types on MSVC.\n    return typename internal::eval&lt;Derived&gt;::type(derived());\n  }\n\n  /** swaps *this with the expression \\a other.\n   *\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT(!OtherDerived::IsPlainObjectBase, THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);\n    eigen_assert(rows() == other.rows() &amp;&amp; cols() == other.cols());\n    call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op&lt;Scalar&gt;());\n  }\n\n  /** swaps *this with the matrix or array \\a other.\n   *\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(PlainObjectBase&lt;OtherDerived&gt;&amp; other) {\n    eigen_assert(rows() == other.rows() &amp;&amp; cols() == other.cols());\n    call_assignment(derived(), other.derived(), internal::swap_assign_op&lt;Scalar&gt;());\n  }\n\n  EIGEN_DEVICE_FUNC inline const NestByValue&lt;Derived&gt; nestByValue() const;\n  EIGEN_DEVICE_FUNC inline const ForceAlignedAccess&lt;Derived&gt; forceAlignedAccess() const;\n  EIGEN_DEVICE_FUNC inline ForceAlignedAccess&lt;Derived&gt; forceAlignedAccess();\n  template &lt;bool Enable&gt;\n  EIGEN_DEVICE_FUNC inline const std::conditional_t&lt;Enable, ForceAlignedAccess&lt;Derived&gt;, Derived&amp;&gt;\n  forceAlignedAccessIf() const;\n  template &lt;bool Enable&gt;\n  EIGEN_DEVICE_FUNC inline std::conditional_t&lt;Enable, ForceAlignedAccess&lt;Derived&gt;, Derived&amp;&gt; forceAlignedAccessIf();\n\n  EIGEN_DEVICE_FUNC Scalar sum() const;\n  EIGEN_DEVICE_FUNC Scalar mean() const;\n  EIGEN_DEVICE_FUNC Scalar trace() const;\n\n  EIGEN_DEVICE_FUNC Scalar prod() const;\n\n  template &lt;int NaNPropagation&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar minCoeff() const;\n  template &lt;int NaNPropagation&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar maxCoeff() const;\n\n  // By default, the fastest version with undefined NaN propagation semantics is\n  // used.\n  // TODO(rmlarsen): Replace with default template argument when we move to\n  // c++11 or beyond.\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar minCoeff() const {\n    return minCoeff&lt;PropagateFast&gt;();\n  }\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar maxCoeff() const {\n    return maxCoeff&lt;PropagateFast&gt;();\n  }\n\n  template &lt;int NaNPropagation, typename IndexType&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar minCoeff(IndexType* row, IndexType* col) const;\n  template &lt;int NaNPropagation, typename IndexType&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar maxCoeff(IndexType* row, IndexType* col) const;\n  template &lt;int NaNPropagation, typename IndexType&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar minCoeff(IndexType* index) const;\n  template &lt;int NaNPropagation, typename IndexType&gt;\n  EIGEN_DEVICE_FUNC typename internal::traits&lt;Derived&gt;::Scalar maxCoeff(IndexType* index) const;\n\n  // TODO(rmlarsen): Replace these methods with a default template argument.\n  template &lt;typename IndexType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar minCoeff(IndexType* row, IndexType* col) const {\n    return minCoeff&lt;PropagateFast&gt;(row, col);\n  }\n  template &lt;typename IndexType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar maxCoeff(IndexType* row, IndexType* col) const {\n    return maxCoeff&lt;PropagateFast&gt;(row, col);\n  }\n  template &lt;typename IndexType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar minCoeff(IndexType* index) const {\n    return minCoeff&lt;PropagateFast&gt;(index);\n  }\n  template &lt;typename IndexType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar maxCoeff(IndexType* index) const {\n    return maxCoeff&lt;PropagateFast&gt;(index);\n  }\n\n  template &lt;typename BinaryOp&gt;\n  EIGEN_DEVICE_FUNC Scalar redux(const BinaryOp&amp; func) const;\n\n  template &lt;typename Visitor&gt;\n  EIGEN_DEVICE_FUNC void visit(Visitor&amp; func) const;\n\n  /** \\returns a WithFormat proxy object allowing to print a matrix the with given\n   * format \\a fmt.\n   *\n   * See class IOFormat for some examples.\n   *\n   * \\sa class IOFormat, class WithFormat\n   */\n  inline const WithFormat&lt;Derived&gt; format(const IOFormat&amp; fmt) const { return WithFormat&lt;Derived&gt;(derived(), fmt); }\n\n  /** \\returns the unique coefficient of a 1x1 expression */\n  EIGEN_DEVICE_FUNC CoeffReturnType value() const {\n    EIGEN_STATIC_ASSERT_SIZE_1x1(Derived) eigen_assert(this-&gt;rows() == 1 &amp;&amp; this-&gt;cols() == 1);\n    return derived().coeff(0, 0);\n  }\n\n  EIGEN_DEVICE_FUNC bool all() const;\n  EIGEN_DEVICE_FUNC bool any() const;\n  EIGEN_DEVICE_FUNC Index count() const;\n\n  typedef VectorwiseOp&lt;Derived, Horizontal&gt; RowwiseReturnType;\n  typedef const VectorwiseOp&lt;const Derived, Horizontal&gt; ConstRowwiseReturnType;\n  typedef VectorwiseOp&lt;Derived, Vertical&gt; ColwiseReturnType;\n  typedef const VectorwiseOp&lt;const Derived, Vertical&gt; ConstColwiseReturnType;\n\n  /** \\returns a VectorwiseOp wrapper of *this for broadcasting and partial reductions\n   *\n   * Example: \\include MatrixBase_rowwise.cpp\n   * Output: \\verbinclude MatrixBase_rowwise.out\n   *\n   * \\sa colwise(), class VectorwiseOp, \\ref TutorialReductionsVisitorsBroadcasting\n   */\n  // Code moved here due to a CUDA compiler bug\n  EIGEN_DEVICE_FUNC inline ConstRowwiseReturnType rowwise() const { return ConstRowwiseReturnType(derived()); }\n  EIGEN_DEVICE_FUNC RowwiseReturnType rowwise();\n\n  /** \\returns a VectorwiseOp wrapper of *this broadcasting and partial reductions\n   *\n   * Example: \\include MatrixBase_colwise.cpp\n   * Output: \\verbinclude MatrixBase_colwise.out\n   *\n   * \\sa rowwise(), class VectorwiseOp, \\ref TutorialReductionsVisitorsBroadcasting\n   */\n  EIGEN_DEVICE_FUNC inline ConstColwiseReturnType colwise() const { return ConstColwiseReturnType(derived()); }\n  EIGEN_DEVICE_FUNC ColwiseReturnType colwise();\n\n  typedef CwiseNullaryOp&lt;internal::scalar_random_op&lt;Scalar&gt;, PlainObject&gt; RandomReturnType;\n  static const RandomReturnType Random(Index rows, Index cols);\n  static const RandomReturnType Random(Index size);\n  static const RandomReturnType Random();\n\n  template &lt;typename ThenDerived, typename ElseDerived&gt;\n  inline EIGEN_DEVICE_FUNC\n      CwiseTernaryOp&lt;internal::scalar_boolean_select_op&lt;typename DenseBase&lt;ThenDerived&gt;::Scalar,\n                                                        typename DenseBase&lt;ElseDerived&gt;::Scalar, Scalar&gt;,\n                     ThenDerived, ElseDerived, Derived&gt;\n      select(const DenseBase&lt;ThenDerived&gt;&amp; thenMatrix, const DenseBase&lt;ElseDerived&gt;&amp; elseMatrix) const;\n\n  template &lt;typename ThenDerived&gt;\n  inline EIGEN_DEVICE_FUNC\n      CwiseTernaryOp&lt;internal::scalar_boolean_select_op&lt;typename DenseBase&lt;ThenDerived&gt;::Scalar,\n                                                        typename DenseBase&lt;ThenDerived&gt;::Scalar, Scalar&gt;,\n                     ThenDerived, typename DenseBase&lt;ThenDerived&gt;::ConstantReturnType, Derived&gt;\n      select(const DenseBase&lt;ThenDerived&gt;&amp; thenMatrix, const typename DenseBase&lt;ThenDerived&gt;::Scalar&amp; elseScalar) const;\n\n  template &lt;typename ElseDerived&gt;\n  inline EIGEN_DEVICE_FUNC\n      CwiseTernaryOp&lt;internal::scalar_boolean_select_op&lt;typename DenseBase&lt;ElseDerived&gt;::Scalar,\n                                                        typename DenseBase&lt;ElseDerived&gt;::Scalar, Scalar&gt;,\n                     typename DenseBase&lt;ElseDerived&gt;::ConstantReturnType, ElseDerived, Derived&gt;\n      select(const typename DenseBase&lt;ElseDerived&gt;::Scalar&amp; thenScalar, const DenseBase&lt;ElseDerived&gt;&amp; elseMatrix) const;\n\n  template &lt;int p&gt;\n  RealScalar lpNorm() const;\n\n  template &lt;int RowFactor, int ColFactor&gt;\n  EIGEN_DEVICE_FUNC const Replicate&lt;Derived, RowFactor, ColFactor&gt; replicate() const;\n  /**\n   * \\return an expression of the replication of \\c *this\n   *\n   * Example: \\include MatrixBase_replicate_int_int.cpp\n   * Output: \\verbinclude MatrixBase_replicate_int_int.out\n   *\n   * \\sa VectorwiseOp::replicate(), DenseBase::replicate&lt;int,int&gt;(), class Replicate\n   */\n  // Code moved here due to a CUDA compiler bug\n  EIGEN_DEVICE_FUNC const Replicate&lt;Derived, Dynamic, Dynamic&gt; replicate(Index rowFactor, Index colFactor) const {\n    return Replicate&lt;Derived, Dynamic, Dynamic&gt;(derived(), rowFactor, colFactor);\n  }\n\n  typedef Reverse&lt;Derived, BothDirections&gt; ReverseReturnType;\n  typedef const Reverse&lt;const Derived, BothDirections&gt; ConstReverseReturnType;\n  EIGEN_DEVICE_FUNC ReverseReturnType reverse();\n  /** This is the const version of reverse(). */\n  // Code moved here due to a CUDA compiler bug\n  EIGEN_DEVICE_FUNC ConstReverseReturnType reverse() const { return ConstReverseReturnType(derived()); }\n  EIGEN_DEVICE_FUNC void reverseInPlace();\n\n#ifdef EIGEN_PARSED_BY_DOXYGEN\n  /** STL-like &lt;a href=&quot;https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator&quot;&gt;RandomAccessIterator&lt;/a&gt;\n   * iterator type as returned by the begin() and end() methods.\n   */\n  typedef random_access_iterator_type iterator;\n  /** This is the const version of iterator (aka read-only) */\n  typedef random_access_iterator_type const_iterator;\n#else\n  typedef std::conditional_t&lt;(Flags &amp; DirectAccessBit) == DirectAccessBit,\n                             internal::pointer_based_stl_iterator&lt;Derived&gt;,\n                             internal::generic_randaccess_stl_iterator&lt;Derived&gt; &gt;\n      iterator_type;\n\n  typedef std::conditional_t&lt;(Flags &amp; DirectAccessBit) == DirectAccessBit,\n                             internal::pointer_based_stl_iterator&lt;const Derived&gt;,\n                             internal::generic_randaccess_stl_iterator&lt;const Derived&gt; &gt;\n      const_iterator_type;\n\n  // Stl-style iterators are supported only for vectors.\n\n  typedef std::conditional_t&lt;IsVectorAtCompileTime, iterator_type, void&gt; iterator;\n\n  typedef std::conditional_t&lt;IsVectorAtCompileTime, const_iterator_type, void&gt; const_iterator;\n#endif\n\n  inline iterator begin();\n  inline const_iterator begin() const;\n  inline const_iterator cbegin() const;\n  inline iterator end();\n  inline const_iterator end() const;\n  inline const_iterator cend() const;\n\n#define EIGEN_CURRENT_STORAGE_BASE_CLASS Eigen::DenseBase\n#define EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL\n#define EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF(COND)\n#define EIGEN_DOC_UNARY_ADDONS(X, Y)\n#include &quot;../plugins/CommonCwiseUnaryOps.inc&quot;\n#include &quot;../plugins/BlockMethods.inc&quot;\n#include &quot;../plugins/IndexedViewMethods.inc&quot;\n#include &quot;../plugins/ReshapedMethods.inc&quot;\n#ifdef EIGEN_DENSEBASE_PLUGIN\n#include EIGEN_DENSEBASE_PLUGIN\n#endif\n#undef EIGEN_CURRENT_STORAGE_BASE_CLASS\n#undef EIGEN_DOC_BLOCK_ADDONS_NOT_INNER_PANEL\n#undef EIGEN_DOC_BLOCK_ADDONS_INNER_PANEL_IF\n#undef EIGEN_DOC_UNARY_ADDONS\n\n  // disable the use of evalTo for dense objects with a nice compilation error\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void evalTo(Dest&amp;) const {\n    EIGEN_STATIC_ASSERT((internal::is_same&lt;Dest, void&gt;::value),\n                        THE_EVAL_EVALTO_FUNCTION_SHOULD_NEVER_BE_CALLED_FOR_DENSE_OBJECTS);\n  }\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(DenseBase)\n  /** Default constructor. Do nothing. */\n#ifdef EIGEN_INTERNAL_DEBUGGING\n  EIGEN_DEVICE_FUNC constexpr DenseBase() {\n    /* Just checks for self-consistency of the flags.\n     * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down\n     */\n    EIGEN_STATIC_ASSERT(\n        (internal::check_implication(MaxRowsAtCompileTime == 1 &amp;&amp; MaxColsAtCompileTime != 1, int(IsRowMajor)) &amp;&amp;\n         internal::check_implication(MaxColsAtCompileTime == 1 &amp;&amp; MaxRowsAtCompileTime != 1, int(!IsRowMajor))),\n        INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)\n  }\n#else\n  EIGEN_DEVICE_FUNC constexpr DenseBase() = default;\n#endif\n\n private:\n  EIGEN_DEVICE_FUNC explicit DenseBase(int);\n  EIGEN_DEVICE_FUNC DenseBase(int, int);\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC explicit DenseBase(const DenseBase&lt;OtherDerived&gt;&amp;);\n};\n\n/** Free-function swap.\n */\ntemplate &lt;typename DerivedA, typename DerivedB&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE\n    // Use forwarding references to capture all combinations of cv-qualified l+r-value cases.\n    std::enable_if_t&lt;std::is_base_of&lt;DenseBase&lt;std::decay_t&lt;DerivedA&gt;&gt;, std::decay_t&lt;DerivedA&gt;&gt;::value &amp;&amp;\n                         std::is_base_of&lt;DenseBase&lt;std::decay_t&lt;DerivedB&gt;&gt;, std::decay_t&lt;DerivedB&gt;&gt;::value,\n                     void&gt;\n    swap(DerivedA&amp;&amp; a, DerivedB&amp;&amp; b) {\n  a.swap(b);\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_DENSEBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2009 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2010-2013 Hauke Heibel &lt;hauke.heibel@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_MATRIXSTORAGE_H\n#define EIGEN_MATRIXSTORAGE_H\n\n#ifdef EIGEN_DENSE_STORAGE_CTOR_PLUGIN\n#define EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(X) \\\n  X;                                                \\\n  EIGEN_DENSE_STORAGE_CTOR_PLUGIN;\n#else\n#define EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(X)\n#endif\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n#if defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)\n#define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)\n#else\n#define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)                                        \\\n  eigen_assert((is_constant_evaluated() || (std::uintptr_t(array) % Alignment == 0)) &amp;&amp;     \\\n               &quot;this assertion is explained here: &quot;                                         \\\n               &quot;http://eigen.tuxfamily.org/dox-devel/group__TopicUnalignedArrayAssert.html&quot; \\\n               &quot; **** READ THIS WEB PAGE !!! ****&quot;);\n#endif\n\n#if EIGEN_STACK_ALLOCATION_LIMIT\n#define EIGEN_MAKE_STACK_ALLOCATION_ASSERT(X) \\\n  EIGEN_STATIC_ASSERT(X &lt;= EIGEN_STACK_ALLOCATION_LIMIT, OBJECT_ALLOCATED_ON_STACK_IS_TOO_BIG)\n#else\n#define EIGEN_MAKE_STACK_ALLOCATION_ASSERT(X)\n#endif\n\n/** \\internal\n * Static array. If the MatrixOrArrayOptions require auto-alignment, the array will be automatically aligned:\n * to 16 bytes boundary if the total size is a multiple of 16 bytes.\n */\n\ntemplate &lt;typename T, int Size, int MatrixOrArrayOptions,\n          int Alignment = (MatrixOrArrayOptions &amp; DontAlign) ? 0 : compute_default_alignment&lt;T, Size&gt;::value&gt;\nstruct plain_array {\n  EIGEN_ALIGN_TO_BOUNDARY(Alignment) T array[Size];\n#if defined(EIGEN_NO_DEBUG) || defined(EIGEN_TESTING_PLAINOBJECT_CTOR)\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;\n#else\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() {\n    EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(Alignment)\n    EIGEN_MAKE_STACK_ALLOCATION_ASSERT(Size * sizeof(T))\n  }\n#endif\n};\n\ntemplate &lt;typename T, int Size, int MatrixOrArrayOptions&gt;\nstruct plain_array&lt;T, Size, MatrixOrArrayOptions, 0&gt; {\n  T array[Size];\n#if defined(EIGEN_NO_DEBUG) || defined(EIGEN_TESTING_PLAINOBJECT_CTOR)\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;\n#else\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() { EIGEN_MAKE_STACK_ALLOCATION_ASSERT(Size * sizeof(T)) }\n#endif\n};\n\ntemplate &lt;typename T, int MatrixOrArrayOptions, int Alignment&gt;\nstruct plain_array&lt;T, 0, MatrixOrArrayOptions, Alignment&gt; {\n  T array[1];\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr plain_array() = default;\n};\n\ntemplate &lt;typename T, int Size, int Options, int Alignment&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap_plain_array(plain_array&lt;T, Size, Options, Alignment&gt;&amp; a,\n                                                                      plain_array&lt;T, Size, Options, Alignment&gt;&amp; b,\n                                                                      Index a_size, Index b_size) {\n  Index common_size = numext::mini(a_size, b_size);\n  std::swap_ranges(a.array, a.array + common_size, b.array);\n  if (a_size &gt; b_size)\n    smart_copy(a.array + common_size, a.array + a_size, b.array + common_size);\n  else if (b_size &gt; a_size)\n    smart_copy(b.array + common_size, b.array + b_size, a.array + common_size);\n}\n\ntemplate &lt;typename T, int Size, int Rows, int Cols, int Options&gt;\nclass DenseStorage_impl {\n  plain_array&lt;T, Size, Options&gt; m_data;\n\n public:\n#ifndef EIGEN_DENSE_STORAGE_CTOR_PLUGIN\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp;) = default;\n#else\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)\n    smart_copy(other.m_data.array, other.m_data.array + Size, m_data.array);\n  }\n#endif\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) {\n    numext::swap(m_data, other.m_data);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/,\n                                                                          Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }\n};\ntemplate &lt;typename T, int Size, int Cols, int Options&gt;\nclass DenseStorage_impl&lt;T, Size, Dynamic, Cols, Options&gt; {\n  plain_array&lt;T, Size, Options&gt; m_data;\n  Index m_rows = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_rows(other.m_rows) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index /*cols*/)\n      : m_rows(rows) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    EIGEN_UNUSED_VARIABLE(size)\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n    m_rows = other.m_rows;\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) {\n    swap_plain_array(m_data, other.m_data, size(), other.size());\n    numext::swap(m_rows, other.m_rows);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index /*cols*/) {\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index /*cols*/) {\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }\n};\ntemplate &lt;typename T, int Size, int Rows, int Options&gt;\nclass DenseStorage_impl&lt;T, Size, Rows, Dynamic, Options&gt; {\n  plain_array&lt;T, Size, Options&gt; m_data;\n  Index m_cols = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_cols(other.m_cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index /*rows*/, Index cols)\n      : m_cols(cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    EIGEN_UNUSED_VARIABLE(size)\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n    m_cols = other.m_cols;\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) {\n    swap_plain_array(m_data, other.m_data, size(), other.size());\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/, Index cols) {\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index cols) {\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }\n};\ntemplate &lt;typename T, int Size, int Options&gt;\nclass DenseStorage_impl&lt;T, Size, Dynamic, Dynamic, Options&gt; {\n  plain_array&lt;T, Size, Options&gt; m_data;\n  Index m_rows = 0;\n  Index m_cols = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_rows(other.m_rows), m_cols(other.m_cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index cols)\n      : m_rows(rows), m_cols(cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    EIGEN_UNUSED_VARIABLE(size)\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    smart_copy(other.m_data.array, other.m_data.array + other.size(), m_data.array);\n    m_rows = other.m_rows;\n    m_cols = other.m_cols;\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) {\n    swap_plain_array(m_data, other.m_data, size(), other.size());\n    numext::swap(m_rows, other.m_rows);\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index cols) {\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index cols) {\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data.array; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data.array; }\n};\n// null matrix variants\ntemplate &lt;typename T, int Rows, int Cols, int Options&gt;\nclass DenseStorage_impl&lt;T, 0, Rows, Cols, Options&gt; {\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp;) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/,\n                                                                          Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index /*cols*/) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }\n};\ntemplate &lt;typename T, int Cols, int Options&gt;\nclass DenseStorage_impl&lt;T, 0, Dynamic, Cols, Options&gt; {\n  Index m_rows = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index rows, Index /*cols*/)\n      : m_rows(rows) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_rows, other.m_rows);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index /*cols*/) {\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index /*cols*/) {\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }\n};\ntemplate &lt;typename T, int Rows, int Options&gt;\nclass DenseStorage_impl&lt;T, 0, Rows, Dynamic, Options&gt; {\n  Index m_cols = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index /*rows*/, Index cols)\n      : m_cols(cols) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index /*rows*/, Index cols) {\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index /*rows*/, Index cols) {\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }\n};\ntemplate &lt;typename T, int Options&gt;\nclass DenseStorage_impl&lt;T, 0, Dynamic, Dynamic, Options&gt; {\n  Index m_rows = 0;\n  Index m_cols = 0;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index /*size*/, Index rows, Index cols)\n      : m_rows(rows), m_cols(cols) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_rows, other.m_rows);\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index /*size*/, Index rows, Index cols) {\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index /*size*/, Index rows, Index cols) {\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return nullptr; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return nullptr; }\n};\n// fixed-size matrix with dynamic memory allocation not currently supported\ntemplate &lt;typename T, int Rows, int Cols, int Options&gt;\nclass DenseStorage_impl&lt;T, Dynamic, Rows, Cols, Options&gt; {};\n// dynamic-sized variants\ntemplate &lt;typename T, int Cols, int Options&gt;\nclass DenseStorage_impl&lt;T, Dynamic, Dynamic, Cols, Options&gt; {\n  static constexpr bool Align = (Options &amp; DontAlign) == 0;\n  T* m_data = nullptr;\n  Index m_rows = 0;\n\n public:\n  static constexpr int Size = Dynamic;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(other.size())), m_rows(other.m_rows) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index /*cols*/)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(size)), m_rows(rows) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&amp;&amp; other) noexcept\n      : m_data(other.m_data), m_rows(other.m_rows) {\n    other.m_data = nullptr;\n    other.m_rows = 0;\n  }\n  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, size()); }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    resize(other.size(), other.rows(), other.cols());\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(DenseStorage_impl&amp;&amp; other) noexcept {\n    this-&gt;swap(other);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_data, other.m_data);\n    numext::swap(m_rows, other.m_rows);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index rows, Index /*cols*/) {\n    m_data = conditional_aligned_realloc_new_auto&lt;T, Align&gt;(m_data, size, this-&gt;size());\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index rows, Index /*cols*/) {\n    Index oldSize = this-&gt;size();\n    if (oldSize != size) {\n      conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, oldSize);\n      m_data = conditional_aligned_new_auto&lt;T, Align&gt;(size);\n      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    }\n    m_rows = rows;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * Cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }\n};\ntemplate &lt;typename T, int Rows, int Options&gt;\nclass DenseStorage_impl&lt;T, Dynamic, Rows, Dynamic, Options&gt; {\n  static constexpr bool Align = (Options &amp; DontAlign) == 0;\n  T* m_data = nullptr;\n  Index m_cols = 0;\n\n public:\n  static constexpr int Size = Dynamic;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(other.size())), m_cols(other.m_cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index /*rows*/, Index cols)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(size)), m_cols(cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&amp;&amp; other) noexcept\n      : m_data(other.m_data), m_cols(other.m_cols) {\n    other.m_data = nullptr;\n    other.m_cols = 0;\n  }\n  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, size()); }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    resize(other.size(), other.rows(), other.cols());\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(DenseStorage_impl&amp;&amp; other) noexcept {\n    this-&gt;swap(other);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_data, other.m_data);\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index /*rows*/, Index cols) {\n    m_data = conditional_aligned_realloc_new_auto&lt;T, Align&gt;(m_data, size, this-&gt;size());\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index /*rows*/, Index cols) {\n    Index oldSize = this-&gt;size();\n    if (oldSize != size) {\n      conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, oldSize);\n      m_data = conditional_aligned_new_auto&lt;T, Align&gt;(size);\n      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    }\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return Rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return Rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }\n};\ntemplate &lt;typename T, int Options&gt;\nclass DenseStorage_impl&lt;T, Dynamic, Dynamic, Dynamic, Options&gt; {\n  static constexpr bool Align = (Options &amp; DontAlign) == 0;\n  T* m_data = nullptr;\n  Index m_rows = 0;\n  Index m_cols = 0;\n\n public:\n  static constexpr int Size = Dynamic;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(const DenseStorage_impl&amp; other)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(other.size())), m_rows(other.m_rows), m_cols(other.m_cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = other.size())\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(Index size, Index rows, Index cols)\n      : m_data(conditional_aligned_new_auto&lt;T, Align&gt;(size)), m_rows(rows), m_cols(cols) {\n    EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl(DenseStorage_impl&amp;&amp; other) noexcept\n      : m_data(other.m_data), m_rows(other.m_rows), m_cols(other.m_cols) {\n    other.m_data = nullptr;\n    other.m_rows = 0;\n    other.m_cols = 0;\n  }\n  EIGEN_DEVICE_FUNC ~DenseStorage_impl() { conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, size()); }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(const DenseStorage_impl&amp; other) {\n    resize(other.size(), other.rows(), other.cols());\n    smart_copy(other.m_data, other.m_data + other.size(), m_data);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage_impl&amp; operator=(DenseStorage_impl&amp;&amp; other) noexcept {\n    this-&gt;swap(other);\n    return *this;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void swap(DenseStorage_impl&amp; other) noexcept {\n    numext::swap(m_data, other.m_data);\n    numext::swap(m_rows, other.m_rows);\n    numext::swap(m_cols, other.m_cols);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void conservativeResize(Index size, Index rows, Index cols) {\n    m_data = conditional_aligned_realloc_new_auto&lt;T, Align&gt;(m_data, size, this-&gt;size());\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index size, Index rows, Index cols) {\n    Index oldSize = this-&gt;size();\n    if (oldSize != size) {\n      conditional_aligned_delete_auto&lt;T, Align&gt;(m_data, oldSize);\n      m_data = conditional_aligned_new_auto&lt;T, Align&gt;(size);\n      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})\n    }\n    m_rows = rows;\n    m_cols = cols;\n  }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index rows() const { return m_rows; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index cols() const { return m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Index size() const { return m_rows * m_cols; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr T* data() { return m_data; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const T* data() const { return m_data; }\n};\ntemplate &lt;typename T, int Size, int Rows, int Cols&gt;\nstruct use_default_move {\n  static constexpr bool DynamicObject = Size == Dynamic;\n  static constexpr bool TrivialObject =\n      (!NumTraits&lt;T&gt;::RequireInitialization) &amp;&amp; (Rows &gt;= 0) &amp;&amp; (Cols &gt;= 0) &amp;&amp; (Size == Rows * Cols);\n  static constexpr bool value = DynamicObject || TrivialObject;\n};\n}  // end namespace internal\n\n/** \\internal\n *\n * \\class DenseStorage_impl\n * \\ingroup Core_Module\n *\n * \\brief Stores the data of a matrix\n *\n * This class stores the data of fixed-size, dynamic-size or mixed matrices\n * in a way as compact as possible.\n *\n * \\sa Matrix\n */\ntemplate &lt;typename T, int Size, int Rows, int Cols, int Options,\n          bool Trivial = internal::use_default_move&lt;T, Size, Rows, Cols&gt;::value&gt;\nclass DenseStorage : public internal::DenseStorage_impl&lt;T, Size, Rows, Cols, Options&gt; {\n  using Base = internal::DenseStorage_impl&lt;T, Size, Rows, Cols, Options&gt;;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(const DenseStorage&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(Index size, Index rows, Index cols)\n      : Base(size, rows, cols) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage&amp; operator=(const DenseStorage&amp;) = default;\n  // if DenseStorage meets the requirements of use_default_move, then use the move construction and move assignment\n  // operation defined in DenseStorage_impl, or the compiler-generated version if none is defined\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(DenseStorage&amp;&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage&amp; operator=(DenseStorage&amp;&amp;) = default;\n};\ntemplate &lt;typename T, int Size, int Rows, int Cols, int Options&gt;\nclass DenseStorage&lt;T, Size, Rows, Cols, Options, false&gt;\n    : public internal::DenseStorage_impl&lt;T, Size, Rows, Cols, Options&gt; {\n  using Base = internal::DenseStorage_impl&lt;T, Size, Rows, Cols, Options&gt;;\n\n public:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage() = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(const DenseStorage&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(Index size, Index rows, Index cols)\n      : Base(size, rows, cols) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage&amp; operator=(const DenseStorage&amp;) = default;\n  // if DenseStorage does not meet the requirements of use_default_move, then defer to the copy construction and copy\n  // assignment behavior\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage(DenseStorage&amp;&amp; other)\n      : DenseStorage(static_cast&lt;const DenseStorage&amp;&gt;(other)) {}\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr DenseStorage&amp; operator=(DenseStorage&amp;&amp; other) {\n    *this = other;\n    return *this;\n  }\n};\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_MATRIX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2023 Charlie Schlosser &lt;cs.schlosser@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_DEVICEWRAPPER_H\n#define EIGEN_DEVICEWRAPPER_H\n\nnamespace Eigen {\ntemplate &lt;typename Derived, typename Device&gt;\nstruct DeviceWrapper {\n  using Base = EigenBase&lt;internal::remove_all_t&lt;Derived&gt;&gt;;\n  using Scalar = typename Derived::Scalar;\n\n  EIGEN_DEVICE_FUNC DeviceWrapper(Base&amp; xpr, Device&amp; device) : m_xpr(xpr.derived()), m_device(device) {}\n  EIGEN_DEVICE_FUNC DeviceWrapper(const Base&amp; xpr, Device&amp; device) : m_xpr(xpr.derived()), m_device(device) {}\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    using AssignOp = internal::assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;;\n    internal::call_assignment(*this, other.derived(), AssignOp());\n    return m_xpr;\n  }\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator+=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    using AddAssignOp = internal::add_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;;\n    internal::call_assignment(*this, other.derived(), AddAssignOp());\n    return m_xpr;\n  }\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator-=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    using SubAssignOp = internal::sub_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;;\n    internal::call_assignment(*this, other.derived(), SubAssignOp());\n    return m_xpr;\n  }\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; derived() { return m_xpr; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Device&amp; device() { return m_device; }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE NoAlias&lt;DeviceWrapper, EigenBase&gt; noalias() {\n    return NoAlias&lt;DeviceWrapper, EigenBase&gt;(*this);\n  }\n\n  Derived&amp; m_xpr;\n  Device&amp; m_device;\n};\n\nnamespace internal {\n\n// this is where we differentiate between lazy assignment and specialized kernels (e.g. matrix products)\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor, typename Device,\n          typename Kind = typename AssignmentKind&lt;typename evaluator_traits&lt;DstXprType&gt;::Shape,\n                                                  typename evaluator_traits&lt;SrcXprType&gt;::Shape&gt;::Kind,\n          typename EnableIf = void&gt;\nstruct AssignmentWithDevice;\n\n// unless otherwise specified, use the default product implementation\ntemplate &lt;typename DstXprType, typename Lhs, typename Rhs, int Options, typename Functor, typename Device,\n          typename Weak&gt;\nstruct AssignmentWithDevice&lt;DstXprType, Product&lt;Lhs, Rhs, Options&gt;, Functor, Device, Dense2Dense, Weak&gt; {\n  using SrcXprType = Product&lt;Lhs, Rhs, Options&gt;;\n  using Base = Assignment&lt;DstXprType, SrcXprType, Functor&gt;;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType&amp; dst, const SrcXprType&amp; src, const Functor&amp; func,\n                                                        Device&amp;) {\n    Base::run(dst, src, func);\n  }\n};\n\n// specialization for coeffcient-wise assignment\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor, typename Device, typename Weak&gt;\nstruct AssignmentWithDevice&lt;DstXprType, SrcXprType, Functor, Device, Dense2Dense, Weak&gt; {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(DstXprType&amp; dst, const SrcXprType&amp; src, const Functor&amp; func,\n                                                        Device&amp; device) {\n#ifndef EIGEN_NO_DEBUG\n    internal::check_for_aliasing(dst, src);\n#endif\n\n    call_dense_assignment_loop(dst, src, func, device);\n  }\n};\n\n// this allows us to use the default evaluation scheme if it is not specialized for the device\ntemplate &lt;typename Kernel, typename Device, int Traversal = Kernel::AssignmentTraits::Traversal,\n          int Unrolling = Kernel::AssignmentTraits::Unrolling&gt;\nstruct dense_assignment_loop_with_device {\n  using Base = dense_assignment_loop&lt;Kernel, Traversal, Unrolling&gt;;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void run(Kernel&amp; kernel, Device&amp;) { Base::run(kernel); }\n};\n\n// entry point for a generic expression with device\ntemplate &lt;typename Dst, typename Src, typename Func, typename Device&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_assignment_no_alias(DeviceWrapper&lt;Dst, Device&gt; dst,\n                                                                                    const Src&amp; src, const Func&amp; func) {\n  enum {\n    NeedToTranspose = ((int(Dst::RowsAtCompileTime) == 1 &amp;&amp; int(Src::ColsAtCompileTime) == 1) ||\n                       (int(Dst::ColsAtCompileTime) == 1 &amp;&amp; int(Src::RowsAtCompileTime) == 1)) &amp;&amp;\n                      int(Dst::SizeAtCompileTime) != 1\n  };\n\n  using ActualDstTypeCleaned = std::conditional_t&lt;NeedToTranspose, Transpose&lt;Dst&gt;, Dst&gt;;\n  using ActualDstType = std::conditional_t&lt;NeedToTranspose, Transpose&lt;Dst&gt;, Dst&amp;&gt;;\n  ActualDstType actualDst(dst.derived());\n\n  // TODO check whether this is the right place to perform these checks:\n  EIGEN_STATIC_ASSERT_LVALUE(Dst)\n  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned, Src)\n  EIGEN_CHECK_BINARY_COMPATIBILIY(Func, typename ActualDstTypeCleaned::Scalar, typename Src::Scalar);\n\n  // this provides a mechanism for specializing simple assignments, matrix products, etc\n  AssignmentWithDevice&lt;ActualDstTypeCleaned, Src, Func, Device&gt;::run(actualDst, src, func, dst.device());\n}\n\n// copy and pasted from AssignEvaluator except forward device to kernel\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor, typename Device&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR void call_dense_assignment_loop(DstXprType&amp; dst,\n                                                                                      const SrcXprType&amp; src,\n                                                                                      const Functor&amp; func,\n                                                                                      Device&amp; device) {\n  using DstEvaluatorType = evaluator&lt;DstXprType&gt;;\n  using SrcEvaluatorType = evaluator&lt;SrcXprType&gt;;\n\n  SrcEvaluatorType srcEvaluator(src);\n\n  // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,\n  // we need to resize the destination after the source evaluator has been created.\n  resize_if_allowed(dst, src, func);\n\n  DstEvaluatorType dstEvaluator(dst);\n\n  using Kernel = generic_dense_assignment_kernel&lt;DstEvaluatorType, SrcEvaluatorType, Functor&gt;;\n\n  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());\n\n  dense_assignment_loop_with_device&lt;Kernel, Device&gt;::run(kernel, device);\n}\n\n}  // namespace internal\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename Device&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper&lt;Derived, Device&gt; EigenBase&lt;Derived&gt;::device(Device&amp; device) {\n  return DeviceWrapper&lt;Derived, Device&gt;(derived(), device);\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename Device&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper&lt;const Derived, Device&gt; EigenBase&lt;Derived&gt;::device(\n    Device&amp; device) const {\n  return DeviceWrapper&lt;const Derived, Device&gt;(derived(), device);\n}\n}  // namespace Eigen\n#endif\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_EIGENBASE_H\n#define EIGEN_EIGENBASE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\class EigenBase\n * \\ingroup Core_Module\n *\n * Common base class for all classes T such that MatrixBase has an operator=(T) and a constructor MatrixBase(T).\n *\n * In other words, an EigenBase object is an object that can be copied into a MatrixBase.\n *\n * Besides MatrixBase-derived classes, this also includes special matrix classes such as diagonal matrices, etc.\n *\n * Notice that this class is trivial, it is only used to disambiguate overloaded functions.\n *\n * \\sa \\blank \\ref TopicClassHierarchy\n */\ntemplate &lt;typename Derived&gt;\nstruct EigenBase {\n  //   typedef typename internal::plain_matrix_type&lt;Derived&gt;::type PlainObject;\n\n  /** \\brief The interface type of indices\n   * \\details To change this, \\c \\#define the preprocessor symbol \\c EIGEN_DEFAULT_DENSE_INDEX_TYPE.\n   * \\sa StorageIndex, \\ref TopicPreprocessorDirectives.\n   * DEPRECATED: Since Eigen 3.3, its usage is deprecated. Use Eigen::Index instead.\n   * Deprecation is not marked with a doxygen comment because there are too many existing usages to add the deprecation\n   * attribute.\n   */\n  typedef Eigen::Index Index;\n\n  // FIXME is it needed?\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n\n  /** \\returns a reference to the derived object */\n  EIGEN_DEVICE_FUNC constexpr Derived&amp; derived() { return *static_cast&lt;Derived*&gt;(this); }\n  /** \\returns a const reference to the derived object */\n  EIGEN_DEVICE_FUNC constexpr const Derived&amp; derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n\n  EIGEN_DEVICE_FUNC inline constexpr Derived&amp; const_cast_derived() const {\n    return *static_cast&lt;Derived*&gt;(const_cast&lt;EigenBase*&gt;(this));\n  }\n  EIGEN_DEVICE_FUNC inline const Derived&amp; const_derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n\n  /** \\returns the number of rows. \\sa cols(), RowsAtCompileTime */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }\n  /** \\returns the number of columns. \\sa rows(), ColsAtCompileTime*/\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }\n  /** \\returns the number of coefficients, which is rows()*cols().\n   * \\sa rows(), cols(), SizeAtCompileTime. */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }\n\n  /** \\internal Don&#x27;t use it, but do the equivalent: \\code dst = *this; \\endcode */\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void evalTo(Dest&amp; dst) const {\n    derived().evalTo(dst);\n  }\n\n  /** \\internal Don&#x27;t use it, but do the equivalent: \\code dst += *this; \\endcode */\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void addTo(Dest&amp; dst) const {\n    // This is the default implementation,\n    // derived class can reimplement it in a more optimized way.\n    typename Dest::PlainObject res(rows(), cols());\n    evalTo(res);\n    dst += res;\n  }\n\n  /** \\internal Don&#x27;t use it, but do the equivalent: \\code dst -= *this; \\endcode */\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void subTo(Dest&amp; dst) const {\n    // This is the default implementation,\n    // derived class can reimplement it in a more optimized way.\n    typename Dest::PlainObject res(rows(), cols());\n    evalTo(res);\n    dst -= res;\n  }\n\n  /** \\internal Don&#x27;t use it, but do the equivalent: \\code dst.applyOnTheRight(*this); \\endcode */\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void applyThisOnTheRight(Dest&amp; dst) const {\n    // This is the default implementation,\n    // derived class can reimplement it in a more optimized way.\n    dst = dst * this-&gt;derived();\n  }\n\n  /** \\internal Don&#x27;t use it, but do the equivalent: \\code dst.applyOnTheLeft(*this); \\endcode */\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void applyThisOnTheLeft(Dest&amp; dst) const {\n    // This is the default implementation,\n    // derived class can reimplement it in a more optimized way.\n    dst = this-&gt;derived() * dst;\n  }\n\n  template &lt;typename Device&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper&lt;Derived, Device&gt; device(Device&amp; device);\n  template &lt;typename Device&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE DeviceWrapper&lt;const Derived, Device&gt; device(Device&amp; device) const;\n};\n\n/***************************************************************************\n * Implementation of matrix base methods\n ***************************************************************************/\n\n/** \\brief Copies the generic expression \\a other into *this.\n *\n * \\details The expression must provide a (templated) evalTo(Derived&amp; dst) const\n * function which does the actual job. In practice, this allows any user to write\n * its own special matrix without having to modify MatrixBase\n *\n * \\returns a reference to *this.\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Derived&amp; DenseBase&lt;Derived&gt;::operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Derived&amp; DenseBase&lt;Derived&gt;::operator+=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  call_assignment(derived(), other.derived(), internal::add_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n  return derived();\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Derived&amp; DenseBase&lt;Derived&gt;::operator-=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  call_assignment(derived(), other.derived(), internal::sub_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n  return derived();\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_EIGENBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2007-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_MAPBASE_H\n#define EIGEN_MAPBASE_H\n\n#define EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)                                                               \\\n  EIGEN_STATIC_ASSERT((int(internal::evaluator&lt;Derived&gt;::Flags) &amp; LinearAccessBit) || Derived::IsVectorAtCompileTime, \\\n                      YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT)\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\ingroup Core_Module\n *\n * \\brief Base class for dense Map and Block expression with direct access\n *\n * This base class provides the const low-level accessors (e.g. coeff, coeffRef) of dense\n * Map and Block objects with direct access.\n * Typical users do not have to directly deal with this class.\n *\n * This class can be extended by through the macro plugin \\c EIGEN_MAPBASE_PLUGIN.\n * See \\link TopicCustomizing_Plugins customizing Eigen \\endlink for details.\n *\n * The \\c Derived class has to provide the following two methods describing the memory layout:\n *  \\code Index innerStride() const; \\endcode\n *  \\code Index outerStride() const; \\endcode\n *\n * \\sa class Map, class Block\n */\ntemplate &lt;typename Derived&gt;\nclass MapBase&lt;Derived, ReadOnlyAccessors&gt; : public internal::dense_xpr_base&lt;Derived&gt;::type {\n public:\n  typedef typename internal::dense_xpr_base&lt;Derived&gt;::type Base;\n  enum {\n    RowsAtCompileTime = internal::traits&lt;Derived&gt;::RowsAtCompileTime,\n    ColsAtCompileTime = internal::traits&lt;Derived&gt;::ColsAtCompileTime,\n    InnerStrideAtCompileTime = internal::traits&lt;Derived&gt;::InnerStrideAtCompileTime,\n    SizeAtCompileTime = Base::SizeAtCompileTime\n  };\n\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n  typedef typename internal::packet_traits&lt;Scalar&gt;::type PacketScalar;\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n  typedef std::conditional_t&lt;bool(internal::is_lvalue&lt;Derived&gt;::value), Scalar*, const Scalar*&gt; PointerType;\n\n  using Base::derived;\n  //    using Base::RowsAtCompileTime;\n  //    using Base::ColsAtCompileTime;\n  //    using Base::SizeAtCompileTime;\n  using Base::Flags;\n  using Base::IsRowMajor;\n  using Base::IsVectorAtCompileTime;\n  using Base::MaxColsAtCompileTime;\n  using Base::MaxRowsAtCompileTime;\n  using Base::MaxSizeAtCompileTime;\n\n  using Base::coeff;\n  using Base::coeffRef;\n  using Base::cols;\n  using Base::eval;\n  using Base::lazyAssign;\n  using Base::rows;\n  using Base::size;\n\n  using Base::colStride;\n  using Base::innerStride;\n  using Base::outerStride;\n  using Base::rowStride;\n\n  // bug 217 - compile error on ICC 11.1\n  using Base::operator=;\n\n  typedef typename Base::CoeffReturnType CoeffReturnType;\n\n  /** \\copydoc DenseBase::rows() */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_rows.value(); }\n  /** \\copydoc DenseBase::cols() */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_cols.value(); }\n\n  /** Returns a pointer to the first coefficient of the matrix or vector.\n   *\n   * \\note When addressing this data, make sure to honor the strides returned by innerStride() and outerStride().\n   *\n   * \\sa innerStride(), outerStride()\n   */\n  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_data; }\n\n  /** \\copydoc PlainObjectBase::coeff(Index,Index) const */\n  EIGEN_DEVICE_FUNC inline const Scalar&amp; coeff(Index rowId, Index colId) const {\n    return m_data[colId * colStride() + rowId * rowStride()];\n  }\n\n  /** \\copydoc PlainObjectBase::coeff(Index) const */\n  EIGEN_DEVICE_FUNC inline const Scalar&amp; coeff(Index index) const {\n    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)\n    return m_data[index * innerStride()];\n  }\n\n  /** \\copydoc PlainObjectBase::coeffRef(Index,Index) const */\n  EIGEN_DEVICE_FUNC inline const Scalar&amp; coeffRef(Index rowId, Index colId) const {\n    return this-&gt;m_data[colId * colStride() + rowId * rowStride()];\n  }\n\n  /** \\copydoc PlainObjectBase::coeffRef(Index) const */\n  EIGEN_DEVICE_FUNC inline const Scalar&amp; coeffRef(Index index) const {\n    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)\n    return this-&gt;m_data[index * innerStride()];\n  }\n\n  /** \\internal */\n  template &lt;int LoadMode&gt;\n  inline PacketScalar packet(Index rowId, Index colId) const {\n    return internal::ploadt&lt;PacketScalar, LoadMode&gt;(m_data + (colId * colStride() + rowId * rowStride()));\n  }\n\n  /** \\internal */\n  template &lt;int LoadMode&gt;\n  inline PacketScalar packet(Index index) const {\n    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)\n    return internal::ploadt&lt;PacketScalar, LoadMode&gt;(m_data + index * innerStride());\n  }\n\n  /** \\internal Constructor for fixed size matrices or vectors */\n  EIGEN_DEVICE_FUNC explicit inline MapBase(PointerType dataPtr)\n      : m_data(dataPtr), m_rows(RowsAtCompileTime), m_cols(ColsAtCompileTime) {\n    EIGEN_STATIC_ASSERT_FIXED_SIZE(Derived)\n    checkSanity&lt;Derived&gt;();\n  }\n\n  /** \\internal Constructor for dynamically sized vectors */\n  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index vecSize)\n      : m_data(dataPtr),\n        m_rows(RowsAtCompileTime == Dynamic ? vecSize : Index(RowsAtCompileTime)),\n        m_cols(ColsAtCompileTime == Dynamic ? vecSize : Index(ColsAtCompileTime)) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)\n    eigen_assert(vecSize &gt;= 0);\n    eigen_assert(dataPtr == 0 || SizeAtCompileTime == Dynamic || SizeAtCompileTime == vecSize);\n    checkSanity&lt;Derived&gt;();\n  }\n\n  /** \\internal Constructor for dynamically sized matrices */\n  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index rows, Index cols)\n      : m_data(dataPtr), m_rows(rows), m_cols(cols) {\n    eigen_assert((dataPtr == 0) || (rows &gt;= 0 &amp;&amp; (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows) &amp;&amp;\n                                    cols &gt;= 0 &amp;&amp; (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols)));\n    checkSanity&lt;Derived&gt;();\n  }\n\n#ifdef EIGEN_MAPBASE_PLUGIN\n#include EIGEN_MAPBASE_PLUGIN\n#endif\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)\n\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC void checkSanity(std::enable_if_t&lt;(internal::traits&lt;T&gt;::Alignment &gt; 0), void*&gt; = 0) const {\n// Temporary macro to allow scalars to not be properly aligned.  This is while we sort out failures\n// in TensorFlow Lite that are currently relying on this UB.\n#ifndef EIGEN_ALLOW_UNALIGNED_SCALARS\n    // Pointer must be aligned to the Scalar type, otherwise we get UB.\n    eigen_assert((std::uintptr_t(m_data) % alignof(Scalar) == 0) &amp;&amp; &quot;data is not scalar-aligned&quot;);\n#endif\n#if EIGEN_MAX_ALIGN_BYTES &gt; 0\n    // innerStride() is not set yet when this function is called, so we optimistically assume the lowest plausible\n    // value:\n    const Index minInnerStride = InnerStrideAtCompileTime == Dynamic ? 1 : Index(InnerStrideAtCompileTime);\n    EIGEN_ONLY_USED_FOR_DEBUG(minInnerStride);\n    eigen_assert((((std::uintptr_t(m_data) % internal::traits&lt;Derived&gt;::Alignment) == 0) ||\n                  (cols() * rows() * minInnerStride * sizeof(Scalar)) &lt; internal::traits&lt;Derived&gt;::Alignment) &amp;&amp;\n                 &quot;data is not aligned&quot;);\n#endif\n  }\n\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC void checkSanity(std::enable_if_t&lt;internal::traits&lt;T&gt;::Alignment == 0, void*&gt; = 0) const {\n#ifndef EIGEN_ALLOW_UNALIGNED_SCALARS\n    // Pointer must be aligned to the Scalar type, otherwise we get UB.\n    eigen_assert((std::uintptr_t(m_data) % alignof(Scalar) == 0) &amp;&amp; &quot;data is not scalar-aligned&quot;);\n#endif\n  }\n\n  PointerType m_data;\n  const internal::variable_if_dynamic&lt;Index, RowsAtCompileTime&gt; m_rows;\n  const internal::variable_if_dynamic&lt;Index, ColsAtCompileTime&gt; m_cols;\n};\n\n/** \\ingroup Core_Module\n *\n * \\brief Base class for non-const dense Map and Block expression with direct access\n *\n * This base class provides the non-const low-level accessors (e.g. coeff and coeffRef) of\n * dense Map and Block objects with direct access.\n * It inherits MapBase&lt;Derived, ReadOnlyAccessors&gt; which defines the const variant for reading specific entries.\n *\n * \\sa class Map, class Block\n */\ntemplate &lt;typename Derived&gt;\nclass MapBase&lt;Derived, WriteAccessors&gt; : public MapBase&lt;Derived, ReadOnlyAccessors&gt; {\n  typedef MapBase&lt;Derived, ReadOnlyAccessors&gt; ReadOnlyMapBase;\n\n public:\n  typedef MapBase&lt;Derived, ReadOnlyAccessors&gt; Base;\n\n  typedef typename Base::Scalar Scalar;\n  typedef typename Base::PacketScalar PacketScalar;\n  typedef typename Base::StorageIndex StorageIndex;\n  typedef typename Base::PointerType PointerType;\n\n  using Base::coeff;\n  using Base::coeffRef;\n  using Base::cols;\n  using Base::derived;\n  using Base::rows;\n  using Base::size;\n\n  using Base::colStride;\n  using Base::innerStride;\n  using Base::outerStride;\n  using Base::rowStride;\n\n  typedef std::conditional_t&lt;internal::is_lvalue&lt;Derived&gt;::value, Scalar, const Scalar&gt; ScalarWithConstIfNotLvalue;\n\n  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return this-&gt;m_data; }\n  EIGEN_DEVICE_FUNC constexpr ScalarWithConstIfNotLvalue* data() {\n    return this-&gt;m_data;\n  }  // no const-cast here so non-const-correct code will give a compile error\n\n  EIGEN_DEVICE_FUNC inline ScalarWithConstIfNotLvalue&amp; coeffRef(Index row, Index col) {\n    return this-&gt;m_data[col * colStride() + row * rowStride()];\n  }\n\n  EIGEN_DEVICE_FUNC inline ScalarWithConstIfNotLvalue&amp; coeffRef(Index index) {\n    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)\n    return this-&gt;m_data[index * innerStride()];\n  }\n\n  template &lt;int StoreMode&gt;\n  inline void writePacket(Index row, Index col, const PacketScalar&amp; val) {\n    internal::pstoret&lt;Scalar, PacketScalar, StoreMode&gt;(this-&gt;m_data + (col * colStride() + row * rowStride()), val);\n  }\n\n  template &lt;int StoreMode&gt;\n  inline void writePacket(Index index, const PacketScalar&amp; val) {\n    EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived)\n    internal::pstoret&lt;Scalar, PacketScalar, StoreMode&gt;(this-&gt;m_data + index * innerStride(), val);\n  }\n\n  EIGEN_DEVICE_FUNC explicit inline MapBase(PointerType dataPtr) : Base(dataPtr) {}\n  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index vecSize) : Base(dataPtr, vecSize) {}\n  EIGEN_DEVICE_FUNC inline MapBase(PointerType dataPtr, Index rows, Index cols) : Base(dataPtr, rows, cols) {}\n\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const MapBase&amp; other) {\n    ReadOnlyMapBase::Base::operator=(other);\n    return derived();\n  }\n\n  // In theory we could simply refer to Base:Base::operator=, but MSVC does not like Base::Base,\n  // see bugs 821 and 920.\n  using ReadOnlyMapBase::Base::operator=;\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)\n};\n\n#undef EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_MAPBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2006-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008-2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_MATRIX_H\n#define EIGEN_MATRIX_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_&gt;\nstruct traits&lt;Matrix&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt; {\n private:\n  constexpr static int size = internal::size_at_compile_time(Rows_, Cols_);\n  typedef typename find_best_packet&lt;Scalar_, size&gt;::type PacketScalar;\n  enum {\n    row_major_bit = Options_ &amp; RowMajor ? RowMajorBit : 0,\n    is_dynamic_size_storage = MaxRows_ == Dynamic || MaxCols_ == Dynamic,\n    max_size = is_dynamic_size_storage ? Dynamic : MaxRows_ * MaxCols_,\n    default_alignment = compute_default_alignment&lt;Scalar_, max_size&gt;::value,\n    actual_alignment = ((Options_ &amp; DontAlign) == 0) ? default_alignment : 0,\n    required_alignment = unpacket_traits&lt;PacketScalar&gt;::alignment,\n    packet_access_bit = (packet_traits&lt;Scalar_&gt;::Vectorizable &amp;&amp;\n                         (EIGEN_UNALIGNED_VECTORIZE || (int(actual_alignment) &gt;= int(required_alignment))))\n                            ? PacketAccessBit\n                            : 0\n  };\n\n public:\n  typedef Scalar_ Scalar;\n  typedef Dense StorageKind;\n  typedef Eigen::Index StorageIndex;\n  typedef MatrixXpr XprKind;\n  enum {\n    RowsAtCompileTime = Rows_,\n    ColsAtCompileTime = Cols_,\n    MaxRowsAtCompileTime = MaxRows_,\n    MaxColsAtCompileTime = MaxCols_,\n    Flags = compute_matrix_flags(Options_),\n    Options = Options_,\n    InnerStrideAtCompileTime = 1,\n    OuterStrideAtCompileTime = (int(Options) &amp; int(RowMajor)) ? ColsAtCompileTime : RowsAtCompileTime,\n\n    // FIXME, the following flag in only used to define NeedsToAlign in PlainObjectBase\n    EvaluatorFlags = LinearAccessBit | DirectAccessBit | packet_access_bit | row_major_bit,\n    Alignment = actual_alignment\n  };\n};\n}  // namespace internal\n\n/** \\class Matrix\n * \\ingroup Core_Module\n *\n * \\brief The matrix class, also used for vectors and row-vectors\n *\n * The %Matrix class is the work-horse for all \\em dense (\\ref dense &quot;note&quot;) matrices and vectors within Eigen.\n * Vectors are matrices with one column, and row-vectors are matrices with one row.\n *\n * The %Matrix class encompasses \\em both fixed-size and dynamic-size objects (\\ref fixedsize &quot;note&quot;).\n *\n * The first three template parameters are required:\n * \\tparam Scalar_ Numeric type, e.g. float, double, int or std::complex&lt;float&gt;.\n *                 User defined scalar types are supported as well (see \\ref user_defined_scalars &quot;here&quot;).\n * \\tparam Rows_ Number of rows, or \\b Dynamic\n * \\tparam Cols_ Number of columns, or \\b Dynamic\n *\n * The remaining template parameters are optional -- in most cases you don&#x27;t have to worry about them.\n * \\tparam Options_ A combination of either \\b #RowMajor or \\b #ColMajor, and of either\n *                 \\b #AutoAlign or \\b #DontAlign.\n *                 The former controls \\ref TopicStorageOrders &quot;storage order&quot;, and defaults to column-major. The latter\n * controls alignment, which is required for vectorization. It defaults to aligning matrices except for fixed sizes that\n * aren&#x27;t a multiple of the packet size. \\tparam MaxRows_ Maximum number of rows. Defaults to \\a Rows_ (\\ref maxrows\n * &quot;note&quot;). \\tparam MaxCols_ Maximum number of columns. Defaults to \\a Cols_ (\\ref maxrows &quot;note&quot;).\n *\n * Eigen provides a number of typedefs covering the usual cases. Here are some examples:\n *\n * \\li \\c Matrix2d is a 2x2 square matrix of doubles (\\c Matrix&lt;double, 2, 2&gt;)\n * \\li \\c Vector4f is a vector of 4 floats (\\c Matrix&lt;float, 4, 1&gt;)\n * \\li \\c RowVector3i is a row-vector of 3 ints (\\c Matrix&lt;int, 1, 3&gt;)\n *\n * \\li \\c MatrixXf is a dynamic-size matrix of floats (\\c Matrix&lt;float, Dynamic, Dynamic&gt;)\n * \\li \\c VectorXf is a dynamic-size vector of floats (\\c Matrix&lt;float, Dynamic, 1&gt;)\n *\n * \\li \\c Matrix2Xf is a partially fixed-size (dynamic-size) matrix of floats (\\c Matrix&lt;float, 2, Dynamic&gt;)\n * \\li \\c MatrixX3d is a partially dynamic-size (fixed-size) matrix of double (\\c Matrix&lt;double, Dynamic, 3&gt;)\n *\n * See \\link matrixtypedefs this page \\endlink for a complete list of predefined \\em %Matrix and \\em Vector typedefs.\n *\n * You can access elements of vectors and matrices using normal subscripting:\n *\n * \\code\n * Eigen::VectorXd v(10);\n * v[0] = 0.1;\n * v[1] = 0.2;\n * v(0) = 0.3;\n * v(1) = 0.4;\n *\n * Eigen::MatrixXi m(10, 10);\n * m(0, 1) = 1;\n * m(0, 2) = 2;\n * m(0, 3) = 3;\n * \\endcode\n *\n * This class can be extended with the help of the plugin mechanism described on the page\n * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_MATRIX_PLUGIN.\n *\n * &lt;i&gt;&lt;b&gt;Some notes:&lt;/b&gt;&lt;/i&gt;\n *\n * &lt;dl&gt;\n * &lt;dt&gt;&lt;b&gt;\\anchor dense Dense versus sparse:&lt;/b&gt;&lt;/dt&gt;\n * &lt;dd&gt;This %Matrix class handles dense, not sparse matrices and vectors. For sparse matrices and vectors, see the\n * Sparse module.\n *\n * Dense matrices and vectors are plain usual arrays of coefficients. All the coefficients are stored, in an ordinary\n * contiguous array. This is unlike Sparse matrices and vectors where the coefficients are stored as a list of nonzero\n * coefficients.&lt;/dd&gt;\n *\n * &lt;dt&gt;&lt;b&gt;\\anchor fixedsize Fixed-size versus dynamic-size:&lt;/b&gt;&lt;/dt&gt;\n * &lt;dd&gt;Fixed-size means that the numbers of rows and columns are known at compile-time. In this case, Eigen allocates\n * the array of coefficients as a fixed-size array, as a class member. This makes sense for very small matrices,\n * typically up to 4x4, sometimes up to 16x16. Larger matrices should be declared as dynamic-size even if one happens to\n * know their size at compile-time.\n *\n * Dynamic-size means that the numbers of rows or columns are not necessarily known at compile-time. In this case they\n * are runtime variables, and the array of coefficients is allocated dynamically on the heap.\n *\n * Note that \\em dense matrices, be they Fixed-size or Dynamic-size, &lt;em&gt;do not&lt;/em&gt; expand dynamically in the sense of\n * a std::map. If you want this behavior, see the Sparse module.&lt;/dd&gt;\n *\n * &lt;dt&gt;&lt;b&gt;\\anchor maxrows MaxRows_ and MaxCols_:&lt;/b&gt;&lt;/dt&gt;\n * &lt;dd&gt;In most cases, one just leaves these parameters to the default values.\n * These parameters mean the maximum size of rows and columns that the matrix may have. They are useful in cases\n * when the exact numbers of rows and columns are not known at compile-time, but it is known at compile-time that they\n * cannot exceed a certain value. This happens when taking dynamic-size blocks inside fixed-size matrices: in this case\n * MaxRows_ and MaxCols_ are the dimensions of the original matrix, while Rows_ and Cols_ are Dynamic.&lt;/dd&gt;\n * &lt;/dl&gt;\n *\n * &lt;i&gt;&lt;b&gt;ABI and storage layout&lt;/b&gt;&lt;/i&gt;\n *\n * The table below summarizes the ABI of some possible Matrix instances which is fixed thorough the lifetime of Eigen 3.\n * &lt;table  class=&quot;manual&quot;&gt;\n * &lt;tr&gt;&lt;th&gt;Matrix type&lt;/th&gt;&lt;th&gt;Equivalent C structure&lt;/th&gt;&lt;/tr&gt;\n * &lt;tr&gt;&lt;td&gt;\\code Matrix&lt;T,Dynamic,Dynamic&gt; \\endcode&lt;/td&gt;&lt;td&gt;\\code\n * struct {\n *   T *data;                  // with (size_t(data)%EIGEN_MAX_ALIGN_BYTES)==0\n *   Eigen::Index rows, cols;\n *  };\n * \\endcode&lt;/td&gt;&lt;/tr&gt;\n * &lt;tr class=&quot;alt&quot;&gt;&lt;td&gt;\\code\n * Matrix&lt;T,Dynamic,1&gt;\n * Matrix&lt;T,1,Dynamic&gt; \\endcode&lt;/td&gt;&lt;td&gt;\\code\n * struct {\n *   T *data;                  // with (size_t(data)%EIGEN_MAX_ALIGN_BYTES)==0\n *   Eigen::Index size;\n *  };\n * \\endcode&lt;/td&gt;&lt;/tr&gt;\n * &lt;tr&gt;&lt;td&gt;\\code Matrix&lt;T,Rows,Cols&gt; \\endcode&lt;/td&gt;&lt;td&gt;\\code\n * struct {\n *   T data[Rows*Cols];        // with (size_t(data)%A(Rows*Cols*sizeof(T)))==0\n *  };\n * \\endcode&lt;/td&gt;&lt;/tr&gt;\n * &lt;tr class=&quot;alt&quot;&gt;&lt;td&gt;\\code Matrix&lt;T,Dynamic,Dynamic,0,MaxRows,MaxCols&gt; \\endcode&lt;/td&gt;&lt;td&gt;\\code\n * struct {\n *   T data[MaxRows*MaxCols];  // with (size_t(data)%A(MaxRows*MaxCols*sizeof(T)))==0\n *   Eigen::Index rows, cols;\n *  };\n * \\endcode&lt;/td&gt;&lt;/tr&gt;\n * &lt;/table&gt;\n * Note that in this table Rows, Cols, MaxRows and MaxCols are all positive integers. A(S) is defined to the largest\n * possible power-of-two smaller to EIGEN_MAX_STATIC_ALIGN_BYTES.\n *\n * \\see MatrixBase for the majority of the API methods for matrices, \\ref TopicClassHierarchy,\n * \\ref TopicStorageOrders\n */\n\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Options_, int MaxRows_, int MaxCols_&gt;\nclass Matrix : public PlainObjectBase&lt;Matrix&lt;Scalar_, Rows_, Cols_, Options_, MaxRows_, MaxCols_&gt;&gt; {\n public:\n  /** \\brief Base class typedef.\n   * \\sa PlainObjectBase\n   */\n  typedef PlainObjectBase&lt;Matrix&gt; Base;\n\n  enum { Options = Options_ };\n\n  EIGEN_DENSE_PUBLIC_INTERFACE(Matrix)\n\n  typedef typename Base::PlainObject PlainObject;\n\n  using Base::base;\n  using Base::coeffRef;\n\n  /**\n   * \\brief Assigns matrices to each other.\n   *\n   * \\note This is a special case of the templated operator=. Its purpose is\n   * to prevent a default operator= from hiding the templated operator=.\n   *\n   * \\callgraph\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix&amp; operator=(const Matrix&amp; other) { return Base::_set(other); }\n\n  /** \\internal\n   * \\brief Copies the value of the expression \\a other into \\c *this with automatic resizing.\n   *\n   * *this might be resized to match the dimensions of \\a other. If *this was a null matrix (not already initialized),\n   * it will be initialized.\n   *\n   * Note that copying a row-vector into a vector (and conversely) is allowed.\n   * The resizing, if any, is then done in the appropriate way so that row-vectors\n   * remain row-vectors and vectors remain vectors.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::_set(other);\n  }\n\n  /**\n   * \\brief Copies the generic expression \\a other into *this.\n   * \\copydetails DenseBase::operator=(const EigenBase&lt;OtherDerived&gt; &amp;other)\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::operator=(other);\n  }\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix&amp; operator=(const ReturnByValue&lt;OtherDerived&gt;&amp; func) {\n    return Base::operator=(func);\n  }\n\n  /** \\brief Default constructor.\n   *\n   * For fixed-size matrices, does nothing.\n   *\n   * For dynamic-size matrices, creates an empty matrix of size 0. Does not allocate any array. Such a matrix\n   * is called a null matrix. This constructor is the unique way to create null matrices: resizing\n   * a matrix to 0 is not supported.\n   *\n   * \\sa resize(Index,Index)\n   */\n#if defined(EIGEN_INITIALIZE_COEFFS)\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix() { EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED }\n#else\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix() = default;\n#endif\n  /** \\brief Move constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix(Matrix&amp;&amp;) = default;\n  /** \\brief Moves the matrix into the other one.\n   *\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix&amp; operator=(Matrix&amp;&amp; other)\n      EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable&lt;Scalar&gt;::value) {\n    Base::operator=(std::move(other));\n    return *this;\n  }\n\n  /** \\brief Construct a row of column vector with fixed size from an arbitrary number of coefficients.\n   *\n   * \\only_for_vectors\n   *\n   * This constructor is for 1D array or vectors with more than 4 coefficients.\n   *\n   * \\warning To construct a column (resp. row) vector of fixed length, the number of values passed to this\n   * constructor must match the the fixed number of rows (resp. columns) of \\c *this.\n   *\n   *\n   * Example: \\include Matrix_variadic_ctor_cxx11.cpp\n   * Output: \\verbinclude Matrix_variadic_ctor_cxx11.out\n   *\n   * \\sa Matrix(const std::initializer_list&lt;std::initializer_list&lt;Scalar&gt;&gt;&amp;)\n   */\n  template &lt;typename... ArgTypes&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2, const Scalar&amp; a3,\n                                               const ArgTypes&amp;... args)\n      : Base(a0, a1, a2, a3, args...) {}\n\n  /** \\brief Constructs a Matrix and initializes it from the coefficients given as initializer-lists grouped by row.\n   * \\cpp11\n   * \\anchor matrix_initializer_list\n   *\n   * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:\n   *\n   * Example: \\include Matrix_initializer_list_23_cxx11.cpp\n   * Output: \\verbinclude Matrix_initializer_list_23_cxx11.out\n   *\n   * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is\n   * triggered.\n   *\n   * In the case of a compile-time column vector, implicit transposition from a single row is allowed.\n   * Therefore &lt;code&gt;VectorXd{{1,2,3,4,5}}&lt;/code&gt; is legal and the more verbose syntax\n   * &lt;code&gt;RowVectorXd{{1},{2},{3},{4},{5}}&lt;/code&gt; can be avoided:\n   *\n   * Example: \\include Matrix_initializer_list_vector_cxx11.cpp\n   * Output: \\verbinclude Matrix_initializer_list_vector_cxx11.out\n   *\n   * In the case of fixed-sized matrices, the initializer list sizes must exactly match the matrix sizes,\n   * and implicit transposition is allowed for compile-time vectors only.\n   *\n   * \\sa Matrix(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2,  const Scalar&amp; a3, const ArgTypes&amp;... args)\n   */\n  EIGEN_DEVICE_FUNC explicit constexpr EIGEN_STRONG_INLINE Matrix(\n      const std::initializer_list&lt;std::initializer_list&lt;Scalar&gt;&gt;&amp; list)\n      : Base(list) {}\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n\n  // This constructor is for both 1x1 matrices and dynamic vectors\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit Matrix(const T&amp; x) {\n    Base::template _init1&lt;T&gt;(x);\n  }\n\n  template &lt;typename T0, typename T1&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const T0&amp; x, const T1&amp; y) {\n    Base::template _init2&lt;T0, T1&gt;(x, y);\n  }\n\n#else\n  /** \\brief Constructs a fixed-sized matrix initialized with coefficients starting at \\a data */\n  EIGEN_DEVICE_FUNC explicit Matrix(const Scalar* data);\n\n  /** \\brief Constructs a vector or row-vector with given dimension. \\only_for_vectors\n   *\n   * This is useful for dynamic-size vectors. For fixed-size vectors,\n   * it is redundant to pass these parameters, so one should use the default constructor\n   * Matrix() instead.\n   *\n   * \\warning This constructor is disabled for fixed-size \\c 1x1 matrices. For instance,\n   * calling Matrix&lt;double,1,1&gt;(1) will call the initialization constructor: Matrix(const Scalar&amp;).\n   * For fixed-size \\c 1x1 matrices it is therefore recommended to use the default\n   * constructor Matrix() instead, especially when using one of the non standard\n   * \\c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\\c NAN} macros (see \\ref TopicPreprocessorDirectives).\n   */\n  EIGEN_STRONG_INLINE explicit Matrix(Index dim);\n  /** \\brief Constructs an initialized 1x1 matrix with the given coefficient\n   * \\sa Matrix(const Scalar&amp;, const Scalar&amp;, const Scalar&amp;,  const Scalar&amp;, const ArgTypes&amp;...) */\n  Matrix(const Scalar&amp; x);\n  /** \\brief Constructs an uninitialized matrix with \\a rows rows and \\a cols columns.\n   *\n   * This is useful for dynamic-size matrices. For fixed-size matrices,\n   * it is redundant to pass these parameters, so one should use the default constructor\n   * Matrix() instead.\n   *\n   * \\warning This constructor is disabled for fixed-size \\c 1x2 and \\c 2x1 vectors. For instance,\n   * calling Matrix2f(2,1) will call the initialization constructor: Matrix(const Scalar&amp; x, const Scalar&amp; y).\n   * For fixed-size \\c 1x2 or \\c 2x1 vectors it is therefore recommended to use the default\n   * constructor Matrix() instead, especially when using one of the non standard\n   * \\c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\\c NAN} macros (see \\ref TopicPreprocessorDirectives).\n   */\n  EIGEN_DEVICE_FUNC Matrix(Index rows, Index cols);\n\n  /** \\brief Constructs an initialized 2D vector with given coefficients\n   * \\sa Matrix(const Scalar&amp;, const Scalar&amp;, const Scalar&amp;,  const Scalar&amp;, const ArgTypes&amp;...) */\n  Matrix(const Scalar&amp; x, const Scalar&amp; y);\n#endif  // end EIGEN_PARSED_BY_DOXYGEN\n\n  /** \\brief Constructs an initialized 3D vector with given coefficients\n   * \\sa Matrix(const Scalar&amp;, const Scalar&amp;, const Scalar&amp;,  const Scalar&amp;, const ArgTypes&amp;...)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar&amp; x, const Scalar&amp; y, const Scalar&amp; z) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Matrix, 3)\n    m_storage.data()[0] = x;\n    m_storage.data()[1] = y;\n    m_storage.data()[2] = z;\n  }\n  /** \\brief Constructs an initialized 4D vector with given coefficients\n   * \\sa Matrix(const Scalar&amp;, const Scalar&amp;, const Scalar&amp;,  const Scalar&amp;, const ArgTypes&amp;...)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const Scalar&amp; x, const Scalar&amp; y, const Scalar&amp; z, const Scalar&amp; w) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Matrix, 4)\n    m_storage.data()[0] = x;\n    m_storage.data()[1] = y;\n    m_storage.data()[2] = z;\n    m_storage.data()[3] = w;\n  }\n\n  /** \\brief Copy constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Matrix(const Matrix&amp;) = default;\n\n  /** \\brief Copy constructor for generic expressions.\n   * \\sa MatrixBase::operator=(const EigenBase&lt;OtherDerived&gt;&amp;)\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Matrix(const EigenBase&lt;OtherDerived&gt;&amp; other) : Base(other.derived()) {}\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return this-&gt;innerSize(); }\n\n  /////////// Geometry module ///////////\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC explicit Matrix(const RotationBase&lt;OtherDerived, ColsAtCompileTime&gt;&amp; r);\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Matrix&amp; operator=(const RotationBase&lt;OtherDerived, ColsAtCompileTime&gt;&amp; r);\n\n// allow to extend Matrix outside Eigen\n#ifdef EIGEN_MATRIX_PLUGIN\n#include EIGEN_MATRIX_PLUGIN\n#endif\n\n protected:\n  template &lt;typename Derived, typename OtherDerived, bool IsVector&gt;\n  friend struct internal::conservative_resize_like_impl;\n\n  using Base::m_storage;\n};\n\n/** \\defgroup matrixtypedefs Global matrix typedefs\n *\n * \\ingroup Core_Module\n *\n * %Eigen defines several typedef shortcuts for most common matrix and vector types.\n *\n * The general patterns are the following:\n *\n * \\c MatrixSizeType where \\c Size can be \\c 2,\\c 3,\\c 4 for fixed size square matrices or \\c X for dynamic size,\n * and where \\c Type can be \\c i for integer, \\c f for float, \\c d for double, \\c cf for complex float, \\c cd\n * for complex double.\n *\n * For example, \\c Matrix3d is a fixed-size 3x3 matrix type of doubles, and \\c MatrixXf is a dynamic-size matrix of\n * floats.\n *\n * There are also \\c VectorSizeType and \\c RowVectorSizeType which are self-explanatory. For example, \\c Vector4cf is\n * a fixed-size vector of 4 complex floats.\n *\n * With \\cpp11, template alias are also defined for common sizes.\n * They follow the same pattern as above except that the scalar type suffix is replaced by a\n * template parameter, i.e.:\n *   - `MatrixSize&lt;Type&gt;` where `Size` can be \\c 2,\\c 3,\\c 4 for fixed size square matrices or \\c X for dynamic size.\n *   - `MatrixXSize&lt;Type&gt;` and `MatrixSizeX&lt;Type&gt;` where `Size` can be \\c 2,\\c 3,\\c 4 for hybrid dynamic/fixed matrices.\n *   - `VectorSize&lt;Type&gt;` and `RowVectorSize&lt;Type&gt;` for column and row vectors.\n *\n * With \\cpp11, you can also use fully generic column and row vector types: `Vector&lt;Type,Size&gt;` and\n * `RowVector&lt;Type,Size&gt;`.\n *\n * \\sa class Matrix\n */\n\n#define EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)    \\\n  /** \\ingroup matrixtypedefs */                                   \\\n  /** \\brief `Size`&amp;times;`Size` matrix of type `Type`. */         \\\n  typedef Matrix&lt;Type, Size, Size&gt; Matrix##SizeSuffix##TypeSuffix; \\\n  /** \\ingroup matrixtypedefs */                                   \\\n  /** \\brief `Size`&amp;times;`1` vector of type `Type`. */            \\\n  typedef Matrix&lt;Type, Size, 1&gt; Vector##SizeSuffix##TypeSuffix;    \\\n  /** \\ingroup matrixtypedefs */                                   \\\n  /** \\brief `1`&amp;times;`Size` vector of type `Type`. */            \\\n  typedef Matrix&lt;Type, 1, Size&gt; RowVector##SizeSuffix##TypeSuffix;\n\n#define EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, Size)          \\\n  /** \\ingroup matrixtypedefs */                                   \\\n  /** \\brief `Size`&amp;times;`Dynamic` matrix of type `Type`. */      \\\n  typedef Matrix&lt;Type, Size, Dynamic&gt; Matrix##Size##X##TypeSuffix; \\\n  /** \\ingroup matrixtypedefs */                                   \\\n  /** \\brief `Dynamic`&amp;times;`Size` matrix of type `Type`. */      \\\n  typedef Matrix&lt;Type, Dynamic, Size&gt; Matrix##X##Size##TypeSuffix;\n\n#define EIGEN_MAKE_TYPEDEFS_ALL_SIZES(Type, TypeSuffix) \\\n  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 2, 2)           \\\n  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 3, 3)           \\\n  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, 4, 4)           \\\n  EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Dynamic, X)     \\\n  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 2)        \\\n  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 3)        \\\n  EIGEN_MAKE_FIXED_TYPEDEFS(Type, TypeSuffix, 4)\n\nEIGEN_MAKE_TYPEDEFS_ALL_SIZES(int, i)\nEIGEN_MAKE_TYPEDEFS_ALL_SIZES(float, f)\nEIGEN_MAKE_TYPEDEFS_ALL_SIZES(double, d)\nEIGEN_MAKE_TYPEDEFS_ALL_SIZES(std::complex&lt;float&gt;, cf)\nEIGEN_MAKE_TYPEDEFS_ALL_SIZES(std::complex&lt;double&gt;, cd)\n\n#undef EIGEN_MAKE_TYPEDEFS_ALL_SIZES\n#undef EIGEN_MAKE_TYPEDEFS\n#undef EIGEN_MAKE_FIXED_TYPEDEFS\n\n#define EIGEN_MAKE_TYPEDEFS(Size, SizeSuffix)                    \\\n  /** \\ingroup matrixtypedefs */                                 \\\n  /** \\brief \\cpp11 `Size`&amp;times;`Size` matrix of type `Type`.*/ \\\n  template &lt;typename Type&gt;                                       \\\n  using Matrix##SizeSuffix = Matrix&lt;Type, Size, Size&gt;;           \\\n  /** \\ingroup matrixtypedefs */                                 \\\n  /** \\brief \\cpp11 `Size`&amp;times;`1` vector of type `Type`.*/    \\\n  template &lt;typename Type&gt;                                       \\\n  using Vector##SizeSuffix = Matrix&lt;Type, Size, 1&gt;;              \\\n  /** \\ingroup matrixtypedefs */                                 \\\n  /** \\brief \\cpp11 `1`&amp;times;`Size` vector of type `Type`.*/    \\\n  template &lt;typename Type&gt;                                       \\\n  using RowVector##SizeSuffix = Matrix&lt;Type, 1, Size&gt;;\n\n#define EIGEN_MAKE_FIXED_TYPEDEFS(Size)                              \\\n  /** \\ingroup matrixtypedefs */                                     \\\n  /** \\brief \\cpp11 `Size`&amp;times;`Dynamic` matrix of type `Type` */  \\\n  template &lt;typename Type&gt;                                           \\\n  using Matrix##Size##X = Matrix&lt;Type, Size, Dynamic&gt;;               \\\n  /** \\ingroup matrixtypedefs */                                     \\\n  /** \\brief \\cpp11 `Dynamic`&amp;times;`Size` matrix of type `Type`. */ \\\n  template &lt;typename Type&gt;                                           \\\n  using Matrix##X##Size = Matrix&lt;Type, Dynamic, Size&gt;;\n\nEIGEN_MAKE_TYPEDEFS(2, 2)\nEIGEN_MAKE_TYPEDEFS(3, 3)\nEIGEN_MAKE_TYPEDEFS(4, 4)\nEIGEN_MAKE_TYPEDEFS(Dynamic, X)\nEIGEN_MAKE_FIXED_TYPEDEFS(2)\nEIGEN_MAKE_FIXED_TYPEDEFS(3)\nEIGEN_MAKE_FIXED_TYPEDEFS(4)\n\n/** \\ingroup matrixtypedefs\n * \\brief \\cpp11 `Size`&amp;times;`1` vector of type `Type`. */\ntemplate &lt;typename Type, int Size&gt;\nusing Vector = Matrix&lt;Type, Size, 1&gt;;\n\n/** \\ingroup matrixtypedefs\n * \\brief \\cpp11 `1`&amp;times;`Size` vector of type `Type`. */\ntemplate &lt;typename Type, int Size&gt;\nusing RowVector = Matrix&lt;Type, 1, Size&gt;;\n\n#undef EIGEN_MAKE_TYPEDEFS\n#undef EIGEN_MAKE_FIXED_TYPEDEFS\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_MATRIX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2006-2009 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_MATRIXBASE_H\n#define EIGEN_MATRIXBASE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\class MatrixBase\n  * \\ingroup Core_Module\n  *\n  * \\brief Base class for all dense matrices, vectors, and expressions\n  *\n  * This class is the base that is inherited by all matrix, vector, and related expression\n  * types. Most of the Eigen API is contained in this class, and its base classes. Other important\n  * classes for the Eigen API are Matrix, and VectorwiseOp.\n  *\n  * Note that some methods are defined in other modules such as the \\ref LU_Module LU module\n  * for all functions related to matrix inversions.\n  *\n  * \\tparam Derived is the derived type, e.g. a matrix type, or an expression, etc.\n  *\n  * When writing a function taking Eigen objects as argument, if you want your function\n  * to take as argument any matrix, vector, or expression, just let it take a\n  * MatrixBase argument. As an example, here is a function printFirstRow which, given\n  * a matrix, vector, or expression \\a x, prints the first row of \\a x.\n  *\n  * \\code\n    template&lt;typename Derived&gt;\n    void printFirstRow(const Eigen::MatrixBase&lt;Derived&gt;&amp; x)\n    {\n      cout &lt;&lt; x.row(0) &lt;&lt; endl;\n    }\n  * \\endcode\n  *\n  * This class can be extended with the help of the plugin mechanism described on the page\n  * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_MATRIXBASE_PLUGIN.\n  *\n  * \\sa \\blank \\ref TopicClassHierarchy\n  */\ntemplate &lt;typename Derived&gt;\nclass MatrixBase : public DenseBase&lt;Derived&gt; {\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef MatrixBase StorageBaseType;\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;Derived&gt;::StorageIndex StorageIndex;\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n  typedef typename internal::packet_traits&lt;Scalar&gt;::type PacketScalar;\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n\n  typedef DenseBase&lt;Derived&gt; Base;\n  using Base::ColsAtCompileTime;\n  using Base::Flags;\n  using Base::IsVectorAtCompileTime;\n  using Base::MaxColsAtCompileTime;\n  using Base::MaxRowsAtCompileTime;\n  using Base::MaxSizeAtCompileTime;\n  using Base::RowsAtCompileTime;\n  using Base::SizeAtCompileTime;\n\n  using Base::coeff;\n  using Base::coeffRef;\n  using Base::cols;\n  using Base::const_cast_derived;\n  using Base::derived;\n  using Base::eval;\n  using Base::lazyAssign;\n  using Base::rows;\n  using Base::size;\n  using Base::operator-;\n  using Base::operator+=;\n  using Base::operator-=;\n  using Base::operator*=;\n  using Base::operator/=;\n\n  typedef typename Base::CoeffReturnType CoeffReturnType;\n  typedef typename Base::ConstTransposeReturnType ConstTransposeReturnType;\n  typedef typename Base::RowXpr RowXpr;\n  typedef typename Base::ColXpr ColXpr;\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** type of the equivalent square matrix */\n  typedef Matrix&lt;Scalar, internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime),\n                 internal::max_size_prefer_dynamic(RowsAtCompileTime, ColsAtCompileTime)&gt;\n      SquareMatrixType;\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n  /** \\returns the size of the main diagonal, which is min(rows(),cols()).\n   * \\sa rows(), cols(), SizeAtCompileTime. */\n  EIGEN_DEVICE_FUNC inline Index diagonalSize() const { return (numext::mini)(rows(), cols()); }\n\n  typedef typename Base::PlainObject PlainObject;\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** \\internal Represents a matrix with all coefficients equal to one another*/\n  typedef CwiseNullaryOp&lt;internal::scalar_constant_op&lt;Scalar&gt;, PlainObject&gt; ConstantReturnType;\n  /** \\internal the return type of MatrixBase::adjoint() */\n  typedef std::conditional_t&lt;NumTraits&lt;Scalar&gt;::IsComplex,\n                             CwiseUnaryOp&lt;internal::scalar_conjugate_op&lt;Scalar&gt;, ConstTransposeReturnType&gt;,\n                             ConstTransposeReturnType&gt;\n      AdjointReturnType;\n  /** \\internal Return type of eigenvalues() */\n  typedef Matrix&lt;internal::make_complex_t&lt;Scalar&gt;, internal::traits&lt;Derived&gt;::ColsAtCompileTime, 1, ColMajor&gt;\n      EigenvaluesReturnType;\n  /** \\internal the return type of identity */\n  typedef CwiseNullaryOp&lt;internal::scalar_identity_op&lt;Scalar&gt;, PlainObject&gt; IdentityReturnType;\n  /** \\internal the return type of unit vectors */\n  typedef Block&lt;const CwiseNullaryOp&lt;internal::scalar_identity_op&lt;Scalar&gt;, SquareMatrixType&gt;,\n                internal::traits&lt;Derived&gt;::RowsAtCompileTime, internal::traits&lt;Derived&gt;::ColsAtCompileTime&gt;\n      BasisReturnType;\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n#define EIGEN_CURRENT_STORAGE_BASE_CLASS Eigen::MatrixBase\n#define EIGEN_DOC_UNARY_ADDONS(X, Y)\n#include &quot;../plugins/CommonCwiseBinaryOps.inc&quot;\n#include &quot;../plugins/MatrixCwiseUnaryOps.inc&quot;\n#include &quot;../plugins/MatrixCwiseBinaryOps.inc&quot;\n#ifdef EIGEN_MATRIXBASE_PLUGIN\n#include EIGEN_MATRIXBASE_PLUGIN\n#endif\n#undef EIGEN_CURRENT_STORAGE_BASE_CLASS\n#undef EIGEN_DOC_UNARY_ADDONS\n\n  /** Special case of the template operator=, in order to prevent the compiler\n   * from generating a default operator= (issue hit with g++ 4.1)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const MatrixBase&amp; other);\n\n  // We cannot inherit here via Base::operator= since it is causing\n  // trouble with MSVC.\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const ReturnByValue&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator+=(const MatrixBase&lt;OtherDerived&gt;&amp; other);\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator-=(const MatrixBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC const Product&lt;Derived, OtherDerived&gt; operator*(const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC const Product&lt;Derived, OtherDerived, LazyProduct&gt; lazyProduct(\n      const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator*=(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  void applyOnTheLeft(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  void applyOnTheRight(const EigenBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename DiagonalDerived&gt;\n  EIGEN_DEVICE_FUNC const Product&lt;Derived, DiagonalDerived, LazyProduct&gt; operator*(\n      const DiagonalBase&lt;DiagonalDerived&gt;&amp; diagonal) const;\n\n  template &lt;typename SkewDerived&gt;\n  EIGEN_DEVICE_FUNC const Product&lt;Derived, SkewDerived, LazyProduct&gt; operator*(\n      const SkewSymmetricBase&lt;SkewDerived&gt;&amp; skew) const;\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC typename ScalarBinaryOpTraits&lt;typename internal::traits&lt;Derived&gt;::Scalar,\n                                                  typename internal::traits&lt;OtherDerived&gt;::Scalar&gt;::ReturnType\n  dot(const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  EIGEN_DEVICE_FUNC RealScalar squaredNorm() const;\n  EIGEN_DEVICE_FUNC RealScalar norm() const;\n  RealScalar stableNorm() const;\n  RealScalar blueNorm() const;\n  RealScalar hypotNorm() const;\n  EIGEN_DEVICE_FUNC const PlainObject normalized() const;\n  EIGEN_DEVICE_FUNC const PlainObject stableNormalized() const;\n  EIGEN_DEVICE_FUNC void normalize();\n  EIGEN_DEVICE_FUNC void stableNormalize();\n\n  EIGEN_DEVICE_FUNC const AdjointReturnType adjoint() const;\n  EIGEN_DEVICE_FUNC void adjointInPlace();\n\n  typedef Diagonal&lt;Derived&gt; DiagonalReturnType;\n  EIGEN_DEVICE_FUNC DiagonalReturnType diagonal();\n\n  typedef Diagonal&lt;const Derived&gt; ConstDiagonalReturnType;\n  EIGEN_DEVICE_FUNC const ConstDiagonalReturnType diagonal() const;\n\n  template &lt;int Index&gt;\n  EIGEN_DEVICE_FUNC Diagonal&lt;Derived, Index&gt; diagonal();\n\n  template &lt;int Index&gt;\n  EIGEN_DEVICE_FUNC const Diagonal&lt;const Derived, Index&gt; diagonal() const;\n\n  EIGEN_DEVICE_FUNC Diagonal&lt;Derived, DynamicIndex&gt; diagonal(Index index);\n  EIGEN_DEVICE_FUNC const Diagonal&lt;const Derived, DynamicIndex&gt; diagonal(Index index) const;\n\n  template &lt;unsigned int Mode&gt;\n  struct TriangularViewReturnType {\n    typedef TriangularView&lt;Derived, Mode&gt; Type;\n  };\n  template &lt;unsigned int Mode&gt;\n  struct ConstTriangularViewReturnType {\n    typedef const TriangularView&lt;const Derived, Mode&gt; Type;\n  };\n\n  template &lt;unsigned int Mode&gt;\n  EIGEN_DEVICE_FUNC typename TriangularViewReturnType&lt;Mode&gt;::Type triangularView();\n  template &lt;unsigned int Mode&gt;\n  EIGEN_DEVICE_FUNC typename ConstTriangularViewReturnType&lt;Mode&gt;::Type triangularView() const;\n\n  template &lt;unsigned int UpLo&gt;\n  struct SelfAdjointViewReturnType {\n    typedef SelfAdjointView&lt;Derived, UpLo&gt; Type;\n  };\n  template &lt;unsigned int UpLo&gt;\n  struct ConstSelfAdjointViewReturnType {\n    typedef const SelfAdjointView&lt;const Derived, UpLo&gt; Type;\n  };\n\n  template &lt;unsigned int UpLo&gt;\n  EIGEN_DEVICE_FUNC typename SelfAdjointViewReturnType&lt;UpLo&gt;::Type selfadjointView();\n  template &lt;unsigned int UpLo&gt;\n  EIGEN_DEVICE_FUNC typename ConstSelfAdjointViewReturnType&lt;UpLo&gt;::Type selfadjointView() const;\n\n  const SparseView&lt;Derived&gt; sparseView(\n      const Scalar&amp; m_reference = Scalar(0),\n      const typename NumTraits&lt;Scalar&gt;::Real&amp; m_epsilon = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  EIGEN_DEVICE_FUNC static const IdentityReturnType Identity();\n  EIGEN_DEVICE_FUNC static const IdentityReturnType Identity(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC static const BasisReturnType Unit(Index size, Index i);\n  EIGEN_DEVICE_FUNC static const BasisReturnType Unit(Index i);\n  EIGEN_DEVICE_FUNC static const BasisReturnType UnitX();\n  EIGEN_DEVICE_FUNC static const BasisReturnType UnitY();\n  EIGEN_DEVICE_FUNC static const BasisReturnType UnitZ();\n  EIGEN_DEVICE_FUNC static const BasisReturnType UnitW();\n\n  EIGEN_DEVICE_FUNC const DiagonalWrapper&lt;const Derived&gt; asDiagonal() const;\n  const PermutationWrapper&lt;const Derived&gt; asPermutation() const;\n  EIGEN_DEVICE_FUNC const SkewSymmetricWrapper&lt;const Derived&gt; asSkewSymmetric() const;\n\n  EIGEN_DEVICE_FUNC Derived&amp; setIdentity();\n  EIGEN_DEVICE_FUNC Derived&amp; setIdentity(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC Derived&amp; setUnit(Index i);\n  EIGEN_DEVICE_FUNC Derived&amp; setUnit(Index newSize, Index i);\n\n  bool isIdentity(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  bool isDiagonal(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  bool isUpperTriangular(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  bool isLowerTriangular(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  bool isSkewSymmetric(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  template &lt;typename OtherDerived&gt;\n  bool isOrthogonal(const MatrixBase&lt;OtherDerived&gt;&amp; other,\n                    const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n  bool isUnitary(const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  /** \\returns true if each coefficients of \\c *this and \\a other are all exactly equal.\n   * \\warning When using floating point scalar values you probably should rather use a\n   *          fuzzy comparison such as isApprox()\n   * \\sa isApprox(), operator!= */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline bool operator==(const MatrixBase&lt;OtherDerived&gt;&amp; other) const {\n    return (this-&gt;rows() == other.rows()) &amp;&amp; (this-&gt;cols() == other.cols()) &amp;&amp; cwiseEqual(other).all();\n  }\n\n  /** \\returns true if at least one pair of coefficients of \\c *this and \\a other are not exactly equal to each other.\n   * \\warning When using floating point scalar values you probably should rather use a\n   *          fuzzy comparison such as isApprox()\n   * \\sa isApprox(), operator== */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline bool operator!=(const MatrixBase&lt;OtherDerived&gt;&amp; other) const {\n    return !(*this == other);\n  }\n\n  NoAlias&lt;Derived, Eigen::MatrixBase&gt; EIGEN_DEVICE_FUNC noalias();\n\n  // TODO forceAlignedAccess is temporarily disabled\n  // Need to find a nicer workaround.\n  inline const Derived&amp; forceAlignedAccess() const { return derived(); }\n  inline Derived&amp; forceAlignedAccess() { return derived(); }\n  template &lt;bool Enable&gt;\n  inline const Derived&amp; forceAlignedAccessIf() const {\n    return derived();\n  }\n  template &lt;bool Enable&gt;\n  inline Derived&amp; forceAlignedAccessIf() {\n    return derived();\n  }\n\n  EIGEN_DEVICE_FUNC Scalar trace() const;\n\n  template &lt;int p&gt;\n  EIGEN_DEVICE_FUNC RealScalar lpNorm() const;\n\n  EIGEN_DEVICE_FUNC MatrixBase&lt;Derived&gt;&amp; matrix() { return *this; }\n  EIGEN_DEVICE_FUNC const MatrixBase&lt;Derived&gt;&amp; matrix() const { return *this; }\n\n  /** \\returns an \\link Eigen::ArrayBase Array \\endlink expression of this matrix\n   * \\sa ArrayBase::matrix() */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ArrayWrapper&lt;Derived&gt; array() { return ArrayWrapper&lt;Derived&gt;(derived()); }\n  /** \\returns a const \\link Eigen::ArrayBase Array \\endlink expression of this matrix\n   * \\sa ArrayBase::matrix() */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const ArrayWrapper&lt;const Derived&gt; array() const {\n    return ArrayWrapper&lt;const Derived&gt;(derived());\n  }\n\n  /////////// LU module ///////////\n\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const FullPivLU&lt;PlainObject, PermutationIndex&gt; fullPivLu() const;\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const PartialPivLU&lt;PlainObject, PermutationIndex&gt; partialPivLu() const;\n\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const PartialPivLU&lt;PlainObject, PermutationIndex&gt; lu() const;\n\n  EIGEN_DEVICE_FUNC inline const Inverse&lt;Derived&gt; inverse() const;\n\n  template &lt;typename ResultType&gt;\n  inline void computeInverseAndDetWithCheck(\n      ResultType&amp; inverse, typename ResultType::Scalar&amp; determinant, bool&amp; invertible,\n      const RealScalar&amp; absDeterminantThreshold = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  template &lt;typename ResultType&gt;\n  inline void computeInverseWithCheck(\n      ResultType&amp; inverse, bool&amp; invertible,\n      const RealScalar&amp; absDeterminantThreshold = NumTraits&lt;Scalar&gt;::dummy_precision()) const;\n\n  EIGEN_DEVICE_FUNC Scalar determinant() const;\n\n  /////////// Cholesky module ///////////\n\n  inline const LLT&lt;PlainObject&gt; llt() const;\n  inline const LDLT&lt;PlainObject&gt; ldlt() const;\n\n  /////////// QR module ///////////\n\n  inline const HouseholderQR&lt;PlainObject&gt; householderQr() const;\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const ColPivHouseholderQR&lt;PlainObject, PermutationIndex&gt; colPivHouseholderQr() const;\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const FullPivHouseholderQR&lt;PlainObject, PermutationIndex&gt; fullPivHouseholderQr() const;\n  template &lt;typename PermutationIndex = DefaultPermutationIndex&gt;\n  inline const CompleteOrthogonalDecomposition&lt;PlainObject, PermutationIndex&gt; completeOrthogonalDecomposition() const;\n\n  /////////// Eigenvalues module ///////////\n\n  inline EigenvaluesReturnType eigenvalues() const;\n  inline RealScalar operatorNorm() const;\n\n  /////////// SVD module ///////////\n\n  template &lt;int Options = 0&gt;\n  inline JacobiSVD&lt;PlainObject, Options&gt; jacobiSvd() const;\n  template &lt;int Options = 0&gt;\n  EIGEN_DEPRECATED inline JacobiSVD&lt;PlainObject, Options&gt; jacobiSvd(unsigned int computationOptions) const;\n\n  template &lt;int Options = 0&gt;\n  inline BDCSVD&lt;PlainObject, Options&gt; bdcSvd() const;\n  template &lt;int Options = 0&gt;\n  EIGEN_DEPRECATED inline BDCSVD&lt;PlainObject, Options&gt; bdcSvd(unsigned int computationOptions) const;\n\n  /////////// Geometry module ///////////\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::cross_impl&lt;Derived, OtherDerived&gt;::return_type cross(\n      const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline PlainObject cross3(const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  EIGEN_DEVICE_FUNC inline PlainObject unitOrthogonal(void) const;\n\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline Matrix&lt;Scalar, 3, 1&gt; eulerAngles(Index a0, Index a1, Index a2) const;\n\n  EIGEN_DEVICE_FUNC inline Matrix&lt;Scalar, 3, 1&gt; canonicalEulerAngles(Index a0, Index a1, Index a2) const;\n\n  // put this as separate enum value to work around possible GCC 4.3 bug (?)\n  enum {\n    HomogeneousReturnTypeDirection =\n        ColsAtCompileTime == 1 &amp;&amp; RowsAtCompileTime == 1\n            ? ((internal::traits&lt;Derived&gt;::Flags &amp; RowMajorBit) == RowMajorBit ? Horizontal : Vertical)\n        : ColsAtCompileTime == 1 ? Vertical\n                                 : Horizontal\n  };\n  typedef Homogeneous&lt;Derived, HomogeneousReturnTypeDirection&gt; HomogeneousReturnType;\n  EIGEN_DEVICE_FUNC inline HomogeneousReturnType homogeneous() const;\n\n  enum { SizeMinusOne = SizeAtCompileTime == Dynamic ? Dynamic : SizeAtCompileTime - 1 };\n  typedef Block&lt;const Derived, internal::traits&lt;Derived&gt;::ColsAtCompileTime == 1 ? SizeMinusOne : 1,\n                internal::traits&lt;Derived&gt;::ColsAtCompileTime == 1 ? 1 : SizeMinusOne&gt;\n      ConstStartMinusOne;\n  typedef EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(ConstStartMinusOne, Scalar, quotient) HNormalizedReturnType;\n  EIGEN_DEVICE_FUNC inline const HNormalizedReturnType hnormalized() const;\n\n  ////////// Householder module ///////////\n\n  EIGEN_DEVICE_FUNC void makeHouseholderInPlace(Scalar&amp; tau, RealScalar&amp; beta);\n  template &lt;typename EssentialPart&gt;\n  EIGEN_DEVICE_FUNC void makeHouseholder(EssentialPart&amp; essential, Scalar&amp; tau, RealScalar&amp; beta) const;\n  template &lt;typename EssentialPart&gt;\n  EIGEN_DEVICE_FUNC void applyHouseholderOnTheLeft(const EssentialPart&amp; essential, const Scalar&amp; tau,\n                                                   Scalar* workspace);\n  template &lt;typename EssentialPart&gt;\n  EIGEN_DEVICE_FUNC void applyHouseholderOnTheRight(const EssentialPart&amp; essential, const Scalar&amp; tau,\n                                                    Scalar* workspace);\n\n  ///////// Jacobi module /////////\n\n  template &lt;typename OtherScalar&gt;\n  EIGEN_DEVICE_FUNC void applyOnTheLeft(Index p, Index q, const JacobiRotation&lt;OtherScalar&gt;&amp; j);\n  template &lt;typename OtherScalar&gt;\n  EIGEN_DEVICE_FUNC void applyOnTheRight(Index p, Index q, const JacobiRotation&lt;OtherScalar&gt;&amp; j);\n\n  ///////// SparseCore module /////////\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_STRONG_INLINE const typename SparseMatrixBase&lt;OtherDerived&gt;::template CwiseProductDenseReturnType&lt;Derived&gt;::Type\n  cwiseProduct(const SparseMatrixBase&lt;OtherDerived&gt;&amp; other) const {\n    return other.cwiseProduct(derived());\n  }\n\n  ///////// MatrixFunctions module /////////\n\n  typedef typename internal::stem_function&lt;Scalar&gt;::type StemFunction;\n#define EIGEN_MATRIX_FUNCTION(ReturnType, Name, Description)                                                        \\\n  /** \\returns an expression of the matrix Description of \\c *this. \\brief This function requires the &lt;a            \\\n   * href=&quot;unsupported/group__MatrixFunctions__Module.html&quot;&gt; unsupported MatrixFunctions module&lt;/a&gt;. To compute the \\\n   * coefficient-wise Description use ArrayBase::##Name . */                                                        \\\n  const ReturnType&lt;Derived&gt; Name() const;\n#define EIGEN_MATRIX_FUNCTION_1(ReturnType, Name, Description, Argument)                                            \\\n  /** \\returns an expression of the matrix Description of \\c *this. \\brief This function requires the &lt;a            \\\n   * href=&quot;unsupported/group__MatrixFunctions__Module.html&quot;&gt; unsupported MatrixFunctions module&lt;/a&gt;. To compute the \\\n   * coefficient-wise Description use ArrayBase::##Name . */                                                        \\\n  const ReturnType&lt;Derived&gt; Name(Argument) const;\n\n  EIGEN_MATRIX_FUNCTION(MatrixExponentialReturnValue, exp, exponential)\n  /** \\brief Helper function for the &lt;a href=&quot;unsupported/group__MatrixFunctions__Module.html&quot;&gt; unsupported\n   * MatrixFunctions module&lt;/a&gt;.*/\n  const MatrixFunctionReturnValue&lt;Derived&gt; matrixFunction(StemFunction f) const;\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, cosh, hyperbolic cosine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, sinh, hyperbolic sine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, atanh, inverse hyperbolic cosine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, acosh, inverse hyperbolic cosine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, asinh, inverse hyperbolic sine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, cos, cosine)\n  EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, sin, sine)\n  EIGEN_MATRIX_FUNCTION(MatrixSquareRootReturnValue, sqrt, square root)\n  EIGEN_MATRIX_FUNCTION(MatrixLogarithmReturnValue, log, logarithm)\n  EIGEN_MATRIX_FUNCTION_1(MatrixPowerReturnValue, pow, power to \\c p, const RealScalar&amp; p)\n  EIGEN_MATRIX_FUNCTION_1(MatrixComplexPowerReturnValue, pow, power to \\c p, const internal::make_complex_t&lt;Scalar&gt;&amp; p)\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(MatrixBase)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MatrixBase)\n\n private:\n  EIGEN_DEVICE_FUNC explicit MatrixBase(int);\n  EIGEN_DEVICE_FUNC MatrixBase(int, int);\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC explicit MatrixBase(const MatrixBase&lt;OtherDerived&gt;&amp;);\n\n protected:\n  // mixing arrays and matrices is not legal\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator+=(const ArrayBase&lt;OtherDerived&gt;&amp;) {\n    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,\n                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);\n    return *this;\n  }\n  // mixing arrays and matrices is not legal\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator-=(const ArrayBase&lt;OtherDerived&gt;&amp;) {\n    EIGEN_STATIC_ASSERT(std::ptrdiff_t(sizeof(typename OtherDerived::Scalar)) == -1,\n                        YOU_CANNOT_MIX_ARRAYS_AND_MATRICES);\n    return *this;\n  }\n};\n\n/***************************************************************************\n * Implementation of matrix base methods\n ***************************************************************************/\n\n/** replaces \\c *this by \\c *this * \\a other.\n *\n * \\returns a reference to \\c *this\n *\n * Example: \\include MatrixBase_applyOnTheRight.cpp\n * Output: \\verbinclude MatrixBase_applyOnTheRight.out\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\ninline Derived&amp; MatrixBase&lt;Derived&gt;::operator*=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  other.derived().applyThisOnTheRight(derived());\n  return derived();\n}\n\n/** replaces \\c *this by \\c *this * \\a other. It is equivalent to MatrixBase::operator*=().\n *\n * Example: \\include MatrixBase_applyOnTheRight.cpp\n * Output: \\verbinclude MatrixBase_applyOnTheRight.out\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\ninline void MatrixBase&lt;Derived&gt;::applyOnTheRight(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  other.derived().applyThisOnTheRight(derived());\n}\n\n/** replaces \\c *this by \\a other * \\c *this.\n *\n * Example: \\include MatrixBase_applyOnTheLeft.cpp\n * Output: \\verbinclude MatrixBase_applyOnTheLeft.out\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\ninline void MatrixBase&lt;Derived&gt;::applyOnTheLeft(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n  other.derived().applyThisOnTheLeft(derived());\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_MATRIXBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_NOALIAS_H\n#define EIGEN_NOALIAS_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\class NoAlias\n * \\ingroup Core_Module\n *\n * \\brief Pseudo expression providing an operator = assuming no aliasing\n *\n * \\tparam ExpressionType the type of the object on which to do the lazy assignment\n *\n * This class represents an expression with special assignment operators\n * assuming no aliasing between the target expression and the source expression.\n * More precisely it alloas to bypass the EvalBeforeAssignBit flag of the source expression.\n * It is the return type of MatrixBase::noalias()\n * and most of the time this is the only way it is used.\n *\n * \\sa MatrixBase::noalias()\n */\ntemplate &lt;typename ExpressionType, template &lt;typename&gt; class StorageBase&gt;\nclass NoAlias {\n public:\n  typedef typename ExpressionType::Scalar Scalar;\n\n  EIGEN_DEVICE_FUNC explicit NoAlias(ExpressionType&amp; expression) : m_expression(expression) {}\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ExpressionType&amp; operator=(const StorageBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment_no_alias(m_expression, other.derived(),\n                             internal::assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return m_expression;\n  }\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ExpressionType&amp; operator+=(const StorageBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment_no_alias(m_expression, other.derived(),\n                             internal::add_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return m_expression;\n  }\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ExpressionType&amp; operator-=(const StorageBase&lt;OtherDerived&gt;&amp; other) {\n    call_assignment_no_alias(m_expression, other.derived(),\n                             internal::sub_assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return m_expression;\n  }\n\n  EIGEN_DEVICE_FUNC ExpressionType&amp; expression() const { return m_expression; }\n\n protected:\n  ExpressionType&amp; m_expression;\n};\n\n/** \\returns a pseudo expression of \\c *this with an operator= assuming\n * no aliasing between \\c *this and the source expression.\n *\n * More precisely, noalias() allows to bypass the EvalBeforeAssignBit flag.\n * Currently, even though several expressions may alias, only product\n * expressions have this flag. Therefore, noalias() is only useful when\n * the source expression contains a matrix product.\n *\n * Here are some examples where noalias is useful:\n * \\code\n * D.noalias()  = A * B;\n * D.noalias() += A.transpose() * B;\n * D.noalias() -= 2 * A * B.adjoint();\n * \\endcode\n *\n * On the other hand the following example will lead to a \\b wrong result:\n * \\code\n * A.noalias() = A * B;\n * \\endcode\n * because the result matrix A is also an operand of the matrix product. Therefore,\n * there is no alternative than evaluating A * B in a temporary, that is the default\n * behavior when you write:\n * \\code\n * A = A * B;\n * \\endcode\n *\n * \\sa class NoAlias\n */\ntemplate &lt;typename Derived&gt;\nNoAlias&lt;Derived, MatrixBase&gt; EIGEN_DEVICE_FUNC MatrixBase&lt;Derived&gt;::noalias() {\n  return NoAlias&lt;Derived, Eigen::MatrixBase&gt;(derived());\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_NOALIAS_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2009-2015 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_PERMUTATIONMATRIX_H\n#define EIGEN_PERMUTATIONMATRIX_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\nenum PermPermProduct_t { PermPermProduct };\n\n}  // end namespace internal\n\n/** \\class PermutationBase\n * \\ingroup Core_Module\n *\n * \\brief Base class for permutations\n *\n * \\tparam Derived the derived class\n *\n * This class is the base class for all expressions representing a permutation matrix,\n * internally stored as a vector of integers.\n * The convention followed here is that if \\f$ \\sigma \\f$ is a permutation, the corresponding permutation matrix\n * \\f$ P_\\sigma \\f$ is such that if \\f$ (e_1,\\ldots,e_p) \\f$ is the canonical basis, we have:\n *  \\f[ P_\\sigma(e_i) = e_{\\sigma(i)}. \\f]\n * This convention ensures that for any two permutations \\f$ \\sigma, \\tau \\f$, we have:\n *  \\f[ P_{\\sigma\\circ\\tau} = P_\\sigma P_\\tau. \\f]\n *\n * Permutation matrices are square and invertible.\n *\n * Notice that in addition to the member functions and operators listed here, there also are non-member\n * operator* to multiply any kind of permutation object with any kind of matrix expression (MatrixBase)\n * on either side.\n *\n * \\sa class PermutationMatrix, class PermutationWrapper\n */\ntemplate &lt;typename Derived&gt;\nclass PermutationBase : public EigenBase&lt;Derived&gt; {\n  typedef internal::traits&lt;Derived&gt; Traits;\n  typedef EigenBase&lt;Derived&gt; Base;\n\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef typename Traits::IndicesType IndicesType;\n  enum {\n    Flags = Traits::Flags,\n    RowsAtCompileTime = Traits::RowsAtCompileTime,\n    ColsAtCompileTime = Traits::ColsAtCompileTime,\n    MaxRowsAtCompileTime = Traits::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = Traits::MaxColsAtCompileTime\n  };\n  typedef typename Traits::StorageIndex StorageIndex;\n  typedef Matrix&lt;StorageIndex, RowsAtCompileTime, ColsAtCompileTime, 0, MaxRowsAtCompileTime, MaxColsAtCompileTime&gt;\n      DenseMatrixType;\n  typedef PermutationMatrix&lt;IndicesType::SizeAtCompileTime, IndicesType::MaxSizeAtCompileTime, StorageIndex&gt;\n      PlainPermutationType;\n  typedef PlainPermutationType PlainObject;\n  using Base::derived;\n  typedef Inverse&lt;Derived&gt; InverseReturnType;\n  typedef void Scalar;\n#endif\n\n  /** Copies the other permutation into *this */\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator=(const PermutationBase&lt;OtherDerived&gt;&amp; other) {\n    indices() = other.indices();\n    return derived();\n  }\n\n  /** Assignment from the Transpositions \\a tr */\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator=(const TranspositionsBase&lt;OtherDerived&gt;&amp; tr) {\n    setIdentity(tr.size());\n    for (Index k = size() - 1; k &gt;= 0; --k) applyTranspositionOnTheRight(k, tr.coeff(k));\n    return derived();\n  }\n\n  /** \\returns the number of rows */\n  inline EIGEN_DEVICE_FUNC Index rows() const { return Index(indices().size()); }\n\n  /** \\returns the number of columns */\n  inline EIGEN_DEVICE_FUNC Index cols() const { return Index(indices().size()); }\n\n  /** \\returns the size of a side of the respective square matrix, i.e., the number of indices */\n  inline EIGEN_DEVICE_FUNC Index size() const { return Index(indices().size()); }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  template &lt;typename DenseDerived&gt;\n  void evalTo(MatrixBase&lt;DenseDerived&gt;&amp; other) const {\n    other.setZero();\n    for (Index i = 0; i &lt; rows(); ++i) other.coeffRef(indices().coeff(i), i) = typename DenseDerived::Scalar(1);\n  }\n#endif\n\n  /** \\returns a Matrix object initialized from this permutation matrix. Notice that it\n   * is inefficient to return this Matrix object by value. For efficiency, favor using\n   * the Matrix constructor taking EigenBase objects.\n   */\n  DenseMatrixType toDenseMatrix() const { return derived(); }\n\n  /** const version of indices(). */\n  const IndicesType&amp; indices() const { return derived().indices(); }\n  /** \\returns a reference to the stored array representing the permutation. */\n  IndicesType&amp; indices() { return derived().indices(); }\n\n  /** Resizes to given size.\n   */\n  inline void resize(Index newSize) { indices().resize(newSize); }\n\n  /** Sets *this to be the identity permutation matrix */\n  void setIdentity() {\n    StorageIndex n = StorageIndex(size());\n    for (StorageIndex i = 0; i &lt; n; ++i) indices().coeffRef(i) = i;\n  }\n\n  /** Sets *this to be the identity permutation matrix of given size.\n   */\n  void setIdentity(Index newSize) {\n    resize(newSize);\n    setIdentity();\n  }\n\n  /** Multiplies *this by the transposition \\f$(ij)\\f$ on the left.\n   *\n   * \\returns a reference to *this.\n   *\n   * \\warning This is much slower than applyTranspositionOnTheRight(Index,Index):\n   * this has linear complexity and requires a lot of branching.\n   *\n   * \\sa applyTranspositionOnTheRight(Index,Index)\n   */\n  Derived&amp; applyTranspositionOnTheLeft(Index i, Index j) {\n    eigen_assert(i &gt;= 0 &amp;&amp; j &gt;= 0 &amp;&amp; i &lt; size() &amp;&amp; j &lt; size());\n    for (Index k = 0; k &lt; size(); ++k) {\n      if (indices().coeff(k) == i)\n        indices().coeffRef(k) = StorageIndex(j);\n      else if (indices().coeff(k) == j)\n        indices().coeffRef(k) = StorageIndex(i);\n    }\n    return derived();\n  }\n\n  /** Multiplies *this by the transposition \\f$(ij)\\f$ on the right.\n   *\n   * \\returns a reference to *this.\n   *\n   * This is a fast operation, it only consists in swapping two indices.\n   *\n   * \\sa applyTranspositionOnTheLeft(Index,Index)\n   */\n  Derived&amp; applyTranspositionOnTheRight(Index i, Index j) {\n    eigen_assert(i &gt;= 0 &amp;&amp; j &gt;= 0 &amp;&amp; i &lt; size() &amp;&amp; j &lt; size());\n    std::swap(indices().coeffRef(i), indices().coeffRef(j));\n    return derived();\n  }\n\n  /** \\returns the inverse permutation matrix.\n   *\n   * \\note \\blank \\note_try_to_help_rvo\n   */\n  inline InverseReturnType inverse() const { return InverseReturnType(derived()); }\n  /** \\returns the transpose permutation matrix.\n   *\n   * \\note \\blank \\note_try_to_help_rvo\n   */\n  inline InverseReturnType transpose() const { return InverseReturnType(derived()); }\n\n  /**** multiplication helpers to hopefully get RVO ****/\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n protected:\n  template &lt;typename OtherDerived&gt;\n  void assignTranspose(const PermutationBase&lt;OtherDerived&gt;&amp; other) {\n    for (Index i = 0; i &lt; rows(); ++i) indices().coeffRef(other.indices().coeff(i)) = i;\n  }\n  template &lt;typename Lhs, typename Rhs&gt;\n  void assignProduct(const Lhs&amp; lhs, const Rhs&amp; rhs) {\n    eigen_assert(lhs.cols() == rhs.rows());\n    for (Index i = 0; i &lt; rows(); ++i) indices().coeffRef(i) = lhs.indices().coeff(rhs.indices().coeff(i));\n  }\n#endif\n\n public:\n  /** \\returns the product permutation matrix.\n   *\n   * \\note \\blank \\note_try_to_help_rvo\n   */\n  template &lt;typename Other&gt;\n  inline PlainPermutationType operator*(const PermutationBase&lt;Other&gt;&amp; other) const {\n    return PlainPermutationType(internal::PermPermProduct, derived(), other.derived());\n  }\n\n  /** \\returns the product of a permutation with another inverse permutation.\n   *\n   * \\note \\blank \\note_try_to_help_rvo\n   */\n  template &lt;typename Other&gt;\n  inline PlainPermutationType operator*(const InverseImpl&lt;Other, PermutationStorage&gt;&amp; other) const {\n    return PlainPermutationType(internal::PermPermProduct, *this, other.eval());\n  }\n\n  /** \\returns the product of an inverse permutation with another permutation.\n   *\n   * \\note \\blank \\note_try_to_help_rvo\n   */\n  template &lt;typename Other&gt;\n  friend inline PlainPermutationType operator*(const InverseImpl&lt;Other, PermutationStorage&gt;&amp; other,\n                                               const PermutationBase&amp; perm) {\n    return PlainPermutationType(internal::PermPermProduct, other.eval(), perm);\n  }\n\n  /** \\returns the determinant of the permutation matrix, which is either 1 or -1 depending on the parity of the\n   * permutation.\n   *\n   * This function is O(\\c n) procedure allocating a buffer of \\c n booleans.\n   */\n  Index determinant() const {\n    Index res = 1;\n    Index n = size();\n    Matrix&lt;bool, RowsAtCompileTime, 1, 0, MaxRowsAtCompileTime&gt; mask(n);\n    mask.fill(false);\n    Index r = 0;\n    while (r &lt; n) {\n      // search for the next seed\n      while (r &lt; n &amp;&amp; mask[r]) r++;\n      if (r &gt;= n) break;\n      // we got one, let&#x27;s follow it until we are back to the seed\n      Index k0 = r++;\n      mask.coeffRef(k0) = true;\n      for (Index k = indices().coeff(k0); k != k0; k = indices().coeff(k)) {\n        mask.coeffRef(k) = true;\n        res = -res;\n      }\n    }\n    return res;\n  }\n\n protected:\n};\n\nnamespace internal {\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_&gt;\nstruct traits&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt;\n    : traits&lt;\n          Matrix&lt;StorageIndex_, SizeAtCompileTime, SizeAtCompileTime, 0, MaxSizeAtCompileTime, MaxSizeAtCompileTime&gt; &gt; {\n  typedef PermutationStorage StorageKind;\n  typedef Matrix&lt;StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1&gt; IndicesType;\n  typedef StorageIndex_ StorageIndex;\n  typedef void Scalar;\n};\n}  // namespace internal\n\n/** \\class PermutationMatrix\n * \\ingroup Core_Module\n *\n * \\brief Permutation matrix\n *\n * \\tparam SizeAtCompileTime the number of rows/cols, or Dynamic\n * \\tparam MaxSizeAtCompileTime the maximum number of rows/cols, or Dynamic. This optional parameter defaults to\n * SizeAtCompileTime. Most of the time, you should not have to specify it. \\tparam StorageIndex_ the integer type of the\n * indices\n *\n * This class represents a permutation matrix, internally stored as a vector of integers.\n *\n * \\sa class PermutationBase, class PermutationWrapper, class DiagonalMatrix\n */\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_&gt;\nclass PermutationMatrix\n    : public PermutationBase&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt; {\n  typedef PermutationBase&lt;PermutationMatrix&gt; Base;\n  typedef internal::traits&lt;PermutationMatrix&gt; Traits;\n\n public:\n  typedef const PermutationMatrix&amp; Nested;\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename Traits::StorageIndex StorageIndex;\n#endif\n\n  inline PermutationMatrix() {}\n\n  /** Constructs an uninitialized permutation matrix of given size.\n   */\n  explicit inline PermutationMatrix(Index size) : m_indices(size) {\n    eigen_internal_assert(size &lt;= NumTraits&lt;StorageIndex&gt;::highest());\n  }\n\n  /** Copy constructor. */\n  template &lt;typename OtherDerived&gt;\n  inline PermutationMatrix(const PermutationBase&lt;OtherDerived&gt;&amp; other) : m_indices(other.indices()) {}\n\n  /** Generic constructor from expression of the indices. The indices\n   * array has the meaning that the permutations sends each integer i to indices[i].\n   *\n   * \\warning It is your responsibility to check that the indices array that you passes actually\n   * describes a permutation, i.e., each value between 0 and n-1 occurs exactly once, where n is the\n   * array&#x27;s size.\n   */\n  template &lt;typename Other&gt;\n  explicit inline PermutationMatrix(const MatrixBase&lt;Other&gt;&amp; indices) : m_indices(indices) {}\n\n  /** Convert the Transpositions \\a tr to a permutation matrix */\n  template &lt;typename Other&gt;\n  explicit PermutationMatrix(const TranspositionsBase&lt;Other&gt;&amp; tr) : m_indices(tr.size()) {\n    *this = tr;\n  }\n\n  /** Copies the other permutation into *this */\n  template &lt;typename Other&gt;\n  PermutationMatrix&amp; operator=(const PermutationBase&lt;Other&gt;&amp; other) {\n    m_indices = other.indices();\n    return *this;\n  }\n\n  /** Assignment from the Transpositions \\a tr */\n  template &lt;typename Other&gt;\n  PermutationMatrix&amp; operator=(const TranspositionsBase&lt;Other&gt;&amp; tr) {\n    return Base::operator=(tr.derived());\n  }\n\n  /** const version of indices(). */\n  const IndicesType&amp; indices() const { return m_indices; }\n  /** \\returns a reference to the stored array representing the permutation. */\n  IndicesType&amp; indices() { return m_indices; }\n\n  /**** multiplication helpers to hopefully get RVO ****/\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  template &lt;typename Other&gt;\n  PermutationMatrix(const InverseImpl&lt;Other, PermutationStorage&gt;&amp; other)\n      : m_indices(other.derived().nestedExpression().size()) {\n    eigen_internal_assert(m_indices.size() &lt;= NumTraits&lt;StorageIndex&gt;::highest());\n    StorageIndex end = StorageIndex(m_indices.size());\n    for (StorageIndex i = 0; i &lt; end; ++i)\n      m_indices.coeffRef(other.derived().nestedExpression().indices().coeff(i)) = i;\n  }\n  template &lt;typename Lhs, typename Rhs&gt;\n  PermutationMatrix(internal::PermPermProduct_t, const Lhs&amp; lhs, const Rhs&amp; rhs) : m_indices(lhs.indices().size()) {\n    Base::assignProduct(lhs, rhs);\n  }\n#endif\n\n protected:\n  IndicesType m_indices;\n};\n\nnamespace internal {\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_&gt;\nstruct traits&lt;Map&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess_&gt; &gt;\n    : traits&lt;\n          Matrix&lt;StorageIndex_, SizeAtCompileTime, SizeAtCompileTime, 0, MaxSizeAtCompileTime, MaxSizeAtCompileTime&gt; &gt; {\n  typedef PermutationStorage StorageKind;\n  typedef Map&lt;const Matrix&lt;StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1&gt;, PacketAccess_&gt; IndicesType;\n  typedef StorageIndex_ StorageIndex;\n  typedef void Scalar;\n};\n}  // namespace internal\n\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_&gt;\nclass Map&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess_&gt;\n    : public PermutationBase&lt;\n          Map&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess_&gt; &gt; {\n  typedef PermutationBase&lt;Map&gt; Base;\n  typedef internal::traits&lt;Map&gt; Traits;\n\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename IndicesType::Scalar StorageIndex;\n#endif\n\n  inline Map(const StorageIndex* indicesPtr) : m_indices(indicesPtr) {}\n\n  inline Map(const StorageIndex* indicesPtr, Index size) : m_indices(indicesPtr, size) {}\n\n  /** Copies the other permutation into *this */\n  template &lt;typename Other&gt;\n  Map&amp; operator=(const PermutationBase&lt;Other&gt;&amp; other) {\n    return Base::operator=(other.derived());\n  }\n\n  /** Assignment from the Transpositions \\a tr */\n  template &lt;typename Other&gt;\n  Map&amp; operator=(const TranspositionsBase&lt;Other&gt;&amp; tr) {\n    return Base::operator=(tr.derived());\n  }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** This is a special case of the templated operator=. Its purpose is to\n   * prevent a default operator= from hiding the templated operator=.\n   */\n  Map&amp; operator=(const Map&amp; other) {\n    m_indices = other.m_indices;\n    return *this;\n  }\n#endif\n\n  /** const version of indices(). */\n  const IndicesType&amp; indices() const { return m_indices; }\n  /** \\returns a reference to the stored array representing the permutation. */\n  IndicesType&amp; indices() { return m_indices; }\n\n protected:\n  IndicesType m_indices;\n};\n\ntemplate &lt;typename IndicesType_&gt;\nclass TranspositionsWrapper;\nnamespace internal {\ntemplate &lt;typename IndicesType_&gt;\nstruct traits&lt;PermutationWrapper&lt;IndicesType_&gt; &gt; {\n  typedef PermutationStorage StorageKind;\n  typedef void Scalar;\n  typedef typename IndicesType_::Scalar StorageIndex;\n  typedef IndicesType_ IndicesType;\n  enum {\n    RowsAtCompileTime = IndicesType_::SizeAtCompileTime,\n    ColsAtCompileTime = IndicesType_::SizeAtCompileTime,\n    MaxRowsAtCompileTime = IndicesType::MaxSizeAtCompileTime,\n    MaxColsAtCompileTime = IndicesType::MaxSizeAtCompileTime,\n    Flags = 0\n  };\n};\n}  // namespace internal\n\n/** \\class PermutationWrapper\n * \\ingroup Core_Module\n *\n * \\brief Class to view a vector of integers as a permutation matrix\n *\n * \\tparam IndicesType_ the type of the vector of integer (can be any compatible expression)\n *\n * This class allows to view any vector expression of integers as a permutation matrix.\n *\n * \\sa class PermutationBase, class PermutationMatrix\n */\ntemplate &lt;typename IndicesType_&gt;\nclass PermutationWrapper : public PermutationBase&lt;PermutationWrapper&lt;IndicesType_&gt; &gt; {\n  typedef PermutationBase&lt;PermutationWrapper&gt; Base;\n  typedef internal::traits&lt;PermutationWrapper&gt; Traits;\n\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef typename Traits::IndicesType IndicesType;\n#endif\n\n  inline PermutationWrapper(const IndicesType&amp; indices) : m_indices(indices) {}\n\n  /** const version of indices(). */\n  const internal::remove_all_t&lt;typename IndicesType::Nested&gt;&amp; indices() const { return m_indices; }\n\n protected:\n  typename IndicesType::Nested m_indices;\n};\n\n/** \\returns the matrix with the permutation applied to the columns.\n */\ntemplate &lt;typename MatrixDerived, typename PermutationDerived&gt;\nEIGEN_DEVICE_FUNC const Product&lt;MatrixDerived, PermutationDerived, AliasFreeProduct&gt; operator*(\n    const MatrixBase&lt;MatrixDerived&gt;&amp; matrix, const PermutationBase&lt;PermutationDerived&gt;&amp; permutation) {\n  return Product&lt;MatrixDerived, PermutationDerived, AliasFreeProduct&gt;(matrix.derived(), permutation.derived());\n}\n\n/** \\returns the matrix with the permutation applied to the rows.\n */\ntemplate &lt;typename PermutationDerived, typename MatrixDerived&gt;\nEIGEN_DEVICE_FUNC const Product&lt;PermutationDerived, MatrixDerived, AliasFreeProduct&gt; operator*(\n    const PermutationBase&lt;PermutationDerived&gt;&amp; permutation, const MatrixBase&lt;MatrixDerived&gt;&amp; matrix) {\n  return Product&lt;PermutationDerived, MatrixDerived, AliasFreeProduct&gt;(permutation.derived(), matrix.derived());\n}\n\ntemplate &lt;typename PermutationType&gt;\nclass InverseImpl&lt;PermutationType, PermutationStorage&gt; : public EigenBase&lt;Inverse&lt;PermutationType&gt; &gt; {\n  typedef typename PermutationType::PlainPermutationType PlainPermutationType;\n  typedef internal::traits&lt;PermutationType&gt; PermTraits;\n\n protected:\n  InverseImpl() {}\n\n public:\n  typedef Inverse&lt;PermutationType&gt; InverseType;\n  using EigenBase&lt;Inverse&lt;PermutationType&gt; &gt;::derived;\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  typedef typename PermutationType::DenseMatrixType DenseMatrixType;\n  enum {\n    RowsAtCompileTime = PermTraits::RowsAtCompileTime,\n    ColsAtCompileTime = PermTraits::ColsAtCompileTime,\n    MaxRowsAtCompileTime = PermTraits::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = PermTraits::MaxColsAtCompileTime\n  };\n#endif\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  template &lt;typename DenseDerived&gt;\n  void evalTo(MatrixBase&lt;DenseDerived&gt;&amp; other) const {\n    other.setZero();\n    for (Index i = 0; i &lt; derived().rows(); ++i)\n      other.coeffRef(i, derived().nestedExpression().indices().coeff(i)) = typename DenseDerived::Scalar(1);\n  }\n#endif\n\n  /** \\return the equivalent permutation matrix */\n  PlainPermutationType eval() const { return derived(); }\n\n  DenseMatrixType toDenseMatrix() const { return derived(); }\n\n  /** \\returns the matrix with the inverse permutation applied to the columns.\n   */\n  template &lt;typename OtherDerived&gt;\n  friend const Product&lt;OtherDerived, InverseType, AliasFreeProduct&gt; operator*(const MatrixBase&lt;OtherDerived&gt;&amp; matrix,\n                                                                              const InverseType&amp; trPerm) {\n    return Product&lt;OtherDerived, InverseType, AliasFreeProduct&gt;(matrix.derived(), trPerm.derived());\n  }\n\n  /** \\returns the matrix with the inverse permutation applied to the rows.\n   */\n  template &lt;typename OtherDerived&gt;\n  const Product&lt;InverseType, OtherDerived, AliasFreeProduct&gt; operator*(const MatrixBase&lt;OtherDerived&gt;&amp; matrix) const {\n    return Product&lt;InverseType, OtherDerived, AliasFreeProduct&gt;(derived(), matrix.derived());\n  }\n};\n\ntemplate &lt;typename Derived&gt;\nconst PermutationWrapper&lt;const Derived&gt; MatrixBase&lt;Derived&gt;::asPermutation() const {\n  return derived();\n}\n\nnamespace internal {\n\ntemplate &lt;&gt;\nstruct AssignmentKind&lt;DenseShape, PermutationShape&gt; {\n  typedef EigenBase2EigenBase Kind;\n};\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_PERMUTATIONMATRIX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_DENSESTORAGEBASE_H\n#define EIGEN_DENSESTORAGEBASE_H\n\n#if defined(EIGEN_INITIALIZE_MATRICES_BY_ZERO)\n#define EIGEN_INITIALIZE_COEFFS\n#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED \\\n  for (Index i = 0; i &lt; base().size(); ++i) coeffRef(i) = Scalar(0);\n#elif defined(EIGEN_INITIALIZE_MATRICES_BY_NAN)\n#define EIGEN_INITIALIZE_COEFFS\n#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED \\\n  for (Index i = 0; i &lt; base().size(); ++i) coeffRef(i) = std::numeric_limits&lt;Scalar&gt;::quiet_NaN();\n#else\n#undef EIGEN_INITIALIZE_COEFFS\n#define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED\n#endif\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n#ifndef EIGEN_NO_DEBUG\ntemplate &lt;int MaxSizeAtCompileTime, int MaxRowsAtCompileTime, int MaxColsAtCompileTime&gt;\nstruct check_rows_cols_for_overflow {\n  EIGEN_STATIC_ASSERT(MaxRowsAtCompileTime* MaxColsAtCompileTime == MaxSizeAtCompileTime,\n                      YOU MADE A PROGRAMMING MISTAKE)\n  template &lt;typename Index&gt;\n  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index, Index) {}\n};\n\ntemplate &lt;int MaxRowsAtCompileTime&gt;\nstruct check_rows_cols_for_overflow&lt;Dynamic, MaxRowsAtCompileTime, Dynamic&gt; {\n  template &lt;typename Index&gt;\n  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index, Index cols) {\n    constexpr Index MaxIndex = NumTraits&lt;Index&gt;::highest();\n    bool error = cols &gt; (MaxIndex / MaxRowsAtCompileTime);\n    if (error) throw_std_bad_alloc();\n  }\n};\n\ntemplate &lt;int MaxColsAtCompileTime&gt;\nstruct check_rows_cols_for_overflow&lt;Dynamic, Dynamic, MaxColsAtCompileTime&gt; {\n  template &lt;typename Index&gt;\n  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index rows, Index) {\n    constexpr Index MaxIndex = NumTraits&lt;Index&gt;::highest();\n    bool error = rows &gt; (MaxIndex / MaxColsAtCompileTime);\n    if (error) throw_std_bad_alloc();\n  }\n};\n\ntemplate &lt;&gt;\nstruct check_rows_cols_for_overflow&lt;Dynamic, Dynamic, Dynamic&gt; {\n  template &lt;typename Index&gt;\n  EIGEN_DEVICE_FUNC static EIGEN_ALWAYS_INLINE constexpr void run(Index rows, Index cols) {\n    constexpr Index MaxIndex = NumTraits&lt;Index&gt;::highest();\n    bool error = cols == 0 ? false : (rows &gt; (MaxIndex / cols));\n    if (error) throw_std_bad_alloc();\n  }\n};\n#endif\n\ntemplate &lt;typename Derived, typename OtherDerived = Derived,\n          bool IsVector = bool(Derived::IsVectorAtCompileTime) &amp;&amp; bool(OtherDerived::IsVectorAtCompileTime)&gt;\nstruct conservative_resize_like_impl;\n\ntemplate &lt;typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers&gt;\nstruct matrix_swap_impl;\n\n}  // end namespace internal\n\n/** \\class PlainObjectBase\n * \\ingroup Core_Module\n * \\brief %Dense storage base class for matrices and arrays.\n *\n * This class can be extended with the help of the plugin mechanism described on the page\n * \\ref TopicCustomizing_Plugins by defining the preprocessor symbol \\c EIGEN_PLAINOBJECTBASE_PLUGIN.\n *\n * \\tparam Derived is the derived type, e.g., a Matrix or Array\n *\n * \\sa \\ref TopicClassHierarchy\n */\ntemplate &lt;typename Derived&gt;\nclass PlainObjectBase : public internal::dense_xpr_base&lt;Derived&gt;::type {\n public:\n  enum { Options = internal::traits&lt;Derived&gt;::Options };\n  typedef typename internal::dense_xpr_base&lt;Derived&gt;::type Base;\n\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n\n  typedef typename internal::packet_traits&lt;Scalar&gt;::type PacketScalar;\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n  typedef Derived DenseType;\n\n  using Base::ColsAtCompileTime;\n  using Base::Flags;\n  using Base::IsVectorAtCompileTime;\n  using Base::MaxColsAtCompileTime;\n  using Base::MaxRowsAtCompileTime;\n  using Base::MaxSizeAtCompileTime;\n  using Base::RowsAtCompileTime;\n  using Base::SizeAtCompileTime;\n\n  typedef Eigen::Map&lt;Derived, Unaligned&gt; MapType;\n  typedef const Eigen::Map&lt;const Derived, Unaligned&gt; ConstMapType;\n  typedef Eigen::Map&lt;Derived, AlignedMax&gt; AlignedMapType;\n  typedef const Eigen::Map&lt;const Derived, AlignedMax&gt; ConstAlignedMapType;\n  template &lt;typename StrideType&gt;\n  struct StridedMapType {\n    typedef Eigen::Map&lt;Derived, Unaligned, StrideType&gt; type;\n  };\n  template &lt;typename StrideType&gt;\n  struct StridedConstMapType {\n    typedef Eigen::Map&lt;const Derived, Unaligned, StrideType&gt; type;\n  };\n  template &lt;typename StrideType&gt;\n  struct StridedAlignedMapType {\n    typedef Eigen::Map&lt;Derived, AlignedMax, StrideType&gt; type;\n  };\n  template &lt;typename StrideType&gt;\n  struct StridedConstAlignedMapType {\n    typedef Eigen::Map&lt;const Derived, AlignedMax, StrideType&gt; type;\n  };\n\n protected:\n  DenseStorage&lt;Scalar, Base::MaxSizeAtCompileTime, Base::RowsAtCompileTime, Base::ColsAtCompileTime, Options&gt; m_storage;\n\n public:\n  enum { NeedsToAlign = (SizeAtCompileTime != Dynamic) &amp;&amp; (internal::traits&lt;Derived&gt;::Alignment &gt; 0) };\n  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)\n\n  EIGEN_STATIC_ASSERT(internal::check_implication(MaxRowsAtCompileTime == 1 &amp;&amp; MaxColsAtCompileTime != 1,\n                                                  (int(Options) &amp; RowMajor) == RowMajor),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT(internal::check_implication(MaxColsAtCompileTime == 1 &amp;&amp; MaxRowsAtCompileTime != 1,\n                                                  (int(Options) &amp; RowMajor) == 0),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime &gt;= 0), INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime &gt;= 0), INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime &gt;= 0),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime &gt;= 0),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime == Dynamic),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT((MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime == Dynamic),\n                      INVALID_MATRIX_TEMPLATE_PARAMETERS)\n  EIGEN_STATIC_ASSERT(((Options &amp; (DontAlign | RowMajor)) == Options), INVALID_MATRIX_TEMPLATE_PARAMETERS)\n\n  EIGEN_DEVICE_FUNC Base&amp; base() { return *static_cast&lt;Base*&gt;(this); }\n  EIGEN_DEVICE_FUNC const Base&amp; base() const { return *static_cast&lt;const Base*&gt;(this); }\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }\n\n  /** This is an overloaded version of DenseCoeffsBase&lt;Derived,ReadOnlyAccessors&gt;::coeff(Index,Index) const\n   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.\n   *\n   * See DenseCoeffsBase&lt;Derived,ReadOnlyAccessors&gt;::coeff(Index) const for details. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar&amp; coeff(Index rowId, Index colId) const {\n    if (Flags &amp; RowMajorBit)\n      return m_storage.data()[colId + rowId * m_storage.cols()];\n    else  // column-major\n      return m_storage.data()[rowId + colId * m_storage.rows()];\n  }\n\n  /** This is an overloaded version of DenseCoeffsBase&lt;Derived,ReadOnlyAccessors&gt;::coeff(Index) const\n   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.\n   *\n   * See DenseCoeffsBase&lt;Derived,ReadOnlyAccessors&gt;::coeff(Index) const for details. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar&amp; coeff(Index index) const {\n    return m_storage.data()[index];\n  }\n\n  /** This is an overloaded version of DenseCoeffsBase&lt;Derived,WriteAccessors&gt;::coeffRef(Index,Index) const\n   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.\n   *\n   * See DenseCoeffsBase&lt;Derived,WriteAccessors&gt;::coeffRef(Index,Index) const for details. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar&amp; coeffRef(Index rowId, Index colId) {\n    if (Flags &amp; RowMajorBit)\n      return m_storage.data()[colId + rowId * m_storage.cols()];\n    else  // column-major\n      return m_storage.data()[rowId + colId * m_storage.rows()];\n  }\n\n  /** This is an overloaded version of DenseCoeffsBase&lt;Derived,WriteAccessors&gt;::coeffRef(Index) const\n   * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.\n   *\n   * See DenseCoeffsBase&lt;Derived,WriteAccessors&gt;::coeffRef(Index) const for details. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Scalar&amp; coeffRef(Index index) { return m_storage.data()[index]; }\n\n  /** This is the const version of coeffRef(Index,Index) which is thus synonym of coeff(Index,Index).\n   * It is provided for convenience. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar&amp; coeffRef(Index rowId, Index colId) const {\n    if (Flags &amp; RowMajorBit)\n      return m_storage.data()[colId + rowId * m_storage.cols()];\n    else  // column-major\n      return m_storage.data()[rowId + colId * m_storage.rows()];\n  }\n\n  /** This is the const version of coeffRef(Index) which is thus synonym of coeff(Index).\n   * It is provided for convenience. */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr const Scalar&amp; coeffRef(Index index) const {\n    return m_storage.data()[index];\n  }\n\n  /** \\internal */\n  template &lt;int LoadMode&gt;\n  EIGEN_STRONG_INLINE PacketScalar packet(Index rowId, Index colId) const {\n    return internal::ploadt&lt;PacketScalar, LoadMode&gt;(\n        m_storage.data() + (Flags &amp; RowMajorBit ? colId + rowId * m_storage.cols() : rowId + colId * m_storage.rows()));\n  }\n\n  /** \\internal */\n  template &lt;int LoadMode&gt;\n  EIGEN_STRONG_INLINE PacketScalar packet(Index index) const {\n    return internal::ploadt&lt;PacketScalar, LoadMode&gt;(m_storage.data() + index);\n  }\n\n  /** \\internal */\n  template &lt;int StoreMode&gt;\n  EIGEN_STRONG_INLINE void writePacket(Index rowId, Index colId, const PacketScalar&amp; val) {\n    internal::pstoret&lt;Scalar, PacketScalar, StoreMode&gt;(\n        m_storage.data() + (Flags &amp; RowMajorBit ? colId + rowId * m_storage.cols() : rowId + colId * m_storage.rows()),\n        val);\n  }\n\n  /** \\internal */\n  template &lt;int StoreMode&gt;\n  EIGEN_STRONG_INLINE void writePacket(Index index, const PacketScalar&amp; val) {\n    internal::pstoret&lt;Scalar, PacketScalar, StoreMode&gt;(m_storage.data() + index, val);\n  }\n\n  /** \\returns a const pointer to the data array of this matrix */\n  EIGEN_DEVICE_FUNC constexpr const Scalar* data() const { return m_storage.data(); }\n\n  /** \\returns a pointer to the data array of this matrix */\n  EIGEN_DEVICE_FUNC constexpr Scalar* data() { return m_storage.data(); }\n\n  /** Resizes \\c *this to a \\a rows x \\a cols matrix.\n   *\n   * This method is intended for dynamic-size matrices, although it is legal to call it on any\n   * matrix as long as fixed dimensions are left unchanged. If you only want to change the number\n   * of rows and/or of columns, you can use resize(NoChange_t, Index), resize(Index, NoChange_t).\n   *\n   * If the current number of coefficients of \\c *this exactly matches the\n   * product \\a rows * \\a cols, then no memory allocation is performed and\n   * the current values are left unchanged. In all other cases, including\n   * shrinking, the data is reallocated and all previous values are lost.\n   *\n   * Example: \\include Matrix_resize_int_int.cpp\n   * Output: \\verbinclude Matrix_resize_int_int.out\n   *\n   * \\sa resize(Index) for vectors, resize(NoChange_t, Index), resize(Index, NoChange_t)\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr void resize(Index rows, Index cols) {\n    eigen_assert(internal::check_implication(RowsAtCompileTime != Dynamic, rows == RowsAtCompileTime) &amp;&amp;\n                 internal::check_implication(ColsAtCompileTime != Dynamic, cols == ColsAtCompileTime) &amp;&amp;\n                 internal::check_implication(RowsAtCompileTime == Dynamic &amp;&amp; MaxRowsAtCompileTime != Dynamic,\n                                             rows &lt;= MaxRowsAtCompileTime) &amp;&amp;\n                 internal::check_implication(ColsAtCompileTime == Dynamic &amp;&amp; MaxColsAtCompileTime != Dynamic,\n                                             cols &lt;= MaxColsAtCompileTime) &amp;&amp;\n                 rows &gt;= 0 &amp;&amp; cols &gt;= 0 &amp;&amp; &quot;Invalid sizes when resizing a matrix or array.&quot;);\n#ifndef EIGEN_NO_DEBUG\n    internal::check_rows_cols_for_overflow&lt;MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime&gt;::run(rows,\n                                                                                                                  cols);\n#endif\n#ifdef EIGEN_INITIALIZE_COEFFS\n    Index size = rows * cols;\n    bool size_changed = size != this-&gt;size();\n    m_storage.resize(size, rows, cols);\n    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED\n#else\n    m_storage.resize(rows * cols, rows, cols);\n#endif\n  }\n\n  /** Resizes \\c *this to a vector of length \\a size\n   *\n   * \\only_for_vectors. This method does not work for\n   * partially dynamic matrices when the static dimension is anything other\n   * than 1. For example it will not work with Matrix&lt;double, 2, Dynamic&gt;.\n   *\n   * Example: \\include Matrix_resize_int.cpp\n   * Output: \\verbinclude Matrix_resize_int.out\n   *\n   * \\sa resize(Index,Index), resize(NoChange_t, Index), resize(Index, NoChange_t)\n   */\n  EIGEN_DEVICE_FUNC inline constexpr void resize(Index size) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(PlainObjectBase)\n    eigen_assert(((SizeAtCompileTime == Dynamic &amp;&amp; (MaxSizeAtCompileTime == Dynamic || size &lt;= MaxSizeAtCompileTime)) ||\n                  SizeAtCompileTime == size) &amp;&amp;\n                 size &gt;= 0);\n#ifdef EIGEN_INITIALIZE_COEFFS\n    bool size_changed = size != this-&gt;size();\n#endif\n    if (RowsAtCompileTime == 1)\n      m_storage.resize(size, 1, size);\n    else\n      m_storage.resize(size, size, 1);\n#ifdef EIGEN_INITIALIZE_COEFFS\n    if (size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED\n#endif\n  }\n\n  /** Resizes the matrix, changing only the number of columns. For the parameter of type NoChange_t, just pass the\n   * special value \\c NoChange as in the example below.\n   *\n   * Example: \\include Matrix_resize_NoChange_int.cpp\n   * Output: \\verbinclude Matrix_resize_NoChange_int.out\n   *\n   * \\sa resize(Index,Index)\n   */\n  EIGEN_DEVICE_FUNC inline constexpr void resize(NoChange_t, Index cols) { resize(rows(), cols); }\n\n  /** Resizes the matrix, changing only the number of rows. For the parameter of type NoChange_t, just pass the special\n   * value \\c NoChange as in the example below.\n   *\n   * Example: \\include Matrix_resize_int_NoChange.cpp\n   * Output: \\verbinclude Matrix_resize_int_NoChange.out\n   *\n   * \\sa resize(Index,Index)\n   */\n  EIGEN_DEVICE_FUNC inline constexpr void resize(Index rows, NoChange_t) { resize(rows, cols()); }\n\n  /** Resizes \\c *this to have the same dimensions as \\a other.\n   * Takes care of doing all the checking that&#x27;s needed.\n   *\n   * Note that copying a row-vector into a vector (and conversely) is allowed.\n   * The resizing, if any, is then done in the appropriate way so that row-vectors\n   * remain row-vectors and vectors remain vectors.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resizeLike(const EigenBase&lt;OtherDerived&gt;&amp; _other) {\n    const OtherDerived&amp; other = _other.derived();\n#ifndef EIGEN_NO_DEBUG\n    internal::check_rows_cols_for_overflow&lt;MaxSizeAtCompileTime, MaxRowsAtCompileTime, MaxColsAtCompileTime&gt;::run(\n        other.rows(), other.cols());\n#endif\n    const Index othersize = other.rows() * other.cols();\n    if (RowsAtCompileTime == 1) {\n      eigen_assert(other.rows() == 1 || other.cols() == 1);\n      resize(1, othersize);\n    } else if (ColsAtCompileTime == 1) {\n      eigen_assert(other.rows() == 1 || other.cols() == 1);\n      resize(othersize, 1);\n    } else\n      resize(other.rows(), other.cols());\n  }\n\n  /** Resizes the matrix to \\a rows x \\a cols while leaving old values untouched.\n   *\n   * The method is intended for matrices of dynamic size. If you only want to change the number\n   * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or\n   * conservativeResize(Index, NoChange_t).\n   *\n   * Matrices are resized relative to the top-left element. In case values need to be\n   * appended to the matrix they will be uninitialized.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index rows, Index cols) {\n    internal::conservative_resize_like_impl&lt;Derived&gt;::run(*this, rows, cols);\n  }\n\n  /** Resizes the matrix to \\a rows x \\a cols while leaving old values untouched.\n   *\n   * As opposed to conservativeResize(Index rows, Index cols), this version leaves\n   * the number of columns unchanged.\n   *\n   * In case the matrix is growing, new rows will be uninitialized.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index rows, NoChange_t) {\n    // Note: see the comment in conservativeResize(Index,Index)\n    conservativeResize(rows, cols());\n  }\n\n  /** Resizes the matrix to \\a rows x \\a cols while leaving old values untouched.\n   *\n   * As opposed to conservativeResize(Index rows, Index cols), this version leaves\n   * the number of rows unchanged.\n   *\n   * In case the matrix is growing, new columns will be uninitialized.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(NoChange_t, Index cols) {\n    // Note: see the comment in conservativeResize(Index,Index)\n    conservativeResize(rows(), cols);\n  }\n\n  /** Resizes the vector to \\a size while retaining old values.\n   *\n   * \\only_for_vectors. This method does not work for\n   * partially dynamic matrices when the static dimension is anything other\n   * than 1. For example it will not work with Matrix&lt;double, 2, Dynamic&gt;.\n   *\n   * When values are appended, they will be uninitialized.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResize(Index size) {\n    internal::conservative_resize_like_impl&lt;Derived&gt;::run(*this, size);\n  }\n\n  /** Resizes the matrix to \\a rows x \\a cols of \\c other, while leaving old values untouched.\n   *\n   * The method is intended for matrices of dynamic size. If you only want to change the number\n   * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or\n   * conservativeResize(Index, NoChange_t).\n   *\n   * Matrices are resized relative to the top-left element. In case values need to be\n   * appended to the matrix they will copied from \\c other.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void conservativeResizeLike(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    internal::conservative_resize_like_impl&lt;Derived, OtherDerived&gt;::run(*this, other);\n  }\n\n  /** This is a special case of the templated operator=. Its purpose is to\n   * prevent a default operator= from hiding the templated operator=.\n   */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived&amp; operator=(const PlainObjectBase&amp; other) {\n    return _set(other);\n  }\n\n  /** \\sa MatrixBase::lazyAssign() */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; lazyAssign(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    _resize_to_match(other);\n    return Base::lazyAssign(other.derived());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const ReturnByValue&lt;OtherDerived&gt;&amp; func) {\n    resize(func.rows(), func.cols());\n    return Base::operator=(func);\n  }\n\n  // Prevent user from trying to instantiate PlainObjectBase objects\n  // by making all its constructor protected. See bug 1074.\n protected:\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase() = default;\n  /** \\brief Move constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase(PlainObjectBase&amp;&amp;) = default;\n  /** \\brief Move assignment operator */\n  EIGEN_DEVICE_FUNC constexpr PlainObjectBase&amp; operator=(PlainObjectBase&amp;&amp; other) EIGEN_NOEXCEPT {\n    m_storage = std::move(other.m_storage);\n    return *this;\n  }\n\n  /** Copy constructor */\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr PlainObjectBase(const PlainObjectBase&amp;) = default;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(Index size, Index rows, Index cols)\n      : m_storage(size, rows, cols) {}\n\n  /** \\brief Construct a row of column vector with fixed size from an arbitrary number of coefficients.\n   *\n   * \\only_for_vectors\n   *\n   * This constructor is for 1D array or vectors with more than 4 coefficients.\n   *\n   * \\warning To construct a column (resp. row) vector of fixed length, the number of values passed to this\n   * constructor must match the the fixed number of rows (resp. columns) of \\c *this.\n   */\n  template &lt;typename... ArgTypes&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const Scalar&amp; a0, const Scalar&amp; a1, const Scalar&amp; a2,\n                                                        const Scalar&amp; a3, const ArgTypes&amp;... args)\n      : m_storage() {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, sizeof...(args) + 4);\n    m_storage.data()[0] = a0;\n    m_storage.data()[1] = a1;\n    m_storage.data()[2] = a2;\n    m_storage.data()[3] = a3;\n    Index i = 4;\n    auto x = {(m_storage.data()[i++] = args, 0)...};\n    static_cast&lt;void&gt;(x);\n  }\n\n  /** \\brief Constructs a Matrix or Array and initializes it by elements given by an initializer list of initializer\n   * lists\n   */\n  EIGEN_DEVICE_FUNC explicit constexpr EIGEN_STRONG_INLINE PlainObjectBase(\n      const std::initializer_list&lt;std::initializer_list&lt;Scalar&gt;&gt;&amp; list)\n      : m_storage() {\n    size_t list_size = 0;\n    if (list.begin() != list.end()) {\n      list_size = list.begin()-&gt;size();\n    }\n\n    // This is to allow syntax like VectorXi {{1, 2, 3, 4}}\n    if (ColsAtCompileTime == 1 &amp;&amp; list.size() == 1) {\n      eigen_assert(list_size == static_cast&lt;size_t&gt;(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);\n      resize(list_size, ColsAtCompileTime);\n      if (list.begin()-&gt;begin() != nullptr) {\n        Index index = 0;\n        for (const Scalar&amp; e : *list.begin()) {\n          coeffRef(index++) = e;\n        }\n      }\n    } else {\n      eigen_assert(list.size() == static_cast&lt;size_t&gt;(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);\n      eigen_assert(list_size == static_cast&lt;size_t&gt;(ColsAtCompileTime) || ColsAtCompileTime == Dynamic);\n      resize(list.size(), list_size);\n\n      Index row_index = 0;\n      for (const std::initializer_list&lt;Scalar&gt;&amp; row : list) {\n        eigen_assert(list_size == row.size());\n        Index col_index = 0;\n        for (const Scalar&amp; e : row) {\n          coeffRef(row_index, col_index) = e;\n          ++col_index;\n        }\n        ++row_index;\n      }\n    }\n  }\n\n  /** \\sa PlainObjectBase::operator=(const EigenBase&lt;OtherDerived&gt;&amp;) */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const DenseBase&lt;OtherDerived&gt;&amp; other) : m_storage() {\n    resizeLike(other);\n    _set_noalias(other);\n  }\n\n  /** \\sa PlainObjectBase::operator=(const EigenBase&lt;OtherDerived&gt;&amp;) */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const EigenBase&lt;OtherDerived&gt;&amp; other) : m_storage() {\n    resizeLike(other);\n    *this = other.derived();\n  }\n  /** \\brief Copy constructor with in-place evaluation */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE PlainObjectBase(const ReturnByValue&lt;OtherDerived&gt;&amp; other) {\n    // FIXME this does not automatically transpose vectors if necessary\n    resize(other.rows(), other.cols());\n    other.evalTo(this-&gt;derived());\n  }\n\n public:\n  /** \\brief Copies the generic expression \\a other into *this.\n   * \\copydetails DenseBase::operator=(const EigenBase&lt;OtherDerived&gt; &amp;other)\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    _resize_to_match(other);\n    Base::operator=(other.derived());\n    return this-&gt;derived();\n  }\n\n  /** \\name Map\n   * These are convenience functions returning Map objects. The Map() static functions return unaligned Map objects,\n   * while the AlignedMap() functions return aligned Map objects and thus should be called only with 16-byte-aligned\n   * \\a data pointers.\n   *\n   * Here is an example using strides:\n   * \\include Matrix_Map_stride.cpp\n   * Output: \\verbinclude Matrix_Map_stride.out\n   *\n   * \\see class Map\n   */\n  ///@{\n  static inline ConstMapType Map(const Scalar* data) { return ConstMapType(data); }\n  static inline MapType Map(Scalar* data) { return MapType(data); }\n  static inline ConstMapType Map(const Scalar* data, Index size) { return ConstMapType(data, size); }\n  static inline MapType Map(Scalar* data, Index size) { return MapType(data, size); }\n  static inline ConstMapType Map(const Scalar* data, Index rows, Index cols) { return ConstMapType(data, rows, cols); }\n  static inline MapType Map(Scalar* data, Index rows, Index cols) { return MapType(data, rows, cols); }\n\n  static inline ConstAlignedMapType MapAligned(const Scalar* data) { return ConstAlignedMapType(data); }\n  static inline AlignedMapType MapAligned(Scalar* data) { return AlignedMapType(data); }\n  static inline ConstAlignedMapType MapAligned(const Scalar* data, Index size) {\n    return ConstAlignedMapType(data, size);\n  }\n  static inline AlignedMapType MapAligned(Scalar* data, Index size) { return AlignedMapType(data, size); }\n  static inline ConstAlignedMapType MapAligned(const Scalar* data, Index rows, Index cols) {\n    return ConstAlignedMapType(data, rows, cols);\n  }\n  static inline AlignedMapType MapAligned(Scalar* data, Index rows, Index cols) {\n    return AlignedMapType(data, rows, cols);\n  }\n\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(const Scalar* data,\n                                                                             const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(Scalar* data,\n                                                                        const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(const Scalar* data, Index size,\n                                                                             const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, size, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(Scalar* data, Index size,\n                                                                        const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, size, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(const Scalar* data, Index rows, Index cols,\n                                                                             const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, rows, cols, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type Map(Scalar* data, Index rows, Index cols,\n                                                                        const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, rows, cols, stride);\n  }\n\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      const Scalar* data, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      Scalar* data, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      const Scalar* data, Index size, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, size, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      Scalar* data, Index size, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, size, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      const Scalar* data, Index rows, Index cols, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedConstAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, rows, cols, stride);\n  }\n  template &lt;int Outer, int Inner&gt;\n  static inline typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type MapAligned(\n      Scalar* data, Index rows, Index cols, const Stride&lt;Outer, Inner&gt;&amp; stride) {\n    return typename StridedAlignedMapType&lt;Stride&lt;Outer, Inner&gt;&gt;::type(data, rows, cols, stride);\n  }\n  ///@}\n\n  using Base::setConstant;\n  EIGEN_DEVICE_FUNC Derived&amp; setConstant(Index size, const Scalar&amp; val);\n  EIGEN_DEVICE_FUNC Derived&amp; setConstant(Index rows, Index cols, const Scalar&amp; val);\n  EIGEN_DEVICE_FUNC Derived&amp; setConstant(NoChange_t, Index cols, const Scalar&amp; val);\n  EIGEN_DEVICE_FUNC Derived&amp; setConstant(Index rows, NoChange_t, const Scalar&amp; val);\n\n  using Base::setZero;\n  EIGEN_DEVICE_FUNC Derived&amp; setZero(Index size);\n  EIGEN_DEVICE_FUNC Derived&amp; setZero(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC Derived&amp; setZero(NoChange_t, Index cols);\n  EIGEN_DEVICE_FUNC Derived&amp; setZero(Index rows, NoChange_t);\n\n  using Base::setOnes;\n  EIGEN_DEVICE_FUNC Derived&amp; setOnes(Index size);\n  EIGEN_DEVICE_FUNC Derived&amp; setOnes(Index rows, Index cols);\n  EIGEN_DEVICE_FUNC Derived&amp; setOnes(NoChange_t, Index cols);\n  EIGEN_DEVICE_FUNC Derived&amp; setOnes(Index rows, NoChange_t);\n\n  using Base::setRandom;\n  Derived&amp; setRandom(Index size);\n  Derived&amp; setRandom(Index rows, Index cols);\n  Derived&amp; setRandom(NoChange_t, Index cols);\n  Derived&amp; setRandom(Index rows, NoChange_t);\n\n#ifdef EIGEN_PLAINOBJECTBASE_PLUGIN\n#include EIGEN_PLAINOBJECTBASE_PLUGIN\n#endif\n\n protected:\n  /** \\internal Resizes *this in preparation for assigning \\a other to it.\n   * Takes care of doing all the checking that&#x27;s needed.\n   *\n   * Note that copying a row-vector into a vector (and conversely) is allowed.\n   * The resizing, if any, is then done in the appropriate way so that row-vectors\n   * remain row-vectors and vectors remain vectors.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _resize_to_match(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n#ifdef EIGEN_NO_AUTOMATIC_RESIZING\n    eigen_assert((this-&gt;size() == 0 || (IsVectorAtCompileTime ? (this-&gt;size() == other.size())\n                                                              : (rows() == other.rows() &amp;&amp; cols() == other.cols()))) &amp;&amp;\n                 &quot;Size mismatch. Automatic resizing is disabled because EIGEN_NO_AUTOMATIC_RESIZING is defined&quot;);\n    EIGEN_ONLY_USED_FOR_DEBUG(other);\n#else\n    resizeLike(other);\n#endif\n  }\n\n  /**\n   * \\brief Copies the value of the expression \\a other into \\c *this with automatic resizing.\n   *\n   * *this might be resized to match the dimensions of \\a other. If *this was a null matrix (not already initialized),\n   * it will be initialized.\n   *\n   * Note that copying a row-vector into a vector (and conversely) is allowed.\n   * The resizing, if any, is then done in the appropriate way so that row-vectors\n   * remain row-vectors and vectors remain vectors.\n   *\n   * \\sa operator=(const MatrixBase&lt;OtherDerived&gt;&amp;), _set_noalias()\n   *\n   * \\internal\n   */\n  // aliasing is dealt once in internal::call_assignment\n  // so at this stage we have to assume aliasing... and resising has to be done later.\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived&amp; _set(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    internal::call_assignment(this-&gt;derived(), other.derived());\n    return this-&gt;derived();\n  }\n\n  /** \\internal Like _set() but additionally makes the assumption that no aliasing effect can happen (which\n   * is the case when creating a new matrix) so one can enforce lazy evaluation.\n   *\n   * \\sa operator=(const MatrixBase&lt;OtherDerived&gt;&amp;), _set()\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE constexpr Derived&amp; _set_noalias(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    // I don&#x27;t think we need this resize call since the lazyAssign will anyways resize\n    // and lazyAssign will be called by the assign selector.\n    //_resize_to_match(other);\n    // the &#x27;false&#x27; below means to enforce lazy evaluation. We don&#x27;t use lazyAssign() because\n    // it wouldn&#x27;t allow to copy a row-vector into a column-vector.\n    internal::call_assignment_no_alias(this-&gt;derived(), other.derived(),\n                                       internal::assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n    return this-&gt;derived();\n  }\n\n  template &lt;typename T0, typename T1&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(Index rows, Index cols,\n                                                    std::enable_if_t&lt;Base::SizeAtCompileTime != 2, T0&gt;* = 0) {\n    EIGEN_STATIC_ASSERT(internal::is_valid_index_type&lt;T0&gt;::value &amp;&amp; internal::is_valid_index_type&lt;T1&gt;::value,\n                        T0 AND T1 MUST BE INTEGER TYPES)\n    resize(rows, cols);\n  }\n\n  template &lt;typename T0, typename T1&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(const T0&amp; val0, const T1&amp; val1,\n                                                    std::enable_if_t&lt;Base::SizeAtCompileTime == 2, T0&gt;* = 0) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 2)\n    m_storage.data()[0] = Scalar(val0);\n    m_storage.data()[1] = Scalar(val1);\n  }\n\n  template &lt;typename T0, typename T1&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init2(\n      const Index&amp; val0, const Index&amp; val1,\n      std::enable_if_t&lt;(!internal::is_same&lt;Index, Scalar&gt;::value) &amp;&amp; (internal::is_same&lt;T0, Index&gt;::value) &amp;&amp;\n                           (internal::is_same&lt;T1, Index&gt;::value) &amp;&amp; Base::SizeAtCompileTime == 2,\n                       T1&gt;* = 0) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 2)\n    m_storage.data()[0] = Scalar(val0);\n    m_storage.data()[1] = Scalar(val1);\n  }\n\n  // The argument is convertible to the Index type and we either have a non 1x1 Matrix, or a dynamic-sized Array,\n  // then the argument is meant to be the size of the object.\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(\n      Index size,\n      std::enable_if_t&lt;(Base::SizeAtCompileTime != 1 || !internal::is_convertible&lt;T, Scalar&gt;::value) &amp;&amp;\n                           ((!internal::is_same&lt;typename internal::traits&lt;Derived&gt;::XprKind, ArrayXpr&gt;::value ||\n                             Base::SizeAtCompileTime == Dynamic)),\n                       T&gt;* = 0) {\n    // NOTE MSVC 2008 complains if we directly put bool(NumTraits&lt;T&gt;::IsInteger) as the EIGEN_STATIC_ASSERT argument.\n    const bool is_integer_alike = internal::is_valid_index_type&lt;T&gt;::value;\n    EIGEN_UNUSED_VARIABLE(is_integer_alike);\n    EIGEN_STATIC_ASSERT(is_integer_alike, FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED)\n    resize(size);\n  }\n\n  // We have a 1x1 matrix/array =&gt; the argument is interpreted as the value of the unique coefficient (case where scalar\n  // type can be implicitly converted)\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(\n      const Scalar&amp; val0,\n      std::enable_if_t&lt;Base::SizeAtCompileTime == 1 &amp;&amp; internal::is_convertible&lt;T, Scalar&gt;::value, T&gt;* = 0) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 1)\n    m_storage.data()[0] = val0;\n  }\n\n  // We have a 1x1 matrix/array =&gt; the argument is interpreted as the value of the unique coefficient (case where scalar\n  // type match the index type)\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(\n      const Index&amp; val0,\n      std::enable_if_t&lt;(!internal::is_same&lt;Index, Scalar&gt;::value) &amp;&amp; (internal::is_same&lt;Index, T&gt;::value) &amp;&amp;\n                           Base::SizeAtCompileTime == 1 &amp;&amp; internal::is_convertible&lt;T, Scalar&gt;::value,\n                       T*&gt;* = 0) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 1)\n    m_storage.data()[0] = Scalar(val0);\n  }\n\n  // Initialize a fixed size matrix from a pointer to raw data\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const Scalar* data) {\n    this-&gt;_set_noalias(ConstMapType(data));\n  }\n\n  // Initialize an arbitrary matrix from a dense expression\n  template &lt;typename T, typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    this-&gt;_set_noalias(other);\n  }\n\n  // Initialize an arbitrary matrix from an object convertible to the Derived type.\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const Derived&amp; other) {\n    this-&gt;_set_noalias(other);\n  }\n\n  // Initialize an arbitrary matrix from a generic Eigen expression\n  template &lt;typename T, typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const EigenBase&lt;OtherDerived&gt;&amp; other) {\n    this-&gt;derived() = other;\n  }\n\n  template &lt;typename T, typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const ReturnByValue&lt;OtherDerived&gt;&amp; other) {\n    resize(other.rows(), other.cols());\n    other.evalTo(this-&gt;derived());\n  }\n\n  template &lt;typename T, typename OtherDerived, int ColsAtCompileTime&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(const RotationBase&lt;OtherDerived, ColsAtCompileTime&gt;&amp; r) {\n    this-&gt;derived() = r;\n  }\n\n  // For fixed-size Array&lt;Scalar,...&gt;\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(\n      const Scalar&amp; val0,\n      std::enable_if_t&lt;Base::SizeAtCompileTime != Dynamic &amp;&amp; Base::SizeAtCompileTime != 1 &amp;&amp;\n                           internal::is_convertible&lt;T, Scalar&gt;::value &amp;&amp;\n                           internal::is_same&lt;typename internal::traits&lt;Derived&gt;::XprKind, ArrayXpr&gt;::value,\n                       T&gt;* = 0) {\n    Base::setConstant(val0);\n  }\n\n  // For fixed-size Array&lt;Index,...&gt;\n  template &lt;typename T&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _init1(\n      const Index&amp; val0,\n      std::enable_if_t&lt;(!internal::is_same&lt;Index, Scalar&gt;::value) &amp;&amp; (internal::is_same&lt;Index, T&gt;::value) &amp;&amp;\n                           Base::SizeAtCompileTime != Dynamic &amp;&amp; Base::SizeAtCompileTime != 1 &amp;&amp;\n                           internal::is_convertible&lt;T, Scalar&gt;::value &amp;&amp;\n                           internal::is_same&lt;typename internal::traits&lt;Derived&gt;::XprKind, ArrayXpr&gt;::value,\n                       T*&gt;* = 0) {\n    Base::setConstant(val0);\n  }\n\n  template &lt;typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers&gt;\n  friend struct internal::matrix_swap_impl;\n\n public:\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** \\internal\n   * \\brief Override DenseBase::swap() since for dynamic-sized matrices\n   * of same type it is enough to swap the data pointers.\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(DenseBase&lt;OtherDerived&gt;&amp; other) {\n    enum {SwapPointers = internal::is_same&lt;Derived, OtherDerived&gt;::value &amp;&amp; Base::SizeAtCompileTime == Dynamic};\n    internal::matrix_swap_impl&lt;Derived, OtherDerived, bool(SwapPointers)&gt;::run(this-&gt;derived(), other.derived());\n  }\n\n  /** \\internal\n   * \\brief const version forwarded to DenseBase::swap\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void swap(DenseBase&lt;OtherDerived&gt; const&amp; other) {\n    Base::swap(other.derived());\n  }\n\n  enum {IsPlainObjectBase = 1};\n#endif\n public:\n  // These apparently need to be down here for nvcc+icc to prevent duplicate\n  // Map symbol.\n  template &lt;typename PlainObjectType, int MapOptions, typename StrideType&gt;\n  friend class Eigen::Map;\n  friend class Eigen::Map&lt;Derived, Unaligned&gt;;\n  friend class Eigen::Map&lt;const Derived, Unaligned&gt;;\n#if EIGEN_MAX_ALIGN_BYTES &gt; 0\n  // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class\n  // twice.\n  friend class Eigen::Map&lt;Derived, AlignedMax&gt;;\n  friend class Eigen::Map&lt;const Derived, AlignedMax&gt;;\n#endif\n};\n\nnamespace internal {\n\ntemplate &lt;typename Derived, typename OtherDerived, bool IsVector&gt;\nstruct conservative_resize_like_impl {\n  static constexpr bool IsRelocatable = std::is_trivially_copyable&lt;typename Derived::Scalar&gt;::value;\n  static void run(DenseBase&lt;Derived&gt;&amp; _this, Index rows, Index cols) {\n    if (_this.rows() == rows &amp;&amp; _this.cols() == cols) return;\n    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)\n\n    if (IsRelocatable &amp;&amp;\n        ((Derived::IsRowMajor &amp;&amp; _this.cols() == cols) ||  // row-major and we change only the number of rows\n         (!Derived::IsRowMajor &amp;&amp; _this.rows() == rows)))  // column-major and we change only the number of columns\n    {\n#ifndef EIGEN_NO_DEBUG\n      internal::check_rows_cols_for_overflow&lt;Derived::MaxSizeAtCompileTime, Derived::MaxRowsAtCompileTime,\n                                             Derived::MaxColsAtCompileTime&gt;::run(rows, cols);\n#endif\n      _this.derived().m_storage.conservativeResize(rows * cols, rows, cols);\n    } else {\n      // The storage order does not allow us to use reallocation.\n      Derived tmp(rows, cols);\n      const Index common_rows = numext::mini(rows, _this.rows());\n      const Index common_cols = numext::mini(cols, _this.cols());\n      tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);\n      _this.derived().swap(tmp);\n    }\n  }\n\n  static void run(DenseBase&lt;Derived&gt;&amp; _this, const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    if (_this.rows() == other.rows() &amp;&amp; _this.cols() == other.cols()) return;\n\n    // Note: Here is space for improvement. Basically, for conservativeResize(Index,Index),\n    // neither RowsAtCompileTime or ColsAtCompileTime must be Dynamic. If only one of the\n    // dimensions is dynamic, one could use either conservativeResize(Index rows, NoChange_t) or\n    // conservativeResize(NoChange_t, Index cols). For these methods new static asserts like\n    // EIGEN_STATIC_ASSERT_DYNAMIC_ROWS and EIGEN_STATIC_ASSERT_DYNAMIC_COLS would be good.\n    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)\n    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(OtherDerived)\n\n    if (IsRelocatable &amp;&amp;\n        ((Derived::IsRowMajor &amp;&amp; _this.cols() == other.cols()) ||  // row-major and we change only the number of rows\n         (!Derived::IsRowMajor &amp;&amp;\n          _this.rows() == other.rows())))  // column-major and we change only the number of columns\n    {\n      const Index new_rows = other.rows() - _this.rows();\n      const Index new_cols = other.cols() - _this.cols();\n      _this.derived().m_storage.conservativeResize(other.size(), other.rows(), other.cols());\n      if (new_rows &gt; 0)\n        _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);\n      else if (new_cols &gt; 0)\n        _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);\n    } else {\n      // The storage order does not allow us to use reallocation.\n      Derived tmp(other);\n      const Index common_rows = numext::mini(tmp.rows(), _this.rows());\n      const Index common_cols = numext::mini(tmp.cols(), _this.cols());\n      tmp.block(0, 0, common_rows, common_cols) = _this.block(0, 0, common_rows, common_cols);\n      _this.derived().swap(tmp);\n    }\n  }\n};\n\n// Here, the specialization for vectors inherits from the general matrix case\n// to allow calling .conservativeResize(rows,cols) on vectors.\ntemplate &lt;typename Derived, typename OtherDerived&gt;\nstruct conservative_resize_like_impl&lt;Derived, OtherDerived, true&gt;\n    : conservative_resize_like_impl&lt;Derived, OtherDerived, false&gt; {\n  typedef conservative_resize_like_impl&lt;Derived, OtherDerived, false&gt; Base;\n  using Base::IsRelocatable;\n  using Base::run;\n\n  static void run(DenseBase&lt;Derived&gt;&amp; _this, Index size) {\n    const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : size;\n    const Index new_cols = Derived::RowsAtCompileTime == 1 ? size : 1;\n    if (IsRelocatable)\n      _this.derived().m_storage.conservativeResize(size, new_rows, new_cols);\n    else\n      Base::run(_this.derived(), new_rows, new_cols);\n  }\n\n  static void run(DenseBase&lt;Derived&gt;&amp; _this, const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    if (_this.rows() == other.rows() &amp;&amp; _this.cols() == other.cols()) return;\n\n    const Index num_new_elements = other.size() - _this.size();\n\n    const Index new_rows = Derived::RowsAtCompileTime == 1 ? 1 : other.rows();\n    const Index new_cols = Derived::RowsAtCompileTime == 1 ? other.cols() : 1;\n    if (IsRelocatable)\n      _this.derived().m_storage.conservativeResize(other.size(), new_rows, new_cols);\n    else\n      Base::run(_this.derived(), new_rows, new_cols);\n\n    if (num_new_elements &gt; 0) _this.tail(num_new_elements) = other.tail(num_new_elements);\n  }\n};\n\ntemplate &lt;typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers&gt;\nstruct matrix_swap_impl {\n  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(MatrixTypeA&amp; a, MatrixTypeB&amp; b) { a.base().swap(b); }\n};\n\ntemplate &lt;typename MatrixTypeA, typename MatrixTypeB&gt;\nstruct matrix_swap_impl&lt;MatrixTypeA, MatrixTypeB, true&gt; {\n  EIGEN_DEVICE_FUNC static inline void run(MatrixTypeA&amp; a, MatrixTypeB&amp; b) {\n    static_cast&lt;typename MatrixTypeA::Base&amp;&gt;(a).m_storage.swap(static_cast&lt;typename MatrixTypeB::Base&amp;&gt;(b).m_storage);\n  }\n};\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_DENSESTORAGEBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2012 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_REF_H\n#define EIGEN_REF_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\ntemplate &lt;typename PlainObjectType_, int Options_, typename StrideType_&gt;\nstruct traits&lt;Ref&lt;PlainObjectType_, Options_, StrideType_&gt; &gt;\n    : public traits&lt;Map&lt;PlainObjectType_, Options_, StrideType_&gt; &gt; {\n  typedef PlainObjectType_ PlainObjectType;\n  typedef StrideType_ StrideType;\n  enum {\n    Options = Options_,\n    Flags = traits&lt;Map&lt;PlainObjectType_, Options_, StrideType_&gt; &gt;::Flags | NestByRefBit,\n    Alignment = traits&lt;Map&lt;PlainObjectType_, Options_, StrideType_&gt; &gt;::Alignment,\n    InnerStrideAtCompileTime = traits&lt;Map&lt;PlainObjectType_, Options_, StrideType_&gt; &gt;::InnerStrideAtCompileTime,\n    OuterStrideAtCompileTime = traits&lt;Map&lt;PlainObjectType_, Options_, StrideType_&gt; &gt;::OuterStrideAtCompileTime\n  };\n\n  template &lt;typename Derived&gt;\n  struct match {\n    enum {\n      IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime || Derived::IsVectorAtCompileTime,\n      HasDirectAccess = internal::has_direct_access&lt;Derived&gt;::ret,\n      StorageOrderMatch =\n          IsVectorAtCompileTime || ((PlainObjectType::Flags &amp; RowMajorBit) == (Derived::Flags &amp; RowMajorBit)),\n      InnerStrideMatch = int(InnerStrideAtCompileTime) == int(Dynamic) ||\n                         int(InnerStrideAtCompileTime) == int(Derived::InnerStrideAtCompileTime) ||\n                         (int(InnerStrideAtCompileTime) == 0 &amp;&amp; int(Derived::InnerStrideAtCompileTime) == 1),\n      OuterStrideMatch = IsVectorAtCompileTime || int(OuterStrideAtCompileTime) == int(Dynamic) ||\n                         int(OuterStrideAtCompileTime) == int(Derived::OuterStrideAtCompileTime),\n      // NOTE, this indirection of evaluator&lt;Derived&gt;::Alignment is needed\n      // to workaround a very strange bug in MSVC related to the instantiation\n      // of has_*ary_operator in evaluator&lt;CwiseNullaryOp&gt;.\n      // This line is surprisingly very sensitive. For instance, simply adding parenthesis\n      // as &quot;DerivedAlignment = (int(evaluator&lt;Derived&gt;::Alignment)),&quot; will make MSVC fail...\n      DerivedAlignment = int(evaluator&lt;Derived&gt;::Alignment),\n      AlignmentMatch = (int(traits&lt;PlainObjectType&gt;::Alignment) == int(Unaligned)) ||\n                       (DerivedAlignment &gt;= int(Alignment)),  // FIXME the first condition is not very clear, it should\n                                                              // be replaced by the required alignment\n      ScalarTypeMatch = internal::is_same&lt;typename PlainObjectType::Scalar, typename Derived::Scalar&gt;::value,\n      MatchAtCompileTime = HasDirectAccess &amp;&amp; StorageOrderMatch &amp;&amp; InnerStrideMatch &amp;&amp; OuterStrideMatch &amp;&amp;\n                           AlignmentMatch &amp;&amp; ScalarTypeMatch\n    };\n    typedef std::conditional_t&lt;MatchAtCompileTime, internal::true_type, internal::false_type&gt; type;\n  };\n};\n\ntemplate &lt;typename Derived&gt;\nstruct traits&lt;RefBase&lt;Derived&gt; &gt; : public traits&lt;Derived&gt; {};\n\n}  // namespace internal\n\ntemplate &lt;typename Derived&gt;\nclass RefBase : public MapBase&lt;Derived&gt; {\n  typedef typename internal::traits&lt;Derived&gt;::PlainObjectType PlainObjectType;\n  typedef typename internal::traits&lt;Derived&gt;::StrideType StrideType;\n\n public:\n  typedef MapBase&lt;Derived&gt; Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(RefBase)\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const {\n    return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;\n  }\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const {\n    return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()\n           : IsVectorAtCompileTime                   ? this-&gt;size()\n           : int(Flags) &amp; RowMajorBit                ? this-&gt;cols()\n                                                     : this-&gt;rows();\n  }\n\n  EIGEN_DEVICE_FUNC RefBase()\n      : Base(0, RowsAtCompileTime == Dynamic ? 0 : RowsAtCompileTime,\n             ColsAtCompileTime == Dynamic ? 0 : ColsAtCompileTime),\n        // Stride&lt;&gt; does not allow default ctor for Dynamic strides, so let&#x27; initialize it with dummy values:\n        m_stride(StrideType::OuterStrideAtCompileTime == Dynamic ? 0 : StrideType::OuterStrideAtCompileTime,\n                 StrideType::InnerStrideAtCompileTime == Dynamic ? 0 : StrideType::InnerStrideAtCompileTime) {}\n\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(RefBase)\n\n protected:\n  typedef Stride&lt;StrideType::OuterStrideAtCompileTime, StrideType::InnerStrideAtCompileTime&gt; StrideBase;\n\n  // Resolves inner stride if default 0.\n  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveInnerStride(Index inner) { return inner == 0 ? 1 : inner; }\n\n  // Resolves outer stride if default 0.\n  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveOuterStride(Index inner, Index outer, Index rows, Index cols,\n                                                                    bool isVectorAtCompileTime, bool isRowMajor) {\n    return outer == 0 ? isVectorAtCompileTime ? inner * rows * cols : isRowMajor ? inner * cols : inner * rows : outer;\n  }\n\n  // Returns true if construction is valid, false if there is a stride mismatch,\n  // and fails if there is a size mismatch.\n  template &lt;typename Expression&gt;\n  EIGEN_DEVICE_FUNC bool construct(Expression&amp; expr) {\n    // Check matrix sizes.  If this is a compile-time vector, we do allow\n    // implicitly transposing.\n    EIGEN_STATIC_ASSERT(EIGEN_PREDICATE_SAME_MATRIX_SIZE(PlainObjectType, Expression)\n                            // If it is a vector, the transpose sizes might match.\n                            || (PlainObjectType::IsVectorAtCompileTime &amp;&amp;\n                                ((int(PlainObjectType::RowsAtCompileTime) == Eigen::Dynamic ||\n                                  int(Expression::ColsAtCompileTime) == Eigen::Dynamic ||\n                                  int(PlainObjectType::RowsAtCompileTime) == int(Expression::ColsAtCompileTime)) &amp;&amp;\n                                 (int(PlainObjectType::ColsAtCompileTime) == Eigen::Dynamic ||\n                                  int(Expression::RowsAtCompileTime) == Eigen::Dynamic ||\n                                  int(PlainObjectType::ColsAtCompileTime) == int(Expression::RowsAtCompileTime)))),\n                        YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES)\n\n    // Determine runtime rows and columns.\n    Index rows = expr.rows();\n    Index cols = expr.cols();\n    if (PlainObjectType::RowsAtCompileTime == 1) {\n      eigen_assert(expr.rows() == 1 || expr.cols() == 1);\n      rows = 1;\n      cols = expr.size();\n    } else if (PlainObjectType::ColsAtCompileTime == 1) {\n      eigen_assert(expr.rows() == 1 || expr.cols() == 1);\n      rows = expr.size();\n      cols = 1;\n    }\n    // Verify that the sizes are valid.\n    eigen_assert((PlainObjectType::RowsAtCompileTime == Dynamic) || (PlainObjectType::RowsAtCompileTime == rows));\n    eigen_assert((PlainObjectType::ColsAtCompileTime == Dynamic) || (PlainObjectType::ColsAtCompileTime == cols));\n\n    // If this is a vector, we might be transposing, which means that stride should swap.\n    const bool transpose = PlainObjectType::IsVectorAtCompileTime &amp;&amp; (rows != expr.rows());\n    // If the storage format differs, we also need to swap the stride.\n    const bool row_major = ((PlainObjectType::Flags)&amp;RowMajorBit) != 0;\n    const bool expr_row_major = (Expression::Flags &amp; RowMajorBit) != 0;\n    const bool storage_differs = (row_major != expr_row_major);\n\n    const bool swap_stride = (transpose != storage_differs);\n\n    // Determine expr&#x27;s actual strides, resolving any defaults if zero.\n    const Index expr_inner_actual = resolveInnerStride(expr.innerStride());\n    const Index expr_outer_actual = resolveOuterStride(expr_inner_actual, expr.outerStride(), expr.rows(), expr.cols(),\n                                                       Expression::IsVectorAtCompileTime != 0, expr_row_major);\n\n    // If this is a column-major row vector or row-major column vector, the inner-stride\n    // is arbitrary, so set it to either the compile-time inner stride or 1.\n    const bool row_vector = (rows == 1);\n    const bool col_vector = (cols == 1);\n    const Index inner_stride =\n        ((!row_major &amp;&amp; row_vector) || (row_major &amp;&amp; col_vector))\n            ? (StrideType::InnerStrideAtCompileTime &gt; 0 ? Index(StrideType::InnerStrideAtCompileTime) : 1)\n        : swap_stride ? expr_outer_actual\n                      : expr_inner_actual;\n\n    // If this is a column-major column vector or row-major row vector, the outer-stride\n    // is arbitrary, so set it to either the compile-time outer stride or vector size.\n    const Index outer_stride =\n        ((!row_major &amp;&amp; col_vector) || (row_major &amp;&amp; row_vector))\n            ? (StrideType::OuterStrideAtCompileTime &gt; 0 ? Index(StrideType::OuterStrideAtCompileTime)\n                                                        : rows * cols * inner_stride)\n        : swap_stride ? expr_inner_actual\n                      : expr_outer_actual;\n\n    // Check if given inner/outer strides are compatible with compile-time strides.\n    const bool inner_valid = (StrideType::InnerStrideAtCompileTime == Dynamic) ||\n                             (resolveInnerStride(Index(StrideType::InnerStrideAtCompileTime)) == inner_stride);\n    if (!inner_valid) {\n      return false;\n    }\n\n    const bool outer_valid =\n        (StrideType::OuterStrideAtCompileTime == Dynamic) ||\n        (resolveOuterStride(inner_stride, Index(StrideType::OuterStrideAtCompileTime), rows, cols,\n                            PlainObjectType::IsVectorAtCompileTime != 0, row_major) == outer_stride);\n    if (!outer_valid) {\n      return false;\n    }\n\n    internal::construct_at&lt;Base&gt;(this, expr.data(), rows, cols);\n    internal::construct_at(&amp;m_stride, (StrideType::OuterStrideAtCompileTime == 0) ? 0 : outer_stride,\n                           (StrideType::InnerStrideAtCompileTime == 0) ? 0 : inner_stride);\n    return true;\n  }\n\n  StrideBase m_stride;\n};\n\n/** \\class Ref\n * \\ingroup Core_Module\n *\n * \\brief A matrix or vector expression mapping an existing expression\n *\n * \\tparam PlainObjectType the equivalent matrix type of the mapped data\n * \\tparam Options specifies the pointer alignment in bytes. It can be: \\c #Aligned128, , \\c #Aligned64, \\c #Aligned32,\n * \\c #Aligned16, \\c #Aligned8 or \\c #Unaligned. The default is \\c #Unaligned. \\tparam StrideType optionally specifies\n * strides. By default, Ref implies a contiguous storage along the inner dimension (inner stride==1), but accepts a\n * variable outer stride (leading dimension). This can be overridden by specifying strides. The type passed here must be\n * a specialization of the Stride template, see examples below.\n *\n * This class provides a way to write non-template functions taking Eigen objects as parameters while limiting the\n * number of copies. A Ref&lt;&gt; object can represent either a const expression or a l-value: \\code\n * // in-out argument:\n * void foo1(Ref&lt;VectorXf&gt; x);\n *\n * // read-only const argument:\n * void foo2(const Ref&lt;const VectorXf&gt;&amp; x);\n * \\endcode\n *\n * In the in-out case, the input argument must satisfy the constraints of the actual Ref&lt;&gt; type, otherwise a compilation\n * issue will be triggered. By default, a Ref&lt;VectorXf&gt; can reference any dense vector expression of float having a\n * contiguous memory layout. Likewise, a Ref&lt;MatrixXf&gt; can reference any column-major dense matrix expression of float\n * whose column&#x27;s elements are contiguously stored with the possibility to have a constant space in-between each column,\n * i.e. the inner stride must be equal to 1, but the outer stride (or leading dimension) can be greater than the number\n * of rows.\n *\n * In the const case, if the input expression does not match the above requirement, then it is evaluated into a\n * temporary before being passed to the function. Here are some examples: \\code MatrixXf A; VectorXf a; foo1(a.head());\n * // OK foo1(A.col());              // OK foo1(A.row());              // Compilation error because here innerstride!=1\n * foo2(A.row());              // Compilation error because A.row() is a 1xN object while foo2 is expecting a Nx1 object\n * foo2(A.row().transpose());  // The row is copied into a contiguous temporary\n * foo2(2*a);                  // The expression is evaluated into a temporary\n * foo2(A.col().segment(2,4)); // No temporary\n * \\endcode\n *\n * The range of inputs that can be referenced without temporary can be enlarged using the last two template parameters.\n * Here is an example accepting an innerstride!=1:\n * \\code\n * // in-out argument:\n * void foo3(Ref&lt;VectorXf,0,InnerStride&lt;&gt; &gt; x);\n * foo3(A.row());              // OK\n * \\endcode\n * The downside here is that the function foo3 might be significantly slower than foo1 because it won&#x27;t be able to\n * exploit vectorization, and will involve more expensive address computations even if the input is contiguously stored\n * in memory. To overcome this issue, one might propose to overload internally calling a template function, e.g.: \\code\n * // in the .h:\n * void foo(const Ref&lt;MatrixXf&gt;&amp; A);\n * void foo(const Ref&lt;MatrixXf,0,Stride&lt;&gt; &gt;&amp; A);\n *\n * // in the .cpp:\n * template&lt;typename TypeOfA&gt; void foo_impl(const TypeOfA&amp; A) {\n *     ... // crazy code goes here\n * }\n * void foo(const Ref&lt;MatrixXf&gt;&amp; A) { foo_impl(A); }\n * void foo(const Ref&lt;MatrixXf,0,Stride&lt;&gt; &gt;&amp; A) { foo_impl(A); }\n * \\endcode\n *\n * See also the following stackoverflow questions for further references:\n *  - &lt;a href=&quot;http://stackoverflow.com/questions/21132538/correct-usage-of-the-eigenref-class&quot;&gt;Correct usage of the\n * Eigen::Ref&lt;&gt; class&lt;/a&gt;\n *\n * \\sa PlainObjectBase::Map(), \\ref TopicStorageOrders\n */\ntemplate &lt;typename PlainObjectType, int Options, typename StrideType&gt;\nclass Ref : public RefBase&lt;Ref&lt;PlainObjectType, Options, StrideType&gt; &gt; {\n private:\n  typedef internal::traits&lt;Ref&gt; Traits;\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline Ref(\n      const PlainObjectBase&lt;Derived&gt;&amp; expr,\n      std::enable_if_t&lt;bool(Traits::template match&lt;Derived&gt;::MatchAtCompileTime), Derived&gt;* = 0);\n\n public:\n  typedef RefBase&lt;Ref&gt; Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(Ref)\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline Ref(\n      PlainObjectBase&lt;Derived&gt;&amp; expr,\n      std::enable_if_t&lt;bool(Traits::template match&lt;Derived&gt;::MatchAtCompileTime), Derived&gt;* = 0) {\n    EIGEN_STATIC_ASSERT(bool(Traits::template match&lt;Derived&gt;::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);\n    // Construction must pass since we will not create temporary storage in the non-const case.\n    const bool success = Base::construct(expr.derived());\n    EIGEN_UNUSED_VARIABLE(success)\n    eigen_assert(success);\n  }\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline Ref(\n      const DenseBase&lt;Derived&gt;&amp; expr,\n      std::enable_if_t&lt;bool(Traits::template match&lt;Derived&gt;::MatchAtCompileTime), Derived&gt;* = 0)\n#else\n  /** Implicit constructor from any dense expression */\n  template &lt;typename Derived&gt;\n  inline Ref(DenseBase&lt;Derived&gt;&amp; expr)\n#endif\n  {\n    EIGEN_STATIC_ASSERT(bool(internal::is_lvalue&lt;Derived&gt;::value), THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);\n    EIGEN_STATIC_ASSERT(bool(Traits::template match&lt;Derived&gt;::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);\n    EIGEN_STATIC_ASSERT(!Derived::IsPlainObjectBase, THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);\n    // Construction must pass since we will not create temporary storage in the non-const case.\n    const bool success = Base::construct(expr.const_cast_derived());\n    EIGEN_UNUSED_VARIABLE(success)\n    eigen_assert(success);\n  }\n\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Ref)\n};\n\n// this is the const ref version\ntemplate &lt;typename TPlainObjectType, int Options, typename StrideType&gt;\nclass Ref&lt;const TPlainObjectType, Options, StrideType&gt;\n    : public RefBase&lt;Ref&lt;const TPlainObjectType, Options, StrideType&gt; &gt; {\n  typedef internal::traits&lt;Ref&gt; Traits;\n\n  static constexpr bool may_map_m_object_successfully =\n      (static_cast&lt;int&gt;(StrideType::InnerStrideAtCompileTime) == 0 ||\n       static_cast&lt;int&gt;(StrideType::InnerStrideAtCompileTime) == 1 ||\n       static_cast&lt;int&gt;(StrideType::InnerStrideAtCompileTime) == Dynamic) &amp;&amp;\n      (TPlainObjectType::IsVectorAtCompileTime || static_cast&lt;int&gt;(StrideType::OuterStrideAtCompileTime) == 0 ||\n       static_cast&lt;int&gt;(StrideType::OuterStrideAtCompileTime) == Dynamic ||\n       static_cast&lt;int&gt;(StrideType::OuterStrideAtCompileTime) ==\n           static_cast&lt;int&gt;(TPlainObjectType::InnerSizeAtCompileTime) ||\n       static_cast&lt;int&gt;(TPlainObjectType::InnerSizeAtCompileTime) == Dynamic);\n\n public:\n  typedef RefBase&lt;Ref&gt; Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(Ref)\n\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline Ref(const DenseBase&lt;Derived&gt;&amp; expr,\n                               std::enable_if_t&lt;bool(Traits::template match&lt;Derived&gt;::ScalarTypeMatch), Derived&gt;* = 0) {\n    //      std::cout &lt;&lt; match_helper&lt;Derived&gt;::HasDirectAccess &lt;&lt; &quot;,&quot; &lt;&lt; match_helper&lt;Derived&gt;::OuterStrideMatch &lt;&lt; &quot;,&quot;\n    //      &lt;&lt; match_helper&lt;Derived&gt;::InnerStrideMatch &lt;&lt; &quot;\\n&quot;; std::cout &lt;&lt; int(StrideType::OuterStrideAtCompileTime)\n    //      &lt;&lt; &quot; - &quot; &lt;&lt; int(Derived::OuterStrideAtCompileTime) &lt;&lt; &quot;\\n&quot;; std::cout &lt;&lt;\n    //      int(StrideType::InnerStrideAtCompileTime) &lt;&lt; &quot; - &quot; &lt;&lt; int(Derived::InnerStrideAtCompileTime) &lt;&lt; &quot;\\n&quot;;\n    EIGEN_STATIC_ASSERT(Traits::template match&lt;Derived&gt;::type::value || may_map_m_object_successfully,\n                        STORAGE_LAYOUT_DOES_NOT_MATCH);\n    construct(expr.derived(), typename Traits::template match&lt;Derived&gt;::type());\n  }\n\n  EIGEN_DEVICE_FUNC inline Ref(const Ref&amp; other) : Base(other) {\n    // copy constructor shall not copy the m_object, to avoid unnecessary malloc and copy\n  }\n\n  EIGEN_DEVICE_FUNC inline Ref(Ref&amp;&amp; other) {\n    if (other.data() == other.m_object.data()) {\n      m_object = std::move(other.m_object);\n      Base::construct(m_object);\n    } else\n      Base::construct(other);\n  }\n\n  template &lt;typename OtherRef&gt;\n  EIGEN_DEVICE_FUNC inline Ref(const RefBase&lt;OtherRef&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT(Traits::template match&lt;OtherRef&gt;::type::value || may_map_m_object_successfully,\n                        STORAGE_LAYOUT_DOES_NOT_MATCH);\n    construct(other.derived(), typename Traits::template match&lt;OtherRef&gt;::type());\n  }\n\n protected:\n  template &lt;typename Expression&gt;\n  EIGEN_DEVICE_FUNC void construct(const Expression&amp; expr, internal::true_type) {\n    // Check if we can use the underlying expr&#x27;s storage directly, otherwise call the copy version.\n    if (!Base::construct(expr)) {\n      construct(expr, internal::false_type());\n    }\n  }\n\n  template &lt;typename Expression&gt;\n  EIGEN_DEVICE_FUNC void construct(const Expression&amp; expr, internal::false_type) {\n    internal::call_assignment_no_alias(m_object, expr, internal::assign_op&lt;Scalar, Scalar&gt;());\n    const bool success = Base::construct(m_object);\n    EIGEN_ONLY_USED_FOR_DEBUG(success)\n    eigen_assert(success);\n  }\n\n protected:\n  TPlainObjectType m_object;\n};\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_REF_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009-2010 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2009-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_RETURNBYVALUE_H\n#define EIGEN_RETURNBYVALUE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\ntemplate &lt;typename Derived&gt;\nstruct traits&lt;ReturnByValue&lt;Derived&gt; &gt; : public traits&lt;typename traits&lt;Derived&gt;::ReturnType&gt; {\n  enum {\n    // We&#x27;re disabling the DirectAccess because e.g. the constructor of\n    // the Block-with-DirectAccess expression requires to have a coeffRef method.\n    // Also, we don&#x27;t want to have to implement the stride stuff.\n    Flags = (traits&lt;typename traits&lt;Derived&gt;::ReturnType&gt;::Flags | EvalBeforeNestingBit) &amp; ~DirectAccessBit\n  };\n};\n\n/* The ReturnByValue object doesn&#x27;t even have a coeff() method.\n * So the only way that nesting it in an expression can work, is by evaluating it into a plain matrix.\n * So internal::nested always gives the plain return matrix type.\n *\n * FIXME: I don&#x27;t understand why we need this specialization: isn&#x27;t this taken care of by the EvalBeforeNestingBit ??\n * Answer: EvalBeforeNestingBit should be deprecated since we have the evaluators\n */\ntemplate &lt;typename Derived, int n, typename PlainObject&gt;\nstruct nested_eval&lt;ReturnByValue&lt;Derived&gt;, n, PlainObject&gt; {\n  typedef typename traits&lt;Derived&gt;::ReturnType type;\n};\n\n}  // end namespace internal\n\n/** \\class ReturnByValue\n * \\ingroup Core_Module\n *\n */\ntemplate &lt;typename Derived&gt;\nclass ReturnByValue : public internal::dense_xpr_base&lt;ReturnByValue&lt;Derived&gt; &gt;::type, internal::no_assignment_operator {\n public:\n  typedef typename internal::traits&lt;Derived&gt;::ReturnType ReturnType;\n\n  typedef typename internal::dense_xpr_base&lt;ReturnByValue&gt;::type Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(ReturnByValue)\n\n  template &lt;typename Dest&gt;\n  EIGEN_DEVICE_FUNC inline void evalTo(Dest&amp; dst) const {\n    static_cast&lt;const Derived*&gt;(this)-&gt;evalTo(dst);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT {\n    return static_cast&lt;const Derived*&gt;(this)-&gt;rows();\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT {\n    return static_cast&lt;const Derived*&gt;(this)-&gt;cols();\n  }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n#define Unusable \\\n  YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT\n  class Unusable {\n    Unusable(const Unusable&amp;) {}\n    Unusable&amp; operator=(const Unusable&amp;) { return *this; }\n  };\n  const Unusable&amp; coeff(Index) const { return *reinterpret_cast&lt;const Unusable*&gt;(this); }\n  const Unusable&amp; coeff(Index, Index) const { return *reinterpret_cast&lt;const Unusable*&gt;(this); }\n  Unusable&amp; coeffRef(Index) { return *reinterpret_cast&lt;Unusable*&gt;(this); }\n  Unusable&amp; coeffRef(Index, Index) { return *reinterpret_cast&lt;Unusable*&gt;(this); }\n#undef Unusable\n#endif\n};\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Derived&amp; DenseBase&lt;Derived&gt;::operator=(const ReturnByValue&lt;OtherDerived&gt;&amp; other) {\n  other.evalTo(derived());\n  return derived();\n}\n\nnamespace internal {\n\n// Expression is evaluated in a temporary; default implementation of Assignment is bypassed so that\n// when a ReturnByValue expression is assigned, the evaluator is not constructed.\n// TODO: Finalize port to new regime; ReturnByValue should not exist in the expression world\n\ntemplate &lt;typename Derived&gt;\nstruct evaluator&lt;ReturnByValue&lt;Derived&gt; &gt; : public evaluator&lt;typename internal::traits&lt;Derived&gt;::ReturnType&gt; {\n  typedef ReturnByValue&lt;Derived&gt; XprType;\n  typedef typename internal::traits&lt;Derived&gt;::ReturnType PlainObject;\n  typedef evaluator&lt;PlainObject&gt; Base;\n\n  EIGEN_DEVICE_FUNC explicit evaluator(const XprType&amp; xpr) : m_result(xpr.rows(), xpr.cols()) {\n    internal::construct_at&lt;Base&gt;(this, m_result);\n    xpr.evalTo(m_result);\n  }\n\n protected:\n  PlainObject m_result;\n};\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_RETURNBYVALUE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_STABLENORM_H\n#define EIGEN_STABLENORM_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\ntemplate &lt;typename ExpressionType, typename Scalar&gt;\ninline void stable_norm_kernel(const ExpressionType&amp; bl, Scalar&amp; ssq, Scalar&amp; scale, Scalar&amp; invScale) {\n  Scalar maxCoeff = bl.cwiseAbs().maxCoeff();\n\n  if (maxCoeff &gt; scale) {\n    ssq = ssq * numext::abs2(scale / maxCoeff);\n    Scalar tmp = Scalar(1) / maxCoeff;\n    if (tmp &gt; NumTraits&lt;Scalar&gt;::highest()) {\n      invScale = NumTraits&lt;Scalar&gt;::highest();\n      scale = Scalar(1) / invScale;\n    } else if (maxCoeff &gt; NumTraits&lt;Scalar&gt;::highest())  // we got a INF\n    {\n      invScale = Scalar(1);\n      scale = maxCoeff;\n    } else {\n      scale = maxCoeff;\n      invScale = tmp;\n    }\n  } else if (maxCoeff != maxCoeff)  // we got a NaN\n  {\n    scale = maxCoeff;\n  }\n\n  // TODO if the maxCoeff is much much smaller than the current scale,\n  // then we can neglect this sub vector\n  if (scale &gt; Scalar(0))  // if scale==0, then bl is 0\n    ssq += (bl * invScale).squaredNorm();\n}\n\ntemplate &lt;typename VectorType, typename RealScalar&gt;\nvoid stable_norm_impl_inner_step(const VectorType&amp; vec, RealScalar&amp; ssq, RealScalar&amp; scale, RealScalar&amp; invScale) {\n  const Index blockSize = 4096;\n\n  Index n = vec.size();\n  Index blockEnd = numext::round_down(n, blockSize);\n  for (Index i = 0; i &lt; blockEnd; i += blockSize) {\n    internal::stable_norm_kernel(vec.template segment&lt;blockSize&gt;(i), ssq, scale, invScale);\n  }\n  if (n &gt; blockEnd) {\n    internal::stable_norm_kernel(vec.tail(n - blockEnd), ssq, scale, invScale);\n  }\n}\n\ntemplate &lt;typename VectorType&gt;\ntypename VectorType::RealScalar stable_norm_impl(const VectorType&amp; vec,\n                                                 std::enable_if_t&lt;VectorType::IsVectorAtCompileTime&gt;* = 0) {\n  using std::abs;\n  using std::sqrt;\n\n  Index n = vec.size();\n  if (EIGEN_PREDICT_FALSE(n == 1)) return abs(vec.coeff(0));\n\n  typedef typename VectorType::RealScalar RealScalar;\n  RealScalar scale(0);\n  RealScalar invScale(1);\n  RealScalar ssq(0);  // sum of squares\n\n  stable_norm_impl_inner_step(vec, ssq, scale, invScale);\n\n  return scale * sqrt(ssq);\n}\n\ntemplate &lt;typename MatrixType&gt;\ntypename MatrixType::RealScalar stable_norm_impl(const MatrixType&amp; mat,\n                                                 std::enable_if_t&lt;!MatrixType::IsVectorAtCompileTime&gt;* = 0) {\n  using std::sqrt;\n\n  typedef typename MatrixType::RealScalar RealScalar;\n  RealScalar scale(0);\n  RealScalar invScale(1);\n  RealScalar ssq(0);  // sum of squares\n\n  for (Index j = 0; j &lt; mat.outerSize(); ++j) stable_norm_impl_inner_step(mat.innerVector(j), ssq, scale, invScale);\n  return scale * sqrt(ssq);\n}\n\ntemplate &lt;typename Derived&gt;\ninline typename NumTraits&lt;typename traits&lt;Derived&gt;::Scalar&gt;::Real blueNorm_impl(const EigenBase&lt;Derived&gt;&amp; _vec) {\n  typedef typename Derived::RealScalar RealScalar;\n  using std::abs;\n  using std::pow;\n  using std::sqrt;\n\n  // This program calculates the machine-dependent constants\n  // bl, b2, slm, s2m, relerr overfl\n  // from the &quot;basic&quot; machine-dependent numbers\n  // nbig, ibeta, it, iemin, iemax, rbig.\n  // The following define the basic machine-dependent constants.\n  // For portability, the PORT subprograms &quot;ilmaeh&quot; and &quot;rlmach&quot;\n  // are used. For any specific computer, each of the assignment\n  // statements can be replaced\n  static const int ibeta = std::numeric_limits&lt;RealScalar&gt;::radix;  // base for floating-point numbers\n  static const int it = NumTraits&lt;RealScalar&gt;::digits();            // number of base-beta digits in mantissa\n  static const int iemin = NumTraits&lt;RealScalar&gt;::min_exponent();   // minimum exponent\n  static const int iemax = NumTraits&lt;RealScalar&gt;::max_exponent();   // maximum exponent\n  static const RealScalar rbig = NumTraits&lt;RealScalar&gt;::highest();  // largest floating-point number\n  static const RealScalar b1 =\n      RealScalar(pow(RealScalar(ibeta), RealScalar(-((1 - iemin) / 2))));  // lower boundary of midrange\n  static const RealScalar b2 =\n      RealScalar(pow(RealScalar(ibeta), RealScalar((iemax + 1 - it) / 2)));  // upper boundary of midrange\n  static const RealScalar s1m =\n      RealScalar(pow(RealScalar(ibeta), RealScalar((2 - iemin) / 2)));  // scaling factor for lower range\n  static const RealScalar s2m =\n      RealScalar(pow(RealScalar(ibeta), RealScalar(-((iemax + it) / 2))));  // scaling factor for upper range\n  static const RealScalar eps = RealScalar(pow(double(ibeta), 1 - it));\n  static const RealScalar relerr = sqrt(eps);  // tolerance for neglecting asml\n\n  const Derived&amp; vec(_vec.derived());\n  Index n = vec.size();\n  RealScalar ab2 = b2 / RealScalar(n);\n  RealScalar asml = RealScalar(0);\n  RealScalar amed = RealScalar(0);\n  RealScalar abig = RealScalar(0);\n\n  for (Index j = 0; j &lt; vec.outerSize(); ++j) {\n    for (typename Derived::InnerIterator iter(vec, j); iter; ++iter) {\n      RealScalar ax = abs(iter.value());\n      if (ax &gt; ab2)\n        abig += numext::abs2(ax * s2m);\n      else if (ax &lt; b1)\n        asml += numext::abs2(ax * s1m);\n      else\n        amed += numext::abs2(ax);\n    }\n  }\n  if (amed != amed) return amed;  // we got a NaN\n  if (abig &gt; RealScalar(0)) {\n    abig = sqrt(abig);\n    if (abig &gt; rbig)  // overflow, or *this contains INF values\n      return abig;    // return INF\n    if (amed &gt; RealScalar(0)) {\n      abig = abig / s2m;\n      amed = sqrt(amed);\n    } else\n      return abig / s2m;\n  } else if (asml &gt; RealScalar(0)) {\n    if (amed &gt; RealScalar(0)) {\n      abig = sqrt(amed);\n      amed = sqrt(asml) / s1m;\n    } else\n      return sqrt(asml) / s1m;\n  } else\n    return sqrt(amed);\n  asml = numext::mini(abig, amed);\n  abig = numext::maxi(abig, amed);\n  if (asml &lt;= abig * relerr)\n    return abig;\n  else\n    return abig * sqrt(RealScalar(1) + numext::abs2(asml / abig));\n}\n\n}  // end namespace internal\n\n/** \\returns the \\em l2 norm of \\c *this avoiding underflow and overflow.\n * This version use a blockwise two passes algorithm:\n *  1 - find the absolute largest coefficient \\c s\n *  2 - compute \\f$ s \\Vert \\frac{*this}{s} \\Vert \\f$ in a standard way\n *\n * For architecture/scalar types supporting vectorization, this version\n * is faster than blueNorm(). Otherwise the blueNorm() is much faster.\n *\n * \\sa norm(), blueNorm(), hypotNorm()\n */\ntemplate &lt;typename Derived&gt;\ninline typename NumTraits&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt;::Real MatrixBase&lt;Derived&gt;::stableNorm() const {\n  return internal::stable_norm_impl(derived());\n}\n\n/** \\returns the \\em l2 norm of \\c *this using the Blue&#x27;s algorithm.\n * A Portable Fortran Program to Find the Euclidean Norm of a Vector,\n * ACM TOMS, Vol 4, Issue 1, 1978.\n *\n * For architecture/scalar types without vectorization, this version\n * is much faster than stableNorm(). Otherwise the stableNorm() is faster.\n *\n * \\sa norm(), stableNorm(), hypotNorm()\n */\ntemplate &lt;typename Derived&gt;\ninline typename NumTraits&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt;::Real MatrixBase&lt;Derived&gt;::blueNorm() const {\n  return internal::blueNorm_impl(*this);\n}\n\n/** \\returns the \\em l2 norm of \\c *this avoiding underflow and overflow.\n * This version use a concatenation of hypot() calls, and it is very slow.\n *\n * \\sa norm(), stableNorm()\n */\ntemplate &lt;typename Derived&gt;\ninline typename NumTraits&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt;::Real MatrixBase&lt;Derived&gt;::hypotNorm() const {\n  if (size() == 1)\n    return numext::abs(coeff(0, 0));\n  else\n    return this-&gt;cwiseAbs().redux(internal::scalar_hypot_op&lt;RealScalar&gt;());\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_STABLENORM_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2010-2011 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_TRANSPOSITIONS_H\n#define EIGEN_TRANSPOSITIONS_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\ntemplate &lt;typename Derived&gt;\nclass TranspositionsBase {\n  typedef internal::traits&lt;Derived&gt; Traits;\n\n public:\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename IndicesType::Scalar StorageIndex;\n  typedef Eigen::Index Index;  ///&lt; \\deprecated since Eigen 3.3\n\n  EIGEN_DEVICE_FUNC Derived&amp; derived() { return *static_cast&lt;Derived*&gt;(this); }\n  EIGEN_DEVICE_FUNC const Derived&amp; derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n\n  /** Copies the \\a other transpositions into \\c *this */\n  template &lt;typename OtherDerived&gt;\n  Derived&amp; operator=(const TranspositionsBase&lt;OtherDerived&gt;&amp; other) {\n    indices() = other.indices();\n    return derived();\n  }\n\n  /** \\returns the number of transpositions */\n  EIGEN_DEVICE_FUNC Index size() const { return indices().size(); }\n  /** \\returns the number of rows of the equivalent permutation matrix */\n  EIGEN_DEVICE_FUNC Index rows() const { return indices().size(); }\n  /** \\returns the number of columns of the equivalent permutation matrix */\n  EIGEN_DEVICE_FUNC Index cols() const { return indices().size(); }\n\n  /** Direct access to the underlying index vector */\n  EIGEN_DEVICE_FUNC inline const StorageIndex&amp; coeff(Index i) const { return indices().coeff(i); }\n  /** Direct access to the underlying index vector */\n  inline StorageIndex&amp; coeffRef(Index i) { return indices().coeffRef(i); }\n  /** Direct access to the underlying index vector */\n  inline const StorageIndex&amp; operator()(Index i) const { return indices()(i); }\n  /** Direct access to the underlying index vector */\n  inline StorageIndex&amp; operator()(Index i) { return indices()(i); }\n  /** Direct access to the underlying index vector */\n  inline const StorageIndex&amp; operator[](Index i) const { return indices()(i); }\n  /** Direct access to the underlying index vector */\n  inline StorageIndex&amp; operator[](Index i) { return indices()(i); }\n\n  /** const version of indices(). */\n  EIGEN_DEVICE_FUNC const IndicesType&amp; indices() const { return derived().indices(); }\n  /** \\returns a reference to the stored array representing the transpositions. */\n  EIGEN_DEVICE_FUNC IndicesType&amp; indices() { return derived().indices(); }\n\n  /** Resizes to given size. */\n  inline void resize(Index newSize) { indices().resize(newSize); }\n\n  /** Sets \\c *this to represents an identity transformation */\n  void setIdentity() {\n    for (StorageIndex i = 0; i &lt; indices().size(); ++i) coeffRef(i) = i;\n  }\n\n  // FIXME: do we want such methods ?\n  // might be useful when the target matrix expression is complex, e.g.:\n  // object.matrix().block(..,..,..,..) = trans * object.matrix().block(..,..,..,..);\n  /*\n  template&lt;typename MatrixType&gt;\n  void applyForwardToRows(MatrixType&amp; mat) const\n  {\n    for(Index k=0 ; k&lt;size() ; ++k)\n      if(m_indices(k)!=k)\n        mat.row(k).swap(mat.row(m_indices(k)));\n  }\n\n  template&lt;typename MatrixType&gt;\n  void applyBackwardToRows(MatrixType&amp; mat) const\n  {\n    for(Index k=size()-1 ; k&gt;=0 ; --k)\n      if(m_indices(k)!=k)\n        mat.row(k).swap(mat.row(m_indices(k)));\n  }\n  */\n\n  /** \\returns the inverse transformation */\n  inline Transpose&lt;TranspositionsBase&gt; inverse() const { return Transpose&lt;TranspositionsBase&gt;(derived()); }\n\n  /** \\returns the transpose transformation */\n  inline Transpose&lt;TranspositionsBase&gt; transpose() const { return Transpose&lt;TranspositionsBase&gt;(derived()); }\n\n protected:\n};\n\nnamespace internal {\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_&gt;\nstruct traits&lt;Transpositions&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt;\n    : traits&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt; {\n  typedef Matrix&lt;StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1&gt; IndicesType;\n  typedef TranspositionsStorage StorageKind;\n};\n}  // namespace internal\n\n/** \\class Transpositions\n * \\ingroup Core_Module\n *\n * \\brief Represents a sequence of transpositions (row/column interchange)\n *\n * \\tparam SizeAtCompileTime the number of transpositions, or Dynamic\n * \\tparam MaxSizeAtCompileTime the maximum number of transpositions, or Dynamic. This optional parameter defaults to\n * SizeAtCompileTime. Most of the time, you should not have to specify it.\n *\n * This class represents a permutation transformation as a sequence of \\em n transpositions\n * \\f$[T_{n-1} \\ldots T_{i} \\ldots T_{0}]\\f$. It is internally stored as a vector of integers \\c indices.\n * Each transposition \\f$ T_{i} \\f$ applied on the left of a matrix (\\f$ T_{i} M\\f$) interchanges\n * the rows \\c i and \\c indices[i] of the matrix \\c M.\n * A transposition applied on the right (e.g., \\f$ M T_{i}\\f$) yields a column interchange.\n *\n * Compared to the class PermutationMatrix, such a sequence of transpositions is what is\n * computed during a decomposition with pivoting, and it is faster when applying the permutation in-place.\n *\n * To apply a sequence of transpositions to a matrix, simply use the operator * as in the following example:\n * \\code\n * Transpositions tr;\n * MatrixXf mat;\n * mat = tr * mat;\n * \\endcode\n * In this example, we detect that the matrix appears on both side, and so the transpositions\n * are applied in-place without any temporary or extra copy.\n *\n * \\sa class PermutationMatrix\n */\n\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_&gt;\nclass Transpositions\n    : public TranspositionsBase&lt;Transpositions&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt; {\n  typedef internal::traits&lt;Transpositions&gt; Traits;\n\n public:\n  typedef TranspositionsBase&lt;Transpositions&gt; Base;\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename IndicesType::Scalar StorageIndex;\n\n  inline Transpositions() {}\n\n  /** Copy constructor. */\n  template &lt;typename OtherDerived&gt;\n  inline Transpositions(const TranspositionsBase&lt;OtherDerived&gt;&amp; other) : m_indices(other.indices()) {}\n\n  /** Generic constructor from expression of the transposition indices. */\n  template &lt;typename Other&gt;\n  explicit inline Transpositions(const MatrixBase&lt;Other&gt;&amp; indices) : m_indices(indices) {}\n\n  /** Copies the \\a other transpositions into \\c *this */\n  template &lt;typename OtherDerived&gt;\n  Transpositions&amp; operator=(const TranspositionsBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::operator=(other);\n  }\n\n  /** Constructs an uninitialized permutation matrix of given size.\n   */\n  inline Transpositions(Index size) : m_indices(size) {}\n\n  /** const version of indices(). */\n  EIGEN_DEVICE_FUNC const IndicesType&amp; indices() const { return m_indices; }\n  /** \\returns a reference to the stored array representing the transpositions. */\n  EIGEN_DEVICE_FUNC IndicesType&amp; indices() { return m_indices; }\n\n protected:\n  IndicesType m_indices;\n};\n\nnamespace internal {\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess_&gt;\nstruct traits&lt;Map&lt;Transpositions&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess_&gt; &gt;\n    : traits&lt;PermutationMatrix&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt; &gt; {\n  typedef Map&lt;const Matrix&lt;StorageIndex_, SizeAtCompileTime, 1, 0, MaxSizeAtCompileTime, 1&gt;, PacketAccess_&gt; IndicesType;\n  typedef StorageIndex_ StorageIndex;\n  typedef TranspositionsStorage StorageKind;\n};\n}  // namespace internal\n\ntemplate &lt;int SizeAtCompileTime, int MaxSizeAtCompileTime, typename StorageIndex_, int PacketAccess&gt;\nclass Map&lt;Transpositions&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess&gt;\n    : public TranspositionsBase&lt;\n          Map&lt;Transpositions&lt;SizeAtCompileTime, MaxSizeAtCompileTime, StorageIndex_&gt;, PacketAccess&gt; &gt; {\n  typedef internal::traits&lt;Map&gt; Traits;\n\n public:\n  typedef TranspositionsBase&lt;Map&gt; Base;\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename IndicesType::Scalar StorageIndex;\n\n  explicit inline Map(const StorageIndex* indicesPtr) : m_indices(indicesPtr) {}\n\n  inline Map(const StorageIndex* indicesPtr, Index size) : m_indices(indicesPtr, size) {}\n\n  /** Copies the \\a other transpositions into \\c *this */\n  template &lt;typename OtherDerived&gt;\n  Map&amp; operator=(const TranspositionsBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::operator=(other);\n  }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  /** This is a special case of the templated operator=. Its purpose is to\n   * prevent a default operator= from hiding the templated operator=.\n   */\n  Map&amp; operator=(const Map&amp; other) {\n    m_indices = other.m_indices;\n    return *this;\n  }\n#endif\n\n  /** const version of indices(). */\n  EIGEN_DEVICE_FUNC const IndicesType&amp; indices() const { return m_indices; }\n\n  /** \\returns a reference to the stored array representing the transpositions. */\n  EIGEN_DEVICE_FUNC IndicesType&amp; indices() { return m_indices; }\n\n protected:\n  IndicesType m_indices;\n};\n\nnamespace internal {\ntemplate &lt;typename IndicesType_&gt;\nstruct traits&lt;TranspositionsWrapper&lt;IndicesType_&gt; &gt; : traits&lt;PermutationWrapper&lt;IndicesType_&gt; &gt; {\n  typedef TranspositionsStorage StorageKind;\n};\n}  // namespace internal\n\ntemplate &lt;typename IndicesType_&gt;\nclass TranspositionsWrapper : public TranspositionsBase&lt;TranspositionsWrapper&lt;IndicesType_&gt; &gt; {\n  typedef internal::traits&lt;TranspositionsWrapper&gt; Traits;\n\n public:\n  typedef TranspositionsBase&lt;TranspositionsWrapper&gt; Base;\n  typedef typename Traits::IndicesType IndicesType;\n  typedef typename IndicesType::Scalar StorageIndex;\n\n  explicit inline TranspositionsWrapper(IndicesType&amp; indices) : m_indices(indices) {}\n\n  /** Copies the \\a other transpositions into \\c *this */\n  template &lt;typename OtherDerived&gt;\n  TranspositionsWrapper&amp; operator=(const TranspositionsBase&lt;OtherDerived&gt;&amp; other) {\n    return Base::operator=(other);\n  }\n\n  /** const version of indices(). */\n  EIGEN_DEVICE_FUNC const IndicesType&amp; indices() const { return m_indices; }\n\n  /** \\returns a reference to the stored array representing the transpositions. */\n  EIGEN_DEVICE_FUNC IndicesType&amp; indices() { return m_indices; }\n\n protected:\n  typename IndicesType::Nested m_indices;\n};\n\n/** \\returns the \\a matrix with the \\a transpositions applied to the columns.\n */\ntemplate &lt;typename MatrixDerived, typename TranspositionsDerived&gt;\nEIGEN_DEVICE_FUNC const Product&lt;MatrixDerived, TranspositionsDerived, AliasFreeProduct&gt; operator*(\n    const MatrixBase&lt;MatrixDerived&gt;&amp; matrix, const TranspositionsBase&lt;TranspositionsDerived&gt;&amp; transpositions) {\n  return Product&lt;MatrixDerived, TranspositionsDerived, AliasFreeProduct&gt;(matrix.derived(), transpositions.derived());\n}\n\n/** \\returns the \\a matrix with the \\a transpositions applied to the rows.\n */\ntemplate &lt;typename TranspositionsDerived, typename MatrixDerived&gt;\nEIGEN_DEVICE_FUNC const Product&lt;TranspositionsDerived, MatrixDerived, AliasFreeProduct&gt; operator*(\n    const TranspositionsBase&lt;TranspositionsDerived&gt;&amp; transpositions, const MatrixBase&lt;MatrixDerived&gt;&amp; matrix) {\n  return Product&lt;TranspositionsDerived, MatrixDerived, AliasFreeProduct&gt;(transpositions.derived(), matrix.derived());\n}\n\n// Template partial specialization for transposed/inverse transpositions\n\nnamespace internal {\n\ntemplate &lt;typename Derived&gt;\nstruct traits&lt;Transpose&lt;TranspositionsBase&lt;Derived&gt; &gt; &gt; : traits&lt;Derived&gt; {};\n\n}  // end namespace internal\n\ntemplate &lt;typename TranspositionsDerived&gt;\nclass Transpose&lt;TranspositionsBase&lt;TranspositionsDerived&gt; &gt; {\n  typedef TranspositionsDerived TranspositionType;\n  typedef typename TranspositionType::IndicesType IndicesType;\n\n public:\n  explicit Transpose(const TranspositionType&amp; t) : m_transpositions(t) {}\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_transpositions.size(); }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_transpositions.size(); }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_transpositions.size(); }\n\n  /** \\returns the \\a matrix with the inverse transpositions applied to the columns.\n   */\n  template &lt;typename OtherDerived&gt;\n  friend const Product&lt;OtherDerived, Transpose, AliasFreeProduct&gt; operator*(const MatrixBase&lt;OtherDerived&gt;&amp; matrix,\n                                                                            const Transpose&amp; trt) {\n    return Product&lt;OtherDerived, Transpose, AliasFreeProduct&gt;(matrix.derived(), trt);\n  }\n\n  /** \\returns the \\a matrix with the inverse transpositions applied to the rows.\n   */\n  template &lt;typename OtherDerived&gt;\n  const Product&lt;Transpose, OtherDerived, AliasFreeProduct&gt; operator*(const MatrixBase&lt;OtherDerived&gt;&amp; matrix) const {\n    return Product&lt;Transpose, OtherDerived, AliasFreeProduct&gt;(*this, matrix.derived());\n  }\n\n  EIGEN_DEVICE_FUNC const TranspositionType&amp; nestedExpression() const { return m_transpositions; }\n\n protected:\n  const TranspositionType&amp; m_transpositions;\n};\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_TRANSPOSITIONS_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2008-2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_TRIANGULARMATRIX_H\n#define EIGEN_TRIANGULARMATRIX_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\ntemplate &lt;int Side, typename TriangularType, typename Rhs&gt;\nstruct triangular_solve_retval;\n\n}\n\n/** \\class TriangularBase\n * \\ingroup Core_Module\n *\n * \\brief Base class for triangular part in a matrix\n */\ntemplate &lt;typename Derived&gt;\nclass TriangularBase : public EigenBase&lt;Derived&gt; {\n public:\n  enum {\n    Mode = internal::traits&lt;Derived&gt;::Mode,\n    RowsAtCompileTime = internal::traits&lt;Derived&gt;::RowsAtCompileTime,\n    ColsAtCompileTime = internal::traits&lt;Derived&gt;::ColsAtCompileTime,\n    MaxRowsAtCompileTime = internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = internal::traits&lt;Derived&gt;::MaxColsAtCompileTime,\n\n    SizeAtCompileTime = (internal::size_of_xpr_at_compile_time&lt;Derived&gt;::ret),\n    /**&lt; This is equal to the number of coefficients, i.e. the number of\n     * rows times the number of columns, or to \\a Dynamic if this is not\n     * known at compile-time. \\sa RowsAtCompileTime, ColsAtCompileTime */\n\n    MaxSizeAtCompileTime = internal::size_at_compile_time(internal::traits&lt;Derived&gt;::MaxRowsAtCompileTime,\n                                                          internal::traits&lt;Derived&gt;::MaxColsAtCompileTime)\n\n  };\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n  typedef typename internal::traits&lt;Derived&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;Derived&gt;::StorageIndex StorageIndex;\n  typedef typename internal::traits&lt;Derived&gt;::FullMatrixType DenseMatrixType;\n  typedef DenseMatrixType DenseType;\n  typedef Derived const&amp; Nested;\n\n  EIGEN_DEVICE_FUNC inline TriangularBase() {\n    eigen_assert(!((int(Mode) &amp; int(UnitDiag)) &amp;&amp; (int(Mode) &amp; int(ZeroDiag))));\n  }\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const EIGEN_NOEXCEPT { return derived().outerStride(); }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const EIGEN_NOEXCEPT { return derived().innerStride(); }\n\n  // dummy resize function\n  EIGEN_DEVICE_FUNC void resize(Index rows, Index cols) {\n    EIGEN_UNUSED_VARIABLE(rows);\n    EIGEN_UNUSED_VARIABLE(cols);\n    eigen_assert(rows == this-&gt;rows() &amp;&amp; cols == this-&gt;cols());\n  }\n\n  EIGEN_DEVICE_FUNC inline Scalar coeff(Index row, Index col) const { return derived().coeff(row, col); }\n  EIGEN_DEVICE_FUNC inline Scalar&amp; coeffRef(Index row, Index col) { return derived().coeffRef(row, col); }\n\n  /** \\see MatrixBase::copyCoeff(row,col)\n   */\n  template &lt;typename Other&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void copyCoeff(Index row, Index col, Other&amp; other) {\n    derived().coeffRef(row, col) = other.coeff(row, col);\n  }\n\n  EIGEN_DEVICE_FUNC inline Scalar operator()(Index row, Index col) const {\n    check_coordinates(row, col);\n    return coeff(row, col);\n  }\n  EIGEN_DEVICE_FUNC inline Scalar&amp; operator()(Index row, Index col) {\n    check_coordinates(row, col);\n    return coeffRef(row, col);\n  }\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  EIGEN_DEVICE_FUNC inline const Derived&amp; derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n  EIGEN_DEVICE_FUNC inline Derived&amp; derived() { return *static_cast&lt;Derived*&gt;(this); }\n#endif  // not EIGEN_PARSED_BY_DOXYGEN\n\n  template &lt;typename DenseDerived&gt;\n  EIGEN_DEVICE_FUNC void evalTo(MatrixBase&lt;DenseDerived&gt;&amp; other) const;\n  template &lt;typename DenseDerived&gt;\n  EIGEN_DEVICE_FUNC void evalToLazy(MatrixBase&lt;DenseDerived&gt;&amp; other) const;\n\n  EIGEN_DEVICE_FUNC DenseMatrixType toDenseMatrix() const {\n    DenseMatrixType res(rows(), cols());\n    evalToLazy(res);\n    return res;\n  }\n\n protected:\n  void check_coordinates(Index row, Index col) const {\n    EIGEN_ONLY_USED_FOR_DEBUG(row);\n    EIGEN_ONLY_USED_FOR_DEBUG(col);\n    eigen_assert(col &gt;= 0 &amp;&amp; col &lt; cols() &amp;&amp; row &gt;= 0 &amp;&amp; row &lt; rows());\n    const int mode = int(Mode) &amp; ~SelfAdjoint;\n    EIGEN_ONLY_USED_FOR_DEBUG(mode);\n    eigen_assert((mode == Upper &amp;&amp; col &gt;= row) || (mode == Lower &amp;&amp; col &lt;= row) ||\n                 ((mode == StrictlyUpper || mode == UnitUpper) &amp;&amp; col &gt; row) ||\n                 ((mode == StrictlyLower || mode == UnitLower) &amp;&amp; col &lt; row));\n  }\n\n#ifdef EIGEN_INTERNAL_DEBUGGING\n  void check_coordinates_internal(Index row, Index col) const { check_coordinates(row, col); }\n#else\n  void check_coordinates_internal(Index, Index) const {}\n#endif\n};\n\n/** \\class TriangularView\n * \\ingroup Core_Module\n *\n * \\brief Expression of a triangular part in a matrix\n *\n * \\tparam MatrixType the type of the object in which we are taking the triangular part\n * \\tparam Mode the kind of triangular matrix expression to construct. Can be #Upper,\n *             #Lower, #UnitUpper, #UnitLower, #StrictlyUpper, or #StrictlyLower.\n *             This is in fact a bit field; it must have either #Upper or #Lower,\n *             and additionally it may have #UnitDiag or #ZeroDiag or neither.\n *\n * This class represents a triangular part of a matrix, not necessarily square. Strictly speaking, for rectangular\n * matrices one should speak of &quot;trapezoid&quot; parts. This class is the return type\n * of MatrixBase::triangularView() and SparseMatrixBase::triangularView(), and most of the time this is the only way it\n * is used.\n *\n * \\sa MatrixBase::triangularView()\n */\nnamespace internal {\ntemplate &lt;typename MatrixType, unsigned int Mode_&gt;\nstruct traits&lt;TriangularView&lt;MatrixType, Mode_&gt;&gt; : traits&lt;MatrixType&gt; {\n  typedef typename ref_selector&lt;MatrixType&gt;::non_const_type MatrixTypeNested;\n  typedef std::remove_reference_t&lt;MatrixTypeNested&gt; MatrixTypeNestedNonRef;\n  typedef remove_all_t&lt;MatrixTypeNested&gt; MatrixTypeNestedCleaned;\n  typedef typename MatrixType::PlainObject FullMatrixType;\n  typedef MatrixType ExpressionType;\n  enum {\n    Mode = Mode_,\n    FlagsLvalueBit = is_lvalue&lt;MatrixType&gt;::value ? LvalueBit : 0,\n    Flags = (MatrixTypeNestedCleaned::Flags &amp; (HereditaryBits | FlagsLvalueBit) &amp;\n             (~(PacketAccessBit | DirectAccessBit | LinearAccessBit)))\n  };\n};\n}  // namespace internal\n\ntemplate &lt;typename MatrixType_, unsigned int Mode_, typename StorageKind&gt;\nclass TriangularViewImpl;\n\ntemplate &lt;typename MatrixType_, unsigned int Mode_&gt;\nclass TriangularView\n    : public TriangularViewImpl&lt;MatrixType_, Mode_, typename internal::traits&lt;MatrixType_&gt;::StorageKind&gt; {\n public:\n  typedef TriangularViewImpl&lt;MatrixType_, Mode_, typename internal::traits&lt;MatrixType_&gt;::StorageKind&gt; Base;\n  typedef typename internal::traits&lt;TriangularView&gt;::Scalar Scalar;\n  typedef MatrixType_ MatrixType;\n\n protected:\n  typedef typename internal::traits&lt;TriangularView&gt;::MatrixTypeNested MatrixTypeNested;\n  typedef typename internal::traits&lt;TriangularView&gt;::MatrixTypeNestedNonRef MatrixTypeNestedNonRef;\n\n  typedef internal::remove_all_t&lt;typename MatrixType::ConjugateReturnType&gt; MatrixConjugateReturnType;\n  typedef TriangularView&lt;std::add_const_t&lt;MatrixType&gt;, Mode_&gt; ConstTriangularView;\n\n public:\n  typedef typename internal::traits&lt;TriangularView&gt;::StorageKind StorageKind;\n  typedef typename internal::traits&lt;TriangularView&gt;::MatrixTypeNestedCleaned NestedExpression;\n\n  enum {\n    Mode = Mode_,\n    Flags = internal::traits&lt;TriangularView&gt;::Flags,\n    TransposeMode = (int(Mode) &amp; int(Upper) ? Lower : 0) | (int(Mode) &amp; int(Lower) ? Upper : 0) |\n                    (int(Mode) &amp; int(UnitDiag)) | (int(Mode) &amp; int(ZeroDiag)),\n    IsVectorAtCompileTime = false\n  };\n\n  EIGEN_DEVICE_FUNC explicit inline TriangularView(MatrixType&amp; matrix) : m_matrix(matrix) {}\n\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(TriangularView)\n\n  /** \\copydoc EigenBase::rows() */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }\n  /** \\copydoc EigenBase::cols() */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }\n\n  /** \\returns a const reference to the nested expression */\n  EIGEN_DEVICE_FUNC const NestedExpression&amp; nestedExpression() const { return m_matrix; }\n\n  /** \\returns a reference to the nested expression */\n  EIGEN_DEVICE_FUNC NestedExpression&amp; nestedExpression() { return m_matrix; }\n\n  typedef TriangularView&lt;const MatrixConjugateReturnType, Mode&gt; ConjugateReturnType;\n  /** \\sa MatrixBase::conjugate() const */\n  EIGEN_DEVICE_FUNC inline const ConjugateReturnType conjugate() const {\n    return ConjugateReturnType(m_matrix.conjugate());\n  }\n\n  /** \\returns an expression of the complex conjugate of \\c *this if Cond==true,\n   *           returns \\c *this otherwise.\n   */\n  template &lt;bool Cond&gt;\n  EIGEN_DEVICE_FUNC inline std::conditional_t&lt;Cond, ConjugateReturnType, ConstTriangularView&gt; conjugateIf() const {\n    typedef std::conditional_t&lt;Cond, ConjugateReturnType, ConstTriangularView&gt; ReturnType;\n    return ReturnType(m_matrix.template conjugateIf&lt;Cond&gt;());\n  }\n\n  typedef TriangularView&lt;const typename MatrixType::AdjointReturnType, TransposeMode&gt; AdjointReturnType;\n  /** \\sa MatrixBase::adjoint() const */\n  EIGEN_DEVICE_FUNC inline const AdjointReturnType adjoint() const { return AdjointReturnType(m_matrix.adjoint()); }\n\n  typedef TriangularView&lt;typename MatrixType::TransposeReturnType, TransposeMode&gt; TransposeReturnType;\n  /** \\sa MatrixBase::transpose() */\n  template &lt;class Dummy = int&gt;\n  EIGEN_DEVICE_FUNC inline TransposeReturnType transpose(\n      std::enable_if_t&lt;Eigen::internal::is_lvalue&lt;MatrixType&gt;::value, Dummy*&gt; = nullptr) {\n    typename MatrixType::TransposeReturnType tmp(m_matrix);\n    return TransposeReturnType(tmp);\n  }\n\n  typedef TriangularView&lt;const typename MatrixType::ConstTransposeReturnType, TransposeMode&gt; ConstTransposeReturnType;\n  /** \\sa MatrixBase::transpose() const */\n  EIGEN_DEVICE_FUNC inline const ConstTransposeReturnType transpose() const {\n    return ConstTransposeReturnType(m_matrix.transpose());\n  }\n\n  template &lt;typename Other&gt;\n  EIGEN_DEVICE_FUNC inline const Solve&lt;TriangularView, Other&gt; solve(const MatrixBase&lt;Other&gt;&amp; other) const {\n    return Solve&lt;TriangularView, Other&gt;(*this, other.derived());\n  }\n\n// workaround MSVC ICE\n#if EIGEN_COMP_MSVC\n  template &lt;int Side, typename Other&gt;\n  EIGEN_DEVICE_FUNC inline const internal::triangular_solve_retval&lt;Side, TriangularView, Other&gt; solve(\n      const MatrixBase&lt;Other&gt;&amp; other) const {\n    return Base::template solve&lt;Side&gt;(other);\n  }\n#else\n  using Base::solve;\n#endif\n\n  /** \\returns a selfadjoint view of the referenced triangular part which must be either \\c #Upper or \\c #Lower.\n   *\n   * This is a shortcut for \\code this-&gt;nestedExpression().selfadjointView&lt;(*this)::Mode&gt;() \\endcode\n   * \\sa MatrixBase::selfadjointView() */\n  EIGEN_DEVICE_FUNC SelfAdjointView&lt;MatrixTypeNestedNonRef, Mode&gt; selfadjointView() {\n    EIGEN_STATIC_ASSERT((Mode &amp; (UnitDiag | ZeroDiag)) == 0, PROGRAMMING_ERROR);\n    return SelfAdjointView&lt;MatrixTypeNestedNonRef, Mode&gt;(m_matrix);\n  }\n\n  /** This is the const version of selfadjointView() */\n  EIGEN_DEVICE_FUNC const SelfAdjointView&lt;MatrixTypeNestedNonRef, Mode&gt; selfadjointView() const {\n    EIGEN_STATIC_ASSERT((Mode &amp; (UnitDiag | ZeroDiag)) == 0, PROGRAMMING_ERROR);\n    return SelfAdjointView&lt;MatrixTypeNestedNonRef, Mode&gt;(m_matrix);\n  }\n\n  /** \\returns the determinant of the triangular matrix\n   * \\sa MatrixBase::determinant() */\n  EIGEN_DEVICE_FUNC Scalar determinant() const {\n    if (Mode &amp; UnitDiag)\n      return 1;\n    else if (Mode &amp; ZeroDiag)\n      return 0;\n    else\n      return m_matrix.diagonal().prod();\n  }\n\n protected:\n  MatrixTypeNested m_matrix;\n};\n\n/** \\ingroup Core_Module\n *\n * \\brief Base class for a triangular part in a \\b dense matrix\n *\n * This class is an abstract base class of class TriangularView, and objects of type TriangularViewImpl cannot be\n * instantiated. It extends class TriangularView with additional methods which available for dense expressions only.\n *\n * \\sa class TriangularView, MatrixBase::triangularView()\n */\ntemplate &lt;typename MatrixType_, unsigned int Mode_&gt;\nclass TriangularViewImpl&lt;MatrixType_, Mode_, Dense&gt; : public TriangularBase&lt;TriangularView&lt;MatrixType_, Mode_&gt;&gt; {\n public:\n  typedef TriangularView&lt;MatrixType_, Mode_&gt; TriangularViewType;\n\n  typedef TriangularBase&lt;TriangularViewType&gt; Base;\n  typedef typename internal::traits&lt;TriangularViewType&gt;::Scalar Scalar;\n\n  typedef MatrixType_ MatrixType;\n  typedef typename MatrixType::PlainObject DenseMatrixType;\n  typedef DenseMatrixType PlainObject;\n\n public:\n  using Base::derived;\n  using Base::evalToLazy;\n\n  typedef typename internal::traits&lt;TriangularViewType&gt;::StorageKind StorageKind;\n\n  enum { Mode = Mode_, Flags = internal::traits&lt;TriangularViewType&gt;::Flags };\n\n  /** \\returns the outer-stride of the underlying dense matrix\n   * \\sa DenseCoeffsBase::outerStride() */\n  EIGEN_DEVICE_FUNC inline Index outerStride() const { return derived().nestedExpression().outerStride(); }\n  /** \\returns the inner-stride of the underlying dense matrix\n   * \\sa DenseCoeffsBase::innerStride() */\n  EIGEN_DEVICE_FUNC inline Index innerStride() const { return derived().nestedExpression().innerStride(); }\n\n  /** \\sa MatrixBase::operator+=() */\n  template &lt;typename Other&gt;\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator+=(const DenseBase&lt;Other&gt;&amp; other) {\n    internal::call_assignment_no_alias(derived(), other.derived(),\n                                       internal::add_assign_op&lt;Scalar, typename Other::Scalar&gt;());\n    return derived();\n  }\n  /** \\sa MatrixBase::operator-=() */\n  template &lt;typename Other&gt;\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator-=(const DenseBase&lt;Other&gt;&amp; other) {\n    internal::call_assignment_no_alias(derived(), other.derived(),\n                                       internal::sub_assign_op&lt;Scalar, typename Other::Scalar&gt;());\n    return derived();\n  }\n\n  /** \\sa MatrixBase::operator*=() */\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator*=(const typename internal::traits&lt;MatrixType&gt;::Scalar&amp; other) {\n    return *this = derived().nestedExpression() * other;\n  }\n  /** \\sa DenseBase::operator/=() */\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator/=(const typename internal::traits&lt;MatrixType&gt;::Scalar&amp; other) {\n    return *this = derived().nestedExpression() / other;\n  }\n\n  /** \\sa MatrixBase::fill() */\n  EIGEN_DEVICE_FUNC void fill(const Scalar&amp; value) { setConstant(value); }\n  /** \\sa MatrixBase::setConstant() */\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; setConstant(const Scalar&amp; value) {\n    return *this = MatrixType::Constant(derived().rows(), derived().cols(), value);\n  }\n  /** \\sa MatrixBase::setZero() */\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; setZero() { return setConstant(Scalar(0)); }\n  /** \\sa MatrixBase::setOnes() */\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; setOnes() { return setConstant(Scalar(1)); }\n\n  /** \\sa MatrixBase::coeff()\n   * \\warning the coordinates must fit into the referenced triangular part\n   */\n  EIGEN_DEVICE_FUNC inline Scalar coeff(Index row, Index col) const {\n    Base::check_coordinates_internal(row, col);\n    return derived().nestedExpression().coeff(row, col);\n  }\n\n  /** \\sa MatrixBase::coeffRef()\n   * \\warning the coordinates must fit into the referenced triangular part\n   */\n  EIGEN_DEVICE_FUNC inline Scalar&amp; coeffRef(Index row, Index col) {\n    EIGEN_STATIC_ASSERT_LVALUE(TriangularViewType);\n    Base::check_coordinates_internal(row, col);\n    return derived().nestedExpression().coeffRef(row, col);\n  }\n\n  /** Assigns a triangular matrix to a triangular part of a dense matrix */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator=(const TriangularBase&lt;OtherDerived&gt;&amp; other);\n\n  /** Shortcut for\\code *this = other.other.triangularView&lt;(*this)::Mode&gt;() \\endcode */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator=(const MatrixBase&lt;OtherDerived&gt;&amp; other);\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  EIGEN_DEVICE_FUNC TriangularViewType&amp; operator=(const TriangularViewImpl&amp; other) {\n    return *this = other.derived().nestedExpression();\n  }\n\n  template &lt;typename OtherDerived&gt;\n  /** \\deprecated */\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC void lazyAssign(const TriangularBase&lt;OtherDerived&gt;&amp; other);\n\n  template &lt;typename OtherDerived&gt;\n  /** \\deprecated */\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC void lazyAssign(const MatrixBase&lt;OtherDerived&gt;&amp; other);\n#endif\n\n  /** Efficient triangular matrix times vector/matrix product */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC const Product&lt;TriangularViewType, OtherDerived&gt; operator*(\n      const MatrixBase&lt;OtherDerived&gt;&amp; rhs) const {\n    return Product&lt;TriangularViewType, OtherDerived&gt;(derived(), rhs.derived());\n  }\n\n  /** Efficient vector/matrix times triangular matrix product */\n  template &lt;typename OtherDerived&gt;\n  friend EIGEN_DEVICE_FUNC const Product&lt;OtherDerived, TriangularViewType&gt; operator*(\n      const MatrixBase&lt;OtherDerived&gt;&amp; lhs, const TriangularViewImpl&amp; rhs) {\n    return Product&lt;OtherDerived, TriangularViewType&gt;(lhs.derived(), rhs.derived());\n  }\n\n  /** \\returns the product of the inverse of \\c *this with \\a other, \\a *this being triangular.\n   *\n   * This function computes the inverse-matrix matrix product inverse(\\c *this) * \\a other if\n   * \\a Side==OnTheLeft (the default), or the right-inverse-multiply  \\a other * inverse(\\c *this) if\n   * \\a Side==OnTheRight.\n   *\n   * Note that the template parameter \\c Side can be omitted, in which case \\c Side==OnTheLeft\n   *\n   * The matrix \\c *this must be triangular and invertible (i.e., all the coefficients of the\n   * diagonal must be non zero). It works as a forward (resp. backward) substitution if \\c *this\n   * is an upper (resp. lower) triangular matrix.\n   *\n   * Example: \\include Triangular_solve.cpp\n   * Output: \\verbinclude Triangular_solve.out\n   *\n   * This function returns an expression of the inverse-multiply and can works in-place if it is assigned\n   * to the same matrix or vector \\a other.\n   *\n   * For users coming from BLAS, this function (and more specifically solveInPlace()) offer\n   * all the operations supported by the \\c *TRSV and \\c *TRSM BLAS routines.\n   *\n   * \\sa TriangularView::solveInPlace()\n   */\n  template &lt;int Side, typename Other&gt;\n  inline const internal::triangular_solve_retval&lt;Side, TriangularViewType, Other&gt; solve(\n      const MatrixBase&lt;Other&gt;&amp; other) const;\n\n  /** &quot;in-place&quot; version of TriangularView::solve() where the result is written in \\a other\n   *\n   * \\warning The parameter is only marked &#x27;const&#x27; to make the C++ compiler accept a temporary expression here.\n   * This function will const_cast it, so constness isn&#x27;t honored here.\n   *\n   * Note that the template parameter \\c Side can be omitted, in which case \\c Side==OnTheLeft\n   *\n   * See TriangularView:solve() for the details.\n   */\n  template &lt;int Side, typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC void solveInPlace(const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC void solveInPlace(const MatrixBase&lt;OtherDerived&gt;&amp; other) const {\n    return solveInPlace&lt;OnTheLeft&gt;(other);\n  }\n\n  /** Swaps the coefficients of the common triangular parts of two matrices */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC\n#ifdef EIGEN_PARSED_BY_DOXYGEN\n      void\n      swap(TriangularBase&lt;OtherDerived&gt;&amp; other)\n#else\n      void\n      swap(TriangularBase&lt;OtherDerived&gt; const&amp; other)\n#endif\n  {\n    EIGEN_STATIC_ASSERT_LVALUE(OtherDerived);\n    call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op&lt;Scalar&gt;());\n  }\n\n  /** Shortcut for \\code (*this).swap(other.triangularView&lt;(*this)::Mode&gt;()) \\endcode */\n  template &lt;typename OtherDerived&gt;\n  /** \\deprecated */\n  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC void swap(MatrixBase&lt;OtherDerived&gt; const&amp; other) {\n    EIGEN_STATIC_ASSERT_LVALUE(OtherDerived);\n    call_assignment(derived(), other.const_cast_derived(), internal::swap_assign_op&lt;Scalar&gt;());\n  }\n\n  template &lt;typename RhsType, typename DstType&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void _solve_impl(const RhsType&amp; rhs, DstType&amp; dst) const {\n    if (!internal::is_same_dense(dst, rhs)) dst = rhs;\n    this-&gt;solveInPlace(dst);\n  }\n\n  template &lt;typename ProductType&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TriangularViewType&amp; _assignProduct(const ProductType&amp; prod, const Scalar&amp; alpha,\n                                                                           bool beta);\n\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(TriangularViewImpl)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(TriangularViewImpl)\n};\n\n/***************************************************************************\n * Implementation of triangular evaluation/assignment\n ***************************************************************************/\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n// FIXME should we keep that possibility\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC inline TriangularView&lt;MatrixType, Mode&gt;&amp; TriangularViewImpl&lt;MatrixType, Mode, Dense&gt;::operator=(\n    const MatrixBase&lt;OtherDerived&gt;&amp; other) {\n  internal::call_assignment_no_alias(derived(), other.derived(),\n                                     internal::assign_op&lt;Scalar, typename OtherDerived::Scalar&gt;());\n  return derived();\n}\n\n// FIXME should we keep that possibility\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC void TriangularViewImpl&lt;MatrixType, Mode, Dense&gt;::lazyAssign(const MatrixBase&lt;OtherDerived&gt;&amp; other) {\n  internal::call_assignment_no_alias(derived(), other.template triangularView&lt;Mode&gt;());\n}\n\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC inline TriangularView&lt;MatrixType, Mode&gt;&amp; TriangularViewImpl&lt;MatrixType, Mode, Dense&gt;::operator=(\n    const TriangularBase&lt;OtherDerived&gt;&amp; other) {\n  eigen_assert(Mode == int(OtherDerived::Mode));\n  internal::call_assignment(derived(), other.derived());\n  return derived();\n}\n\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC void TriangularViewImpl&lt;MatrixType, Mode, Dense&gt;::lazyAssign(\n    const TriangularBase&lt;OtherDerived&gt;&amp; other) {\n  eigen_assert(Mode == int(OtherDerived::Mode));\n  internal::call_assignment_no_alias(derived(), other.derived());\n}\n#endif\n\n/***************************************************************************\n * Implementation of TriangularBase methods\n ***************************************************************************/\n\n/** Assigns a triangular or selfadjoint matrix to a dense matrix.\n * If the matrix is triangular, the opposite part is set to zero. */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename DenseDerived&gt;\nEIGEN_DEVICE_FUNC void TriangularBase&lt;Derived&gt;::evalTo(MatrixBase&lt;DenseDerived&gt;&amp; other) const {\n  evalToLazy(other.derived());\n}\n\n/***************************************************************************\n * Implementation of TriangularView methods\n ***************************************************************************/\n\n/***************************************************************************\n * Implementation of MatrixBase methods\n ***************************************************************************/\n\n/**\n * \\returns an expression of a triangular view extracted from the current matrix\n *\n * The parameter \\a Mode can have the following values: \\c #Upper, \\c #StrictlyUpper, \\c #UnitUpper,\n * \\c #Lower, \\c #StrictlyLower, \\c #UnitLower.\n *\n * Example: \\include MatrixBase_triangularView.cpp\n * Output: \\verbinclude MatrixBase_triangularView.out\n *\n * \\sa class TriangularView\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;unsigned int Mode&gt;\nEIGEN_DEVICE_FUNC typename MatrixBase&lt;Derived&gt;::template TriangularViewReturnType&lt;Mode&gt;::Type\nMatrixBase&lt;Derived&gt;::triangularView() {\n  return typename TriangularViewReturnType&lt;Mode&gt;::Type(derived());\n}\n\n/** This is the const version of MatrixBase::triangularView() */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;unsigned int Mode&gt;\nEIGEN_DEVICE_FUNC typename MatrixBase&lt;Derived&gt;::template ConstTriangularViewReturnType&lt;Mode&gt;::Type\nMatrixBase&lt;Derived&gt;::triangularView() const {\n  return typename ConstTriangularViewReturnType&lt;Mode&gt;::Type(derived());\n}\n\n/** \\returns true if *this is approximately equal to an upper triangular matrix,\n *          within the precision given by \\a prec.\n *\n * \\sa isLowerTriangular()\n */\ntemplate &lt;typename Derived&gt;\nbool MatrixBase&lt;Derived&gt;::isUpperTriangular(const RealScalar&amp; prec) const {\n  RealScalar maxAbsOnUpperPart = static_cast&lt;RealScalar&gt;(-1);\n  for (Index j = 0; j &lt; cols(); ++j) {\n    Index maxi = numext::mini(j, rows() - 1);\n    for (Index i = 0; i &lt;= maxi; ++i) {\n      RealScalar absValue = numext::abs(coeff(i, j));\n      if (absValue &gt; maxAbsOnUpperPart) maxAbsOnUpperPart = absValue;\n    }\n  }\n  RealScalar threshold = maxAbsOnUpperPart * prec;\n  for (Index j = 0; j &lt; cols(); ++j)\n    for (Index i = j + 1; i &lt; rows(); ++i)\n      if (numext::abs(coeff(i, j)) &gt; threshold) return false;\n  return true;\n}\n\n/** \\returns true if *this is approximately equal to a lower triangular matrix,\n *          within the precision given by \\a prec.\n *\n * \\sa isUpperTriangular()\n */\ntemplate &lt;typename Derived&gt;\nbool MatrixBase&lt;Derived&gt;::isLowerTriangular(const RealScalar&amp; prec) const {\n  RealScalar maxAbsOnLowerPart = static_cast&lt;RealScalar&gt;(-1);\n  for (Index j = 0; j &lt; cols(); ++j)\n    for (Index i = j; i &lt; rows(); ++i) {\n      RealScalar absValue = numext::abs(coeff(i, j));\n      if (absValue &gt; maxAbsOnLowerPart) maxAbsOnLowerPart = absValue;\n    }\n  RealScalar threshold = maxAbsOnLowerPart * prec;\n  for (Index j = 1; j &lt; cols(); ++j) {\n    Index maxi = numext::mini(j, rows() - 1);\n    for (Index i = 0; i &lt; maxi; ++i)\n      if (numext::abs(coeff(i, j)) &gt; threshold) return false;\n  }\n  return true;\n}\n\n/***************************************************************************\n****************************************************************************\n* Evaluators and Assignment of triangular expressions\n***************************************************************************\n***************************************************************************/\n\nnamespace internal {\n\n// TODO currently a triangular expression has the form TriangularView&lt;.,.&gt;\n//      in the future triangular-ness should be defined by the expression traits\n//      such that Transpose&lt;TriangularView&lt;.,.&gt; &gt; is valid. (currently TriangularBase::transpose() is overloaded to make\n//      it work)\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\nstruct evaluator_traits&lt;TriangularView&lt;MatrixType, Mode&gt;&gt; {\n  typedef typename storage_kind_to_evaluator_kind&lt;typename MatrixType::StorageKind&gt;::Kind Kind;\n  typedef typename glue_shapes&lt;typename evaluator_traits&lt;MatrixType&gt;::Shape, TriangularShape&gt;::type Shape;\n};\n\ntemplate &lt;typename MatrixType, unsigned int Mode&gt;\nstruct unary_evaluator&lt;TriangularView&lt;MatrixType, Mode&gt;, IndexBased&gt; : evaluator&lt;internal::remove_all_t&lt;MatrixType&gt;&gt; {\n  typedef TriangularView&lt;MatrixType, Mode&gt; XprType;\n  typedef evaluator&lt;internal::remove_all_t&lt;MatrixType&gt;&gt; Base;\n  EIGEN_DEVICE_FUNC unary_evaluator(const XprType&amp; xpr) : Base(xpr.nestedExpression()) {}\n};\n\n// Additional assignment kinds:\nstruct Triangular2Triangular {};\nstruct Triangular2Dense {};\nstruct Dense2Triangular {};\n\ntemplate &lt;typename Kernel, unsigned int Mode, int UnrollCount, bool ClearOpposite&gt;\nstruct triangular_assignment_loop;\n\n/** \\internal Specialization of the dense assignment kernel for triangular matrices.\n * The main difference is that the triangular, diagonal, and opposite parts are processed through three different\n * functions. \\tparam UpLo must be either Lower or Upper \\tparam Mode must be either 0, UnitDiag, ZeroDiag, or\n * SelfAdjoint\n */\ntemplate &lt;int UpLo, int Mode, int SetOpposite, typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor,\n          int Version = Specialized&gt;\nclass triangular_dense_assignment_kernel\n    : public generic_dense_assignment_kernel&lt;DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version&gt; {\n protected:\n  typedef generic_dense_assignment_kernel&lt;DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version&gt; Base;\n  typedef typename Base::DstXprType DstXprType;\n  typedef typename Base::SrcXprType SrcXprType;\n  using Base::m_dst;\n  using Base::m_functor;\n  using Base::m_src;\n\n public:\n  typedef typename Base::DstEvaluatorType DstEvaluatorType;\n  typedef typename Base::SrcEvaluatorType SrcEvaluatorType;\n  typedef typename Base::Scalar Scalar;\n  typedef typename Base::AssignmentTraits AssignmentTraits;\n\n  EIGEN_DEVICE_FUNC triangular_dense_assignment_kernel(DstEvaluatorType&amp; dst, const SrcEvaluatorType&amp; src,\n                                                       const Functor&amp; func, DstXprType&amp; dstExpr)\n      : Base(dst, src, func, dstExpr) {}\n\n#ifdef EIGEN_INTERNAL_DEBUGGING\n  EIGEN_DEVICE_FUNC void assignCoeff(Index row, Index col) {\n    eigen_internal_assert(row != col);\n    Base::assignCoeff(row, col);\n  }\n#else\n  using Base::assignCoeff;\n#endif\n\n  EIGEN_DEVICE_FUNC void assignDiagonalCoeff(Index id) {\n    if (Mode == UnitDiag &amp;&amp; SetOpposite)\n      m_functor.assignCoeff(m_dst.coeffRef(id, id), Scalar(1));\n    else if (Mode == ZeroDiag &amp;&amp; SetOpposite)\n      m_functor.assignCoeff(m_dst.coeffRef(id, id), Scalar(0));\n    else if (Mode == 0)\n      Base::assignCoeff(id, id);\n  }\n\n  EIGEN_DEVICE_FUNC void assignOppositeCoeff(Index row, Index col) {\n    eigen_internal_assert(row != col);\n    if (SetOpposite) m_functor.assignCoeff(m_dst.coeffRef(row, col), Scalar(0));\n  }\n};\n\ntemplate &lt;int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType, typename Functor&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_triangular_assignment_loop(DstXprType&amp; dst, const SrcXprType&amp; src,\n                                                                           const Functor&amp; func) {\n  typedef evaluator&lt;DstXprType&gt; DstEvaluatorType;\n  typedef evaluator&lt;SrcXprType&gt; SrcEvaluatorType;\n\n  SrcEvaluatorType srcEvaluator(src);\n\n  Index dstRows = src.rows();\n  Index dstCols = src.cols();\n  if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);\n  DstEvaluatorType dstEvaluator(dst);\n\n  typedef triangular_dense_assignment_kernel&lt;Mode&amp;(Lower | Upper), Mode&amp;(UnitDiag | ZeroDiag | SelfAdjoint),\n                                             SetOpposite, DstEvaluatorType, SrcEvaluatorType, Functor&gt;\n      Kernel;\n  Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());\n\n  enum {\n    unroll = DstXprType::SizeAtCompileTime != Dynamic &amp;&amp; SrcEvaluatorType::CoeffReadCost &lt; HugeCost &amp;&amp;\n             DstXprType::SizeAtCompileTime *\n                     (int(DstEvaluatorType::CoeffReadCost) + int(SrcEvaluatorType::CoeffReadCost)) / 2 &lt;=\n                 EIGEN_UNROLLING_LIMIT\n  };\n\n  triangular_assignment_loop&lt;Kernel, Mode, unroll ? int(DstXprType::SizeAtCompileTime) : Dynamic, SetOpposite&gt;::run(\n      kernel);\n}\n\ntemplate &lt;int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_triangular_assignment_loop(DstXprType&amp; dst, const SrcXprType&amp; src) {\n  call_triangular_assignment_loop&lt;Mode, SetOpposite&gt;(\n      dst, src, internal::assign_op&lt;typename DstXprType::Scalar, typename SrcXprType::Scalar&gt;());\n}\n\ntemplate &lt;&gt;\nstruct AssignmentKind&lt;TriangularShape, TriangularShape&gt; {\n  typedef Triangular2Triangular Kind;\n};\ntemplate &lt;&gt;\nstruct AssignmentKind&lt;DenseShape, TriangularShape&gt; {\n  typedef Triangular2Dense Kind;\n};\ntemplate &lt;&gt;\nstruct AssignmentKind&lt;TriangularShape, DenseShape&gt; {\n  typedef Dense2Triangular Kind;\n};\n\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor&gt;\nstruct Assignment&lt;DstXprType, SrcXprType, Functor, Triangular2Triangular&gt; {\n  EIGEN_DEVICE_FUNC static void run(DstXprType&amp; dst, const SrcXprType&amp; src, const Functor&amp; func) {\n    eigen_assert(int(DstXprType::Mode) == int(SrcXprType::Mode));\n\n    call_triangular_assignment_loop&lt;DstXprType::Mode, false&gt;(dst, src, func);\n  }\n};\n\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor&gt;\nstruct Assignment&lt;DstXprType, SrcXprType, Functor, Triangular2Dense&gt; {\n  EIGEN_DEVICE_FUNC static void run(DstXprType&amp; dst, const SrcXprType&amp; src, const Functor&amp; func) {\n    call_triangular_assignment_loop&lt;SrcXprType::Mode, (int(SrcXprType::Mode) &amp; int(SelfAdjoint)) == 0&gt;(dst, src, func);\n  }\n};\n\ntemplate &lt;typename DstXprType, typename SrcXprType, typename Functor&gt;\nstruct Assignment&lt;DstXprType, SrcXprType, Functor, Dense2Triangular&gt; {\n  EIGEN_DEVICE_FUNC static void run(DstXprType&amp; dst, const SrcXprType&amp; src, const Functor&amp; func) {\n    call_triangular_assignment_loop&lt;DstXprType::Mode, false&gt;(dst, src, func);\n  }\n};\n\ntemplate &lt;typename Kernel, unsigned int Mode, int UnrollCount, bool SetOpposite&gt;\nstruct triangular_assignment_loop {\n  // FIXME: this is not very clean, perhaps this information should be provided by the kernel?\n  typedef typename Kernel::DstEvaluatorType DstEvaluatorType;\n  typedef typename DstEvaluatorType::XprType DstXprType;\n\n  enum {\n    col = (UnrollCount - 1) / DstXprType::RowsAtCompileTime,\n    row = (UnrollCount - 1) % DstXprType::RowsAtCompileTime\n  };\n\n  typedef typename Kernel::Scalar Scalar;\n\n  EIGEN_DEVICE_FUNC static inline void run(Kernel&amp; kernel) {\n    triangular_assignment_loop&lt;Kernel, Mode, UnrollCount - 1, SetOpposite&gt;::run(kernel);\n\n    if (row == col)\n      kernel.assignDiagonalCoeff(row);\n    else if (((Mode &amp; Lower) &amp;&amp; row &gt; col) || ((Mode &amp; Upper) &amp;&amp; row &lt; col))\n      kernel.assignCoeff(row, col);\n    else if (SetOpposite)\n      kernel.assignOppositeCoeff(row, col);\n  }\n};\n\n// prevent buggy user code from causing an infinite recursion\ntemplate &lt;typename Kernel, unsigned int Mode, bool SetOpposite&gt;\nstruct triangular_assignment_loop&lt;Kernel, Mode, 0, SetOpposite&gt; {\n  EIGEN_DEVICE_FUNC static inline void run(Kernel&amp;) {}\n};\n\n// TODO: experiment with a recursive assignment procedure splitting the current\n//       triangular part into one rectangular and two triangular parts.\n\ntemplate &lt;typename Kernel, unsigned int Mode, bool SetOpposite&gt;\nstruct triangular_assignment_loop&lt;Kernel, Mode, Dynamic, SetOpposite&gt; {\n  typedef typename Kernel::Scalar Scalar;\n  EIGEN_DEVICE_FUNC static inline void run(Kernel&amp; kernel) {\n    for (Index j = 0; j &lt; kernel.cols(); ++j) {\n      Index maxi = numext::mini(j, kernel.rows());\n      Index i = 0;\n      if (((Mode &amp; Lower) &amp;&amp; SetOpposite) || (Mode &amp; Upper)) {\n        for (; i &lt; maxi; ++i)\n          if (Mode &amp; Upper)\n            kernel.assignCoeff(i, j);\n          else\n            kernel.assignOppositeCoeff(i, j);\n      } else\n        i = maxi;\n\n      if (i &lt; kernel.rows())  // then i==j\n        kernel.assignDiagonalCoeff(i++);\n\n      if (((Mode &amp; Upper) &amp;&amp; SetOpposite) || (Mode &amp; Lower)) {\n        for (; i &lt; kernel.rows(); ++i)\n          if (Mode &amp; Lower)\n            kernel.assignCoeff(i, j);\n          else\n            kernel.assignOppositeCoeff(i, j);\n      }\n    }\n  }\n};\n\n}  // end namespace internal\n\n/** Assigns a triangular or selfadjoint matrix to a dense matrix.\n * If the matrix is triangular, the opposite part is set to zero. */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;typename DenseDerived&gt;\nEIGEN_DEVICE_FUNC void TriangularBase&lt;Derived&gt;::evalToLazy(MatrixBase&lt;DenseDerived&gt;&amp; other) const {\n  other.derived().resize(this-&gt;rows(), this-&gt;cols());\n  internal::call_triangular_assignment_loop&lt;Derived::Mode,\n                                            (int(Derived::Mode) &amp; int(SelfAdjoint)) == 0 /* SetOpposite */&gt;(\n      other.derived(), derived().nestedExpression());\n}\n\nnamespace internal {\n\n// Triangular = Product\ntemplate &lt;typename DstXprType, typename Lhs, typename Rhs, typename Scalar&gt;\nstruct Assignment&lt;DstXprType, Product&lt;Lhs, Rhs, DefaultProduct&gt;,\n                  internal::assign_op&lt;Scalar, typename Product&lt;Lhs, Rhs, DefaultProduct&gt;::Scalar&gt;, Dense2Triangular&gt; {\n  typedef Product&lt;Lhs, Rhs, DefaultProduct&gt; SrcXprType;\n  static void run(DstXprType&amp; dst, const SrcXprType&amp; src,\n                  const internal::assign_op&lt;Scalar, typename SrcXprType::Scalar&gt;&amp;) {\n    Index dstRows = src.rows();\n    Index dstCols = src.cols();\n    if ((dst.rows() != dstRows) || (dst.cols() != dstCols)) dst.resize(dstRows, dstCols);\n\n    dst._assignProduct(src, Scalar(1), false);\n  }\n};\n\n// Triangular += Product\ntemplate &lt;typename DstXprType, typename Lhs, typename Rhs, typename Scalar&gt;\nstruct Assignment&lt;DstXprType, Product&lt;Lhs, Rhs, DefaultProduct&gt;,\n                  internal::add_assign_op&lt;Scalar, typename Product&lt;Lhs, Rhs, DefaultProduct&gt;::Scalar&gt;,\n                  Dense2Triangular&gt; {\n  typedef Product&lt;Lhs, Rhs, DefaultProduct&gt; SrcXprType;\n  static void run(DstXprType&amp; dst, const SrcXprType&amp; src,\n                  const internal::add_assign_op&lt;Scalar, typename SrcXprType::Scalar&gt;&amp;) {\n    dst._assignProduct(src, Scalar(1), true);\n  }\n};\n\n// Triangular -= Product\ntemplate &lt;typename DstXprType, typename Lhs, typename Rhs, typename Scalar&gt;\nstruct Assignment&lt;DstXprType, Product&lt;Lhs, Rhs, DefaultProduct&gt;,\n                  internal::sub_assign_op&lt;Scalar, typename Product&lt;Lhs, Rhs, DefaultProduct&gt;::Scalar&gt;,\n                  Dense2Triangular&gt; {\n  typedef Product&lt;Lhs, Rhs, DefaultProduct&gt; SrcXprType;\n  static void run(DstXprType&amp; dst, const SrcXprType&amp; src,\n                  const internal::sub_assign_op&lt;Scalar, typename SrcXprType::Scalar&gt;&amp;) {\n    dst._assignProduct(src, Scalar(-1), true);\n  }\n};\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_TRIANGULARMATRIX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2019 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_PARTIAL_REDUX_H\n#define EIGEN_PARTIAL_REDUX_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\class PartialReduxExpr\n * \\ingroup Core_Module\n *\n * \\brief Generic expression of a partially reduxed matrix\n *\n * \\tparam MatrixType the type of the matrix we are applying the redux operation\n * \\tparam MemberOp type of the member functor\n * \\tparam Direction indicates the direction of the redux (#Vertical or #Horizontal)\n *\n * This class represents an expression of a partial redux operator of a matrix.\n * It is the return type of some VectorwiseOp functions,\n * and most of the time this is the only way it is used.\n *\n * \\sa class VectorwiseOp\n */\n\ntemplate &lt;typename MatrixType, typename MemberOp, int Direction&gt;\nclass PartialReduxExpr;\n\nnamespace internal {\n\ntemplate &lt;typename ArgType, typename MemberOp, int Direction&gt;\nstruct enable_packet_segment&lt;PartialReduxExpr&lt;ArgType, MemberOp, Direction&gt;&gt; : std::false_type {};\n\ntemplate &lt;typename MatrixType, typename MemberOp, int Direction&gt;\nstruct traits&lt;PartialReduxExpr&lt;MatrixType, MemberOp, Direction&gt; &gt; : traits&lt;MatrixType&gt; {\n  typedef typename MemberOp::result_type Scalar;\n  typedef typename traits&lt;MatrixType&gt;::StorageKind StorageKind;\n  typedef typename traits&lt;MatrixType&gt;::XprKind XprKind;\n  typedef typename MatrixType::Scalar InputScalar;\n  enum {\n    RowsAtCompileTime = Direction == Vertical ? 1 : MatrixType::RowsAtCompileTime,\n    ColsAtCompileTime = Direction == Horizontal ? 1 : MatrixType::ColsAtCompileTime,\n    MaxRowsAtCompileTime = Direction == Vertical ? 1 : MatrixType::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = Direction == Horizontal ? 1 : MatrixType::MaxColsAtCompileTime,\n    Flags = RowsAtCompileTime == 1 ? RowMajorBit : 0,\n    TraversalSize = Direction == Vertical ? MatrixType::RowsAtCompileTime : MatrixType::ColsAtCompileTime\n  };\n};\n}  // namespace internal\n\ntemplate &lt;typename MatrixType, typename MemberOp, int Direction&gt;\nclass PartialReduxExpr : public internal::dense_xpr_base&lt;PartialReduxExpr&lt;MatrixType, MemberOp, Direction&gt; &gt;::type,\n                         internal::no_assignment_operator {\n public:\n  typedef typename internal::dense_xpr_base&lt;PartialReduxExpr&gt;::type Base;\n  EIGEN_DENSE_PUBLIC_INTERFACE(PartialReduxExpr)\n\n  EIGEN_DEVICE_FUNC explicit PartialReduxExpr(const MatrixType&amp; mat, const MemberOp&amp; func = MemberOp())\n      : m_matrix(mat), m_functor(func) {}\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT {\n    return (Direction == Vertical ? 1 : m_matrix.rows());\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT {\n    return (Direction == Horizontal ? 1 : m_matrix.cols());\n  }\n\n  EIGEN_DEVICE_FUNC typename MatrixType::Nested nestedExpression() const { return m_matrix; }\n\n  EIGEN_DEVICE_FUNC const MemberOp&amp; functor() const { return m_functor; }\n\n protected:\n  typename MatrixType::Nested m_matrix;\n  const MemberOp m_functor;\n};\n\ntemplate &lt;typename A, typename B&gt;\nstruct partial_redux_dummy_func;\n\n#define EIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(MEMBER, COST, VECTORIZABLE, BINARYOP)              \\\n  template &lt;typename ResultType, typename Scalar&gt;                                           \\\n  struct member_##MEMBER {                                                                  \\\n    typedef ResultType result_type;                                                         \\\n    typedef BINARYOP&lt;Scalar, Scalar&gt; BinaryOp;                                              \\\n    template &lt;int Size&gt;                                                                     \\\n    struct Cost {                                                                           \\\n      enum { value = COST };                                                                \\\n    };                                                                                      \\\n    enum { Vectorizable = VECTORIZABLE };                                                   \\\n    template &lt;typename XprType&gt;                                                             \\\n    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType operator()(const XprType&amp; mat) const { \\\n      return mat.MEMBER();                                                                  \\\n    }                                                                                       \\\n    BinaryOp binaryFunc() const { return BinaryOp(); }                                      \\\n  }\n\n#define EIGEN_MEMBER_FUNCTOR(MEMBER, COST) EIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(MEMBER, COST, 0, partial_redux_dummy_func)\n\nnamespace internal {\n\nEIGEN_MEMBER_FUNCTOR(norm, (Size + 5) * NumTraits&lt;Scalar&gt;::MulCost + (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\nEIGEN_MEMBER_FUNCTOR(stableNorm, (Size + 5) * NumTraits&lt;Scalar&gt;::MulCost + (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\nEIGEN_MEMBER_FUNCTOR(blueNorm, (Size + 5) * NumTraits&lt;Scalar&gt;::MulCost + (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\nEIGEN_MEMBER_FUNCTOR(hypotNorm, (Size - 1) * functor_traits&lt;scalar_hypot_op&lt;Scalar&gt; &gt;::Cost);\nEIGEN_MEMBER_FUNCTOR(all, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\nEIGEN_MEMBER_FUNCTOR(any, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\nEIGEN_MEMBER_FUNCTOR(count, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost);\n\nEIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(sum, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost, 1, internal::scalar_sum_op);\nEIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(minCoeff, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost, 1, internal::scalar_min_op);\nEIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(maxCoeff, (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost, 1, internal::scalar_max_op);\nEIGEN_MAKE_PARTIAL_REDUX_FUNCTOR(prod, (Size - 1) * NumTraits&lt;Scalar&gt;::MulCost, 1, internal::scalar_product_op);\n\ntemplate &lt;int p, typename ResultType, typename Scalar&gt;\nstruct member_lpnorm {\n  typedef ResultType result_type;\n  enum { Vectorizable = 0 };\n  template &lt;int Size&gt;\n  struct Cost {\n    enum { value = (Size + 5) * NumTraits&lt;Scalar&gt;::MulCost + (Size - 1) * NumTraits&lt;Scalar&gt;::AddCost };\n  };\n  EIGEN_DEVICE_FUNC member_lpnorm() {}\n  template &lt;typename XprType&gt;\n  EIGEN_DEVICE_FUNC inline ResultType operator()(const XprType&amp; mat) const {\n    return mat.template lpNorm&lt;p&gt;();\n  }\n};\n\ntemplate &lt;typename BinaryOpT, typename Scalar&gt;\nstruct member_redux {\n  typedef BinaryOpT BinaryOp;\n  typedef typename result_of&lt;BinaryOp(const Scalar&amp;, const Scalar&amp;)&gt;::type result_type;\n\n  enum { Vectorizable = functor_traits&lt;BinaryOp&gt;::PacketAccess };\n  template &lt;int Size&gt;\n  struct Cost {\n    enum { value = (Size - 1) * functor_traits&lt;BinaryOp&gt;::Cost };\n  };\n  EIGEN_DEVICE_FUNC explicit member_redux(const BinaryOp func) : m_functor(func) {}\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline result_type operator()(const DenseBase&lt;Derived&gt;&amp; mat) const {\n    return mat.redux(m_functor);\n  }\n  const BinaryOp&amp; binaryFunc() const { return m_functor; }\n  const BinaryOp m_functor;\n};\n}  // namespace internal\n\n/** \\class VectorwiseOp\n * \\ingroup Core_Module\n *\n * \\brief Pseudo expression providing broadcasting and partial reduction operations\n *\n * \\tparam ExpressionType the type of the object on which to do partial reductions\n * \\tparam Direction indicates whether to operate on columns (#Vertical) or rows (#Horizontal)\n *\n * This class represents a pseudo expression with broadcasting and partial reduction features.\n * It is the return type of DenseBase::colwise() and DenseBase::rowwise()\n * and most of the time this is the only way it is explicitly used.\n *\n * To understand the logic of rowwise/colwise expression, let&#x27;s consider a generic case `A.colwise().foo()`\n * where `foo` is any method of `VectorwiseOp`. This expression is equivalent to applying `foo()` to each\n * column of `A` and then re-assemble the outputs in a matrix expression:\n * \\code [A.col(0).foo(), A.col(1).foo(), ..., A.col(A.cols()-1).foo()] \\endcode\n *\n * Example: \\include MatrixBase_colwise.cpp\n * Output: \\verbinclude MatrixBase_colwise.out\n *\n * The begin() and end() methods are obviously exceptions to the previous rule as they\n * return STL-compatible begin/end iterators to the rows or columns of the nested expression.\n * Typical use cases include for-range-loop and calls to STL algorithms:\n *\n * Example: \\include MatrixBase_colwise_iterator_cxx11.cpp\n * Output: \\verbinclude MatrixBase_colwise_iterator_cxx11.out\n *\n * For a partial reduction on an empty input, some rules apply.\n * For the sake of clarity, let&#x27;s consider a vertical reduction:\n *   - If the number of columns is zero, then a 1x0 row-major vector expression is returned.\n *   - Otherwise, if the number of rows is zero, then\n *       - a row vector of zeros is returned for sum-like reductions (sum, squaredNorm, norm, etc.)\n *       - a row vector of ones is returned for a product reduction (e.g., &lt;code&gt;MatrixXd(n,0).colwise().prod()&lt;/code&gt;)\n *       - an assert is triggered for all other reductions (minCoeff,maxCoeff,redux(bin_op))\n *\n * \\sa DenseBase::colwise(), DenseBase::rowwise(), class PartialReduxExpr\n */\ntemplate &lt;typename ExpressionType, int Direction&gt;\nclass VectorwiseOp {\n public:\n  typedef typename ExpressionType::Scalar Scalar;\n  typedef typename ExpressionType::RealScalar RealScalar;\n  typedef Eigen::Index Index;  ///&lt; \\deprecated since Eigen 3.3\n  typedef typename internal::ref_selector&lt;ExpressionType&gt;::non_const_type ExpressionTypeNested;\n  typedef internal::remove_all_t&lt;ExpressionTypeNested&gt; ExpressionTypeNestedCleaned;\n\n  template &lt;template &lt;typename OutScalar, typename InputScalar&gt; class Functor, typename ReturnScalar = Scalar&gt;\n  struct ReturnType {\n    typedef PartialReduxExpr&lt;ExpressionType, Functor&lt;ReturnScalar, Scalar&gt;, Direction&gt; Type;\n  };\n\n  template &lt;typename BinaryOp&gt;\n  struct ReduxReturnType {\n    typedef PartialReduxExpr&lt;ExpressionType, internal::member_redux&lt;BinaryOp, Scalar&gt;, Direction&gt; Type;\n  };\n\n  enum { isVertical = (Direction == Vertical) ? 1 : 0, isHorizontal = (Direction == Horizontal) ? 1 : 0 };\n\n protected:\n  template &lt;typename OtherDerived&gt;\n  struct ExtendedType {\n    typedef Replicate&lt;OtherDerived, isVertical ? 1 : ExpressionType::RowsAtCompileTime,\n                      isHorizontal ? 1 : ExpressionType::ColsAtCompileTime&gt;\n        Type;\n  };\n\n  /** \\internal\n   * Replicates a vector to match the size of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC typename ExtendedType&lt;OtherDerived&gt;::Type extendedTo(const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT(internal::check_implication(isVertical, OtherDerived::MaxColsAtCompileTime == 1),\n                        YOU_PASSED_A_ROW_VECTOR_BUT_A_COLUMN_VECTOR_WAS_EXPECTED)\n    EIGEN_STATIC_ASSERT(internal::check_implication(isHorizontal, OtherDerived::MaxRowsAtCompileTime == 1),\n                        YOU_PASSED_A_COLUMN_VECTOR_BUT_A_ROW_VECTOR_WAS_EXPECTED)\n    return typename ExtendedType&lt;OtherDerived&gt;::Type(other.derived(), isVertical ? 1 : m_matrix.rows(),\n                                                     isHorizontal ? 1 : m_matrix.cols());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  struct OppositeExtendedType {\n    typedef Replicate&lt;OtherDerived, isHorizontal ? 1 : ExpressionType::RowsAtCompileTime,\n                      isVertical ? 1 : ExpressionType::ColsAtCompileTime&gt;\n        Type;\n  };\n\n  /** \\internal\n   * Replicates a vector in the opposite direction to match the size of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC typename OppositeExtendedType&lt;OtherDerived&gt;::Type extendedToOpposite(\n      const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT(internal::check_implication(isHorizontal, OtherDerived::MaxColsAtCompileTime == 1),\n                        YOU_PASSED_A_ROW_VECTOR_BUT_A_COLUMN_VECTOR_WAS_EXPECTED)\n    EIGEN_STATIC_ASSERT(internal::check_implication(isVertical, OtherDerived::MaxRowsAtCompileTime == 1),\n                        YOU_PASSED_A_COLUMN_VECTOR_BUT_A_ROW_VECTOR_WAS_EXPECTED)\n    return typename OppositeExtendedType&lt;OtherDerived&gt;::Type(other.derived(), isHorizontal ? 1 : m_matrix.rows(),\n                                                             isVertical ? 1 : m_matrix.cols());\n  }\n\n public:\n  EIGEN_DEVICE_FUNC explicit inline VectorwiseOp(ExpressionType&amp; matrix) : m_matrix(matrix) {}\n\n  /** \\internal */\n  EIGEN_DEVICE_FUNC inline const ExpressionType&amp; _expression() const { return m_matrix; }\n\n#ifdef EIGEN_PARSED_BY_DOXYGEN\n  /** STL-like &lt;a href=&quot;https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator&quot;&gt;RandomAccessIterator&lt;/a&gt;\n   * iterator type over the columns or rows as returned by the begin() and end() methods.\n   */\n  random_access_iterator_type iterator;\n  /** This is the const version of iterator (aka read-only) */\n  random_access_iterator_type const_iterator;\n#else\n  typedef internal::subvector_stl_iterator&lt;ExpressionType, DirectionType(Direction)&gt; iterator;\n  typedef internal::subvector_stl_iterator&lt;const ExpressionType, DirectionType(Direction)&gt; const_iterator;\n  typedef internal::subvector_stl_reverse_iterator&lt;ExpressionType, DirectionType(Direction)&gt; reverse_iterator;\n  typedef internal::subvector_stl_reverse_iterator&lt;const ExpressionType, DirectionType(Direction)&gt;\n      const_reverse_iterator;\n#endif\n\n  /** returns an iterator to the first row (rowwise) or column (colwise) of the nested expression.\n   * \\sa end(), cbegin()\n   */\n  iterator begin() { return iterator(m_matrix, 0); }\n  /** const version of begin() */\n  const_iterator begin() const { return const_iterator(m_matrix, 0); }\n  /** const version of begin() */\n  const_iterator cbegin() const { return const_iterator(m_matrix, 0); }\n\n  /** returns a reverse iterator to the last row (rowwise) or column (colwise) of the nested expression.\n   * \\sa rend(), crbegin()\n   */\n  reverse_iterator rbegin() {\n    return reverse_iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;() - 1);\n  }\n  /** const version of rbegin() */\n  const_reverse_iterator rbegin() const {\n    return const_reverse_iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;() - 1);\n  }\n  /** const version of rbegin() */\n  const_reverse_iterator crbegin() const {\n    return const_reverse_iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;() - 1);\n  }\n\n  /** returns an iterator to the row (resp. column) following the last row (resp. column) of the nested expression\n   * \\sa begin(), cend()\n   */\n  iterator end() { return iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;()); }\n  /** const version of end() */\n  const_iterator end() const {\n    return const_iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;());\n  }\n  /** const version of end() */\n  const_iterator cend() const {\n    return const_iterator(m_matrix, m_matrix.template subVectors&lt;DirectionType(Direction)&gt;());\n  }\n\n  /** returns a reverse iterator to the row (resp. column) before the first row (resp. column) of the nested expression\n   * \\sa begin(), cend()\n   */\n  reverse_iterator rend() { return reverse_iterator(m_matrix, -1); }\n  /** const version of rend() */\n  const_reverse_iterator rend() const { return const_reverse_iterator(m_matrix, -1); }\n  /** const version of rend() */\n  const_reverse_iterator crend() const { return const_reverse_iterator(m_matrix, -1); }\n\n  /** \\returns a row or column vector expression of \\c *this reduxed by \\a func\n   *\n   * The template parameter \\a BinaryOp is the type of the functor\n   * of the custom redux operator. Note that func must be an associative operator.\n   *\n   * \\warning the size along the reduction direction must be strictly positive,\n   *          otherwise an assertion is triggered.\n   *\n   * \\sa class VectorwiseOp, DenseBase::colwise(), DenseBase::rowwise()\n   */\n  template &lt;typename BinaryOp&gt;\n  EIGEN_DEVICE_FUNC const typename ReduxReturnType&lt;BinaryOp&gt;::Type redux(const BinaryOp&amp; func = BinaryOp()) const {\n    eigen_assert(redux_length() &gt; 0 &amp;&amp; &quot;you are using an empty matrix&quot;);\n    return typename ReduxReturnType&lt;BinaryOp&gt;::Type(_expression(), internal::member_redux&lt;BinaryOp, Scalar&gt;(func));\n  }\n\n  typedef typename ReturnType&lt;internal::member_minCoeff&gt;::Type MinCoeffReturnType;\n  typedef typename ReturnType&lt;internal::member_maxCoeff&gt;::Type MaxCoeffReturnType;\n  typedef PartialReduxExpr&lt;const CwiseUnaryOp&lt;internal::scalar_abs2_op&lt;Scalar&gt;, const ExpressionTypeNestedCleaned&gt;,\n                           internal::member_sum&lt;RealScalar, RealScalar&gt;, Direction&gt;\n      SquaredNormReturnType;\n  typedef CwiseUnaryOp&lt;internal::scalar_sqrt_op&lt;RealScalar&gt;, const SquaredNormReturnType&gt; NormReturnType;\n  typedef typename ReturnType&lt;internal::member_blueNorm, RealScalar&gt;::Type BlueNormReturnType;\n  typedef typename ReturnType&lt;internal::member_stableNorm, RealScalar&gt;::Type StableNormReturnType;\n  typedef typename ReturnType&lt;internal::member_hypotNorm, RealScalar&gt;::Type HypotNormReturnType;\n  typedef typename ReturnType&lt;internal::member_sum&gt;::Type SumReturnType;\n  typedef EIGEN_EXPR_BINARYOP_SCALAR_RETURN_TYPE(SumReturnType, Scalar, quotient) MeanReturnType;\n  typedef typename ReturnType&lt;internal::member_all, bool&gt;::Type AllReturnType;\n  typedef typename ReturnType&lt;internal::member_any, bool&gt;::Type AnyReturnType;\n  typedef PartialReduxExpr&lt;ExpressionType, internal::member_count&lt;Index, Scalar&gt;, Direction&gt; CountReturnType;\n  typedef typename ReturnType&lt;internal::member_prod&gt;::Type ProdReturnType;\n  typedef Reverse&lt;const ExpressionType, Direction&gt; ConstReverseReturnType;\n  typedef Reverse&lt;ExpressionType, Direction&gt; ReverseReturnType;\n\n  template &lt;int p&gt;\n  struct LpNormReturnType {\n    typedef PartialReduxExpr&lt;ExpressionType, internal::member_lpnorm&lt;p, RealScalar, Scalar&gt;, Direction&gt; Type;\n  };\n\n  /** \\returns a row (or column) vector expression of the smallest coefficient\n   * of each column (or row) of the referenced expression.\n   *\n   * \\warning the size along the reduction direction must be strictly positive,\n   *          otherwise an assertion is triggered.\n   *\n   * \\warning the result is undefined if \\c *this contains NaN.\n   *\n   * Example: \\include PartialRedux_minCoeff.cpp\n   * Output: \\verbinclude PartialRedux_minCoeff.out\n   *\n   * \\sa DenseBase::minCoeff() */\n  EIGEN_DEVICE_FUNC const MinCoeffReturnType minCoeff() const {\n    eigen_assert(redux_length() &gt; 0 &amp;&amp; &quot;you are using an empty matrix&quot;);\n    return MinCoeffReturnType(_expression());\n  }\n\n  /** \\returns a row (or column) vector expression of the largest coefficient\n   * of each column (or row) of the referenced expression.\n   *\n   * \\warning the size along the reduction direction must be strictly positive,\n   *          otherwise an assertion is triggered.\n   *\n   * \\warning the result is undefined if \\c *this contains NaN.\n   *\n   * Example: \\include PartialRedux_maxCoeff.cpp\n   * Output: \\verbinclude PartialRedux_maxCoeff.out\n   *\n   * \\sa DenseBase::maxCoeff() */\n  EIGEN_DEVICE_FUNC const MaxCoeffReturnType maxCoeff() const {\n    eigen_assert(redux_length() &gt; 0 &amp;&amp; &quot;you are using an empty matrix&quot;);\n    return MaxCoeffReturnType(_expression());\n  }\n\n  /** \\returns a row (or column) vector expression of the squared norm\n   * of each column (or row) of the referenced expression.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * Example: \\include PartialRedux_squaredNorm.cpp\n   * Output: \\verbinclude PartialRedux_squaredNorm.out\n   *\n   * \\sa DenseBase::squaredNorm() */\n  EIGEN_DEVICE_FUNC const SquaredNormReturnType squaredNorm() const {\n    return SquaredNormReturnType(m_matrix.cwiseAbs2());\n  }\n\n  /** \\returns a row (or column) vector expression of the norm\n   * of each column (or row) of the referenced expression.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * Example: \\include PartialRedux_norm.cpp\n   * Output: \\verbinclude PartialRedux_norm.out\n   *\n   * \\sa DenseBase::norm() */\n  EIGEN_DEVICE_FUNC const NormReturnType norm() const { return NormReturnType(squaredNorm()); }\n\n  /** \\returns a row (or column) vector expression of the norm\n   * of each column (or row) of the referenced expression.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * Example: \\include PartialRedux_norm.cpp\n   * Output: \\verbinclude PartialRedux_norm.out\n   *\n   * \\sa DenseBase::norm() */\n  template &lt;int p&gt;\n  EIGEN_DEVICE_FUNC const typename LpNormReturnType&lt;p&gt;::Type lpNorm() const {\n    return typename LpNormReturnType&lt;p&gt;::Type(_expression());\n  }\n\n  /** \\returns a row (or column) vector expression of the norm\n   * of each column (or row) of the referenced expression, using\n   * Blue&#x27;s algorithm.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * \\sa DenseBase::blueNorm() */\n  EIGEN_DEVICE_FUNC const BlueNormReturnType blueNorm() const { return BlueNormReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression of the norm\n   * of each column (or row) of the referenced expression, avoiding\n   * underflow and overflow.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * \\sa DenseBase::stableNorm() */\n  EIGEN_DEVICE_FUNC const StableNormReturnType stableNorm() const { return StableNormReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression of the norm\n   * of each column (or row) of the referenced expression, avoiding\n   * underflow and overflow using a concatenation of hypot() calls.\n   * This is a vector with real entries, even if the original matrix has complex entries.\n   *\n   * \\sa DenseBase::hypotNorm() */\n  EIGEN_DEVICE_FUNC const HypotNormReturnType hypotNorm() const { return HypotNormReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression of the sum\n   * of each column (or row) of the referenced expression.\n   *\n   * Example: \\include PartialRedux_sum.cpp\n   * Output: \\verbinclude PartialRedux_sum.out\n   *\n   * \\sa DenseBase::sum() */\n  EIGEN_DEVICE_FUNC const SumReturnType sum() const { return SumReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression of the mean\n   * of each column (or row) of the referenced expression.\n   *\n   * \\sa DenseBase::mean() */\n  EIGEN_DEVICE_FUNC const MeanReturnType mean() const {\n    return sum() / Scalar(Direction == Vertical ? m_matrix.rows() : m_matrix.cols());\n  }\n\n  /** \\returns a row (or column) vector expression representing\n   * whether \\b all coefficients of each respective column (or row) are \\c true.\n   * This expression can be assigned to a vector with entries of type \\c bool.\n   *\n   * \\sa DenseBase::all() */\n  EIGEN_DEVICE_FUNC const AllReturnType all() const { return AllReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression representing\n   * whether \\b at \\b least one coefficient of each respective column (or row) is \\c true.\n   * This expression can be assigned to a vector with entries of type \\c bool.\n   *\n   * \\sa DenseBase::any() */\n  EIGEN_DEVICE_FUNC const AnyReturnType any() const { return AnyReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression representing\n   * the number of \\c true coefficients of each respective column (or row).\n   * This expression can be assigned to a vector whose entries have the same type as is used to\n   * index entries of the original matrix; for dense matrices, this is \\c std::ptrdiff_t .\n   *\n   * Example: \\include PartialRedux_count.cpp\n   * Output: \\verbinclude PartialRedux_count.out\n   *\n   * \\sa DenseBase::count() */\n  EIGEN_DEVICE_FUNC const CountReturnType count() const { return CountReturnType(_expression()); }\n\n  /** \\returns a row (or column) vector expression of the product\n   * of each column (or row) of the referenced expression.\n   *\n   * Example: \\include PartialRedux_prod.cpp\n   * Output: \\verbinclude PartialRedux_prod.out\n   *\n   * \\sa DenseBase::prod() */\n  EIGEN_DEVICE_FUNC const ProdReturnType prod() const { return ProdReturnType(_expression()); }\n\n  /** \\returns a matrix expression\n   * where each column (or row) are reversed.\n   *\n   * Example: \\include Vectorwise_reverse.cpp\n   * Output: \\verbinclude Vectorwise_reverse.out\n   *\n   * \\sa DenseBase::reverse() */\n  EIGEN_DEVICE_FUNC const ConstReverseReturnType reverse() const { return ConstReverseReturnType(_expression()); }\n\n  /** \\returns a writable matrix expression\n   * where each column (or row) are reversed.\n   *\n   * \\sa reverse() const */\n  EIGEN_DEVICE_FUNC ReverseReturnType reverse() { return ReverseReturnType(_expression()); }\n\n  typedef Replicate&lt;ExpressionType, (isVertical ? Dynamic : 1), (isHorizontal ? Dynamic : 1)&gt; ReplicateReturnType;\n  EIGEN_DEVICE_FUNC const ReplicateReturnType replicate(Index factor) const;\n\n  /**\n   * \\return an expression of the replication of each column (or row) of \\c *this\n   *\n   * Example: \\include DirectionWise_replicate.cpp\n   * Output: \\verbinclude DirectionWise_replicate.out\n   *\n   * \\sa VectorwiseOp::replicate(Index), DenseBase::replicate(), class Replicate\n   */\n  // NOTE implemented here because of sunstudio&#x27;s compilation errors\n  // isVertical*Factor+isHorizontal instead of (isVertical?Factor:1) to handle CUDA bug with ternary operator\n  template &lt;int Factor&gt;\n  const Replicate&lt;ExpressionType, isVertical * Factor + isHorizontal,\n                  isHorizontal * Factor + isVertical&gt; EIGEN_DEVICE_FUNC\n  replicate(Index factor = Factor) const {\n    return Replicate&lt;ExpressionType, (isVertical ? Factor : 1), (isHorizontal ? Factor : 1)&gt;(\n        _expression(), isVertical ? factor : 1, isHorizontal ? factor : 1);\n  }\n\n  /////////// Artithmetic operators ///////////\n\n  /** Copies the vector \\a other to each subvector of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC ExpressionType&amp; operator=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    // eigen_assert((m_matrix.isNull()) == (other.isNull())); FIXME\n    return m_matrix = extendedTo(other.derived());\n  }\n\n  /** Adds the vector \\a other to each subvector of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC ExpressionType&amp; operator+=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix += extendedTo(other.derived());\n  }\n\n  /** Subtracts the vector \\a other to each subvector of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC ExpressionType&amp; operator-=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix -= extendedTo(other.derived());\n  }\n\n  /** Multiplies each subvector of \\c *this by the vector \\a other */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC ExpressionType&amp; operator*=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_ARRAYXPR(ExpressionType)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    m_matrix *= extendedTo(other.derived());\n    return m_matrix;\n  }\n\n  /** Divides each subvector of \\c *this by the vector \\a other */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC ExpressionType&amp; operator/=(const DenseBase&lt;OtherDerived&gt;&amp; other) {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_ARRAYXPR(ExpressionType)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    m_matrix /= extendedTo(other.derived());\n    return m_matrix;\n  }\n\n  /** Returns the expression of the sum of the vector \\a other to each subvector of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC\n      CwiseBinaryOp&lt;internal::scalar_sum_op&lt;Scalar, typename OtherDerived::Scalar&gt;, const ExpressionTypeNestedCleaned,\n                    const typename ExtendedType&lt;OtherDerived&gt;::Type&gt;\n      operator+(const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix + extendedTo(other.derived());\n  }\n\n  /** Returns the expression of the difference between each subvector of \\c *this and the vector \\a other */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC CwiseBinaryOp&lt;internal::scalar_difference_op&lt;Scalar, typename OtherDerived::Scalar&gt;,\n                                  const ExpressionTypeNestedCleaned, const typename ExtendedType&lt;OtherDerived&gt;::Type&gt;\n  operator-(const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix - extendedTo(other.derived());\n  }\n\n  /** Returns the expression where each subvector is the product of the vector \\a other\n   * by the corresponding subvector of \\c *this */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC\n      CwiseBinaryOp&lt;internal::scalar_product_op&lt;Scalar&gt;, const ExpressionTypeNestedCleaned,\n                    const typename ExtendedType&lt;OtherDerived&gt;::Type&gt; EIGEN_DEVICE_FUNC\n      operator*(const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_ARRAYXPR(ExpressionType)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix * extendedTo(other.derived());\n  }\n\n  /** Returns the expression where each subvector is the quotient of the corresponding\n   * subvector of \\c *this by the vector \\a other */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC CwiseBinaryOp&lt;internal::scalar_quotient_op&lt;Scalar&gt;, const ExpressionTypeNestedCleaned,\n                                  const typename ExtendedType&lt;OtherDerived&gt;::Type&gt;\n  operator/(const DenseBase&lt;OtherDerived&gt;&amp; other) const {\n    EIGEN_STATIC_ASSERT_VECTOR_ONLY(OtherDerived)\n    EIGEN_STATIC_ASSERT_ARRAYXPR(ExpressionType)\n    EIGEN_STATIC_ASSERT_SAME_XPR_KIND(ExpressionType, OtherDerived)\n    return m_matrix / extendedTo(other.derived());\n  }\n\n  /** \\returns an expression where each column (or row) of the referenced matrix are normalized.\n   * The referenced matrix is \\b not modified.\n   * \\sa MatrixBase::normalized(), normalize()\n   */\n  EIGEN_DEVICE_FUNC CwiseBinaryOp&lt;internal::scalar_quotient_op&lt;Scalar&gt;, const ExpressionTypeNestedCleaned,\n                                  const typename OppositeExtendedType&lt;NormReturnType&gt;::Type&gt;\n  normalized() const {\n    return m_matrix.cwiseQuotient(extendedToOpposite(this-&gt;norm()));\n  }\n\n  /** Normalize in-place each row or columns of the referenced matrix.\n   * \\sa MatrixBase::normalize(), normalized()\n   */\n  EIGEN_DEVICE_FUNC void normalize() { m_matrix = this-&gt;normalized(); }\n\n  EIGEN_DEVICE_FUNC inline void reverseInPlace();\n\n  /////////// Geometry module ///////////\n\n  typedef Homogeneous&lt;ExpressionType, Direction&gt; HomogeneousReturnType;\n  EIGEN_DEVICE_FUNC HomogeneousReturnType homogeneous() const;\n\n  typedef typename ExpressionType::PlainObject CrossReturnType;\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC const CrossReturnType cross(const MatrixBase&lt;OtherDerived&gt;&amp; other) const;\n\n  enum {\n    HNormalized_Size = Direction == Vertical ? internal::traits&lt;ExpressionType&gt;::RowsAtCompileTime\n                                             : internal::traits&lt;ExpressionType&gt;::ColsAtCompileTime,\n    HNormalized_SizeMinusOne = HNormalized_Size == Dynamic ? Dynamic : HNormalized_Size - 1\n  };\n  typedef Block&lt;const ExpressionType,\n                Direction == Vertical ? int(HNormalized_SizeMinusOne)\n                                      : int(internal::traits&lt;ExpressionType&gt;::RowsAtCompileTime),\n                Direction == Horizontal ? int(HNormalized_SizeMinusOne)\n                                        : int(internal::traits&lt;ExpressionType&gt;::ColsAtCompileTime)&gt;\n      HNormalized_Block;\n  typedef Block&lt;const ExpressionType,\n                Direction == Vertical ? 1 : int(internal::traits&lt;ExpressionType&gt;::RowsAtCompileTime),\n                Direction == Horizontal ? 1 : int(internal::traits&lt;ExpressionType&gt;::ColsAtCompileTime)&gt;\n      HNormalized_Factors;\n  typedef CwiseBinaryOp&lt;internal::scalar_quotient_op&lt;typename internal::traits&lt;ExpressionType&gt;::Scalar&gt;,\n                        const HNormalized_Block,\n                        const Replicate&lt;HNormalized_Factors, Direction == Vertical ? HNormalized_SizeMinusOne : 1,\n                                        Direction == Horizontal ? HNormalized_SizeMinusOne : 1&gt; &gt;\n      HNormalizedReturnType;\n\n  EIGEN_DEVICE_FUNC const HNormalizedReturnType hnormalized() const;\n\n#ifdef EIGEN_VECTORWISEOP_PLUGIN\n#include EIGEN_VECTORWISEOP_PLUGIN\n#endif\n\n protected:\n  EIGEN_DEVICE_FUNC Index redux_length() const { return Direction == Vertical ? m_matrix.rows() : m_matrix.cols(); }\n  ExpressionTypeNested m_matrix;\n};\n\n// const colwise moved to DenseBase.h due to CUDA compiler bug\n\n/** \\returns a writable VectorwiseOp wrapper of *this providing additional partial reduction operations\n *\n * \\sa rowwise(), class VectorwiseOp, \\ref TutorialReductionsVisitorsBroadcasting\n */\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC inline typename DenseBase&lt;Derived&gt;::ColwiseReturnType DenseBase&lt;Derived&gt;::colwise() {\n  return ColwiseReturnType(derived());\n}\n\n// const rowwise moved to DenseBase.h due to CUDA compiler bug\n\n/** \\returns a writable VectorwiseOp wrapper of *this providing additional partial reduction operations\n *\n * \\sa colwise(), class VectorwiseOp, \\ref TutorialReductionsVisitorsBroadcasting\n */\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC inline typename DenseBase&lt;Derived&gt;::RowwiseReturnType DenseBase&lt;Derived&gt;::rowwise() {\n  return RowwiseReturnType(derived());\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_PARTIAL_REDUX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "content": "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the &quot;License&quot;);\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an &quot;AS IS&quot; BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef EIGEN_BFLOAT16_H\n#define EIGEN_BFLOAT16_H\n\n// IWYU pragma: private\n#include &quot;../../InternalHeaderCheck.h&quot;\n\n#if defined(EIGEN_HAS_HIP_BF16)\n// When compiling with GPU support, the &quot;hip_bfloat16&quot; base class as well as\n// some other routines are defined in the GPU compiler header files\n// (hip_bfloat16.h), and they are not tagged constexpr\n// As a consequence, we get compile failures when compiling Eigen with\n// GPU support. Hence the need to disable EIGEN_CONSTEXPR when building\n// Eigen with GPU support\n#pragma push_macro(&quot;EIGEN_CONSTEXPR&quot;)\n#undef EIGEN_CONSTEXPR\n#define EIGEN_CONSTEXPR\n#endif\n\n#define BF16_PACKET_FUNCTION(PACKET_F, PACKET_BF16, METHOD)                                         \\\n  template &lt;&gt;                                                                                       \\\n  EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED PACKET_BF16 METHOD&lt;PACKET_BF16&gt;( \\\n      const PACKET_BF16&amp; _x) {                                                                      \\\n    return F32ToBf16(METHOD&lt;PACKET_F&gt;(Bf16ToF32(_x)));                                              \\\n  }\n\n// Only use HIP GPU bf16 in kernels\n#if defined(EIGEN_HAS_HIP_BF16) &amp;&amp; defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_USE_HIP_BF16\n#endif\n\nnamespace Eigen {\n\nstruct bfloat16;\n\nnamespace numext {\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::bfloat16 bit_cast&lt;Eigen::bfloat16, uint16_t&gt;(const uint16_t&amp; src);\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast&lt;uint16_t, Eigen::bfloat16&gt;(const Eigen::bfloat16&amp; src);\n}  // namespace numext\nnamespace bfloat16_impl {\n\n#if defined(EIGEN_USE_HIP_BF16)\n\nstruct __bfloat16_raw : public hip_bfloat16 {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() {}\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(hip_bfloat16 hb) : hip_bfloat16(hb) {}\n  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(unsigned short raw) : hip_bfloat16(raw) {}\n};\n\n#else\n\n// Make our own __bfloat16_raw definition.\nstruct __bfloat16_raw {\n#if defined(EIGEN_HAS_HIP_BF16) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() {}\n#else\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() : value(0) {}\n#endif\n  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(unsigned short raw) : value(raw) {}\n  unsigned short value;\n};\n\n#endif  // defined(EIGEN_USE_HIP_BF16)\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value);\ntemplate &lt;bool AssumeArgumentIsNormalOrInfinityOrZero&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne(float ff);\n// Forward declarations of template specializations, to avoid Visual C++ 2019 errors, saying:\n// &gt; error C2908: explicit specialization; &#x27;float_to_bfloat16_rtne&#x27; has already been instantiated\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne&lt;false&gt;(float ff);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne&lt;true&gt;(float ff);\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h);\n\nstruct bfloat16_base : public __bfloat16_raw {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base() {}\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base(const __bfloat16_raw&amp; h) : __bfloat16_raw(h) {}\n};\n\n}  // namespace bfloat16_impl\n\n// Class definition.\nstruct bfloat16 : public bfloat16_impl::bfloat16_base {\n  typedef bfloat16_impl::__bfloat16_raw __bfloat16_raw;\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16() {}\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const __bfloat16_raw&amp; h) : bfloat16_impl::bfloat16_base(h) {}\n\n  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(bool b)\n      : bfloat16_impl::bfloat16_base(bfloat16_impl::raw_uint16_to_bfloat16(b ? 0x3f80 : 0)) {}\n\n  template &lt;class T&gt;\n  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(T val)\n      : bfloat16_impl::bfloat16_base(\n            bfloat16_impl::float_to_bfloat16_rtne&lt;internal::is_integral&lt;T&gt;::value&gt;(static_cast&lt;float&gt;(val))) {}\n\n  explicit EIGEN_DEVICE_FUNC bfloat16(float f)\n      : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne&lt;false&gt;(f)) {}\n\n  // Following the convention of numpy, converting between complex and\n  // float will lead to loss of imag value.\n  template &lt;typename RealScalar&gt;\n  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const std::complex&lt;RealScalar&gt;&amp; val)\n      : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne&lt;false&gt;(static_cast&lt;float&gt;(val.real()))) {}\n\n  EIGEN_DEVICE_FUNC operator float() const {  // NOLINT: Allow implicit conversion to float, because it is lossless.\n    return bfloat16_impl::bfloat16_to_float(*this);\n  }\n};\n\n// TODO(majnemer): Get rid of this once we can rely on C++17 inline variables do\n// solve the ODR issue.\nnamespace bfloat16_impl {\ntemplate &lt;typename = void&gt;\nstruct numeric_limits_bfloat16_impl {\n  static EIGEN_CONSTEXPR const bool is_specialized = true;\n  static EIGEN_CONSTEXPR const bool is_signed = true;\n  static EIGEN_CONSTEXPR const bool is_integer = false;\n  static EIGEN_CONSTEXPR const bool is_exact = false;\n  static EIGEN_CONSTEXPR const bool has_infinity = true;\n  static EIGEN_CONSTEXPR const bool has_quiet_NaN = true;\n  static EIGEN_CONSTEXPR const bool has_signaling_NaN = true;\n  EIGEN_DIAGNOSTICS(push)\n  EIGEN_DISABLE_DEPRECATED_WARNING\n  static EIGEN_CONSTEXPR const std::float_denorm_style has_denorm = std::denorm_present;\n  static EIGEN_CONSTEXPR const bool has_denorm_loss = false;\n  EIGEN_DIAGNOSTICS(pop)\n  static EIGEN_CONSTEXPR const std::float_round_style round_style = std::numeric_limits&lt;float&gt;::round_style;\n  static EIGEN_CONSTEXPR const bool is_iec559 = true;\n  // The C++ standard defines this as &quot;true if the set of values representable\n  // by the type is finite.&quot; BFloat16 has finite precision.\n  static EIGEN_CONSTEXPR const bool is_bounded = true;\n  static EIGEN_CONSTEXPR const bool is_modulo = false;\n  static EIGEN_CONSTEXPR const int digits = 8;\n  static EIGEN_CONSTEXPR const int digits10 = 2;\n  static EIGEN_CONSTEXPR const int max_digits10 = 4;\n  static EIGEN_CONSTEXPR const int radix = std::numeric_limits&lt;float&gt;::radix;\n  static EIGEN_CONSTEXPR const int min_exponent = std::numeric_limits&lt;float&gt;::min_exponent;\n  static EIGEN_CONSTEXPR const int min_exponent10 = std::numeric_limits&lt;float&gt;::min_exponent10;\n  static EIGEN_CONSTEXPR const int max_exponent = std::numeric_limits&lt;float&gt;::max_exponent;\n  static EIGEN_CONSTEXPR const int max_exponent10 = std::numeric_limits&lt;float&gt;::max_exponent10;\n  static EIGEN_CONSTEXPR const bool traps = std::numeric_limits&lt;float&gt;::traps;\n  // IEEE754: &quot;The implementer shall choose how tininess is detected, but shall\n  // detect tininess in the same way for all operations in radix two&quot;\n  static EIGEN_CONSTEXPR const bool tinyness_before = std::numeric_limits&lt;float&gt;::tinyness_before;\n\n  static EIGEN_CONSTEXPR Eigen::bfloat16(min)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0080); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 lowest() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0xff7f); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16(max)() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f7f); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 epsilon() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3c00); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 round_error() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x3f00); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 infinity() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7f80); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 quiet_NaN() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0); }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 signaling_NaN() {\n    return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x7fa0);\n  }\n  static EIGEN_CONSTEXPR Eigen::bfloat16 denorm_min() { return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(0x0001); }\n};\n\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_specialized;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_signed;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_integer;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_exact;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::has_infinity;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::has_quiet_NaN;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::has_signaling_NaN;\nEIGEN_DIAGNOSTICS(push)\nEIGEN_DISABLE_DEPRECATED_WARNING\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const std::float_denorm_style numeric_limits_bfloat16_impl&lt;T&gt;::has_denorm;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::has_denorm_loss;\nEIGEN_DIAGNOSTICS(pop)\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const std::float_round_style numeric_limits_bfloat16_impl&lt;T&gt;::round_style;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_iec559;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_bounded;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::is_modulo;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::digits;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::digits10;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::max_digits10;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::radix;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::min_exponent;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::min_exponent10;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::max_exponent;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const int numeric_limits_bfloat16_impl&lt;T&gt;::max_exponent10;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::traps;\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR const bool numeric_limits_bfloat16_impl&lt;T&gt;::tinyness_before;\n}  // end namespace bfloat16_impl\n}  // end namespace Eigen\n\nnamespace std {\n// If std::numeric_limits&lt;T&gt; is specialized, should also specialize\n// std::numeric_limits&lt;const T&gt;, std::numeric_limits&lt;volatile T&gt;, and\n// std::numeric_limits&lt;const volatile T&gt;\n// https://stackoverflow.com/a/16519653/\ntemplate &lt;&gt;\nclass numeric_limits&lt;Eigen::bfloat16&gt; : public Eigen::bfloat16_impl::numeric_limits_bfloat16_impl&lt;&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;const Eigen::bfloat16&gt; : public numeric_limits&lt;Eigen::bfloat16&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;volatile Eigen::bfloat16&gt; : public numeric_limits&lt;Eigen::bfloat16&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;const volatile Eigen::bfloat16&gt; : public numeric_limits&lt;Eigen::bfloat16&gt; {};\n}  // end namespace std\n\nnamespace Eigen {\n\nnamespace bfloat16_impl {\n\n// We need to distinguish \u2018clang as the CUDA compiler\u2019 from \u2018clang as the host compiler,\n// invoked by NVCC\u2019 (e.g. on MacOS). The former needs to see both host and device implementation\n// of the functions, while the latter can only deal with one of them.\n#if !defined(EIGEN_HAS_NATIVE_BF16) || (EIGEN_COMP_CLANG &amp;&amp; !EIGEN_COMP_NVCC)  // Emulate support for bfloat16 floats\n\n#if EIGEN_COMP_CLANG &amp;&amp; defined(EIGEN_CUDACC)\n// We need to provide emulated *host-side* BF16 operators for clang.\n#pragma push_macro(&quot;EIGEN_DEVICE_FUNC&quot;)\n#undef EIGEN_DEVICE_FUNC\n#if (defined(EIGEN_HAS_GPU_BF16) &amp;&amp; defined(EIGEN_HAS_NATIVE_BF16))\n#define EIGEN_DEVICE_FUNC __host__\n#else  // both host and device need emulated ops.\n#define EIGEN_DEVICE_FUNC __host__ __device__\n#endif\n#endif\n\n// Definitions for CPUs, mostly working through conversion\n// to/from fp32.\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(float(a) + float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const bfloat16&amp; a, const int&amp; b) {\n  return bfloat16(float(a) + static_cast&lt;float&gt;(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator+(const int&amp; a, const bfloat16&amp; b) {\n  return bfloat16(static_cast&lt;float&gt;(a) + float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator*(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(float(a) * float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator-(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(float(a) - float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator/(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(float(a) / float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator-(const bfloat16&amp; a) {\n  numext::uint16_t x = numext::bit_cast&lt;uint16_t&gt;(a) ^ 0x8000;\n  return numext::bit_cast&lt;bfloat16&gt;(x);\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16&amp; operator+=(bfloat16&amp; a, const bfloat16&amp; b) {\n  a = bfloat16(float(a) + float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16&amp; operator*=(bfloat16&amp; a, const bfloat16&amp; b) {\n  a = bfloat16(float(a) * float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16&amp; operator-=(bfloat16&amp; a, const bfloat16&amp; b) {\n  a = bfloat16(float(a) - float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16&amp; operator/=(bfloat16&amp; a, const bfloat16&amp; b) {\n  a = bfloat16(float(a) / float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator++(bfloat16&amp; a) {\n  a += bfloat16(1);\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator--(bfloat16&amp; a) {\n  a -= bfloat16(1);\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator++(bfloat16&amp; a, int) {\n  bfloat16 original_value = a;\n  ++a;\n  return original_value;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator--(bfloat16&amp; a, int) {\n  bfloat16 original_value = a;\n  --a;\n  return original_value;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return numext::equal_strict(float(a), float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return numext::not_equal_strict(float(a), float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return float(a) &lt; float(b);\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;=(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return float(a) &lt;= float(b);\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return float(a) &gt; float(b);\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;=(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return float(a) &gt;= float(b);\n}\n\n#if EIGEN_COMP_CLANG &amp;&amp; defined(EIGEN_CUDACC)\n#pragma pop_macro(&quot;EIGEN_DEVICE_FUNC&quot;)\n#endif\n#endif  // Emulate support for bfloat16 floats\n\n// Division by an index. Do it in full float precision to avoid accuracy\n// issues in converting the denominator to bfloat16.\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator/(const bfloat16&amp; a, Index b) {\n  return bfloat16(static_cast&lt;float&gt;(a) / static_cast&lt;float&gt;(b));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw truncate_to_bfloat16(const float v) {\n#if defined(EIGEN_USE_HIP_BF16)\n  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(v, __bfloat16_raw::truncate));\n#else\n  __bfloat16_raw output;\n  if (numext::isnan EIGEN_NOT_A_MACRO(v)) {\n    output.value = std::signbit(v) ? 0xFFC0 : 0x7FC0;\n    return output;\n  }\n  output.value = static_cast&lt;numext::uint16_t&gt;(numext::bit_cast&lt;numext::uint32_t&gt;(v) &gt;&gt; 16);\n  return output;\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(numext::uint16_t value) {\n#if defined(EIGEN_USE_HIP_BF16)\n  __bfloat16_raw bf;\n  bf.data = value;\n  return bf;\n#else\n  return __bfloat16_raw(value);\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR numext::uint16_t raw_bfloat16_as_uint16(\n    const __bfloat16_raw&amp; bf) {\n#if defined(EIGEN_USE_HIP_BF16)\n  return bf.data;\n#else\n  return bf.value;\n#endif\n}\n\n// float_to_bfloat16_rtne template specialization that does not make any\n// assumption about the value of its function argument (ff).\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne&lt;false&gt;(float ff) {\n#if defined(EIGEN_USE_HIP_BF16)\n  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(ff));\n#else\n  __bfloat16_raw output;\n\n  if (numext::isnan EIGEN_NOT_A_MACRO(ff)) {\n    // If the value is a NaN, squash it to a qNaN with msb of fraction set,\n    // this makes sure after truncation we don&#x27;t end up with an inf.\n    //\n    // qNaN magic: All exponent bits set + most significant bit of fraction\n    // set.\n    output.value = std::signbit(ff) ? 0xFFC0 : 0x7FC0;\n  } else {\n    // Fast rounding algorithm that rounds a half value to nearest even. This\n    // reduces expected error when we convert a large number of floats. Here\n    // is how it works:\n    //\n    // Definitions:\n    // To convert a float 32 to bfloat16, a float 32 can be viewed as 32 bits\n    // with the following tags:\n    //\n    // Sign |  Exp (8 bits) | Frac (23 bits)\n    //  S     EEEEEEEE         FFFFFFLRTTTTTTTTTTTTTTT\n    //\n    //  S: Sign bit.\n    //  E: Exponent bits.\n    //  F: First 6 bits of fraction.\n    //  L: Least significant bit of resulting bfloat16 if we truncate away the\n    //  rest of the float32. This is also the 7th bit of fraction\n    //  R: Rounding bit, 8th bit of fraction.\n    //  T: Sticky bits, rest of fraction, 15 bits.\n    //\n    // To round half to nearest even, there are 3 cases where we want to round\n    // down (simply truncate the result of the bits away, which consists of\n    // rounding bit and sticky bits) and two cases where we want to round up\n    // (truncate then add one to the result).\n    //\n    // The fast converting algorithm simply adds lsb (L) to 0x7fff (15 bits of\n    // 1s) as the rounding bias, adds the rounding bias to the input, then\n    // truncates the last 16 bits away.\n    //\n    // To understand how it works, we can analyze this algorithm case by case:\n    //\n    // 1. L = 0, R = 0:\n    //   Expect: round down, this is less than half value.\n    //\n    //   Algorithm:\n    //   - Rounding bias: 0x7fff + 0 = 0x7fff\n    //   - Adding rounding bias to input may create any carry, depending on\n    //   whether there is any value set to 1 in T bits.\n    //   - R may be set to 1 if there is a carry.\n    //   - L remains 0.\n    //   - Note that this case also handles Inf and -Inf, where all fraction\n    //   bits, including L, R and Ts are all 0. The output remains Inf after\n    //   this algorithm.\n    //\n    // 2. L = 1, R = 0:\n    //   Expect: round down, this is less than half value.\n    //\n    //   Algorithm:\n    //   - Rounding bias: 0x7fff + 1 = 0x8000\n    //   - Adding rounding bias to input doesn&#x27;t change sticky bits but\n    //   adds 1 to rounding bit.\n    //   - L remains 1.\n    //\n    // 3. L = 0, R = 1, all of T are 0:\n    //   Expect: round down, this is exactly at half, the result is already\n    //   even (L=0).\n    //\n    //   Algorithm:\n    //   - Rounding bias: 0x7fff + 0 = 0x7fff\n    //   - Adding rounding bias to input sets all sticky bits to 1, but\n    //   doesn&#x27;t create a carry.\n    //   - R remains 1.\n    //   - L remains 0.\n    //\n    // 4. L = 1, R = 1:\n    //   Expect: round up, this is exactly at half, the result needs to be\n    //   round to the next even number.\n    //\n    //   Algorithm:\n    //   - Rounding bias: 0x7fff + 1 = 0x8000\n    //   - Adding rounding bias to input doesn&#x27;t change sticky bits, but\n    //   creates a carry from rounding bit.\n    //   - The carry sets L to 0, creates another carry bit and propagate\n    //   forward to F bits.\n    //   - If all the F bits are 1, a carry then propagates to the exponent\n    //   bits, which then creates the minimum value with the next exponent\n    //   value. Note that we won&#x27;t have the case where exponents are all 1,\n    //   since that&#x27;s either a NaN (handled in the other if condition) or inf\n    //   (handled in case 1).\n    //\n    // 5. L = 0, R = 1, any of T is 1:\n    //   Expect: round up, this is greater than half.\n    //\n    //   Algorithm:\n    //   - Rounding bias: 0x7fff + 0 = 0x7fff\n    //   - Adding rounding bias to input creates a carry from sticky bits,\n    //   sets rounding bit to 0, then create another carry.\n    //   - The second carry sets L to 1.\n    //\n    // Examples:\n    //\n    //  Exact half value that is already even:\n    //    Input:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)\n    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT\n    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0     1000000000000000\n    //\n    //     This falls into case 3. We truncate the rest of 16 bits and no\n    //     carry is created into F and L:\n    //\n    //    Output:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)\n    //     S     E E E E E E E E      F F F F F F L\n    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0\n    //\n    //  Exact half value, round to next even number:\n    //    Input:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)\n    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT\n    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 0 1     1000000000000000\n    //\n    //     This falls into case 4. We create a carry from R and T,\n    //     which then propagates into L and F:\n    //\n    //    Output:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)\n    //     S     E E E E E E E E      F F F F F F L\n    //     0     0 0 0 0 0 0 0 0      0 0 0 0 0 1 0\n    //\n    //\n    //  Max denormal value round to min normal value:\n    //    Input:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)\n    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT\n    //     0     0 0 0 0 0 0 0 0      1 1 1 1 1 1 1     1111111111111111\n    //\n    //     This falls into case 4. We create a carry from R and T,\n    //     propagate into L and F, which then propagates into exponent\n    //     bits:\n    //\n    //    Output:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)\n    //     S     E E E E E E E E      F F F F F F L\n    //     0     0 0 0 0 0 0 0 1      0 0 0 0 0 0 0\n    //\n    //  Max normal value round to Inf:\n    //    Input:\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit) | Frac (last 16 bit)\n    //     S     E E E E E E E E      F F F F F F L     RTTTTTTTTTTTTTTT\n    //     0     1 1 1 1 1 1 1 0      1 1 1 1 1 1 1     1111111111111111\n    //\n    //     This falls into case 4. We create a carry from R and T,\n    //     propagate into L and F, which then propagates into exponent\n    //     bits:\n    //\n    //    Sign |  Exp (8 bit)     | Frac (first 7 bit)\n    //     S     E E E E E E E E      F F F F F F L\n    //     0     1 1 1 1 1 1 1 1      0 0 0 0 0 0 0\n\n    // At this point, ff must be either a normal float, or +/-infinity.\n    output = float_to_bfloat16_rtne&lt;true&gt;(ff);\n  }\n  return output;\n#endif\n}\n\n// float_to_bfloat16_rtne template specialization that assumes that its function\n// argument (ff) is either a normal floating point number, or +/-infinity, or\n// zero. Used to improve the runtime performance of conversion from an integer\n// type to bfloat16.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne&lt;true&gt;(float ff) {\n#if defined(EIGEN_USE_HIP_BF16)\n  return __bfloat16_raw(__bfloat16_raw::round_to_bfloat16(ff));\n#else\n  numext::uint32_t input = numext::bit_cast&lt;numext::uint32_t&gt;(ff);\n  __bfloat16_raw output;\n\n  // Least significant bit of resulting bfloat.\n  numext::uint32_t lsb = (input &gt;&gt; 16) &amp; 1;\n  numext::uint32_t rounding_bias = 0x7fff + lsb;\n  input += rounding_bias;\n  output.value = static_cast&lt;numext::uint16_t&gt;(input &gt;&gt; 16);\n  return output;\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h) {\n#if defined(EIGEN_USE_HIP_BF16)\n  return static_cast&lt;float&gt;(h);\n#else\n  return numext::bit_cast&lt;float&gt;(static_cast&lt;numext::uint32_t&gt;(h.value) &lt;&lt; 16);\n#endif\n}\n\n// --- standard functions ---\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isinf)(const bfloat16&amp; a) {\n  EIGEN_USING_STD(isinf);\n#if defined(EIGEN_USE_HIP_BF16)\n  return (isinf)(a);  // Uses HIP hip_bfloat16 isinf operator\n#else\n  return (isinf)(float(a));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isnan)(const bfloat16&amp; a) {\n  EIGEN_USING_STD(isnan);\n#if defined(EIGEN_USE_HIP_BF16)\n  return (isnan)(a);  // Uses HIP hip_bfloat16 isnan operator\n#else\n  return (isnan)(float(a));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isfinite)(const bfloat16&amp; a) {\n  return !(isinf EIGEN_NOT_A_MACRO(a)) &amp;&amp; !(isnan EIGEN_NOT_A_MACRO(a));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 abs(const bfloat16&amp; a) {\n  numext::uint16_t x = numext::bit_cast&lt;numext::uint16_t&gt;(a) &amp; 0x7FFF;\n  return numext::bit_cast&lt;bfloat16&gt;(x);\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 exp(const bfloat16&amp; a) { return bfloat16(::expf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 exp2(const bfloat16&amp; a) { return bfloat16(::exp2f(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 expm1(const bfloat16&amp; a) { return bfloat16(numext::expm1(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log(const bfloat16&amp; a) { return bfloat16(::logf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log1p(const bfloat16&amp; a) { return bfloat16(numext::log1p(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log10(const bfloat16&amp; a) { return bfloat16(::log10f(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log2(const bfloat16&amp; a) {\n  return bfloat16(static_cast&lt;float&gt;(EIGEN_LOG2E) * ::logf(float(a)));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sqrt(const bfloat16&amp; a) { return bfloat16(::sqrtf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 pow(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(::powf(float(a), float(b)));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atan2(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(::atan2f(float(a), float(b)));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sin(const bfloat16&amp; a) { return bfloat16(::sinf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 cos(const bfloat16&amp; a) { return bfloat16(::cosf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 tan(const bfloat16&amp; a) { return bfloat16(::tanf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 asin(const bfloat16&amp; a) { return bfloat16(::asinf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 acos(const bfloat16&amp; a) { return bfloat16(::acosf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atan(const bfloat16&amp; a) { return bfloat16(::atanf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sinh(const bfloat16&amp; a) { return bfloat16(::sinhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 cosh(const bfloat16&amp; a) { return bfloat16(::coshf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 tanh(const bfloat16&amp; a) { return bfloat16(::tanhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 asinh(const bfloat16&amp; a) { return bfloat16(::asinhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 acosh(const bfloat16&amp; a) { return bfloat16(::acoshf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atanh(const bfloat16&amp; a) { return bfloat16(::atanhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 floor(const bfloat16&amp; a) { return bfloat16(::floorf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 ceil(const bfloat16&amp; a) { return bfloat16(::ceilf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 rint(const bfloat16&amp; a) { return bfloat16(::rintf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 round(const bfloat16&amp; a) { return bfloat16(::roundf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 trunc(const bfloat16&amp; a) { return bfloat16(::truncf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmod(const bfloat16&amp; a, const bfloat16&amp; b) {\n  return bfloat16(::fmodf(float(a), float(b)));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16(min)(const bfloat16&amp; a, const bfloat16&amp; b) {\n  const float f1 = static_cast&lt;float&gt;(a);\n  const float f2 = static_cast&lt;float&gt;(b);\n  return f2 &lt; f1 ? b : a;\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16(max)(const bfloat16&amp; a, const bfloat16&amp; b) {\n  const float f1 = static_cast&lt;float&gt;(a);\n  const float f2 = static_cast&lt;float&gt;(b);\n  return f1 &lt; f2 ? b : a;\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmin(const bfloat16&amp; a, const bfloat16&amp; b) {\n  const float f1 = static_cast&lt;float&gt;(a);\n  const float f2 = static_cast&lt;float&gt;(b);\n  return bfloat16(::fminf(f1, f2));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmax(const bfloat16&amp; a, const bfloat16&amp; b) {\n  const float f1 = static_cast&lt;float&gt;(a);\n  const float f2 = static_cast&lt;float&gt;(b);\n  return bfloat16(::fmaxf(f1, f2));\n}\n\nEIGEN_DEVICE_FUNC inline bfloat16 fma(const bfloat16&amp; a, const bfloat16&amp; b, const bfloat16&amp; c) {\n  // Emulate FMA via float.\n  return bfloat16(numext::fma(static_cast&lt;float&gt;(a), static_cast&lt;float&gt;(b), static_cast&lt;float&gt;(c)));\n}\n\n#ifndef EIGEN_NO_IO\nEIGEN_ALWAYS_INLINE std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const bfloat16&amp; v) {\n  os &lt;&lt; static_cast&lt;float&gt;(v);\n  return os;\n}\n#endif\n\n}  // namespace bfloat16_impl\n\nnamespace internal {\n\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;bfloat16&gt; {\n  enum { value = true };\n};\n\ntemplate &lt;&gt;\nstruct random_impl&lt;bfloat16&gt; {\n  enum : int { MantissaBits = 7 };\n  using Impl = random_impl&lt;float&gt;;\n  static EIGEN_DEVICE_FUNC inline bfloat16 run(const bfloat16&amp; x, const bfloat16&amp; y) {\n    float result = Impl::run(x, y, MantissaBits);\n    return bfloat16(result);\n  }\n  static EIGEN_DEVICE_FUNC inline bfloat16 run() {\n    float result = Impl::run(MantissaBits);\n    return bfloat16(result);\n  }\n};\n\n}  // namespace internal\n\ntemplate &lt;&gt;\nstruct NumTraits&lt;Eigen::bfloat16&gt; : GenericNumTraits&lt;Eigen::bfloat16&gt; {\n  enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };\n\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 epsilon() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0x3c00);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 dummy_precision() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0x3D4D);  // bfloat16(5e-2f);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 highest() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0x7F7F);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 lowest() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0xFF7F);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 infinity() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0x7f80);\n  }\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 quiet_NaN() {\n    return bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0);\n  }\n};\n\n}  // namespace Eigen\n\n#if defined(EIGEN_HAS_HIP_BF16)\n#pragma pop_macro(&quot;EIGEN_CONSTEXPR&quot;)\n#endif\n\nnamespace Eigen {\nnamespace numext {\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isnan)(const Eigen::bfloat16&amp; h) {\n  return (bfloat16_impl::isnan)(h);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isinf)(const Eigen::bfloat16&amp; h) {\n  return (bfloat16_impl::isinf)(h);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isfinite)(const Eigen::bfloat16&amp; h) {\n  return (bfloat16_impl::isfinite)(h);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::bfloat16 bit_cast&lt;Eigen::bfloat16, uint16_t&gt;(const uint16_t&amp; src) {\n  return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(src);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast&lt;uint16_t, Eigen::bfloat16&gt;(const Eigen::bfloat16&amp; src) {\n  return Eigen::bfloat16_impl::raw_bfloat16_as_uint16(src);\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 nextafter(const bfloat16&amp; from, const bfloat16&amp; to) {\n  if (numext::isnan EIGEN_NOT_A_MACRO(from)) {\n    return from;\n  }\n  if (numext::isnan EIGEN_NOT_A_MACRO(to)) {\n    return to;\n  }\n  if (from == to) {\n    return to;\n  }\n  uint16_t from_bits = numext::bit_cast&lt;uint16_t&gt;(from);\n  bool from_sign = from_bits &gt;&gt; 15;\n  // Whether we are adjusting toward the infinity with the same sign as from.\n  bool toward_inf = (to &gt; from) == !from_sign;\n  if (toward_inf) {\n    ++from_bits;\n  } else if ((from_bits &amp; 0x7fff) == 0) {\n    // Adjusting away from inf, but from is zero, so just toggle the sign.\n    from_bits ^= 0x8000;\n  } else {\n    --from_bits;\n  }\n  return numext::bit_cast&lt;bfloat16&gt;(from_bits);\n}\n\n}  // namespace numext\n}  // namespace Eigen\n\n#if EIGEN_HAS_STD_HASH\nnamespace std {\ntemplate &lt;&gt;\nstruct hash&lt;Eigen::bfloat16&gt; {\n  EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::bfloat16&amp; a) const {\n    return static_cast&lt;std::size_t&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(a));\n  }\n};\n}  // namespace std\n#endif\n\n// Add the missing shfl* intrinsics.\n// The __shfl* functions are only valid on HIP or _CUDA_ARCH_ &gt;= 300.\n//   CUDA defines them for (__CUDA_ARCH__ &gt;= 300 || !defined(__CUDA_ARCH__))\n//\n// HIP and CUDA prior to SDK 9.0 define\n//    __shfl, __shfl_up, __shfl_down, __shfl_xor for int and float\n// CUDA since 9.0 deprecates those and instead defines\n//    __shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync,\n//    with native support for __half and __nv_bfloat16\n//\n// Note that the following are __device__ - only functions.\n#if defined(EIGEN_HIPCC)\n\n#if defined(EIGEN_HAS_HIP_BF16)\n\n__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl(Eigen::bfloat16 var, int srcLane, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::bfloat16&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl(ivar, srcLane, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_up(Eigen::bfloat16 var, unsigned int delta,\n                                                         int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::bfloat16&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_up(ivar, delta, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_down(Eigen::bfloat16 var, unsigned int delta,\n                                                           int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::bfloat16&gt;(\n      static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_down(ivar, delta, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::bfloat16 __shfl_xor(Eigen::bfloat16 var, int laneMask, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::bfloat16&gt;(\n      static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_xor(ivar, laneMask, width)));\n}\n\n#endif  // HIP\n\n#endif  // __shfl*\n\n#if defined(EIGEN_HIPCC)\nEIGEN_STRONG_INLINE __device__ Eigen::bfloat16 __ldg(const Eigen::bfloat16* ptr) {\n  return Eigen::bfloat16_impl::raw_uint16_to_bfloat16(\n      __ldg(Eigen::numext::bit_cast&lt;const Eigen::numext::uint16_t*&gt;(ptr)));\n}\n#endif  // __ldg\n\n#endif  // EIGEN_BFLOAT16_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2007 Julien Pommier\n// Copyright (C) 2014 Pedro Gonnet (pedro.gonnet@gmail.com)\n// Copyright (C) 2009-2019 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n/* The exp and log functions of this file initially come from\n * Julien Pommier&#x27;s sse math library: http://gruntthepeon.free.fr/ssemath/\n */\n\n#ifndef EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H\n#define EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H\n\n// IWYU pragma: private\n#include &quot;../../InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\nnamespace internal {\n\n// Creates a Scalar integer type with same bit-width.\ntemplate &lt;typename T&gt;\nstruct make_integer;\ntemplate &lt;&gt;\nstruct make_integer&lt;float&gt; {\n  typedef numext::int32_t type;\n};\ntemplate &lt;&gt;\nstruct make_integer&lt;double&gt; {\n  typedef numext::int64_t type;\n};\ntemplate &lt;&gt;\nstruct make_integer&lt;half&gt; {\n  typedef numext::int16_t type;\n};\ntemplate &lt;&gt;\nstruct make_integer&lt;bfloat16&gt; {\n  typedef numext::int16_t type;\n};\n\n/* polevl (modified for Eigen)\n *\n *      Evaluate polynomial\n *\n *\n *\n * SYNOPSIS:\n *\n * int N;\n * Scalar x, y, coef[N+1];\n *\n * y = polevl&lt;decltype(x), N&gt;( x, coef);\n *\n *\n *\n * DESCRIPTION:\n *\n * Evaluates polynomial of degree N:\n *\n *                     2          N\n * y  =  C  + C x + C x  +...+ C x\n *        0    1     2          N\n *\n * Coefficients are stored in reverse order:\n *\n * coef[0] = C  , ..., coef[N] = C  .\n *            N                   0\n *\n *  The function p1evl() assumes that coef[N] = 1.0 and is\n * omitted from the array.  Its calling arguments are\n * otherwise the same as polevl().\n *\n *\n * The Eigen implementation is templatized.  For best speed, store\n * coef as a const array (constexpr), e.g.\n *\n * const double coef[] = {1.0, 2.0, 3.0, ...};\n *\n */\ntemplate &lt;typename Packet, int N&gt;\nstruct ppolevl {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x,\n                                                          const typename unpacket_traits&lt;Packet&gt;::type coeff[]) {\n    EIGEN_STATIC_ASSERT((N &gt; 0), YOU_MADE_A_PROGRAMMING_MISTAKE);\n    return pmadd(ppolevl&lt;Packet, N - 1&gt;::run(x, coeff), x, pset1&lt;Packet&gt;(coeff[N]));\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct ppolevl&lt;Packet, 0&gt; {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x,\n                                                          const typename unpacket_traits&lt;Packet&gt;::type coeff[]) {\n    EIGEN_UNUSED_VARIABLE(x);\n    return pset1&lt;Packet&gt;(coeff[0]);\n  }\n};\n\n/* chbevl (modified for Eigen)\n *\n *     Evaluate Chebyshev series\n *\n *\n *\n * SYNOPSIS:\n *\n * int N;\n * Scalar x, y, coef[N], chebevl();\n *\n * y = chbevl( x, coef, N );\n *\n *\n *\n * DESCRIPTION:\n *\n * Evaluates the series\n *\n *        N-1\n *         - &#x27;\n *  y  =   &gt;   coef[i] T (x/2)\n *         -            i\n *        i=0\n *\n * of Chebyshev polynomials Ti at argument x/2.\n *\n * Coefficients are stored in reverse order, i.e. the zero\n * order term is last in the array.  Note N is the number of\n * coefficients, not the order.\n *\n * If coefficients are for the interval a to b, x must\n * have been transformed to x -&gt; 2(2x - b - a)/(b-a) before\n * entering the routine.  This maps x from (a, b) to (-1, 1),\n * over which the Chebyshev polynomials are defined.\n *\n * If the coefficients are for the inverted interval, in\n * which (a, b) is mapped to (1/b, 1/a), the transformation\n * required is x -&gt; 2(2ab/x - b - a)/(b-a).  If b is infinity,\n * this becomes x -&gt; 4a/x - 1.\n *\n *\n *\n * SPEED:\n *\n * Taking advantage of the recurrence properties of the\n * Chebyshev polynomials, the routine requires one more\n * addition per loop than evaluating a nested polynomial of\n * the same degree.\n *\n */\n\ntemplate &lt;typename Packet, int N&gt;\nstruct pchebevl {\n  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Packet run(Packet x,\n                                                          const typename unpacket_traits&lt;Packet&gt;::type coef[]) {\n    typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n    Packet b0 = pset1&lt;Packet&gt;(coef[0]);\n    Packet b1 = pset1&lt;Packet&gt;(static_cast&lt;Scalar&gt;(0.f));\n    Packet b2;\n\n    for (int i = 1; i &lt; N; i++) {\n      b2 = b1;\n      b1 = b0;\n      b0 = psub(pmadd(x, b1, pset1&lt;Packet&gt;(coef[i])), b2);\n    }\n\n    return pmul(pset1&lt;Packet&gt;(static_cast&lt;Scalar&gt;(0.5f)), psub(b0, b2));\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic_get_biased_exponent(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename unpacket_traits&lt;Packet&gt;::integer_packet PacketI;\n  static constexpr int mantissa_bits = numext::numeric_limits&lt;Scalar&gt;::digits - 1;\n  return pcast&lt;PacketI, Packet&gt;(plogical_shift_right&lt;mantissa_bits&gt;(preinterpret&lt;PacketI&gt;(pabs(a))));\n}\n\n// Safely applies frexp, correctly handles denormals.\n// Assumes IEEE floating point format.\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pfrexp_generic(const Packet&amp; a, Packet&amp; exponent) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename make_unsigned&lt;typename make_integer&lt;Scalar&gt;::type&gt;::type ScalarUI;\n  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits&lt;Scalar&gt;::digits - 1,\n                       ExponentBits = TotalBits - MantissaBits - 1;\n\n  EIGEN_CONSTEXPR ScalarUI scalar_sign_mantissa_mask =\n      ~(((ScalarUI(1) &lt;&lt; ExponentBits) - ScalarUI(1)) &lt;&lt; MantissaBits);  // ~0x7f800000\n  const Packet sign_mantissa_mask = pset1frombits&lt;Packet&gt;(static_cast&lt;ScalarUI&gt;(scalar_sign_mantissa_mask));\n  const Packet half = pset1&lt;Packet&gt;(Scalar(0.5));\n  const Packet zero = pzero(a);\n  const Packet normal_min = pset1&lt;Packet&gt;((numext::numeric_limits&lt;Scalar&gt;::min)());  // Minimum normal value, 2^-126\n\n  // To handle denormals, normalize by multiplying by 2^(int(MantissaBits)+1).\n  const Packet is_denormal = pcmp_lt(pabs(a), normal_min);\n  EIGEN_CONSTEXPR ScalarUI scalar_normalization_offset = ScalarUI(MantissaBits + 1);  // 24\n  // The following cannot be constexpr because bfloat16(uint16_t) is not constexpr.\n  const Scalar scalar_normalization_factor = Scalar(ScalarUI(1) &lt;&lt; int(scalar_normalization_offset));  // 2^24\n  const Packet normalization_factor = pset1&lt;Packet&gt;(scalar_normalization_factor);\n  const Packet normalized_a = pselect(is_denormal, pmul(a, normalization_factor), a);\n\n  // Determine exponent offset: -126 if normal, -126-24 if denormal\n  const Scalar scalar_exponent_offset = -Scalar((ScalarUI(1) &lt;&lt; (ExponentBits - 1)) - ScalarUI(2));  // -126\n  Packet exponent_offset = pset1&lt;Packet&gt;(scalar_exponent_offset);\n  const Packet normalization_offset = pset1&lt;Packet&gt;(-Scalar(scalar_normalization_offset));  // -24\n  exponent_offset = pselect(is_denormal, padd(exponent_offset, normalization_offset), exponent_offset);\n\n  // Determine exponent and mantissa from normalized_a.\n  exponent = pfrexp_generic_get_biased_exponent(normalized_a);\n  // Zero, Inf and NaN return &#x27;a&#x27; unmodified, exponent is zero\n  // (technically the exponent is unspecified for inf/NaN, but GCC/Clang set it to zero)\n  const Scalar scalar_non_finite_exponent = Scalar((ScalarUI(1) &lt;&lt; ExponentBits) - ScalarUI(1));  // 255\n  const Packet non_finite_exponent = pset1&lt;Packet&gt;(scalar_non_finite_exponent);\n  const Packet is_zero_or_not_finite = por(pcmp_eq(a, zero), pcmp_eq(exponent, non_finite_exponent));\n  const Packet m = pselect(is_zero_or_not_finite, a, por(pand(normalized_a, sign_mantissa_mask), half));\n  exponent = pselect(is_zero_or_not_finite, zero, padd(exponent, exponent_offset));\n  return m;\n}\n\n// Safely applies ldexp, correctly handles overflows, underflows and denormals.\n// Assumes IEEE floating point format.\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_generic(const Packet&amp; a, const Packet&amp; exponent) {\n  // We want to return a * 2^exponent, allowing for all possible integer\n  // exponents without overflowing or underflowing in intermediate\n  // computations.\n  //\n  // Since &#x27;a&#x27; and the output can be denormal, the maximum range of &#x27;exponent&#x27;\n  // to consider for a float is:\n  //   -255-23 -&gt; 255+23\n  // Below -278 any finite float &#x27;a&#x27; will become zero, and above +278 any\n  // finite float will become inf, including when &#x27;a&#x27; is the smallest possible\n  // denormal.\n  //\n  // Unfortunately, 2^(278) cannot be represented using either one or two\n  // finite normal floats, so we must split the scale factor into at least\n  // three parts. It turns out to be faster to split &#x27;exponent&#x27; into four\n  // factors, since [exponent&gt;&gt;2] is much faster to compute that [exponent/3].\n  //\n  // Set e = min(max(exponent, -278), 278);\n  //     b = floor(e/4);\n  //   out = ((((a * 2^(b)) * 2^(b)) * 2^(b)) * 2^(e-3*b))\n  //\n  // This will avoid any intermediate overflows and correctly handle 0, inf,\n  // NaN cases.\n  typedef typename unpacket_traits&lt;Packet&gt;::integer_packet PacketI;\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename unpacket_traits&lt;PacketI&gt;::type ScalarI;\n  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits&lt;Scalar&gt;::digits - 1,\n                       ExponentBits = TotalBits - MantissaBits - 1;\n\n  const Packet max_exponent = pset1&lt;Packet&gt;(Scalar((ScalarI(1) &lt;&lt; ExponentBits) + ScalarI(MantissaBits - 1)));  // 278\n  const PacketI bias = pset1&lt;PacketI&gt;((ScalarI(1) &lt;&lt; (ExponentBits - 1)) - ScalarI(1));                         // 127\n  const PacketI e = pcast&lt;Packet, PacketI&gt;(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));\n  PacketI b = parithmetic_shift_right&lt;2&gt;(e);                                          // floor(e/4);\n  Packet c = preinterpret&lt;Packet&gt;(plogical_shift_left&lt;MantissaBits&gt;(padd(b, bias)));  // 2^b\n  Packet out = pmul(pmul(pmul(a, c), c), c);                                          // a * 2^(3b)\n  b = pnmadd(pset1&lt;PacketI&gt;(3), b, e);                                                // e - 3b\n  c = preinterpret&lt;Packet&gt;(plogical_shift_left&lt;MantissaBits&gt;(padd(b, bias)));         // 2^(e-3*b)\n  out = pmul(out, c);\n  return out;\n}\n\n// Explicitly multiplies\n//    a * (2^e)\n// clamping e to the range\n// [NumTraits&lt;Scalar&gt;::min_exponent()-2, NumTraits&lt;Scalar&gt;::max_exponent()]\n//\n// This is approx 7x faster than pldexp_impl, but will prematurely over/underflow\n// if 2^e doesn&#x27;t fit into a normal floating-point Scalar.\n//\n// Assumes IEEE floating point format\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Packet pldexp_fast(const Packet&amp; a, const Packet&amp; exponent) {\n  typedef typename unpacket_traits&lt;Packet&gt;::integer_packet PacketI;\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename unpacket_traits&lt;PacketI&gt;::type ScalarI;\n  static constexpr int TotalBits = sizeof(Scalar) * CHAR_BIT, MantissaBits = numext::numeric_limits&lt;Scalar&gt;::digits - 1,\n                       ExponentBits = TotalBits - MantissaBits - 1;\n\n  const Packet bias = pset1&lt;Packet&gt;(Scalar((ScalarI(1) &lt;&lt; (ExponentBits - 1)) - ScalarI(1)));  // 127\n  const Packet limit = pset1&lt;Packet&gt;(Scalar((ScalarI(1) &lt;&lt; ExponentBits) - ScalarI(1)));       // 255\n  // restrict biased exponent between 0 and 255 for float.\n  const PacketI e = pcast&lt;Packet, PacketI&gt;(pmin(pmax(padd(exponent, bias), pzero(limit)), limit));  // exponent + 127\n  // return a * (2^e)\n  return pmul(a, preinterpret&lt;Packet&gt;(plogical_shift_left&lt;MantissaBits&gt;(e)));\n}\n\n// Natural or base 2 logarithm.\n// Computes log(x) as log(2^e * m) = C*e + log(m), where the constant C =log(2)\n// and m is in the range [sqrt(1/2),sqrt(2)). In this range, the logarithm can\n// be easily approximated by a polynomial centered on m=1 for stability.\n// TODO(gonnet): Further reduce the interval allowing for lower-degree\n//               polynomial interpolants -&gt; ... -&gt; profit!\ntemplate &lt;typename Packet, bool base2&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_impl_float(const Packet _x) {\n  const Packet cst_1 = pset1&lt;Packet&gt;(1.0f);\n  const Packet cst_minus_inf = pset1frombits&lt;Packet&gt;(static_cast&lt;Eigen::numext::uint32_t&gt;(0xff800000u));\n  const Packet cst_pos_inf = pset1frombits&lt;Packet&gt;(static_cast&lt;Eigen::numext::uint32_t&gt;(0x7f800000u));\n\n  const Packet cst_cephes_SQRTHF = pset1&lt;Packet&gt;(0.707106781186547524f);\n  Packet e, x;\n  // extract significant in the range [0.5,1) and exponent\n  x = pfrexp(_x, e);\n\n  // part2: Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))\n  // and shift by -1. The values are then centered around 0, which improves\n  // the stability of the polynomial evaluation.\n  //   if( x &lt; SQRTHF ) {\n  //     e -= 1;\n  //     x = x + x - 1.0;\n  //   } else { x = x - 1.0; }\n  Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);\n  Packet tmp = pand(x, mask);\n  x = psub(x, cst_1);\n  e = psub(e, pand(cst_1, mask));\n  x = padd(x, tmp);\n\n  // Polynomial coefficients for rational r(x) = p(x)/q(x)\n  // approximating log(1+x) on [sqrt(0.5)-1;sqrt(2)-1].\n  constexpr float alpha[] = {0.18256296349849254f, 1.0000000190281063f, 1.0000000190281136f};\n  constexpr float beta[] = {0.049616247954120038f, 0.59923249590823520f, 1.4999999999999927f, 1.0f};\n\n  Packet p = ppolevl&lt;Packet, 2&gt;::run(x, alpha);\n  p = pmul(x, p);\n  Packet q = ppolevl&lt;Packet, 3&gt;::run(x, beta);\n  x = pdiv(p, q);\n\n  // Add the logarithm of the exponent back to the result of the interpolation.\n  if (base2) {\n    const Packet cst_log2e = pset1&lt;Packet&gt;(static_cast&lt;float&gt;(EIGEN_LOG2E));\n    x = pmadd(x, cst_log2e, e);\n  } else {\n    const Packet cst_ln2 = pset1&lt;Packet&gt;(static_cast&lt;float&gt;(EIGEN_LN2));\n    x = pmadd(e, cst_ln2, x);\n  }\n\n  Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));\n  Packet iszero_mask = pcmp_eq(_x, pzero(_x));\n  Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);\n  // Filter out invalid inputs, i.e.:\n  //  - negative arg will be NAN\n  //  - 0 will be -INF\n  //  - +INF will be +INF\n  return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_float(const Packet _x) {\n  return plog_impl_float&lt;Packet, /* base2 */ false&gt;(_x);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_float(const Packet _x) {\n  return plog_impl_float&lt;Packet, /* base2 */ true&gt;(_x);\n}\n\n/* Returns the base e (2.718...) or base 2 logarithm of x.\n * The argument is separated into its exponent and fractional parts.\n * The logarithm of the fraction in the interval [sqrt(1/2), sqrt(2)],\n * is approximated by\n *\n *     log(1+x) = x - 0.5 x**2 + x**3 P(x)/Q(x).\n *\n * for more detail see: http://www.netlib.org/cephes/\n */\ntemplate &lt;typename Packet, bool base2&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_impl_double(const Packet _x) {\n  Packet x = _x;\n\n  const Packet cst_1 = pset1&lt;Packet&gt;(1.0);\n  const Packet cst_neg_half = pset1&lt;Packet&gt;(-0.5);\n  const Packet cst_minus_inf = pset1frombits&lt;Packet&gt;(static_cast&lt;uint64_t&gt;(0xfff0000000000000ull));\n  const Packet cst_pos_inf = pset1frombits&lt;Packet&gt;(static_cast&lt;uint64_t&gt;(0x7ff0000000000000ull));\n\n  // Polynomial Coefficients for log(1+x) = x - x**2/2 + x**3 P(x)/Q(x)\n  //                             1/sqrt(2) &lt;= x &lt; sqrt(2)\n  const Packet cst_cephes_SQRTHF = pset1&lt;Packet&gt;(0.70710678118654752440E0);\n  const Packet cst_cephes_log_p0 = pset1&lt;Packet&gt;(1.01875663804580931796E-4);\n  const Packet cst_cephes_log_p1 = pset1&lt;Packet&gt;(4.97494994976747001425E-1);\n  const Packet cst_cephes_log_p2 = pset1&lt;Packet&gt;(4.70579119878881725854E0);\n  const Packet cst_cephes_log_p3 = pset1&lt;Packet&gt;(1.44989225341610930846E1);\n  const Packet cst_cephes_log_p4 = pset1&lt;Packet&gt;(1.79368678507819816313E1);\n  const Packet cst_cephes_log_p5 = pset1&lt;Packet&gt;(7.70838733755885391666E0);\n\n  const Packet cst_cephes_log_q0 = pset1&lt;Packet&gt;(1.0);\n  const Packet cst_cephes_log_q1 = pset1&lt;Packet&gt;(1.12873587189167450590E1);\n  const Packet cst_cephes_log_q2 = pset1&lt;Packet&gt;(4.52279145837532221105E1);\n  const Packet cst_cephes_log_q3 = pset1&lt;Packet&gt;(8.29875266912776603211E1);\n  const Packet cst_cephes_log_q4 = pset1&lt;Packet&gt;(7.11544750618563894466E1);\n  const Packet cst_cephes_log_q5 = pset1&lt;Packet&gt;(2.31251620126765340583E1);\n\n  Packet e;\n  // extract significant in the range [0.5,1) and exponent\n  x = pfrexp(x, e);\n\n  // Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))\n  // and shift by -1. The values are then centered around 0, which improves\n  // the stability of the polynomial evaluation.\n  //   if( x &lt; SQRTHF ) {\n  //     e -= 1;\n  //     x = x + x - 1.0;\n  //   } else { x = x - 1.0; }\n  Packet mask = pcmp_lt(x, cst_cephes_SQRTHF);\n  Packet tmp = pand(x, mask);\n  x = psub(x, cst_1);\n  e = psub(e, pand(cst_1, mask));\n  x = padd(x, tmp);\n\n  Packet x2 = pmul(x, x);\n  Packet x3 = pmul(x2, x);\n\n  // Evaluate the polynomial approximant , probably to improve instruction-level parallelism.\n  // y = x - 0.5*x^2 + x^3 * polevl( x, P, 5 ) / p1evl( x, Q, 5 ) );\n  Packet y, y1, y_;\n  y = pmadd(cst_cephes_log_p0, x, cst_cephes_log_p1);\n  y1 = pmadd(cst_cephes_log_p3, x, cst_cephes_log_p4);\n  y = pmadd(y, x, cst_cephes_log_p2);\n  y1 = pmadd(y1, x, cst_cephes_log_p5);\n  y_ = pmadd(y, x3, y1);\n\n  y = pmadd(cst_cephes_log_q0, x, cst_cephes_log_q1);\n  y1 = pmadd(cst_cephes_log_q3, x, cst_cephes_log_q4);\n  y = pmadd(y, x, cst_cephes_log_q2);\n  y1 = pmadd(y1, x, cst_cephes_log_q5);\n  y = pmadd(y, x3, y1);\n\n  y_ = pmul(y_, x3);\n  y = pdiv(y_, y);\n\n  y = pmadd(cst_neg_half, x2, y);\n  x = padd(x, y);\n\n  // Add the logarithm of the exponent back to the result of the interpolation.\n  if (base2) {\n    const Packet cst_log2e = pset1&lt;Packet&gt;(static_cast&lt;double&gt;(EIGEN_LOG2E));\n    x = pmadd(x, cst_log2e, e);\n  } else {\n    const Packet cst_ln2 = pset1&lt;Packet&gt;(static_cast&lt;double&gt;(EIGEN_LN2));\n    x = pmadd(e, cst_ln2, x);\n  }\n\n  Packet invalid_mask = pcmp_lt_or_nan(_x, pzero(_x));\n  Packet iszero_mask = pcmp_eq(_x, pzero(_x));\n  Packet pos_inf_mask = pcmp_eq(_x, cst_pos_inf);\n  // Filter out invalid inputs, i.e.:\n  //  - negative arg will be NAN\n  //  - 0 will be -INF\n  //  - +INF will be +INF\n  return pselect(iszero_mask, cst_minus_inf, por(pselect(pos_inf_mask, cst_pos_inf, x), invalid_mask));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_double(const Packet _x) {\n  return plog_impl_double&lt;Packet, /* base2 */ false&gt;(_x);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2_double(const Packet _x) {\n  return plog_impl_double&lt;Packet, /* base2 */ true&gt;(_x);\n}\n\n/** \\internal \\returns log(1 + x) computed using W. Kahan&#x27;s formula.\n    See: http://www.plunk.org/~hatch/rightway.php\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_log1p(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type ScalarType;\n  const Packet one = pset1&lt;Packet&gt;(ScalarType(1));\n  Packet xp1 = padd(x, one);\n  Packet small_mask = pcmp_eq(xp1, one);\n  Packet log1 = plog(xp1);\n  Packet inf_mask = pcmp_eq(xp1, log1);\n  Packet log_large = pmul(x, pdiv(log1, psub(xp1, one)));\n  return pselect(por(small_mask, inf_mask), x, log_large);\n}\n\n/** \\internal \\returns exp(x)-1 computed using W. Kahan&#x27;s formula.\n    See: http://www.plunk.org/~hatch/rightway.php\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_expm1(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type ScalarType;\n  const Packet one = pset1&lt;Packet&gt;(ScalarType(1));\n  const Packet neg_one = pset1&lt;Packet&gt;(ScalarType(-1));\n  Packet u = pexp(x);\n  Packet one_mask = pcmp_eq(u, one);\n  Packet u_minus_one = psub(u, one);\n  Packet neg_one_mask = pcmp_eq(u_minus_one, neg_one);\n  Packet logu = plog(u);\n  // The following comparison is to catch the case where\n  // exp(x) = +inf. It is written in this way to avoid having\n  // to form the constant +inf, which depends on the packet\n  // type.\n  Packet pos_inf_mask = pcmp_eq(logu, u);\n  Packet expm1 = pmul(u_minus_one, pdiv(x, logu));\n  expm1 = pselect(pos_inf_mask, u, expm1);\n  return pselect(one_mask, x, pselect(neg_one_mask, neg_one, expm1));\n}\n\n// Exponential function. Works by writing &quot;x = m*log(2) + r&quot; where\n// &quot;m = floor(x/log(2)+1/2)&quot; and &quot;r&quot; is the remainder. The result is then\n// &quot;exp(x) = 2^m*exp(r)&quot; where exp(r) is in the range [-1,1).\n// exp(r) is computed using a 6th order minimax polynomial approximation.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_float(const Packet _x) {\n  const Packet cst_zero = pset1&lt;Packet&gt;(0.0f);\n  const Packet cst_one = pset1&lt;Packet&gt;(1.0f);\n  const Packet cst_half = pset1&lt;Packet&gt;(0.5f);\n  const Packet cst_exp_hi = pset1&lt;Packet&gt;(88.723f);\n  const Packet cst_exp_lo = pset1&lt;Packet&gt;(-104.f);\n  const Packet cst_pldexp_threshold = pset1&lt;Packet&gt;(87.0);\n\n  const Packet cst_cephes_LOG2EF = pset1&lt;Packet&gt;(1.44269504088896341f);\n  const Packet cst_p2 = pset1&lt;Packet&gt;(0.49999988079071044921875f);\n  const Packet cst_p3 = pset1&lt;Packet&gt;(0.16666518151760101318359375f);\n  const Packet cst_p4 = pset1&lt;Packet&gt;(4.166965186595916748046875e-2f);\n  const Packet cst_p5 = pset1&lt;Packet&gt;(8.36894474923610687255859375e-3f);\n  const Packet cst_p6 = pset1&lt;Packet&gt;(1.37449637986719608306884765625e-3f);\n\n  // Clamp x.\n  Packet zero_mask = pcmp_lt(_x, cst_exp_lo);\n  Packet x = pmin(_x, cst_exp_hi);\n\n  // Express exp(x) as exp(m*ln(2) + r), start by extracting\n  // m = floor(x/ln(2) + 0.5).\n  Packet m = pfloor(pmadd(x, cst_cephes_LOG2EF, cst_half));\n\n  // Get r = x - m*ln(2). If no FMA instructions are available, m*ln(2) is\n  // subtracted out in two parts, m*C1+m*C2 = m*ln(2), to avoid accumulating\n  // truncation errors.\n  const Packet cst_cephes_exp_C1 = pset1&lt;Packet&gt;(-0.693359375f);\n  const Packet cst_cephes_exp_C2 = pset1&lt;Packet&gt;(2.12194440e-4f);\n  Packet r = pmadd(m, cst_cephes_exp_C1, x);\n  r = pmadd(m, cst_cephes_exp_C2, r);\n\n  // Evaluate the 6th order polynomial approximation to exp(r)\n  // with r in the interval [-ln(2)/2;ln(2)/2].\n  const Packet r2 = pmul(r, r);\n  Packet p_even = pmadd(r2, cst_p6, cst_p4);\n  const Packet p_odd = pmadd(r2, cst_p5, cst_p3);\n  p_even = pmadd(r2, p_even, cst_p2);\n  const Packet p_low = padd(r, cst_one);\n  Packet y = pmadd(r, p_odd, p_even);\n  y = pmadd(r2, y, p_low);\n\n  // Return 2^m * exp(r).\n  const Packet fast_pldexp_unsafe = pcmp_lt(cst_pldexp_threshold, pabs(x));\n  if (!predux_any(fast_pldexp_unsafe)) {\n    // For |x| &lt;= 87, we know the result is not zero or inf, and we can safely use\n    // the fast version of pldexp.\n    return pmax(pldexp_fast(y, m), _x);\n  }\n  return pselect(zero_mask, cst_zero, pmax(pldexp(y, m), _x));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_double(const Packet _x) {\n  Packet x = _x;\n  const Packet cst_zero = pset1&lt;Packet&gt;(0.0);\n  const Packet cst_1 = pset1&lt;Packet&gt;(1.0);\n  const Packet cst_2 = pset1&lt;Packet&gt;(2.0);\n  const Packet cst_half = pset1&lt;Packet&gt;(0.5);\n\n  const Packet cst_exp_hi = pset1&lt;Packet&gt;(709.784);\n  const Packet cst_exp_lo = pset1&lt;Packet&gt;(-745.519);\n  const Packet cst_pldexp_threshold = pset1&lt;Packet&gt;(708.0);\n  const Packet cst_cephes_LOG2EF = pset1&lt;Packet&gt;(1.4426950408889634073599);\n  const Packet cst_cephes_exp_p0 = pset1&lt;Packet&gt;(1.26177193074810590878e-4);\n  const Packet cst_cephes_exp_p1 = pset1&lt;Packet&gt;(3.02994407707441961300e-2);\n  const Packet cst_cephes_exp_p2 = pset1&lt;Packet&gt;(9.99999999999999999910e-1);\n  const Packet cst_cephes_exp_q0 = pset1&lt;Packet&gt;(3.00198505138664455042e-6);\n  const Packet cst_cephes_exp_q1 = pset1&lt;Packet&gt;(2.52448340349684104192e-3);\n  const Packet cst_cephes_exp_q2 = pset1&lt;Packet&gt;(2.27265548208155028766e-1);\n  const Packet cst_cephes_exp_q3 = pset1&lt;Packet&gt;(2.00000000000000000009e0);\n  const Packet cst_cephes_exp_C1 = pset1&lt;Packet&gt;(0.693145751953125);\n  const Packet cst_cephes_exp_C2 = pset1&lt;Packet&gt;(1.42860682030941723212e-6);\n\n  Packet tmp, fx;\n\n  // clamp x\n  Packet zero_mask = pcmp_lt(_x, cst_exp_lo);\n  x = pmin(x, cst_exp_hi);\n  // Express exp(x) as exp(g + n*log(2)).\n  fx = pmadd(cst_cephes_LOG2EF, x, cst_half);\n\n  // Get the integer modulus of log(2), i.e. the &quot;n&quot; described above.\n  fx = pfloor(fx);\n\n  // Get the remainder modulo log(2), i.e. the &quot;g&quot; described above. Subtract\n  // n*log(2) out in two steps, i.e. n*C1 + n*C2, C1+C2=log2 to get the last\n  // digits right.\n  tmp = pmul(fx, cst_cephes_exp_C1);\n  Packet z = pmul(fx, cst_cephes_exp_C2);\n  x = psub(x, tmp);\n  x = psub(x, z);\n\n  Packet x2 = pmul(x, x);\n\n  // Evaluate the numerator polynomial of the rational interpolant.\n  Packet px = cst_cephes_exp_p0;\n  px = pmadd(px, x2, cst_cephes_exp_p1);\n  px = pmadd(px, x2, cst_cephes_exp_p2);\n  px = pmul(px, x);\n\n  // Evaluate the denominator polynomial of the rational interpolant.\n  Packet qx = cst_cephes_exp_q0;\n  qx = pmadd(qx, x2, cst_cephes_exp_q1);\n  qx = pmadd(qx, x2, cst_cephes_exp_q2);\n  qx = pmadd(qx, x2, cst_cephes_exp_q3);\n\n  // I don&#x27;t really get this bit, copied from the SSE2 routines, so...\n  // TODO(gonnet): Figure out what is going on here, perhaps find a better\n  // rational interpolant?\n  x = pdiv(px, psub(qx, px));\n  x = pmadd(cst_2, x, cst_1);\n\n  // Construct the result 2^n * exp(g) = e * x. The max is used to catch\n  // non-finite values in the input.\n  const Packet fast_pldexp_unsafe = pcmp_lt(cst_pldexp_threshold, pabs(_x));\n  if (!predux_any(fast_pldexp_unsafe)) {\n    // For |x| &lt;= 708, we know the result is not zero or inf, and we can safely use\n    // the fast version of pldexp.\n    return pmax(pldexp_fast(x, fx), _x);\n  }\n  return pselect(zero_mask, cst_zero, pmax(pldexp(x, fx), _x));\n}\n\n// The following code is inspired by the following stack-overflow answer:\n//   https://stackoverflow.com/questions/30463616/payne-hanek-algorithm-implementation-in-c/30465751#30465751\n// It has been largely optimized:\n//  - By-pass calls to frexp.\n//  - Aligned loads of required 96 bits of 2/pi. This is accomplished by\n//    (1) balancing the mantissa and exponent to the required bits of 2/pi are\n//    aligned on 8-bits, and (2) replicating the storage of the bits of 2/pi.\n//  - Avoid a branch in rounding and extraction of the remaining fractional part.\n// Overall, I measured a speed up higher than x2 on x86-64.\ninline float trig_reduce_huge(float xf, Eigen::numext::int32_t* quadrant) {\n  using Eigen::numext::int32_t;\n  using Eigen::numext::int64_t;\n  using Eigen::numext::uint32_t;\n  using Eigen::numext::uint64_t;\n\n  const double pio2_62 = 3.4061215800865545e-19;     // pi/2 * 2^-62\n  const uint64_t zero_dot_five = uint64_t(1) &lt;&lt; 61;  // 0.5 in 2.62-bit fixed-point format\n\n  // 192 bits of 2/pi for Payne-Hanek reduction\n  // Bits are introduced by packet of 8 to enable aligned reads.\n  static const uint32_t two_over_pi[] = {\n      0x00000028, 0x000028be, 0x0028be60, 0x28be60db, 0xbe60db93, 0x60db9391, 0xdb939105, 0x9391054a, 0x91054a7f,\n      0x054a7f09, 0x4a7f09d5, 0x7f09d5f4, 0x09d5f47d, 0xd5f47d4d, 0xf47d4d37, 0x7d4d3770, 0x4d377036, 0x377036d8,\n      0x7036d8a5, 0x36d8a566, 0xd8a5664f, 0xa5664f10, 0x664f10e4, 0x4f10e410, 0x10e41000, 0xe4100000};\n\n  uint32_t xi = numext::bit_cast&lt;uint32_t&gt;(xf);\n  // Below, -118 = -126 + 8.\n  //   -126 is to get the exponent,\n  //   +8 is to enable alignment of 2/pi&#x27;s bits on 8 bits.\n  // This is possible because the fractional part of x as only 24 meaningful bits.\n  uint32_t e = (xi &gt;&gt; 23) - 118;\n  // Extract the mantissa and shift it to align it wrt the exponent\n  xi = ((xi &amp; 0x007fffffu) | 0x00800000u) &lt;&lt; (e &amp; 0x7);\n\n  uint32_t i = e &gt;&gt; 3;\n  uint32_t twoopi_1 = two_over_pi[i - 1];\n  uint32_t twoopi_2 = two_over_pi[i + 3];\n  uint32_t twoopi_3 = two_over_pi[i + 7];\n\n  // Compute x * 2/pi in 2.62-bit fixed-point format.\n  uint64_t p;\n  p = uint64_t(xi) * twoopi_3;\n  p = uint64_t(xi) * twoopi_2 + (p &gt;&gt; 32);\n  p = (uint64_t(xi * twoopi_1) &lt;&lt; 32) + p;\n\n  // Round to nearest: add 0.5 and extract integral part.\n  uint64_t q = (p + zero_dot_five) &gt;&gt; 62;\n  *quadrant = int(q);\n  // Now it remains to compute &quot;r = x - q*pi/2&quot; with high accuracy,\n  // since we have p=x/(pi/2) with high accuracy, we can more efficiently compute r as:\n  //   r = (p-q)*pi/2,\n  // where the product can be be carried out with sufficient accuracy using double precision.\n  p -= q &lt;&lt; 62;\n  return float(double(int64_t(p)) * pio2_62);\n}\n\ntemplate &lt;bool ComputeSine, typename Packet, bool ComputeBoth = false&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS\n#if EIGEN_COMP_GNUC_STRICT\n    __attribute__((optimize(&quot;-fno-unsafe-math-optimizations&quot;)))\n#endif\n    Packet\n    psincos_float(const Packet&amp; _x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::integer_packet PacketI;\n\n  const Packet cst_2oPI = pset1&lt;Packet&gt;(0.636619746685028076171875f);  // 2/PI\n  const Packet cst_rounding_magic = pset1&lt;Packet&gt;(12582912);           // 2^23 for rounding\n  const PacketI csti_1 = pset1&lt;PacketI&gt;(1);\n  const Packet cst_sign_mask = pset1frombits&lt;Packet&gt;(static_cast&lt;Eigen::numext::uint32_t&gt;(0x80000000u));\n\n  Packet x = pabs(_x);\n\n  // Scale x by 2/Pi to find x&#x27;s octant.\n  Packet y = pmul(x, cst_2oPI);\n\n  // Rounding trick to find nearest integer:\n  Packet y_round = padd(y, cst_rounding_magic);\n  EIGEN_OPTIMIZATION_BARRIER(y_round)\n  PacketI y_int = preinterpret&lt;PacketI&gt;(y_round);  // last 23 digits represent integer (if abs(x)&lt;2^24)\n  y = psub(y_round, cst_rounding_magic);           // nearest integer to x * (2/pi)\n\n// Subtract y * Pi/2 to reduce x to the interval -Pi/4 &lt;= x &lt;= +Pi/4\n// using &quot;Extended precision modular arithmetic&quot;\n#if defined(EIGEN_VECTORIZE_FMA)\n  // This version requires true FMA for high accuracy.\n  // It provides a max error of 1ULP up to (with absolute_error &lt; 5.9605e-08):\n  const float huge_th = ComputeSine ? 117435.992f : 71476.0625f;\n  x = pmadd(y, pset1&lt;Packet&gt;(-1.57079601287841796875f), x);\n  x = pmadd(y, pset1&lt;Packet&gt;(-3.1391647326017846353352069854736328125e-07f), x);\n  x = pmadd(y, pset1&lt;Packet&gt;(-5.390302529957764765544681040410068817436695098876953125e-15f), x);\n#else\n  // Without true FMA, the previous set of coefficients maintain 1ULP accuracy\n  // up to x&lt;15.7 (for sin), but accuracy is immediately lost for x&gt;15.7.\n  // We thus use one more iteration to maintain 2ULPs up to reasonably large inputs.\n\n  // The following set of coefficients maintain 1ULP up to 9.43 and 14.16 for sin and cos respectively.\n  // and 2 ULP up to:\n  const float huge_th = ComputeSine ? 25966.f : 18838.f;\n  x = pmadd(y, pset1&lt;Packet&gt;(-1.5703125), x);  // = 0xbfc90000\n  EIGEN_OPTIMIZATION_BARRIER(x)\n  x = pmadd(y, pset1&lt;Packet&gt;(-0.000483989715576171875), x);  // = 0xb9fdc000\n  EIGEN_OPTIMIZATION_BARRIER(x)\n  x = pmadd(y, pset1&lt;Packet&gt;(1.62865035235881805419921875e-07), x);                      // = 0x342ee000\n  x = pmadd(y, pset1&lt;Packet&gt;(5.5644315544167710640977020375430583953857421875e-11), x);  // = 0x2e74b9ee\n\n// For the record, the following set of coefficients maintain 2ULP up\n// to a slightly larger range:\n// const float huge_th = ComputeSine ? 51981.f : 39086.125f;\n// but it slightly fails to maintain 1ULP for two values of sin below pi.\n// x = pmadd(y, pset1&lt;Packet&gt;(-3.140625/2.), x);\n// x = pmadd(y, pset1&lt;Packet&gt;(-0.00048351287841796875), x);\n// x = pmadd(y, pset1&lt;Packet&gt;(-3.13855707645416259765625e-07), x);\n// x = pmadd(y, pset1&lt;Packet&gt;(-6.0771006282767103812147979624569416046142578125e-11), x);\n\n// For the record, with only 3 iterations it is possible to maintain\n// 1 ULP up to 3PI (maybe more) and 2ULP up to 255.\n// The coefficients are: 0xbfc90f80, 0xb7354480, 0x2e74b9ee\n#endif\n\n  if (predux_any(pcmp_le(pset1&lt;Packet&gt;(huge_th), pabs(_x)))) {\n    const int PacketSize = unpacket_traits&lt;Packet&gt;::size;\n    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) float vals[PacketSize];\n    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) float x_cpy[PacketSize];\n    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Eigen::numext::int32_t y_int2[PacketSize];\n    pstoreu(vals, pabs(_x));\n    pstoreu(x_cpy, x);\n    pstoreu(y_int2, y_int);\n    for (int k = 0; k &lt; PacketSize; ++k) {\n      float val = vals[k];\n      if (val &gt;= huge_th &amp;&amp; (numext::isfinite)(val)) x_cpy[k] = trig_reduce_huge(val, &amp;y_int2[k]);\n    }\n    x = ploadu&lt;Packet&gt;(x_cpy);\n    y_int = ploadu&lt;PacketI&gt;(y_int2);\n  }\n\n  // Compute the sign to apply to the polynomial.\n  // sin: sign = second_bit(y_int) xor signbit(_x)\n  // cos: sign = second_bit(y_int+1)\n  Packet sign_bit = ComputeSine ? pxor(_x, preinterpret&lt;Packet&gt;(plogical_shift_left&lt;30&gt;(y_int)))\n                                : preinterpret&lt;Packet&gt;(plogical_shift_left&lt;30&gt;(padd(y_int, csti_1)));\n  sign_bit = pand(sign_bit, cst_sign_mask);  // clear all but left most bit\n\n  // Get the polynomial selection mask from the second bit of y_int\n  // We&#x27;ll calculate both (sin and cos) polynomials and then select from the two.\n  Packet poly_mask = preinterpret&lt;Packet&gt;(pcmp_eq(pand(y_int, csti_1), pzero(y_int)));\n\n  Packet x2 = pmul(x, x);\n\n  // Evaluate the cos(x) polynomial. (-Pi/4 &lt;= x &lt;= Pi/4)\n  Packet y1 = pset1&lt;Packet&gt;(2.4372266125283204019069671630859375e-05f);\n  y1 = pmadd(y1, x2, pset1&lt;Packet&gt;(-0.00138865201734006404876708984375f));\n  y1 = pmadd(y1, x2, pset1&lt;Packet&gt;(0.041666619479656219482421875f));\n  y1 = pmadd(y1, x2, pset1&lt;Packet&gt;(-0.5f));\n  y1 = pmadd(y1, x2, pset1&lt;Packet&gt;(1.f));\n\n  // Evaluate the sin(x) polynomial. (Pi/4 &lt;= x &lt;= Pi/4)\n  // octave/matlab code to compute those coefficients:\n  //    x = (0:0.0001:pi/4)&#x27;;\n  //    A = [x.^3 x.^5 x.^7];\n  //    w = ((1.-(x/(pi/4)).^2).^5)*2000+1;         # weights trading relative accuracy\n  //    c = (A&#x27;*diag(w)*A)\\(A&#x27;*diag(w)*(sin(x)-x)); # weighted LS, linear coeff forced to 1\n  //    printf(&#x27;%.64f\\n %.64f\\n%.64f\\n&#x27;, c(3), c(2), c(1))\n  //\n  Packet y2 = pset1&lt;Packet&gt;(-0.0001959234114083702898469196984621021329076029360294342041015625f);\n  y2 = pmadd(y2, x2, pset1&lt;Packet&gt;(0.0083326873655616851693794799871284340042620897293090820312500000f));\n  y2 = pmadd(y2, x2, pset1&lt;Packet&gt;(-0.1666666203982298255503735617821803316473960876464843750000000000f));\n  y2 = pmul(y2, x2);\n  y2 = pmadd(y2, x, x);\n\n  // Select the correct result from the two polynomials.\n  if (ComputeBoth) {\n    Packet peven = peven_mask(x);\n    Packet ysin = pselect(poly_mask, y2, y1);\n    Packet ycos = pselect(poly_mask, y1, y2);\n    Packet sign_bit_sin = pxor(_x, preinterpret&lt;Packet&gt;(plogical_shift_left&lt;30&gt;(y_int)));\n    Packet sign_bit_cos = preinterpret&lt;Packet&gt;(plogical_shift_left&lt;30&gt;(padd(y_int, csti_1)));\n    sign_bit_sin = pand(sign_bit_sin, cst_sign_mask);  // clear all but left most bit\n    sign_bit_cos = pand(sign_bit_cos, cst_sign_mask);  // clear all but left most bit\n    y = pselect(peven, pxor(ysin, sign_bit_sin), pxor(ycos, sign_bit_cos));\n  } else {\n    y = ComputeSine ? pselect(poly_mask, y2, y1) : pselect(poly_mask, y1, y2);\n    y = pxor(y, sign_bit);\n  }\n  // Update the sign and filter huge inputs\n  return y;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_float(const Packet&amp; x) {\n  return psincos_float&lt;true&gt;(x);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_float(const Packet&amp; x) {\n  return psincos_float&lt;false&gt;(x);\n}\n\n// Trigonometric argument reduction for double for inputs smaller than 15.\n// Reduces trigonometric arguments for double inputs where x &lt; 15. Given an argument x and its corresponding quadrant\n// count n, the function computes and returns the reduced argument t such that x = n * pi/2 + t.\ntemplate &lt;typename Packet&gt;\nPacket trig_reduce_small_double(const Packet&amp; x, const Packet&amp; q) {\n  // Pi/2 split into 2 values\n  const Packet cst_pio2_a = pset1&lt;Packet&gt;(-1.570796325802803);\n  const Packet cst_pio2_b = pset1&lt;Packet&gt;(-9.920935184482005e-10);\n\n  Packet t;\n  t = pmadd(cst_pio2_a, q, x);\n  t = pmadd(cst_pio2_b, q, t);\n  return t;\n}\n\n// Trigonometric argument reduction for double for inputs smaller than 1e14.\n// Reduces trigonometric arguments for double inputs where x &lt; 1e14. Given an argument x and its corresponding quadrant\n// count n, the function computes and returns the reduced argument t such that x = n * pi/2 + t.\ntemplate &lt;typename Packet&gt;\nPacket trig_reduce_medium_double(const Packet&amp; x, const Packet&amp; q_high, const Packet&amp; q_low) {\n  // Pi/2 split into 4 values\n  const Packet cst_pio2_a = pset1&lt;Packet&gt;(-1.570796325802803);\n  const Packet cst_pio2_b = pset1&lt;Packet&gt;(-9.920935184482005e-10);\n  const Packet cst_pio2_c = pset1&lt;Packet&gt;(-6.123234014771656e-17);\n  const Packet cst_pio2_d = pset1&lt;Packet&gt;(1.903488962019325e-25);\n\n  Packet t;\n  t = pmadd(cst_pio2_a, q_high, x);\n  t = pmadd(cst_pio2_a, q_low, t);\n  t = pmadd(cst_pio2_b, q_high, t);\n  t = pmadd(cst_pio2_b, q_low, t);\n  t = pmadd(cst_pio2_c, q_high, t);\n  t = pmadd(cst_pio2_c, q_low, t);\n  t = pmadd(cst_pio2_d, padd(q_low, q_high), t);\n  return t;\n}\n\ntemplate &lt;bool ComputeSine, typename Packet, bool ComputeBoth = false&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS\n#if EIGEN_COMP_GNUC_STRICT\n    __attribute__((optimize(&quot;-fno-unsafe-math-optimizations&quot;)))\n#endif\n    Packet\n    psincos_double(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::integer_packet PacketI;\n  typedef typename unpacket_traits&lt;PacketI&gt;::type ScalarI;\n\n  const Packet cst_sign_mask = pset1frombits&lt;Packet&gt;(static_cast&lt;Eigen::numext::uint64_t&gt;(0x8000000000000000u));\n\n  // If the argument is smaller than this value, use a simpler argument reduction\n  const double small_th = 15;\n  // If the argument is bigger than this value, use the non-vectorized std version\n  const double huge_th = 1e14;\n\n  const Packet cst_2oPI = pset1&lt;Packet&gt;(0.63661977236758134307553505349006);  // 2/PI\n  // Integer Packet constants\n  const PacketI cst_one = pset1&lt;PacketI&gt;(ScalarI(1));\n  // Constant for splitting\n  const Packet cst_split = pset1&lt;Packet&gt;(1 &lt;&lt; 24);\n\n  Packet x_abs = pabs(x);\n\n  // Scale x by 2/Pi\n  PacketI q_int;\n  Packet s;\n\n  // TODO Implement huge angle argument reduction\n  if (EIGEN_PREDICT_FALSE(predux_any(pcmp_le(pset1&lt;Packet&gt;(small_th), x_abs)))) {\n    Packet q_high = pmul(pfloor(pmul(x_abs, pdiv(cst_2oPI, cst_split))), cst_split);\n    Packet q_low_noround = psub(pmul(x_abs, cst_2oPI), q_high);\n    q_int = pcast&lt;Packet, PacketI&gt;(padd(q_low_noround, pset1&lt;Packet&gt;(0.5)));\n    Packet q_low = pcast&lt;PacketI, Packet&gt;(q_int);\n    s = trig_reduce_medium_double(x_abs, q_high, q_low);\n  } else {\n    Packet qval_noround = pmul(x_abs, cst_2oPI);\n    q_int = pcast&lt;Packet, PacketI&gt;(padd(qval_noround, pset1&lt;Packet&gt;(0.5)));\n    Packet q = pcast&lt;PacketI, Packet&gt;(q_int);\n    s = trig_reduce_small_double(x_abs, q);\n  }\n\n  // All the upcoming approximating polynomials have even exponents\n  Packet ss = pmul(s, s);\n\n  // Pad\u00e9 approximant of cos(x)\n  // Assuring &lt; 1 ULP error on the interval [-pi/4, pi/4]\n  // cos(x) ~= (80737373*x^8 - 13853547000*x^6 + 727718024880*x^4 - 11275015752000*x^2 + 23594700729600)/(147173*x^8 +\n  // 39328920*x^6 + 5772800880*x^4 + 522334612800*x^2 + 23594700729600)\n  // MATLAB code to compute those coefficients:\n  //    syms x;\n  //    cosf = @(x) cos(x);\n  //    pade_cosf = pade(cosf(x), x, 0, &#x27;Order&#x27;, 8)\n  Packet sc1_num = pmadd(ss, pset1&lt;Packet&gt;(80737373), pset1&lt;Packet&gt;(-13853547000));\n  Packet sc2_num = pmadd(sc1_num, ss, pset1&lt;Packet&gt;(727718024880));\n  Packet sc3_num = pmadd(sc2_num, ss, pset1&lt;Packet&gt;(-11275015752000));\n  Packet sc4_num = pmadd(sc3_num, ss, pset1&lt;Packet&gt;(23594700729600));\n  Packet sc1_denum = pmadd(ss, pset1&lt;Packet&gt;(147173), pset1&lt;Packet&gt;(39328920));\n  Packet sc2_denum = pmadd(sc1_denum, ss, pset1&lt;Packet&gt;(5772800880));\n  Packet sc3_denum = pmadd(sc2_denum, ss, pset1&lt;Packet&gt;(522334612800));\n  Packet sc4_denum = pmadd(sc3_denum, ss, pset1&lt;Packet&gt;(23594700729600));\n  Packet scos = pdiv(sc4_num, sc4_denum);\n\n  // Pad\u00e9 approximant of sin(x)\n  // Assuring &lt; 1 ULP error on the interval [-pi/4, pi/4]\n  // sin(x) ~= (x*(4585922449*x^8 - 1066023933480*x^6 + 83284044283440*x^4 - 2303682236856000*x^2 +\n  // 15605159573203200))/(45*(1029037*x^8 + 345207016*x^6 + 61570292784*x^4 + 6603948711360*x^2 + 346781323848960))\n  // MATLAB code to compute those coefficients:\n  //    syms x;\n  //    sinf = @(x) sin(x);\n  //    pade_sinf = pade(sinf(x), x, 0, &#x27;Order&#x27;, 8, &#x27;OrderMode&#x27;, &#x27;relative&#x27;)\n  Packet ss1_num = pmadd(ss, pset1&lt;Packet&gt;(4585922449), pset1&lt;Packet&gt;(-1066023933480));\n  Packet ss2_num = pmadd(ss1_num, ss, pset1&lt;Packet&gt;(83284044283440));\n  Packet ss3_num = pmadd(ss2_num, ss, pset1&lt;Packet&gt;(-2303682236856000));\n  Packet ss4_num = pmadd(ss3_num, ss, pset1&lt;Packet&gt;(15605159573203200));\n  Packet ss1_denum = pmadd(ss, pset1&lt;Packet&gt;(1029037), pset1&lt;Packet&gt;(345207016));\n  Packet ss2_denum = pmadd(ss1_denum, ss, pset1&lt;Packet&gt;(61570292784));\n  Packet ss3_denum = pmadd(ss2_denum, ss, pset1&lt;Packet&gt;(6603948711360));\n  Packet ss4_denum = pmadd(ss3_denum, ss, pset1&lt;Packet&gt;(346781323848960));\n  Packet ssin = pdiv(pmul(s, ss4_num), pmul(pset1&lt;Packet&gt;(45), ss4_denum));\n\n  Packet poly_mask = preinterpret&lt;Packet&gt;(pcmp_eq(pand(q_int, cst_one), pzero(q_int)));\n\n  Packet sign_sin = pxor(x, preinterpret&lt;Packet&gt;(plogical_shift_left&lt;62&gt;(q_int)));\n  Packet sign_cos = preinterpret&lt;Packet&gt;(plogical_shift_left&lt;62&gt;(padd(q_int, cst_one)));\n  Packet sign_bit, sFinalRes;\n  if (ComputeBoth) {\n    Packet peven = peven_mask(x);\n    sign_bit = pselect((s), sign_sin, sign_cos);\n    sFinalRes = pselect(pxor(peven, poly_mask), ssin, scos);\n  } else {\n    sign_bit = ComputeSine ? sign_sin : sign_cos;\n    sFinalRes = ComputeSine ? pselect(poly_mask, ssin, scos) : pselect(poly_mask, scos, ssin);\n  }\n  sign_bit = pand(sign_bit, cst_sign_mask);  // clear all but left most bit\n  sFinalRes = pxor(sFinalRes, sign_bit);\n\n  // If the inputs values are higher than that a value that the argument reduction can currently address, compute them\n  // using std::sin and std::cos\n  // TODO Remove it when huge angle argument reduction is implemented\n  if (EIGEN_PREDICT_FALSE(predux_any(pcmp_le(pset1&lt;Packet&gt;(huge_th), x_abs)))) {\n    const int PacketSize = unpacket_traits&lt;Packet&gt;::size;\n    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) double sincos_vals[PacketSize];\n    EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) double x_cpy[PacketSize];\n    pstoreu(x_cpy, x);\n    pstoreu(sincos_vals, sFinalRes);\n    for (int k = 0; k &lt; PacketSize; ++k) {\n      double val = x_cpy[k];\n      if (std::abs(val) &gt; huge_th &amp;&amp; (numext::isfinite)(val)) {\n        if (ComputeBoth)\n          sincos_vals[k] = k % 2 == 0 ? std::sin(val) : std::cos(val);\n        else\n          sincos_vals[k] = ComputeSine ? std::sin(val) : std::cos(val);\n      }\n    }\n    sFinalRes = ploadu&lt;Packet&gt;(sincos_vals);\n  }\n  return sFinalRes;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin_double(const Packet&amp; x) {\n  return psincos_double&lt;true&gt;(x);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos_double(const Packet&amp; x) {\n  return psincos_double&lt;false&gt;(x);\n}\n\n// Generic implementation of acos(x).\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pacos_float(const Packet&amp; x_in) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static_assert(std::is_same&lt;Scalar, float&gt;::value, &quot;Scalar type must be float&quot;);\n\n  const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n  const Packet cst_pi = pset1&lt;Packet&gt;(Scalar(EIGEN_PI));\n  const Packet p6 = pset1&lt;Packet&gt;(Scalar(2.36423197202384471893310546875e-3));\n  const Packet p5 = pset1&lt;Packet&gt;(Scalar(-1.1368644423782825469970703125e-2));\n  const Packet p4 = pset1&lt;Packet&gt;(Scalar(2.717843465507030487060546875e-2));\n  const Packet p3 = pset1&lt;Packet&gt;(Scalar(-4.8969544470310211181640625e-2));\n  const Packet p2 = pset1&lt;Packet&gt;(Scalar(8.8804088532924652099609375e-2));\n  const Packet p1 = pset1&lt;Packet&gt;(Scalar(-0.214591205120086669921875));\n  const Packet p0 = pset1&lt;Packet&gt;(Scalar(1.57079637050628662109375));\n\n  // For x in [0:1], we approximate acos(x)/sqrt(1-x), which is a smooth\n  // function, by a 6&#x27;th order polynomial.\n  // For x in [-1:0) we use that acos(-x) = pi - acos(x).\n  const Packet neg_mask = psignbit(x_in);\n  const Packet abs_x = pabs(x_in);\n\n  // Evaluate the polynomial using Horner&#x27;s rule:\n  //   P(x) = p0 + x * (p1 +  x * (p2 + ... (p5 + x * p6)) ... ) .\n  // We evaluate even and odd terms independently to increase\n  // instruction level parallelism.\n  Packet x2 = pmul(x_in, x_in);\n  Packet p_even = pmadd(p6, x2, p4);\n  Packet p_odd = pmadd(p5, x2, p3);\n  p_even = pmadd(p_even, x2, p2);\n  p_odd = pmadd(p_odd, x2, p1);\n  p_even = pmadd(p_even, x2, p0);\n  Packet p = pmadd(p_odd, abs_x, p_even);\n\n  // The polynomial approximates acos(x)/sqrt(1-x), so\n  // multiply by sqrt(1-x) to get acos(x).\n  // Conveniently returns NaN for arguments outside [-1:1].\n  Packet denom = psqrt(psub(cst_one, abs_x));\n  Packet result = pmul(denom, p);\n  // Undo mapping for negative arguments.\n  return pselect(neg_mask, psub(cst_pi, result), result);\n}\n\n// Generic implementation of asin(x).\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pasin_float(const Packet&amp; x_in) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static_assert(std::is_same&lt;Scalar, float&gt;::value, &quot;Scalar type must be float&quot;);\n\n  constexpr float kPiOverTwo = static_cast&lt;float&gt;(EIGEN_PI / 2);\n\n  const Packet cst_half = pset1&lt;Packet&gt;(0.5f);\n  const Packet cst_one = pset1&lt;Packet&gt;(1.0f);\n  const Packet cst_two = pset1&lt;Packet&gt;(2.0f);\n  const Packet cst_pi_over_two = pset1&lt;Packet&gt;(kPiOverTwo);\n\n  const Packet abs_x = pabs(x_in);\n  const Packet sign_mask = pandnot(x_in, abs_x);\n  const Packet invalid_mask = pcmp_lt(cst_one, abs_x);\n\n  // For arguments |x| &gt; 0.5, we map x back to [0:0.5] using\n  // the transformation x_large = sqrt(0.5*(1-x)), and use the\n  // identity\n  //   asin(x) = pi/2 - 2 * asin( sqrt( 0.5 * (1 - x)))\n\n  const Packet x_large = psqrt(pnmadd(cst_half, abs_x, cst_half));\n  const Packet large_mask = pcmp_lt(cst_half, abs_x);\n  const Packet x = pselect(large_mask, x_large, abs_x);\n  const Packet x2 = pmul(x, x);\n\n  // For |x| &lt; 0.5 approximate asin(x)/x by an 8th order polynomial with\n  // even terms only.\n  constexpr float alpha[] = {5.08838854730129241943359375e-2f, 3.95139865577220916748046875e-2f,\n                             7.550220191478729248046875e-2f, 0.16664917767047882080078125f, 1.00000011920928955078125f};\n  Packet p = ppolevl&lt;Packet, 4&gt;::run(x2, alpha);\n  p = pmul(p, x);\n\n  const Packet p_large = pnmadd(cst_two, p, cst_pi_over_two);\n  p = pselect(large_mask, p_large, p);\n  // Flip the sign for negative arguments.\n  p = pxor(p, sign_mask);\n  // Return NaN for arguments outside [-1:1].\n  return por(invalid_mask, p);\n}\n\ntemplate &lt;typename Scalar&gt;\nstruct patan_reduced {\n  template &lt;typename Packet&gt;\n  static EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet run(const Packet&amp; x);\n};\n\ntemplate &lt;&gt;\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan_reduced&lt;double&gt;::run(const Packet&amp; x) {\n  constexpr double alpha[] = {2.6667153866462208e-05, 3.0917513112462781e-03, 5.2574296781008604e-02,\n                              3.0409318473444424e-01, 7.5365702534987022e-01, 8.2704055405494614e-01,\n                              3.3004361289279920e-01};\n\n  constexpr double beta[] = {\n      2.7311202462436667e-04, 1.0899150928962708e-02, 1.1548932646420353e-01, 4.9716458728465573e-01, 1.0,\n      9.3705509168587852e-01, 3.3004361289279920e-01};\n\n  Packet x2 = pmul(x, x);\n  Packet p = ppolevl&lt;Packet, 6&gt;::run(x2, alpha);\n  Packet q = ppolevl&lt;Packet, 6&gt;::run(x2, beta);\n  return pmul(x, pdiv(p, q));\n}\n\n// Computes elementwise atan(x) for x in [-1:1] with 2 ulp accuracy.\ntemplate &lt;&gt;\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan_reduced&lt;float&gt;::run(const Packet&amp; x) {\n  constexpr float alpha[] = {1.12026982009410858154296875e-01f, 7.296695709228515625e-01f, 8.109951019287109375e-01f};\n\n  constexpr float beta[] = {1.00917108356952667236328125e-02f, 2.8318560123443603515625e-01f, 1.0f,\n                            8.109951019287109375e-01f};\n\n  Packet x2 = pmul(x, x);\n  Packet p = ppolevl&lt;Packet, 2&gt;::run(x2, alpha);\n  Packet q = ppolevl&lt;Packet, 3&gt;::run(x2, beta);\n  return pmul(x, pdiv(p, q));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_atan(const Packet&amp; x_in) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n\n  constexpr Scalar kPiOverTwo = static_cast&lt;Scalar&gt;(EIGEN_PI / 2);\n\n  const Packet cst_signmask = pset1&lt;Packet&gt;(-Scalar(0));\n  const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n  const Packet cst_pi_over_two = pset1&lt;Packet&gt;(kPiOverTwo);\n\n  //   &quot;Large&quot;: For |x| &gt; 1, use atan(1/x) = sign(x)*pi/2 - atan(x).\n  //   &quot;Small&quot;: For |x| &lt;= 1, approximate atan(x) directly by a polynomial\n  //            calculated using Rminimax.\n\n  const Packet abs_x = pabs(x_in);\n  const Packet x_signmask = pand(x_in, cst_signmask);\n  const Packet large_mask = pcmp_lt(cst_one, abs_x);\n  const Packet x = pselect(large_mask, preciprocal(abs_x), abs_x);\n  const Packet p = patan_reduced&lt;Scalar&gt;::run(x);\n  // Apply transformations according to the range reduction masks.\n  Packet result = pselect(large_mask, psub(cst_pi_over_two, p), p);\n  // Return correct sign\n  return pxor(result, x_signmask);\n}\n\n/** \\internal \\returns the hyperbolic tan of \\a a (coeff-wise)\n    Doesn&#x27;t do anything fancy, just a 9/8-degree rational interpolant which\n    is accurate up to a couple of ulps in the (approximate) range [-8, 8],\n    outside of which tanh(x) = +/-1 in single precision. The input is clamped\n    to the range [-c, c]. The value c is chosen as the smallest value where\n    the approximation evaluates to exactly 1.\n\n    This implementation works on both scalars and packets.\n*/\ntemplate &lt;typename T&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS T ptanh_float(const T&amp; a_x) {\n  // Clamp the inputs to the range [-c, c] and set everything\n  // outside that range to 1.0. The value c is chosen as the smallest\n  // floating point argument such that the approximation is exactly 1.\n  // This saves clamping the value at the end.\n#ifdef EIGEN_VECTORIZE_FMA\n  const T plus_clamp = pset1&lt;T&gt;(8.01773357391357422f);\n  const T minus_clamp = pset1&lt;T&gt;(-8.01773357391357422f);\n#else\n  const T plus_clamp = pset1&lt;T&gt;(7.90738964080810547f);\n  const T minus_clamp = pset1&lt;T&gt;(-7.90738964080810547f);\n#endif\n  const T x = pmax(pmin(a_x, plus_clamp), minus_clamp);\n\n  // The following rational approximation was generated by rminimax\n  // (https://gitlab.inria.fr/sfilip/rminimax) using the following\n  // command:\n  // $ ratapprox --function=&quot;tanh(x)&quot; --dom=&#x27;[-8.67,8.67]&#x27; --num=&quot;odd&quot;\n  //   --den=&quot;even&quot; --type=&quot;[9,8]&quot; --numF=&quot;[SG]&quot; --denF=&quot;[SG]&quot; --log\n  //   --output=tanhf.sollya --dispCoeff=&quot;dec&quot;\n\n  // The monomial coefficients of the numerator polynomial (odd).\n  constexpr float alpha[] = {1.394553628e-8f, 2.102733560e-5f, 3.520756727e-3f, 1.340216100e-1f};\n\n  // The monomial coefficients of the denominator polynomial (even).\n  constexpr float beta[] = {8.015776984e-7f, 3.326951409e-4f, 2.597254514e-2f, 4.673548340e-1f, 1.0f};\n\n  // Since the polynomials are odd/even, we need x^2.\n  const T x2 = pmul(x, x);\n  const T x3 = pmul(x2, x);\n\n  T p = ppolevl&lt;T, 3&gt;::run(x2, alpha);\n  T q = ppolevl&lt;T, 4&gt;::run(x2, beta);\n  // Take advantage of the fact that the constant term in p is 1 to compute\n  // x*(x^2*p + 1) = x^3 * p + x.\n  p = pmadd(x3, p, x);\n\n  // Divide the numerator by the denominator.\n  return pdiv(p, q);\n}\n\n/** \\internal \\returns the hyperbolic tan of \\a a (coeff-wise)\n    This uses a 19/18-degree rational interpolant which\n    is accurate up to a couple of ulps in the (approximate) range [-18.7, 18.7],\n    outside of which tanh(x) = +/-1 in single precision. The input is clamped\n    to the range [-c, c]. The value c is chosen as the smallest value where\n    the approximation evaluates to exactly 1.\n\n    This implementation works on both scalars and packets.\n*/\ntemplate &lt;typename T&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS T ptanh_double(const T&amp; a_x) {\n  // Clamp the inputs to the range [-c, c] and set everything\n  // outside that range to 1.0. The value c is chosen as the smallest\n  // floating point argument such that the approximation is exactly 1.\n  // This saves clamping the value at the end.\n#ifdef EIGEN_VECTORIZE_FMA\n  const T plus_clamp = pset1&lt;T&gt;(17.6610191624600077);\n  const T minus_clamp = pset1&lt;T&gt;(-17.6610191624600077);\n#else\n  const T plus_clamp = pset1&lt;T&gt;(17.714196154005176);\n  const T minus_clamp = pset1&lt;T&gt;(-17.714196154005176);\n#endif\n  const T x = pmax(pmin(a_x, plus_clamp), minus_clamp);\n\n  // The following rational approximation was generated by rminimax\n  // (https://gitlab.inria.fr/sfilip/rminimax) using the following\n  // command:\n  // $ ./ratapprox --function=&quot;tanh(x)&quot; --dom=&#x27;[-18.72,18.72]&#x27;\n  //   --num=&quot;odd&quot; --den=&quot;even&quot; --type=&quot;[19,18]&quot; --numF=&quot;[D]&quot;\n  //   --denF=&quot;[D]&quot; --log --output=tanh.sollya --dispCoeff=&quot;dec&quot;\n\n  // The monomial coefficients of the numerator polynomial (odd).\n  constexpr double alpha[] = {2.6158007860482230e-23, 7.6534862268749319e-19, 3.1309488231386680e-15,\n                              4.2303918148209176e-12, 2.4618379131293676e-09, 6.8644367682497074e-07,\n                              9.3839087674268880e-05, 5.9809711724441161e-03, 1.5184719640284322e-01};\n\n  // The monomial coefficients of the denominator polynomial (even).\n  constexpr double beta[] = {6.463747022670968018e-21, 5.782506856739003571e-17,\n                             1.293019623712687916e-13, 1.123643448069621992e-10,\n                             4.492975677839633985e-08, 8.785185266237658698e-06,\n                             8.295161192716231542e-04, 3.437448108450402717e-02,\n                             4.851805297361760360e-01, 1.0};\n\n  // Since the polynomials are odd/even, we need x^2.\n  const T x2 = pmul(x, x);\n  const T x3 = pmul(x2, x);\n\n  // Interleave the evaluation of the numerator polynomial p and\n  // denominator polynomial q.\n  T p = ppolevl&lt;T, 8&gt;::run(x2, alpha);\n  T q = ppolevl&lt;T, 9&gt;::run(x2, beta);\n  // Take advantage of the fact that the constant term in p is 1 to compute\n  // x*(x^2*p + 1) = x^3 * p + x.\n  p = pmadd(x3, p, x);\n\n  // Divide the numerator by the denominator.\n  return pdiv(p, q);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_float(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static_assert(std::is_same&lt;Scalar, float&gt;::value, &quot;Scalar type must be float&quot;);\n\n  // For |x| in [0:0.5] we use a polynomial approximation of the form\n  // P(x) = x + x^3*(alpha[4] + x^2 * (alpha[3] + x^2 * (... x^2 * alpha[0]) ... )).\n  constexpr float alpha[] = {0.1819281280040740966796875f, 8.2311116158962249755859375e-2f,\n                             0.14672131836414337158203125f, 0.1997792422771453857421875f, 0.3333373963832855224609375f};\n  const Packet x2 = pmul(x, x);\n  const Packet x3 = pmul(x, x2);\n  Packet p = ppolevl&lt;Packet, 4&gt;::run(x2, alpha);\n  p = pmadd(x3, p, x);\n\n  // For |x| in ]0.5:1.0] we use atanh = 0.5*ln((1+x)/(1-x));\n  const Packet half = pset1&lt;Packet&gt;(0.5f);\n  const Packet one = pset1&lt;Packet&gt;(1.0f);\n  Packet r = pdiv(padd(one, x), psub(one, x));\n  r = pmul(half, plog(r));\n\n  const Packet x_gt_half = pcmp_le(half, pabs(x));\n  const Packet x_eq_one = pcmp_eq(one, pabs(x));\n  const Packet x_gt_one = pcmp_lt(one, pabs(x));\n  const Packet sign_mask = pset1&lt;Packet&gt;(-0.0f);\n  const Packet x_sign = pand(sign_mask, x);\n  const Packet inf = pset1&lt;Packet&gt;(std::numeric_limits&lt;float&gt;::infinity());\n  return por(x_gt_one, pselect(x_eq_one, por(x_sign, inf), pselect(x_gt_half, r, p)));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh_double(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static_assert(std::is_same&lt;Scalar, double&gt;::value, &quot;Scalar type must be double&quot;);\n  // For x in [-0.5:0.5] we use a rational approximation of the form\n  // R(x) = x + x^3*P(x^2)/Q(x^2), where P is or order 4 and Q is of order 5.\n  constexpr double alpha[] = {3.3071338469301391e-03, -4.7129526768798737e-02, 1.8185306179826699e-01,\n                              -2.5949536095445679e-01, 1.2306328729812676e-01};\n\n  constexpr double beta[] = {-3.8679974580640881e-03, 7.6391885763341910e-02,  -4.2828141436397615e-01,\n                             9.8733495886883648e-01,  -1.0000000000000000e+00, 3.6918986189438030e-01};\n\n  const Packet x2 = pmul(x, x);\n  const Packet x3 = pmul(x, x2);\n  Packet p = ppolevl&lt;Packet, 4&gt;::run(x2, alpha);\n  Packet q = ppolevl&lt;Packet, 5&gt;::run(x2, beta);\n  Packet y_small = pmadd(x3, pdiv(p, q), x);\n\n  // For |x| in ]0.5:1.0] we use atanh = 0.5*ln((1+x)/(1-x));\n  const Packet half = pset1&lt;Packet&gt;(0.5);\n  const Packet one = pset1&lt;Packet&gt;(1.0);\n  Packet y_large = pdiv(padd(one, x), psub(one, x));\n  y_large = pmul(half, plog(y_large));\n\n  const Packet x_gt_half = pcmp_le(half, pabs(x));\n  const Packet x_eq_one = pcmp_eq(one, pabs(x));\n  const Packet x_gt_one = pcmp_lt(one, pabs(x));\n  const Packet sign_mask = pset1&lt;Packet&gt;(-0.0);\n  const Packet x_sign = pand(sign_mask, x);\n  const Packet inf = pset1&lt;Packet&gt;(std::numeric_limits&lt;double&gt;::infinity());\n  return por(x_gt_one, pselect(x_eq_one, por(x_sign, inf), pselect(x_gt_half, y_large, y_small)));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pdiv_complex(const Packet&amp; x, const Packet&amp; y) {\n  typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n  // In the following we annotate the code for the case where the inputs\n  // are a pair length-2 SIMD vectors representing a single pair of complex\n  // numbers x = a + i*b, y = c + i*d.\n  const RealPacket y_abs = pabs(y.v);                        // |c|, |d|\n  const RealPacket y_abs_flip = pcplxflip(Packet(y_abs)).v;  // |d|, |c|\n  const RealPacket y_max = pmax(y_abs, y_abs_flip);          // max(|c|, |d|), max(|c|, |d|)\n  const RealPacket y_scaled = pdiv(y.v, y_max);              // c / max(|c|, |d|), d / max(|c|, |d|)\n  // Compute scaled denominator.\n  const RealPacket y_scaled_sq = pmul(y_scaled, y_scaled);  // c&#x27;**2, d&#x27;**2\n  const RealPacket denom = padd(y_scaled_sq, pcplxflip(Packet(y_scaled_sq)).v);\n  Packet result_scaled = pmul(x, pconj(Packet(y_scaled)));  // a * c&#x27; + b * d&#x27;, -a * d + b * c\n  // Divide elementwise by denom.\n  result_scaled = Packet(pdiv(result_scaled.v, denom));\n  // Rescale result\n  return Packet(pdiv(result_scaled.v, y_max));\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog_complex(const Packet&amp; x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename Scalar::value_type RealScalar;\n  typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n\n  RealPacket real_mask_rp = peven_mask(x.v);\n  Packet real_mask(real_mask_rp);\n\n  // Real part\n  RealPacket x_flip = pcplxflip(x).v;  // b, a\n  Packet x_norm = phypot_complex(x);   // sqrt(a^2 + b^2), sqrt(a^2 + b^2)\n  RealPacket xlogr = plog(x_norm.v);   // log(sqrt(a^2 + b^2)), log(sqrt(a^2 + b^2))\n\n  // Imag part\n  RealPacket ximg = patan2(x.v, x_flip);  // atan2(a, b), atan2(b, a)\n\n  const RealPacket cst_pos_inf = pset1&lt;RealPacket&gt;(NumTraits&lt;RealScalar&gt;::infinity());\n  RealPacket x_abs = pabs(x.v);\n  RealPacket is_x_pos_inf = pcmp_eq(x_abs, cst_pos_inf);\n  RealPacket is_y_pos_inf = pcplxflip(Packet(is_x_pos_inf)).v;\n  RealPacket is_any_inf = por(is_x_pos_inf, is_y_pos_inf);\n  RealPacket xreal = pselect(is_any_inf, cst_pos_inf, xlogr);\n\n  Packet xres = pselect(real_mask, Packet(xreal), Packet(ximg));  // log(sqrt(a^2 + b^2)), atan2(b, a)\n  return xres;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp_complex(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename Scalar::value_type RealScalar;\n  const RealPacket even_mask = peven_mask(a.v);\n  const RealPacket odd_mask = pcplxflip(Packet(even_mask)).v;\n\n  // Let a = x + iy.\n  // exp(a) = exp(x) * cis(y), plus some special edge-case handling.\n\n  // exp(x):\n  RealPacket x = pand(a.v, even_mask);\n  x = por(x, pcplxflip(Packet(x)).v);\n  RealPacket expx = pexp(x);  // exp(x);\n\n  // cis(y):\n  RealPacket y = pand(odd_mask, a.v);\n  y = por(y, pcplxflip(Packet(y)).v);\n  RealPacket cisy = psincos_float&lt;false, RealPacket, true&gt;(y);\n  cisy = pcplxflip(Packet(cisy)).v;  // cos(y) + i * sin(y)\n\n  const RealPacket cst_pos_inf = pset1&lt;RealPacket&gt;(NumTraits&lt;RealScalar&gt;::infinity());\n  const RealPacket cst_neg_inf = pset1&lt;RealPacket&gt;(-NumTraits&lt;RealScalar&gt;::infinity());\n\n  // If x is -inf, we know that cossin(y) is bounded,\n  //   so the result is (0, +/-0), where the sign of the imaginary part comes\n  //   from the sign of cossin(y).\n  RealPacket cisy_sign = por(pandnot(cisy, pabs(cisy)), pset1&lt;RealPacket&gt;(RealScalar(1)));\n  cisy = pselect(pcmp_eq(x, cst_neg_inf), cisy_sign, cisy);\n\n  // If x is inf, and cos(y) has unknown sign (y is inf or NaN), the result\n  // is (+/-inf, NaN), where the signs are undetermined (take the sign of y).\n  RealPacket y_sign = por(pandnot(y, pabs(y)), pset1&lt;RealPacket&gt;(RealScalar(1)));\n  cisy = pselect(pand(pcmp_eq(x, cst_pos_inf), pisnan(cisy)), pand(y_sign, even_mask), cisy);\n  Packet result = Packet(pmul(expx, cisy));\n\n  // If y is +/- 0, the input is real, so take the real result for consistency.\n  result = pselect(Packet(pcmp_eq(y, pzero(y))), Packet(por(pand(expx, even_mask), pand(y, odd_mask))), result);\n\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psqrt_complex(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename Scalar::value_type RealScalar;\n  typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n\n  // Computes the principal sqrt of the complex numbers in the input.\n  //\n  // For example, for packets containing 2 complex numbers stored in interleaved format\n  //    a = [a0, a1] = [x0, y0, x1, y1],\n  // where x0 = real(a0), y0 = imag(a0) etc., this function returns\n  //    b = [b0, b1] = [u0, v0, u1, v1],\n  // such that b0^2 = a0, b1^2 = a1.\n  //\n  // To derive the formula for the complex square roots, let&#x27;s consider the equation for\n  // a single complex square root of the number x + i*y. We want to find real numbers\n  // u and v such that\n  //    (u + i*v)^2 = x + i*y  &lt;=&gt;\n  //    u^2 - v^2 + i*2*u*v = x + i*v.\n  // By equating the real and imaginary parts we get:\n  //    u^2 - v^2 = x\n  //    2*u*v = y.\n  //\n  // For x &gt;= 0, this has the numerically stable solution\n  //    u = sqrt(0.5 * (x + sqrt(x^2 + y^2)))\n  //    v = 0.5 * (y / u)\n  // and for x &lt; 0,\n  //    v = sign(y) * sqrt(0.5 * (-x + sqrt(x^2 + y^2)))\n  //    u = 0.5 * (y / v)\n  //\n  //  To avoid unnecessary over- and underflow, we compute sqrt(x^2 + y^2) as\n  //     l = max(|x|, |y|) * sqrt(1 + (min(|x|, |y|) / max(|x|, |y|))^2) ,\n\n  // In the following, without lack of generality, we have annotated the code, assuming\n  // that the input is a packet of 2 complex numbers.\n  //\n  // Step 1. Compute l = [l0, l0, l1, l1], where\n  //    l0 = sqrt(x0^2 + y0^2),  l1 = sqrt(x1^2 + y1^2)\n  // To avoid over- and underflow, we use the stable formula for each hypotenuse\n  //    l0 = (min0 == 0 ? max0 : max0 * sqrt(1 + (min0/max0)**2)),\n  // where max0 = max(|x0|, |y0|), min0 = min(|x0|, |y0|), and similarly for l1.\n\n  RealPacket a_abs = pabs(a.v);                        // [|x0|, |y0|, |x1|, |y1|]\n  RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;  // [|y0|, |x0|, |y1|, |x1|]\n  RealPacket a_max = pmax(a_abs, a_abs_flip);\n  RealPacket a_min = pmin(a_abs, a_abs_flip);\n  RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));\n  RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));\n  RealPacket r = pdiv(a_min, a_max);\n  const RealPacket cst_one = pset1&lt;RealPacket&gt;(RealScalar(1));\n  RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));  // [l0, l0, l1, l1]\n  // Set l to a_max if a_min is zero.\n  l = pselect(a_min_zero_mask, a_max, l);\n\n  // Step 2. Compute [rho0, *, rho1, *], where\n  // rho0 = sqrt(0.5 * (l0 + |x0|)), rho1 =  sqrt(0.5 * (l1 + |x1|))\n  // We don&#x27;t care about the imaginary parts computed here. They will be overwritten later.\n  const RealPacket cst_half = pset1&lt;RealPacket&gt;(RealScalar(0.5));\n  Packet rho;\n  rho.v = psqrt(pmul(cst_half, padd(a_abs, l)));\n\n  // Step 3. Compute [rho0, eta0, rho1, eta1], where\n  // eta0 = (y0 / l0) / 2, and eta1 = (y1 / l1) / 2.\n  // set eta = 0 of input is 0 + i0.\n  RealPacket eta = pandnot(pmul(cst_half, pdiv(a.v, pcplxflip(rho).v)), a_max_zero_mask);\n  RealPacket real_mask = peven_mask(a.v);\n  Packet positive_real_result;\n  // Compute result for inputs with positive real part.\n  positive_real_result.v = pselect(real_mask, rho.v, eta);\n\n  // Step 4. Compute solution for inputs with negative real part:\n  //         [|eta0|, sign(y0)*rho0, |eta1|, sign(y1)*rho1]\n  const RealPacket cst_imag_sign_mask = pset1&lt;Packet&gt;(Scalar(RealScalar(0.0), RealScalar(-0.0))).v;\n  RealPacket imag_signs = pand(a.v, cst_imag_sign_mask);\n  Packet negative_real_result;\n  // Notice that rho is positive, so taking it&#x27;s absolute value is a noop.\n  negative_real_result.v = por(pabs(pcplxflip(positive_real_result).v), imag_signs);\n\n  // Step 5. Select solution branch based on the sign of the real parts.\n  Packet negative_real_mask;\n  negative_real_mask.v = pcmp_lt(pand(real_mask, a.v), pzero(a.v));\n  negative_real_mask.v = por(negative_real_mask.v, pcplxflip(negative_real_mask).v);\n  Packet result = pselect(negative_real_mask, negative_real_result, positive_real_result);\n\n  // Step 6. Handle special cases for infinities:\n  // * If z is (x,+\u221e), the result is (+\u221e,+\u221e) even if x is NaN\n  // * If z is (x,-\u221e), the result is (+\u221e,-\u221e) even if x is NaN\n  // * If z is (-\u221e,y), the result is (0*|y|,+\u221e) for finite or NaN y\n  // * If z is (+\u221e,y), the result is (+\u221e,0*|y|) for finite or NaN y\n  const RealPacket cst_pos_inf = pset1&lt;RealPacket&gt;(NumTraits&lt;RealScalar&gt;::infinity());\n  Packet is_inf;\n  is_inf.v = pcmp_eq(a_abs, cst_pos_inf);\n  Packet is_real_inf;\n  is_real_inf.v = pand(is_inf.v, real_mask);\n  is_real_inf = por(is_real_inf, pcplxflip(is_real_inf));\n  // prepare packet of (+\u221e,0*|y|) or (0*|y|,+\u221e), depending on the sign of the infinite real part.\n  Packet real_inf_result;\n  real_inf_result.v = pmul(a_abs, pset1&lt;Packet&gt;(Scalar(RealScalar(1.0), RealScalar(0.0))).v);\n  real_inf_result.v = pselect(negative_real_mask.v, pcplxflip(real_inf_result).v, real_inf_result.v);\n  // prepare packet of (+\u221e,+\u221e) or (+\u221e,-\u221e), depending on the sign of the infinite imaginary part.\n  Packet is_imag_inf;\n  is_imag_inf.v = pandnot(is_inf.v, real_mask);\n  is_imag_inf = por(is_imag_inf, pcplxflip(is_imag_inf));\n  Packet imag_inf_result;\n  imag_inf_result.v = por(pand(cst_pos_inf, real_mask), pandnot(a.v, real_mask));\n  // unless otherwise specified, if either the real or imaginary component is nan, the entire result is nan\n  Packet result_is_nan = pisnan(result);\n  result = por(result_is_nan, result);\n\n  return pselect(is_imag_inf, imag_inf_result, pselect(is_real_inf, real_inf_result, result));\n}\n\n// \\internal \\returns the norm of a complex number z = x + i*y, defined as sqrt(x^2 + y^2).\n// Implemented using the hypot(a,b) algorithm from https://doi.org/10.48550/arXiv.1904.09481\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet phypot_complex(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  typedef typename Scalar::value_type RealScalar;\n  typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n\n  const RealPacket cst_zero_rp = pset1&lt;RealPacket&gt;(static_cast&lt;RealScalar&gt;(0.0));\n  const RealPacket cst_minus_one_rp = pset1&lt;RealPacket&gt;(static_cast&lt;RealScalar&gt;(-1.0));\n  const RealPacket cst_two_rp = pset1&lt;RealPacket&gt;(static_cast&lt;RealScalar&gt;(2.0));\n  const RealPacket evenmask = peven_mask(a.v);\n\n  RealPacket a_abs = pabs(a.v);\n  RealPacket a_flip = pcplxflip(Packet(a_abs)).v;       // |b|, |a|\n  RealPacket a_all = pselect(evenmask, a_abs, a_flip);  // |a|, |a|\n  RealPacket b_all = pselect(evenmask, a_flip, a_abs);  // |b|, |b|\n\n  RealPacket a2 = pmul(a.v, a.v);                    // |a^2, b^2|\n  RealPacket a2_flip = pcplxflip(Packet(a2)).v;      // |b^2, a^2|\n  RealPacket h = psqrt(padd(a2, a2_flip));           // |sqrt(a^2 + b^2), sqrt(a^2 + b^2)|\n  RealPacket h_sq = pmul(h, h);                      // |a^2 + b^2, a^2 + b^2|\n  RealPacket a_sq = pselect(evenmask, a2, a2_flip);  // |a^2, a^2|\n  RealPacket m_h_sq = pmul(h_sq, cst_minus_one_rp);\n  RealPacket m_a_sq = pmul(a_sq, cst_minus_one_rp);\n  RealPacket x = psub(psub(pmadd(h, h, m_h_sq), pmadd(b_all, b_all, psub(a_sq, h_sq))), pmadd(a_all, a_all, m_a_sq));\n  h = psub(h, pdiv(x, pmul(cst_two_rp, h)));  // |h - x/(2*h), h - x/(2*h)|\n\n  // handle zero-case\n  RealPacket iszero = pcmp_eq(por(a_abs, a_flip), cst_zero_rp);\n\n  h = pandnot(h, iszero);  // |sqrt(a^2+b^2), sqrt(a^2+b^2)|\n  return Packet(h);        // |sqrt(a^2+b^2), sqrt(a^2+b^2)|\n}\n\ntemplate &lt;typename Packet&gt;\nstruct psign_impl&lt;Packet, std::enable_if_t&lt;!NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsComplex &amp;&amp;\n                                           !NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a) {\n    using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n    const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n    const Packet cst_zero = pzero(a);\n\n    const Packet abs_a = pabs(a);\n    const Packet sign_mask = pandnot(a, abs_a);\n    const Packet nonzero_mask = pcmp_lt(cst_zero, abs_a);\n\n    return pselect(nonzero_mask, por(sign_mask, cst_one), abs_a);\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct psign_impl&lt;Packet, std::enable_if_t&lt;!NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsComplex &amp;&amp;\n                                           NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsSigned &amp;&amp;\n                                           NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a) {\n    using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n    const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n    const Packet cst_minus_one = pset1&lt;Packet&gt;(Scalar(-1));\n    const Packet cst_zero = pzero(a);\n\n    const Packet positive_mask = pcmp_lt(cst_zero, a);\n    const Packet positive = pand(positive_mask, cst_one);\n    const Packet negative_mask = pcmp_lt(a, cst_zero);\n    const Packet negative = pand(negative_mask, cst_minus_one);\n\n    return por(positive, negative);\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct psign_impl&lt;Packet, std::enable_if_t&lt;!NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsComplex &amp;&amp;\n                                           !NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsSigned &amp;&amp;\n                                           NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a) {\n    using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n    const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n    const Packet cst_zero = pzero(a);\n\n    const Packet zero_mask = pcmp_eq(cst_zero, a);\n    return pandnot(cst_one, zero_mask);\n  }\n};\n\n// \\internal \\returns the the sign of a complex number z, defined as z / abs(z).\ntemplate &lt;typename Packet&gt;\nstruct psign_impl&lt;Packet, std::enable_if_t&lt;NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsComplex &amp;&amp;\n                                           unpacket_traits&lt;Packet&gt;::vectorizable&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a) {\n    typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n    typedef typename Scalar::value_type RealScalar;\n    typedef typename unpacket_traits&lt;Packet&gt;::as_real RealPacket;\n\n    // Step 1. Compute (for each element z = x + i*y in a)\n    //     l = abs(z) = sqrt(x^2 + y^2).\n    // To avoid over- and underflow, we use the stable formula for each hypotenuse\n    //    l = (zmin == 0 ? zmax : zmax * sqrt(1 + (zmin/zmax)**2)),\n    // where zmax = max(|x|, |y|), zmin = min(|x|, |y|),\n    RealPacket a_abs = pabs(a.v);\n    RealPacket a_abs_flip = pcplxflip(Packet(a_abs)).v;\n    RealPacket a_max = pmax(a_abs, a_abs_flip);\n    RealPacket a_min = pmin(a_abs, a_abs_flip);\n    RealPacket a_min_zero_mask = pcmp_eq(a_min, pzero(a_min));\n    RealPacket a_max_zero_mask = pcmp_eq(a_max, pzero(a_max));\n    RealPacket r = pdiv(a_min, a_max);\n    const RealPacket cst_one = pset1&lt;RealPacket&gt;(RealScalar(1));\n    RealPacket l = pmul(a_max, psqrt(padd(cst_one, pmul(r, r))));  // [l0, l0, l1, l1]\n    // Set l to a_max if a_min is zero, since the roundtrip sqrt(a_max^2) may be\n    // lossy.\n    l = pselect(a_min_zero_mask, a_max, l);\n    // Step 2 compute a / abs(a).\n    RealPacket sign_as_real = pandnot(pdiv(a.v, l), a_max_zero_mask);\n    Packet sign;\n    sign.v = sign_as_real;\n    return sign;\n  }\n};\n\n// TODO(rmlarsen): The following set of utilities for double word arithmetic\n// should perhaps be refactored as a separate file, since it would be generally\n// useful for special function implementation etc. Writing the algorithms in\n// terms if a double word type would also make the code more readable.\n\n// This function splits x into the nearest integer n and fractional part r,\n// such that x = n + r holds exactly.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void absolute_split(const Packet&amp; x, Packet&amp; n, Packet&amp; r) {\n  n = pround(x);\n  r = psub(x, n);\n}\n\n// This function computes the sum {s, r}, such that x + y = s_hi + s_lo\n// holds exactly, and s_hi = fl(x+y), if |x| &gt;= |y|.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet&amp; x, const Packet&amp; y, Packet&amp; s_hi, Packet&amp; s_lo) {\n  s_hi = padd(x, y);\n  const Packet t = psub(s_hi, x);\n  s_lo = psub(y, t);\n}\n\n#ifdef EIGEN_VECTORIZE_FMA\n// This function implements the extended precision product of\n// a pair of floating point numbers. Given {x, y}, it computes the pair\n// {p_hi, p_lo} such that x * y = p_hi + p_lo holds exactly and\n// p_hi = fl(x * y).\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet&amp; x, const Packet&amp; y, Packet&amp; p_hi, Packet&amp; p_lo) {\n  p_hi = pmul(x, y);\n  p_lo = pmsub(x, y, p_hi);\n}\n\n// A version of twoprod that takes x, y, and fl(x*y) as input and returns the p_lo such that\n// x * y = xy + p_lo holds exactly.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet twoprod_low(const Packet&amp; x, const Packet&amp; y, const Packet&amp; xy) {\n  return pmsub(x, y, xy);\n}\n\n#else\n\n// This function implements the Veltkamp splitting. Given a floating point\n// number x it returns the pair {x_hi, x_lo} such that x_hi + x_lo = x holds\n// exactly and that half of the significant of x fits in x_hi.\n// This is Algorithm 3 from Jean-Michel Muller, &quot;Elementary Functions&quot;,\n// 3rd edition, Birkh\\&quot;auser, 2016.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void veltkamp_splitting(const Packet&amp; x, Packet&amp; x_hi, Packet&amp; x_lo) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  EIGEN_CONSTEXPR int shift = (NumTraits&lt;Scalar&gt;::digits() + 1) / 2;\n  const Scalar shift_scale = Scalar(uint64_t(1) &lt;&lt; shift);  // Scalar constructor not necessarily constexpr.\n  const Packet gamma = pmul(pset1&lt;Packet&gt;(shift_scale + Scalar(1)), x);\n  Packet rho = psub(x, gamma);\n  x_hi = padd(rho, gamma);\n  x_lo = psub(x, x_hi);\n}\n\n// This function implements Dekker&#x27;s algorithm for products x * y.\n// Given floating point numbers {x, y} computes the pair\n// {p_hi, p_lo} such that x * y = p_hi + p_lo holds exactly and\n// p_hi = fl(x * y).\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet&amp; x, const Packet&amp; y, Packet&amp; p_hi, Packet&amp; p_lo) {\n  Packet x_hi, x_lo, y_hi, y_lo;\n  veltkamp_splitting(x, x_hi, x_lo);\n  veltkamp_splitting(y, y_hi, y_lo);\n\n  p_hi = pmul(x, y);\n  p_lo = pmadd(x_hi, y_hi, pnegate(p_hi));\n  p_lo = pmadd(x_hi, y_lo, p_lo);\n  p_lo = pmadd(x_lo, y_hi, p_lo);\n  p_lo = pmadd(x_lo, y_lo, p_lo);\n}\n\n// A version of twoprod that takes x, y, and fl(x*y) as input and returns the p_lo such that\n// x * y = xy + p_lo holds exactly.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet twoprod_low(const Packet&amp; x, const Packet&amp; y, const Packet&amp; xy) {\n  Packet x_hi, x_lo, y_hi, y_lo;\n  veltkamp_splitting(x, x_hi, x_lo);\n  veltkamp_splitting(y, y_hi, y_lo);\n\n  Packet p_lo = pmadd(x_hi, y_hi, pnegate(xy));\n  p_lo = pmadd(x_hi, y_lo, p_lo);\n  p_lo = pmadd(x_lo, y_hi, p_lo);\n  p_lo = pmadd(x_lo, y_lo, p_lo);\n  return p_lo;\n}\n\n#endif  // EIGEN_VECTORIZE_FMA\n\n// This function implements Dekker&#x27;s algorithm for the addition\n// of two double word numbers represented by {x_hi, x_lo} and {y_hi, y_lo}.\n// It returns the result as a pair {s_hi, s_lo} such that\n// x_hi + x_lo + y_hi + y_lo = s_hi + s_lo holds exactly.\n// This is Algorithm 5 from Jean-Michel Muller, &quot;Elementary Functions&quot;,\n// 3rd edition, Birkh\\&quot;auser, 2016.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twosum(const Packet&amp; x_hi, const Packet&amp; x_lo, const Packet&amp; y_hi,\n                                                  const Packet&amp; y_lo, Packet&amp; s_hi, Packet&amp; s_lo) {\n  const Packet x_greater_mask = pcmp_lt(pabs(y_hi), pabs(x_hi));\n  Packet r_hi_1, r_lo_1;\n  fast_twosum(x_hi, y_hi, r_hi_1, r_lo_1);\n  Packet r_hi_2, r_lo_2;\n  fast_twosum(y_hi, x_hi, r_hi_2, r_lo_2);\n  const Packet r_hi = pselect(x_greater_mask, r_hi_1, r_hi_2);\n\n  const Packet s1 = padd(padd(y_lo, r_lo_1), x_lo);\n  const Packet s2 = padd(padd(x_lo, r_lo_2), y_lo);\n  const Packet s = pselect(x_greater_mask, s1, s2);\n\n  fast_twosum(r_hi, s, s_hi, s_lo);\n}\n\n// This is a version of twosum for double word numbers,\n// which assumes that |x_hi| &gt;= |y_hi|.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet&amp; x_hi, const Packet&amp; x_lo, const Packet&amp; y_hi,\n                                                       const Packet&amp; y_lo, Packet&amp; s_hi, Packet&amp; s_lo) {\n  Packet r_hi, r_lo;\n  fast_twosum(x_hi, y_hi, r_hi, r_lo);\n  const Packet s = padd(padd(y_lo, r_lo), x_lo);\n  fast_twosum(r_hi, s, s_hi, s_lo);\n}\n\n// This is a version of twosum for adding a floating point number x to\n// double word number {y_hi, y_lo} number, with the assumption\n// that |x| &gt;= |y_hi|.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void fast_twosum(const Packet&amp; x, const Packet&amp; y_hi, const Packet&amp; y_lo,\n                                                       Packet&amp; s_hi, Packet&amp; s_lo) {\n  Packet r_hi, r_lo;\n  fast_twosum(x, y_hi, r_hi, r_lo);\n  const Packet s = padd(y_lo, r_lo);\n  fast_twosum(r_hi, s, s_hi, s_lo);\n}\n\n// This function implements the multiplication of a double word\n// number represented by {x_hi, x_lo} by a floating point number y.\n// It returns the result as a pair {p_hi, p_lo} such that\n// (x_hi + x_lo) * y = p_hi + p_lo hold with a relative error\n// of less than 2*2^{-2p}, where p is the number of significand bit\n// in the floating point type.\n// This is Algorithm 7 from Jean-Michel Muller, &quot;Elementary Functions&quot;,\n// 3rd edition, Birkh\\&quot;auser, 2016.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet&amp; x_hi, const Packet&amp; x_lo, const Packet&amp; y,\n                                                   Packet&amp; p_hi, Packet&amp; p_lo) {\n  Packet c_hi, c_lo1;\n  twoprod(x_hi, y, c_hi, c_lo1);\n  const Packet c_lo2 = pmul(x_lo, y);\n  Packet t_hi, t_lo1;\n  fast_twosum(c_hi, c_lo2, t_hi, t_lo1);\n  const Packet t_lo2 = padd(t_lo1, c_lo1);\n  fast_twosum(t_hi, t_lo2, p_hi, p_lo);\n}\n\n// This function implements the multiplication of two double word\n// numbers represented by {x_hi, x_lo} and {y_hi, y_lo}.\n// It returns the result as a pair {p_hi, p_lo} such that\n// (x_hi + x_lo) * (y_hi + y_lo) = p_hi + p_lo holds with a relative error\n// of less than 2*2^{-2p}, where p is the number of significand bit\n// in the floating point type.\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void twoprod(const Packet&amp; x_hi, const Packet&amp; x_lo, const Packet&amp; y_hi,\n                                                   const Packet&amp; y_lo, Packet&amp; p_hi, Packet&amp; p_lo) {\n  Packet p_hi_hi, p_hi_lo;\n  twoprod(x_hi, x_lo, y_hi, p_hi_hi, p_hi_lo);\n  Packet p_lo_hi, p_lo_lo;\n  twoprod(x_hi, x_lo, y_lo, p_lo_hi, p_lo_lo);\n  fast_twosum(p_hi_hi, p_hi_lo, p_lo_hi, p_lo_lo, p_hi, p_lo);\n}\n\n// This function implements the division of double word {x_hi, x_lo}\n// by float y. This is Algorithm 15 from &quot;Tight and rigorous error bounds\n// for basic building blocks of double-word arithmetic&quot;, Joldes, Muller, &amp; Popescu,\n// 2017. https://hal.archives-ouvertes.fr/hal-01351529\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void doubleword_div_fp(const Packet&amp; x_hi, const Packet&amp; x_lo, const Packet&amp; y,\n                                                             Packet&amp; z_hi, Packet&amp; z_lo) {\n  const Packet t_hi = pdiv(x_hi, y);\n  Packet pi_hi, pi_lo;\n  twoprod(t_hi, y, pi_hi, pi_lo);\n  const Packet delta_hi = psub(x_hi, pi_hi);\n  const Packet delta_t = psub(delta_hi, pi_lo);\n  const Packet delta = padd(delta_t, x_lo);\n  const Packet t_lo = pdiv(delta, y);\n  fast_twosum(t_hi, t_lo, z_hi, z_lo);\n}\n\n// This function computes log2(x) and returns the result as a double word.\ntemplate &lt;typename Scalar&gt;\nstruct accurate_log2 {\n  template &lt;typename Packet&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet&amp; x, Packet&amp; log2_x_hi, Packet&amp; log2_x_lo) {\n    log2_x_hi = plog2(x);\n    log2_x_lo = pzero(x);\n  }\n};\n\n// This specialization uses a more accurate algorithm to compute log2(x) for\n// floats in [1/sqrt(2);sqrt(2)] with a relative accuracy of ~6.56508e-10.\n// This additional accuracy is needed to counter the error-magnification\n// inherent in multiplying by a potentially large exponent in pow(x,y).\n// The minimax polynomial used was calculated using the Rminimax tool,\n// see https://gitlab.inria.fr/sfilip/rminimax.\n// Command line:\n//   $ ratapprox --function=&quot;log2(1+x)/x&quot;  --dom=&#x27;[-0.2929,0.41422]&#x27;\n//   --type=[10,0]\n//       --numF=&quot;[D,D,SG]&quot; --denF=&quot;[SG]&quot; --log --dispCoeff=&quot;dec&quot;\n//\n// The resulting implementation of pow(x,y) is accurate to 3 ulps.\ntemplate &lt;&gt;\nstruct accurate_log2&lt;float&gt; {\n  template &lt;typename Packet&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet&amp; z, Packet&amp; log2_x_hi, Packet&amp; log2_x_lo) {\n    // Split the two lowest order constant coefficient into double-word representation.\n    constexpr double kC0 = 1.442695041742110273474963832995854318141937255859375e+00;\n    constexpr float kC0_hi = static_cast&lt;float&gt;(kC0);\n    constexpr float kC0_lo = static_cast&lt;float&gt;(kC0 - static_cast&lt;double&gt;(kC0_hi));\n    const Packet c0_hi = pset1&lt;Packet&gt;(kC0_hi);\n    const Packet c0_lo = pset1&lt;Packet&gt;(kC0_lo);\n\n    constexpr double kC1 = -7.2134751588268664068692714863573201000690460205078125e-01;\n    constexpr float kC1_hi = static_cast&lt;float&gt;(kC1);\n    constexpr float kC1_lo = static_cast&lt;float&gt;(kC1 - static_cast&lt;double&gt;(kC1_hi));\n    const Packet c1_hi = pset1&lt;Packet&gt;(kC1_hi);\n    const Packet c1_lo = pset1&lt;Packet&gt;(kC1_lo);\n\n    constexpr float c[] = {\n        9.7010828554630279541015625e-02,  -1.6896486282348632812500000e-01, 1.7200836539268493652343750e-01,\n        -1.7892272770404815673828125e-01, 2.0505344867706298828125000e-01,  -2.4046677350997924804687500e-01,\n        2.8857553005218505859375000e-01,  -3.6067414283752441406250000e-01, 4.8089790344238281250000000e-01};\n\n    // Evaluate the higher order terms in the polynomial using\n    // standard arithmetic.\n    const Packet one = pset1&lt;Packet&gt;(1.0f);\n    const Packet x = psub(z, one);\n    Packet p = ppolevl&lt;Packet, 8&gt;::run(x, c);\n    // Evaluate the final two step in Horner&#x27;s rule using double-word\n    // arithmetic.\n    Packet p_hi, p_lo;\n    twoprod(x, p, p_hi, p_lo);\n    fast_twosum(c1_hi, c1_lo, p_hi, p_lo, p_hi, p_lo);\n    twoprod(p_hi, p_lo, x, p_hi, p_lo);\n    fast_twosum(c0_hi, c0_lo, p_hi, p_lo, p_hi, p_lo);\n    // Multiply by x to recover log2(z).\n    twoprod(p_hi, p_lo, x, log2_x_hi, log2_x_lo);\n  }\n};\n\n// This specialization uses a more accurate algorithm to compute log2(x) for\n// floats in [1/sqrt(2);sqrt(2)] with a relative accuracy of ~1.27e-18.\n// This additional accuracy is needed to counter the error-magnification\n// inherent in multiplying by a potentially large exponent in pow(x,y).\n// The minimax polynomial used was calculated using the Sollya tool.\n// See sollya.org.\n\ntemplate &lt;&gt;\nstruct accurate_log2&lt;double&gt; {\n  template &lt;typename Packet&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void operator()(const Packet&amp; x, Packet&amp; log2_x_hi, Packet&amp; log2_x_lo) {\n    // We use a transformation of variables:\n    //    r = c * (x-1) / (x+1),\n    // such that\n    //    log2(x) = log2((1 + r/c) / (1 - r/c)) = f(r).\n    // The function f(r) can be approximated well using an odd polynomial\n    // of the form\n    //   P(r) = ((Q(r^2) * r^2 + C) * r^2 + 1) * r,\n    // For the implementation of log2&lt;double&gt; here, Q is of degree 6 with\n    // coefficient represented in working precision (double), while C is a\n    // constant represented in extra precision as a double word to achieve\n    // full accuracy.\n    //\n    // The polynomial coefficients were computed by the Sollya script:\n    //\n    // c = 2 / log(2);\n    // trans = c * (x-1)/(x+1);\n    // itrans = (1+x/c)/(1-x/c);\n    // interval=[trans(sqrt(0.5)); trans(sqrt(2))];\n    // print(interval);\n    // f = log2(itrans(x));\n    // p=fpminimax(f,[|1,3,5,7,9,11,13,15,17|],[|1,DD,double...|],interval,relative,floating);\n    const Packet q12 = pset1&lt;Packet&gt;(2.87074255468000586e-9);\n    const Packet q10 = pset1&lt;Packet&gt;(2.38957980901884082e-8);\n    const Packet q8 = pset1&lt;Packet&gt;(2.31032094540014656e-7);\n    const Packet q6 = pset1&lt;Packet&gt;(2.27279857398537278e-6);\n    const Packet q4 = pset1&lt;Packet&gt;(2.31271023278625638e-5);\n    const Packet q2 = pset1&lt;Packet&gt;(2.47556738444535513e-4);\n    const Packet q0 = pset1&lt;Packet&gt;(2.88543873228900172e-3);\n    const Packet C_hi = pset1&lt;Packet&gt;(0.0400377511598501157);\n    const Packet C_lo = pset1&lt;Packet&gt;(-4.77726582251425391e-19);\n    const Packet one = pset1&lt;Packet&gt;(1.0);\n\n    const Packet cst_2_log2e_hi = pset1&lt;Packet&gt;(2.88539008177792677);\n    const Packet cst_2_log2e_lo = pset1&lt;Packet&gt;(4.07660016854549667e-17);\n    // c * (x - 1)\n    Packet t_hi, t_lo;\n    // t = c * (x-1)\n    twoprod(cst_2_log2e_hi, cst_2_log2e_lo, psub(x, one), t_hi, t_lo);\n    // r = c * (x-1) / (x+1),\n    Packet r_hi, r_lo;\n    doubleword_div_fp(t_hi, t_lo, padd(x, one), r_hi, r_lo);\n\n    // r2 = r * r\n    Packet r2_hi, r2_lo;\n    twoprod(r_hi, r_lo, r_hi, r_lo, r2_hi, r2_lo);\n    // r4 = r2 * r2\n    Packet r4_hi, r4_lo;\n    twoprod(r2_hi, r2_lo, r2_hi, r2_lo, r4_hi, r4_lo);\n\n    // Evaluate Q(r^2) in working precision. We evaluate it in two parts\n    // (even and odd in r^2) to improve instruction level parallelism.\n    Packet q_even = pmadd(q12, r4_hi, q8);\n    Packet q_odd = pmadd(q10, r4_hi, q6);\n    q_even = pmadd(q_even, r4_hi, q4);\n    q_odd = pmadd(q_odd, r4_hi, q2);\n    q_even = pmadd(q_even, r4_hi, q0);\n    Packet q = pmadd(q_odd, r2_hi, q_even);\n\n    // Now evaluate the low order terms of P(x) in double word precision.\n    // In the following, due to the increasing magnitude of the coefficients\n    // and r being constrained to [-0.5, 0.5] we can use fast_twosum instead\n    // of the slower twosum.\n    // Q(r^2) * r^2\n    Packet p_hi, p_lo;\n    twoprod(r2_hi, r2_lo, q, p_hi, p_lo);\n    // Q(r^2) * r^2 + C\n    Packet p1_hi, p1_lo;\n    fast_twosum(C_hi, C_lo, p_hi, p_lo, p1_hi, p1_lo);\n    // (Q(r^2) * r^2 + C) * r^2\n    Packet p2_hi, p2_lo;\n    twoprod(r2_hi, r2_lo, p1_hi, p1_lo, p2_hi, p2_lo);\n    // ((Q(r^2) * r^2 + C) * r^2 + 1)\n    Packet p3_hi, p3_lo;\n    fast_twosum(one, p2_hi, p2_lo, p3_hi, p3_lo);\n\n    // log(z) ~= ((Q(r^2) * r^2 + C) * r^2 + 1) * r\n    twoprod(p3_hi, p3_lo, r_hi, r_lo, log2_x_hi, log2_x_lo);\n  }\n};\n\n// This function implements the non-trivial case of pow(x,y) where x is\n// positive and y is (possibly) non-integer.\n// Formally, pow(x,y) = exp2(y * log2(x)), where exp2(x) is shorthand for 2^x.\n// TODO(rmlarsen): We should probably add this as a packet up &#x27;ppow&#x27;, to make it\n// easier to specialize or turn off for specific types and/or backends.x\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_pow_impl(const Packet&amp; x, const Packet&amp; y) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  // Split x into exponent e_x and mantissa m_x.\n  Packet e_x;\n  Packet m_x = pfrexp(x, e_x);\n\n  // Adjust m_x to lie in [1/sqrt(2):sqrt(2)] to minimize absolute error in log2(m_x).\n  EIGEN_CONSTEXPR Scalar sqrt_half = Scalar(0.70710678118654752440);\n  const Packet m_x_scale_mask = pcmp_lt(m_x, pset1&lt;Packet&gt;(sqrt_half));\n  m_x = pselect(m_x_scale_mask, pmul(pset1&lt;Packet&gt;(Scalar(2)), m_x), m_x);\n  e_x = pselect(m_x_scale_mask, psub(e_x, pset1&lt;Packet&gt;(Scalar(1))), e_x);\n\n  // Compute log2(m_x) with 6 extra bits of accuracy.\n  Packet rx_hi, rx_lo;\n  accurate_log2&lt;Scalar&gt;()(m_x, rx_hi, rx_lo);\n\n  // Compute the two terms {y * e_x, y * r_x} in f = y * log2(x) with doubled\n  // precision using double word arithmetic.\n  Packet f1_hi, f1_lo, f2_hi, f2_lo;\n  twoprod(e_x, y, f1_hi, f1_lo);\n  twoprod(rx_hi, rx_lo, y, f2_hi, f2_lo);\n  // Sum the two terms in f using double word arithmetic. We know\n  // that |e_x| &gt; |log2(m_x)|, except for the case where e_x==0.\n  // This means that we can use fast_twosum(f1,f2).\n  // In the case e_x == 0, e_x * y = f1 = 0, so we don&#x27;t lose any\n  // accuracy by violating the assumption of fast_twosum, because\n  // it&#x27;s a no-op.\n  Packet f_hi, f_lo;\n  fast_twosum(f1_hi, f1_lo, f2_hi, f2_lo, f_hi, f_lo);\n\n  // Split f into integer and fractional parts.\n  Packet n_z, r_z;\n  absolute_split(f_hi, n_z, r_z);\n  r_z = padd(r_z, f_lo);\n  Packet n_r;\n  absolute_split(r_z, n_r, r_z);\n  n_z = padd(n_z, n_r);\n\n  // We now have an accurate split of f = n_z + r_z and can compute\n  //   x^y = 2**{n_z + r_z) = exp2(r_z) * 2**{n_z}.\n  // Multiplication by the second factor can be done exactly using pldexp(), since\n  // it is an integer power of 2.\n  const Packet e_r = generic_exp2(r_z);\n\n  // Since we know that e_r is in [1/sqrt(2); sqrt(2)], we can use the fast version\n  // of pldexp to multiply by 2**{n_z} when |n_z| is sufficiently small.\n  constexpr Scalar kPldExpThresh = std::numeric_limits&lt;Scalar&gt;::max_exponent - 2;\n  const Packet pldexp_fast_unsafe = pcmp_lt(pset1&lt;Packet&gt;(kPldExpThresh), pabs(n_z));\n  if (predux_any(pldexp_fast_unsafe)) {\n    return pldexp(e_r, n_z);\n  }\n  return pldexp_fast(e_r, n_z);\n}\n\n// Generic implementation of pow(x,y).\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_pow(const Packet&amp; x, const Packet&amp; y) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n\n  const Packet cst_inf = pset1&lt;Packet&gt;(NumTraits&lt;Scalar&gt;::infinity());\n  const Packet cst_zero = pset1&lt;Packet&gt;(Scalar(0));\n  const Packet cst_one = pset1&lt;Packet&gt;(Scalar(1));\n  const Packet cst_nan = pset1&lt;Packet&gt;(NumTraits&lt;Scalar&gt;::quiet_NaN());\n\n  const Packet x_abs = pabs(x);\n  Packet pow = generic_pow_impl(x_abs, y);\n\n  // In the following we enforce the special case handling prescribed in\n  // https://en.cppreference.com/w/cpp/numeric/math/pow.\n\n  // Predicates for sign and magnitude of x.\n  const Packet x_is_negative = pcmp_lt(x, cst_zero);\n  const Packet x_is_zero = pcmp_eq(x, cst_zero);\n  const Packet x_is_one = pcmp_eq(x, cst_one);\n  const Packet x_has_signbit = psignbit(x);\n  const Packet x_abs_gt_one = pcmp_lt(cst_one, x_abs);\n  const Packet x_abs_is_inf = pcmp_eq(x_abs, cst_inf);\n\n  // Predicates for sign and magnitude of y.\n  const Packet y_abs = pabs(y);\n  const Packet y_abs_is_inf = pcmp_eq(y_abs, cst_inf);\n  const Packet y_is_negative = pcmp_lt(y, cst_zero);\n  const Packet y_is_zero = pcmp_eq(y, cst_zero);\n  const Packet y_is_one = pcmp_eq(y, cst_one);\n  // Predicates for whether y is integer and odd/even.\n  const Packet y_is_int = pandnot(pcmp_eq(pfloor(y), y), y_abs_is_inf);\n  const Packet y_div_2 = pmul(y, pset1&lt;Packet&gt;(Scalar(0.5)));\n  const Packet y_is_even = pcmp_eq(pround(y_div_2), y_div_2);\n  const Packet y_is_odd_int = pandnot(y_is_int, y_is_even);\n  // Smallest exponent for which (1 + epsilon) overflows to infinity.\n  EIGEN_CONSTEXPR Scalar huge_exponent =\n      (NumTraits&lt;Scalar&gt;::max_exponent() * Scalar(EIGEN_LN2)) / NumTraits&lt;Scalar&gt;::epsilon();\n  const Packet y_abs_is_huge = pcmp_le(pset1&lt;Packet&gt;(huge_exponent), y_abs);\n\n  // *  pow(base, exp) returns NaN if base is finite and negative\n  //    and exp is finite and non-integer.\n  pow = pselect(pandnot(x_is_negative, y_is_int), cst_nan, pow);\n\n  // * pow(\u00b10, exp), where exp is negative, finite, and is an even integer or\n  // a non-integer, returns +\u221e\n  // * pow(\u00b10, exp), where exp is positive non-integer or a positive even\n  // integer, returns +0\n  // * pow(+0, exp), where exp is a negative odd integer, returns +\u221e\n  // * pow(-0, exp), where exp is a negative odd integer, returns -\u221e\n  // * pow(+0, exp), where exp is a positive odd integer, returns +0\n  // * pow(-0, exp), where exp is a positive odd integer, returns -0\n  // Sign is flipped by the rule below.\n  pow = pselect(x_is_zero, pselect(y_is_negative, cst_inf, cst_zero), pow);\n\n  // pow(base, exp) returns -pow(abs(base), exp) if base has the sign bit set,\n  // and exp is an odd integer exponent.\n  pow = pselect(pand(x_has_signbit, y_is_odd_int), pnegate(pow), pow);\n\n  // * pow(base, -\u221e) returns +\u221e for any |base|&lt;1\n  // * pow(base, -\u221e) returns +0 for any |base|&gt;1\n  // * pow(base, +\u221e) returns +0 for any |base|&lt;1\n  // * pow(base, +\u221e) returns +\u221e for any |base|&gt;1\n  // * pow(\u00b10, -\u221e) returns +\u221e\n  // * pow(-1, +-\u221e) = 1\n  Packet inf_y_val = pselect(por(pand(y_is_negative, x_is_zero), pxor(y_is_negative, x_abs_gt_one)), cst_inf, cst_zero);\n  inf_y_val = pselect(pcmp_eq(x, pset1&lt;Packet&gt;(Scalar(-1.0))), cst_one, inf_y_val);\n  pow = pselect(y_abs_is_huge, inf_y_val, pow);\n\n  // * pow(+\u221e, exp) returns +0 for any negative exp\n  // * pow(+\u221e, exp) returns +\u221e for any positive exp\n  // * pow(-\u221e, exp) returns -0 if exp is a negative odd integer.\n  // * pow(-\u221e, exp) returns +0 if exp is a negative non-integer or negative\n  //     even integer.\n  // * pow(-\u221e, exp) returns -\u221e if exp is a positive odd integer.\n  // * pow(-\u221e, exp) returns +\u221e if exp is a positive non-integer or positive\n  //     even integer.\n  auto x_pos_inf_value = pselect(y_is_negative, cst_zero, cst_inf);\n  auto x_neg_inf_value = pselect(y_is_odd_int, pnegate(x_pos_inf_value), x_pos_inf_value);\n  pow = pselect(x_abs_is_inf, pselect(x_is_negative, x_neg_inf_value, x_pos_inf_value), pow);\n\n  // All cases of NaN inputs return NaN, except the two below.\n  pow = pselect(por(pisnan(x), pisnan(y)), cst_nan, pow);\n\n  // * pow(base, 1) returns base.\n  // * pow(base, +/-0) returns 1, regardless of base, even NaN.\n  // * pow(+1, exp) returns 1, regardless of exponent, even NaN.\n  pow = pselect(y_is_one, x, pselect(por(x_is_one, y_is_zero), cst_one, pow));\n\n  return pow;\n}\n\nnamespace unary_pow {\n\ntemplate &lt;typename ScalarExponent, bool IsInteger = NumTraits&lt;ScalarExponent&gt;::IsInteger&gt;\nstruct exponent_helper {\n  using safe_abs_type = ScalarExponent;\n  static constexpr ScalarExponent one_half = ScalarExponent(0.5);\n  // these routines assume that exp is an integer stored as a floating point type\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ScalarExponent safe_abs(const ScalarExponent&amp; exp) {\n    return numext::abs(exp);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool is_odd(const ScalarExponent&amp; exp) {\n    eigen_assert(((numext::isfinite)(exp) &amp;&amp; exp == numext::floor(exp)) &amp;&amp; &quot;exp must be an integer&quot;);\n    ScalarExponent exp_div_2 = exp * one_half;\n    ScalarExponent floor_exp_div_2 = numext::floor(exp_div_2);\n    return exp_div_2 != floor_exp_div_2;\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ScalarExponent floor_div_two(const ScalarExponent&amp; exp) {\n    ScalarExponent exp_div_2 = exp * one_half;\n    return numext::floor(exp_div_2);\n  }\n};\n\ntemplate &lt;typename ScalarExponent&gt;\nstruct exponent_helper&lt;ScalarExponent, true&gt; {\n  // if `exp` is a signed integer type, cast it to its unsigned counterpart to safely store its absolute value\n  // consider the (rare) case where `exp` is an int32_t: abs(-2147483648) != 2147483648\n  using safe_abs_type = typename numext::get_integer_by_size&lt;sizeof(ScalarExponent)&gt;::unsigned_type;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE safe_abs_type safe_abs(const ScalarExponent&amp; exp) {\n    ScalarExponent mask = numext::signbit(exp);\n    safe_abs_type result = safe_abs_type(exp ^ mask);\n    return result + safe_abs_type(ScalarExponent(1) &amp; mask);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool is_odd(const safe_abs_type&amp; exp) {\n    return exp % safe_abs_type(2) != safe_abs_type(0);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE safe_abs_type floor_div_two(const safe_abs_type&amp; exp) {\n    return exp &gt;&gt; safe_abs_type(1);\n  }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent,\n          bool ReciprocateIfExponentIsNegative =\n              !NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger &amp;&amp; NumTraits&lt;ScalarExponent&gt;::IsSigned&gt;\nstruct reciprocate {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n    using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n    const Packet cst_pos_one = pset1&lt;Packet&gt;(Scalar(1));\n    return exponent &lt; 0 ? pdiv(cst_pos_one, x) : x;\n  }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent&gt;\nstruct reciprocate&lt;Packet, ScalarExponent, false&gt; {\n  // pdiv not defined, nor necessary for integer base types\n  // if the exponent is unsigned, then the exponent cannot be negative\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp;) { return x; }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet int_pow(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  using ExponentHelper = exponent_helper&lt;ScalarExponent&gt;;\n  using AbsExponentType = typename ExponentHelper::safe_abs_type;\n  const Packet cst_pos_one = pset1&lt;Packet&gt;(Scalar(1));\n  if (exponent == ScalarExponent(0)) return cst_pos_one;\n\n  Packet result = reciprocate&lt;Packet, ScalarExponent&gt;::run(x, exponent);\n  Packet y = cst_pos_one;\n  AbsExponentType m = ExponentHelper::safe_abs(exponent);\n\n  while (m &gt; 1) {\n    bool odd = ExponentHelper::is_odd(m);\n    if (odd) y = pmul(y, result);\n    result = pmul(result, result);\n    m = ExponentHelper::floor_div_two(m);\n  }\n\n  return pmul(y, result);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet gen_pow(const Packet&amp; x,\n                                                     const typename unpacket_traits&lt;Packet&gt;::type&amp; exponent) {\n  const Packet exponent_packet = pset1&lt;Packet&gt;(exponent);\n  return generic_pow_impl(x, exponent_packet);\n}\n\ntemplate &lt;typename Packet, typename ScalarExponent&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_nonint_nonint_errors(const Packet&amp; x, const Packet&amp; powx,\n                                                                         const ScalarExponent&amp; exponent) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n\n  // non-integer base and exponent case\n\n  const Scalar pos_zero = Scalar(0);\n  const Scalar all_ones = ptrue&lt;Scalar&gt;(Scalar());\n  const Scalar pos_one = Scalar(1);\n  const Scalar pos_inf = NumTraits&lt;Scalar&gt;::infinity();\n\n  const Packet cst_pos_zero = pzero(x);\n  const Packet cst_pos_one = pset1&lt;Packet&gt;(pos_one);\n  const Packet cst_pos_inf = pset1&lt;Packet&gt;(pos_inf);\n\n  const bool exponent_is_not_fin = !(numext::isfinite)(exponent);\n  const bool exponent_is_neg = exponent &lt; ScalarExponent(0);\n  const bool exponent_is_pos = exponent &gt; ScalarExponent(0);\n\n  const Packet exp_is_not_fin = pset1&lt;Packet&gt;(exponent_is_not_fin ? all_ones : pos_zero);\n  const Packet exp_is_neg = pset1&lt;Packet&gt;(exponent_is_neg ? all_ones : pos_zero);\n  const Packet exp_is_pos = pset1&lt;Packet&gt;(exponent_is_pos ? all_ones : pos_zero);\n  const Packet exp_is_inf = pand(exp_is_not_fin, por(exp_is_neg, exp_is_pos));\n  const Packet exp_is_nan = pandnot(exp_is_not_fin, por(exp_is_neg, exp_is_pos));\n\n  const Packet x_is_le_zero = pcmp_le(x, cst_pos_zero);\n  const Packet x_is_ge_zero = pcmp_le(cst_pos_zero, x);\n  const Packet x_is_zero = pand(x_is_le_zero, x_is_ge_zero);\n\n  const Packet abs_x = pabs(x);\n  const Packet abs_x_is_le_one = pcmp_le(abs_x, cst_pos_one);\n  const Packet abs_x_is_ge_one = pcmp_le(cst_pos_one, abs_x);\n  const Packet abs_x_is_inf = pcmp_eq(abs_x, cst_pos_inf);\n  const Packet abs_x_is_one = pand(abs_x_is_le_one, abs_x_is_ge_one);\n\n  Packet pow_is_inf_if_exp_is_neg = por(x_is_zero, pand(abs_x_is_le_one, exp_is_inf));\n  Packet pow_is_inf_if_exp_is_pos = por(abs_x_is_inf, pand(abs_x_is_ge_one, exp_is_inf));\n  Packet pow_is_one = pand(abs_x_is_one, por(exp_is_inf, x_is_ge_zero));\n\n  Packet result = powx;\n  result = por(x_is_le_zero, result);\n  result = pselect(pow_is_inf_if_exp_is_neg, pand(cst_pos_inf, exp_is_neg), result);\n  result = pselect(pow_is_inf_if_exp_is_pos, pand(cst_pos_inf, exp_is_pos), result);\n  result = por(exp_is_nan, result);\n  result = pselect(pow_is_one, cst_pos_one, result);\n  return result;\n}\n\ntemplate &lt;typename Packet, typename ScalarExponent,\n          std::enable_if_t&lt;NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsSigned, bool&gt; = true&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_negative_exponent(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n\n  // signed integer base, signed integer exponent case\n\n  // This routine handles negative exponents.\n  // The return value is either 0, 1, or -1.\n\n  const Scalar pos_zero = Scalar(0);\n  const Scalar all_ones = ptrue&lt;Scalar&gt;(Scalar());\n  const Scalar pos_one = Scalar(1);\n\n  const Packet cst_pos_one = pset1&lt;Packet&gt;(pos_one);\n\n  const bool exponent_is_odd = exponent % ScalarExponent(2) != ScalarExponent(0);\n\n  const Packet exp_is_odd = pset1&lt;Packet&gt;(exponent_is_odd ? all_ones : pos_zero);\n\n  const Packet abs_x = pabs(x);\n  const Packet abs_x_is_one = pcmp_eq(abs_x, cst_pos_one);\n\n  Packet result = pselect(exp_is_odd, x, abs_x);\n  result = pand(abs_x_is_one, result);\n  return result;\n}\n\ntemplate &lt;typename Packet, typename ScalarExponent,\n          std::enable_if_t&lt;!NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsSigned, bool&gt; = true&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet handle_negative_exponent(const Packet&amp; x, const ScalarExponent&amp;) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n\n  // unsigned integer base, signed integer exponent case\n\n  // This routine handles negative exponents.\n  // The return value is either 0 or 1\n\n  const Scalar pos_one = Scalar(1);\n\n  const Packet cst_pos_one = pset1&lt;Packet&gt;(pos_one);\n\n  const Packet x_is_one = pcmp_eq(x, cst_pos_one);\n\n  return pand(x_is_one, x);\n}\n\n}  // end namespace unary_pow\n\ntemplate &lt;typename Packet, typename ScalarExponent,\n          bool BaseIsIntegerType = NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger,\n          bool ExponentIsIntegerType = NumTraits&lt;ScalarExponent&gt;::IsInteger,\n          bool ExponentIsSigned = NumTraits&lt;ScalarExponent&gt;::IsSigned&gt;\nstruct unary_pow_impl;\n\ntemplate &lt;typename Packet, typename ScalarExponent, bool ExponentIsSigned&gt;\nstruct unary_pow_impl&lt;Packet, ScalarExponent, false, false, ExponentIsSigned&gt; {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n    const bool exponent_is_integer = (numext::isfinite)(exponent) &amp;&amp; numext::round(exponent) == exponent;\n    if (exponent_is_integer) {\n      // The simple recursive doubling implementation is only accurate to 3 ulps\n      // for integer exponents in [-3:7]. Since this is a common case, we\n      // specialize it here.\n      bool use_repeated_squaring =\n          (exponent &lt;= ScalarExponent(7) &amp;&amp; (!ExponentIsSigned || exponent &gt;= ScalarExponent(-3)));\n      return use_repeated_squaring ? unary_pow::int_pow(x, exponent) : generic_pow(x, pset1&lt;Packet&gt;(exponent));\n    } else {\n      Packet result = unary_pow::gen_pow(x, exponent);\n      result = unary_pow::handle_nonint_nonint_errors(x, result, exponent);\n      return result;\n    }\n  }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent, bool ExponentIsSigned&gt;\nstruct unary_pow_impl&lt;Packet, ScalarExponent, false, true, ExponentIsSigned&gt; {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n    return unary_pow::int_pow(x, exponent);\n  }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent&gt;\nstruct unary_pow_impl&lt;Packet, ScalarExponent, true, true, true&gt; {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n    if (exponent &lt; ScalarExponent(0)) {\n      return unary_pow::handle_negative_exponent(x, exponent);\n    } else {\n      return unary_pow::int_pow(x, exponent);\n    }\n  }\n};\n\ntemplate &lt;typename Packet, typename ScalarExponent&gt;\nstruct unary_pow_impl&lt;Packet, ScalarExponent, true, true, false&gt; {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; x, const ScalarExponent&amp; exponent) {\n    return unary_pow::int_pow(x, exponent);\n  }\n};\n\n// This function computes exp2(x) = exp(ln(2) * x).\n// To improve accuracy, the product ln(2)*x is computed using the twoprod\n// algorithm, such that ln(2) * x = p_hi + p_lo holds exactly. Then exp2(x) is\n// computed as exp2(x) = exp(p_hi) * exp(p_lo) ~= exp(p_hi) * (1 + p_lo). This\n// correction step this reduces the maximum absolute error as follows:\n//\n// type   | max error (simple product) | max error (twoprod) |\n// -----------------------------------------------------------\n// float  |       35 ulps              |       4 ulps        |\n// double |      363 ulps              |     110 ulps        |\n//\ntemplate &lt;typename Packet&gt;\nEIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet generic_exp2(const Packet&amp; _x) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  constexpr int max_exponent = std::numeric_limits&lt;Scalar&gt;::max_exponent;\n  constexpr int digits = std::numeric_limits&lt;Scalar&gt;::digits;\n  constexpr Scalar max_cap = Scalar(max_exponent + 1);\n  constexpr Scalar min_cap = -Scalar(max_exponent + digits - 1);\n  Packet x = pmax(pmin(_x, pset1&lt;Packet&gt;(max_cap)), pset1&lt;Packet&gt;(min_cap));\n  Packet p_hi, p_lo;\n  twoprod(pset1&lt;Packet&gt;(Scalar(EIGEN_LN2)), x, p_hi, p_lo);\n  Packet exp2_hi = pexp(p_hi);\n  Packet exp2_lo = padd(pset1&lt;Packet&gt;(Scalar(1)), p_lo);\n  return pmul(exp2_hi, exp2_lo);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_rint(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  using IntType = typename numext::get_integer_by_size&lt;sizeof(Scalar)&gt;::signed_type;\n  // Adds and subtracts signum(a) * 2^kMantissaBits to force rounding.\n  const IntType kLimit = IntType(1) &lt;&lt; (NumTraits&lt;Scalar&gt;::digits() - 1);\n  const Packet cst_limit = pset1&lt;Packet&gt;(static_cast&lt;Scalar&gt;(kLimit));\n  Packet abs_a = pabs(a);\n  Packet sign_a = pandnot(a, abs_a);\n  Packet rint_a = padd(abs_a, cst_limit);\n  // Don&#x27;t compile-away addition and subtraction.\n  EIGEN_OPTIMIZATION_BARRIER(rint_a);\n  rint_a = psub(rint_a, cst_limit);\n  rint_a = por(rint_a, sign_a);\n  // If greater than limit (or NaN), simply return a.\n  Packet mask = pcmp_lt(abs_a, cst_limit);\n  Packet result = pselect(mask, rint_a, a);\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_floor(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  const Packet cst_1 = pset1&lt;Packet&gt;(Scalar(1));\n  Packet rint_a = generic_rint(a);\n  // if a &lt; rint(a), then rint(a) == ceil(a)\n  Packet mask = pcmp_lt(a, rint_a);\n  Packet offset = pand(cst_1, mask);\n  Packet result = psub(rint_a, offset);\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_ceil(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  const Packet cst_1 = pset1&lt;Packet&gt;(Scalar(1));\n  const Packet sign_mask = pset1&lt;Packet&gt;(static_cast&lt;Scalar&gt;(-0.0));\n  Packet rint_a = generic_rint(a);\n  // if rint(a) &lt; a, then rint(a) == floor(a)\n  Packet mask = pcmp_lt(rint_a, a);\n  Packet offset = pand(cst_1, mask);\n  Packet result = padd(rint_a, offset);\n  // Signed zero must remain signed (e.g. ceil(-0.02) == -0).\n  result = por(result, pand(sign_mask, a));\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_trunc(const Packet&amp; a) {\n  Packet abs_a = pabs(a);\n  Packet sign_a = pandnot(a, abs_a);\n  Packet floor_abs_a = generic_floor(abs_a);\n  Packet result = por(floor_abs_a, sign_a);\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet generic_round(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  const Packet cst_half = pset1&lt;Packet&gt;(Scalar(0.5));\n  const Packet cst_1 = pset1&lt;Packet&gt;(Scalar(1));\n  Packet abs_a = pabs(a);\n  Packet sign_a = pandnot(a, abs_a);\n  Packet floor_abs_a = generic_floor(abs_a);\n  Packet diff = psub(abs_a, floor_abs_a);\n  Packet mask = pcmp_le(cst_half, diff);\n  Packet offset = pand(cst_1, mask);\n  Packet result = padd(floor_abs_a, offset);\n  result = por(result, sign_a);\n  return result;\n}\n\ntemplate &lt;typename Packet&gt;\nstruct nearest_integer_packetop_impl&lt;Packet, /*IsScalar*/ false, /*IsInteger*/ false&gt; {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  static_assert(packet_traits&lt;Scalar&gt;::HasRound, &quot;Generic nearest integer functions are disabled for this type.&quot;);\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet&amp; x) { return generic_floor(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet&amp; x) { return generic_ceil(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet&amp; x) { return generic_rint(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet&amp; x) { return generic_round(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet&amp; x) { return generic_trunc(x); }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct nearest_integer_packetop_impl&lt;Packet, /*IsScalar*/ false, /*IsInteger*/ true&gt; {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet&amp; x) { return x; }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet&amp; x) { return x; }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet&amp; x) { return x; }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet&amp; x) { return x; }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet&amp; x) { return x; }\n};\n\n}  // end namespace internal\n}  // end namespace Eigen\n\n#endif  // EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n//\n// The conversion routines are Copyright (c) Fabian Giesen, 2016.\n// The original license follows:\n//\n// Copyright (c) Fabian Giesen, 2016\n// All rights reserved.\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted.\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n// Standard 16-bit float type, mostly useful for GPUs. Defines a new\n// type Eigen::half (inheriting either from CUDA&#x27;s or HIP&#x27;s __half struct) with\n// operator overloads such that it behaves basically as an arithmetic\n// type. It will be quite slow on CPUs (so it is recommended to stay\n// in fp32 for CPUs, except for simple parameter conversions, I/O\n// to disk and the likes), but fast on GPUs.\n\n#ifndef EIGEN_HALF_H\n#define EIGEN_HALF_H\n\n// IWYU pragma: private\n#include &quot;../../InternalHeaderCheck.h&quot;\n\n// When compiling with GPU support, the &quot;__half_raw&quot; base class as well as\n// some other routines are defined in the GPU compiler header files\n// (cuda_fp16.h, hip_fp16.h), and they are not tagged constexpr\n// As a consequence, we get compile failures when compiling Eigen with\n// GPU support. Hence the need to disable EIGEN_CONSTEXPR when building\n// Eigen with GPU support.\n// Any functions that require `numext::bit_cast` may also not be constexpr,\n// including any native types when setting via raw bit values.\n#if defined(EIGEN_HAS_GPU_FP16) || defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) || defined(EIGEN_HAS_BUILTIN_FLOAT16)\n#define _EIGEN_MAYBE_CONSTEXPR\n#else\n#define _EIGEN_MAYBE_CONSTEXPR constexpr\n#endif\n\n#define F16_PACKET_FUNCTION(PACKET_F, PACKET_F16, METHOD)                                                  \\\n  template &lt;&gt;                                                                                              \\\n  EIGEN_UNUSED EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC PACKET_F16 METHOD&lt;PACKET_F16&gt;(const PACKET_F16&amp; _x) { \\\n    return float2half(METHOD&lt;PACKET_F&gt;(half2float(_x)));                                                   \\\n  }\n\nnamespace Eigen {\n\nstruct half;\n\nnamespace half_impl {\n\n// We want to use the __half_raw struct from the HIP header file only during the device compile phase.\n// This is required because of a quirk in the way TensorFlow GPU builds are done.\n// When compiling TensorFlow source code with GPU support, files that\n//  * contain GPU kernels (i.e. *.cu.cc files) are compiled via hipcc\n//  * do not contain GPU kernels ( i.e. *.cc files) are compiled via gcc (typically)\n//\n// Tensorflow uses the Eigen::half type as its FP16 type, and there are functions that\n//  * are defined in a file that gets compiled via hipcc AND\n//  * have Eigen::half as a pass-by-value argument AND\n//  * are called in a file that gets compiled via gcc\n//\n// In the scenario described above the caller and callee will see different versions\n// of the Eigen::half base class __half_raw, and they will be compiled by different compilers\n//\n// There appears to be an ABI mismatch between gcc and clang (which is called by hipcc) that results in\n// the callee getting corrupted values for the Eigen::half argument.\n//\n// Making the host side compile phase of hipcc use the same Eigen::half impl, as the gcc compile, resolves\n// this error, and hence the following convoluted #if condition\n#if !defined(EIGEN_HAS_GPU_FP16) || !defined(EIGEN_GPU_COMPILE_PHASE)\n\n// Make our own __half_raw definition that is similar to CUDA&#x27;s.\nstruct __half_raw {\n  struct construct_from_rep_tag {};\n#if (defined(EIGEN_HAS_GPU_FP16) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE))\n  // Eigen::half can be used as the datatype for shared memory declarations (in Eigen and TF)\n  // The element type for shared memory cannot have non-trivial constructors\n  // and hence the following special casing (which skips the zero-initilization).\n  // Note that this check gets done even in the host compilation phase, and\n  // hence the need for this\n  EIGEN_DEVICE_FUNC __half_raw() {}\n#else\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR __half_raw() : x(0) {}\n#endif\n\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  explicit EIGEN_DEVICE_FUNC __half_raw(numext::uint16_t raw) : x(numext::bit_cast&lt;__fp16&gt;(raw)) {}\n  EIGEN_DEVICE_FUNC constexpr __half_raw(construct_from_rep_tag, __fp16 rep) : x{rep} {}\n  __fp16 x;\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  explicit EIGEN_DEVICE_FUNC __half_raw(numext::uint16_t raw) : x(numext::bit_cast&lt;_Float16&gt;(raw)) {}\n  EIGEN_DEVICE_FUNC constexpr __half_raw(construct_from_rep_tag, _Float16 rep) : x{rep} {}\n  _Float16 x;\n#else\n  explicit EIGEN_DEVICE_FUNC constexpr __half_raw(numext::uint16_t raw) : x(raw) {}\n  EIGEN_DEVICE_FUNC constexpr __half_raw(construct_from_rep_tag, numext::uint16_t rep) : x{rep} {}\n  numext::uint16_t x;\n#endif\n};\n\n#elif defined(EIGEN_HAS_HIP_FP16)\n// HIP GPU compile phase: nothing to do here.\n// HIP fp16 header file has a definition for __half_raw\n#elif defined(EIGEN_HAS_CUDA_FP16)\n\n// CUDA GPU compile phase.\n#if EIGEN_CUDA_SDK_VER &lt; 90000\n// In CUDA &lt; 9.0, __half is the equivalent of CUDA 9&#x27;s __half_raw\ntypedef __half __half_raw;\n#endif  // defined(EIGEN_HAS_CUDA_FP16)\n\n#elif defined(SYCL_DEVICE_ONLY)\ntypedef cl::sycl::half __half_raw;\n#endif\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR __half_raw raw_uint16_to_half(numext::uint16_t x);\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __half_raw float_to_half_rtne(float ff);\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float half_to_float(__half_raw h);\n\nstruct half_base : public __half_raw {\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half_base() {}\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half_base(const __half_raw&amp; h) : __half_raw(h) {}\n\n#if defined(EIGEN_HAS_GPU_FP16)\n#if defined(EIGEN_HAS_HIP_FP16)\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half_base(const __half&amp; h) { x = __half_as_ushort(h); }\n#elif defined(EIGEN_HAS_CUDA_FP16)\n#if EIGEN_CUDA_SDK_VER &gt;= 90000\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half_base(const __half&amp; h) : __half_raw(*(__half_raw*)&amp;h) {}\n#endif\n#endif\n#endif\n};\n\n}  // namespace half_impl\n\n// Class definition.\nstruct half : public half_impl::half_base {\n  // Writing this out as separate #if-else blocks to make the code easier to follow\n  // The same applies to most #if-else blocks in this file\n#if !defined(EIGEN_HAS_GPU_FP16) || !defined(EIGEN_GPU_COMPILE_PHASE)\n  // Use the same base class for the following two scenarios\n  // * when compiling without GPU support enabled\n  // * during host compile phase when compiling with GPU support enabled\n  typedef half_impl::__half_raw __half_raw;\n#elif defined(EIGEN_HAS_HIP_FP16)\n  // Nothing to do here\n  // HIP fp16 header file has a definition for __half_raw\n#elif defined(EIGEN_HAS_CUDA_FP16)\n// Note that EIGEN_CUDA_SDK_VER is set to 0 even when compiling with HIP, so\n// (EIGEN_CUDA_SDK_VER &lt; 90000) is true even for HIP!  So keeping this within\n// #if defined(EIGEN_HAS_CUDA_FP16) is needed\n#if defined(EIGEN_CUDA_SDK_VER) &amp;&amp; EIGEN_CUDA_SDK_VER &lt; 90000\n  typedef half_impl::__half_raw __half_raw;\n#endif\n#endif\n\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half() {}\n\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(const __half_raw&amp; h) : half_impl::half_base(h) {}\n\n#if defined(EIGEN_HAS_GPU_FP16)\n#if defined(EIGEN_HAS_HIP_FP16)\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(const __half&amp; h) : half_impl::half_base(h) {}\n#elif defined(EIGEN_HAS_CUDA_FP16)\n#if defined(EIGEN_CUDA_SDK_VER) &amp;&amp; EIGEN_CUDA_SDK_VER &gt;= 90000\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(const __half&amp; h) : half_impl::half_base(h) {}\n#endif\n#endif\n#endif\n\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  explicit EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(__fp16 b)\n      : half(__half_raw(__half_raw::construct_from_rep_tag(), b)) {}\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  explicit EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(_Float16 b)\n      : half(__half_raw(__half_raw::construct_from_rep_tag(), b)) {}\n#endif\n\n  explicit EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR half(bool b)\n      : half_impl::half_base(half_impl::raw_uint16_to_half(b ? 0x3c00 : 0)) {}\n  template &lt;class T&gt;\n  explicit EIGEN_DEVICE_FUNC half(T val)\n      : half_impl::half_base(half_impl::float_to_half_rtne(static_cast&lt;float&gt;(val))) {}\n  explicit EIGEN_DEVICE_FUNC half(float f) : half_impl::half_base(half_impl::float_to_half_rtne(f)) {}\n\n  // Following the convention of numpy, converting between complex and\n  // float will lead to loss of imag value.\n  template &lt;typename RealScalar&gt;\n  explicit EIGEN_DEVICE_FUNC half(std::complex&lt;RealScalar&gt; c)\n      : half_impl::half_base(half_impl::float_to_half_rtne(static_cast&lt;float&gt;(c.real()))) {}\n\n  EIGEN_DEVICE_FUNC operator float() const {  // NOLINT: Allow implicit conversion to float, because it is lossless.\n    return half_impl::half_to_float(*this);\n  }\n\n#if defined(EIGEN_HAS_GPU_FP16) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\n  EIGEN_DEVICE_FUNC operator __half() const {\n    ::__half_raw hr;\n    hr.x = x;\n    return __half(hr);\n  }\n#endif\n};\n\n// TODO(majnemer): Get rid of this once we can rely on C++17 inline variables do\n// solve the ODR issue.\nnamespace half_impl {\ntemplate &lt;typename = void&gt;\nstruct numeric_limits_half_impl {\n  static constexpr const bool is_specialized = true;\n  static constexpr const bool is_signed = true;\n  static constexpr const bool is_integer = false;\n  static constexpr const bool is_exact = false;\n  static constexpr const bool has_infinity = true;\n  static constexpr const bool has_quiet_NaN = true;\n  static constexpr const bool has_signaling_NaN = true;\n  EIGEN_DIAGNOSTICS(push)\n  EIGEN_DISABLE_DEPRECATED_WARNING\n  static constexpr const std::float_denorm_style has_denorm = std::denorm_present;\n  static constexpr const bool has_denorm_loss = false;\n  EIGEN_DIAGNOSTICS(pop)\n  static constexpr const std::float_round_style round_style = std::round_to_nearest;\n  static constexpr const bool is_iec559 = true;\n  // The C++ standard defines this as &quot;true if the set of values representable\n  // by the type is finite.&quot; Half has finite precision.\n  static constexpr const bool is_bounded = true;\n  static constexpr const bool is_modulo = false;\n  static constexpr const int digits = 11;\n  static constexpr const int digits10 =\n      3;  // according to http://half.sourceforge.net/structstd_1_1numeric__limits_3_01half__float_1_1half_01_4.html\n  static constexpr const int max_digits10 =\n      5;  // according to http://half.sourceforge.net/structstd_1_1numeric__limits_3_01half__float_1_1half_01_4.html\n  static constexpr const int radix = std::numeric_limits&lt;float&gt;::radix;\n  static constexpr const int min_exponent = -13;\n  static constexpr const int min_exponent10 = -4;\n  static constexpr const int max_exponent = 16;\n  static constexpr const int max_exponent10 = 4;\n  static constexpr const bool traps = std::numeric_limits&lt;float&gt;::traps;\n  // IEEE754: &quot;The implementer shall choose how tininess is detected, but shall\n  // detect tininess in the same way for all operations in radix two&quot;\n  static constexpr const bool tinyness_before = std::numeric_limits&lt;float&gt;::tinyness_before;\n\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half(min)() { return Eigen::half_impl::raw_uint16_to_half(0x0400); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half lowest() { return Eigen::half_impl::raw_uint16_to_half(0xfbff); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half(max)() { return Eigen::half_impl::raw_uint16_to_half(0x7bff); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half epsilon() { return Eigen::half_impl::raw_uint16_to_half(0x1400); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half round_error() { return Eigen::half_impl::raw_uint16_to_half(0x3800); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half infinity() { return Eigen::half_impl::raw_uint16_to_half(0x7c00); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half quiet_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7e00); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half signaling_NaN() { return Eigen::half_impl::raw_uint16_to_half(0x7d00); }\n  static _EIGEN_MAYBE_CONSTEXPR Eigen::half denorm_min() { return Eigen::half_impl::raw_uint16_to_half(0x0001); }\n};\n\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_specialized;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_signed;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_integer;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_exact;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::has_infinity;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::has_quiet_NaN;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::has_signaling_NaN;\nEIGEN_DIAGNOSTICS(push)\nEIGEN_DISABLE_DEPRECATED_WARNING\ntemplate &lt;typename T&gt;\nconstexpr const std::float_denorm_style numeric_limits_half_impl&lt;T&gt;::has_denorm;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::has_denorm_loss;\nEIGEN_DIAGNOSTICS(pop)\ntemplate &lt;typename T&gt;\nconstexpr const std::float_round_style numeric_limits_half_impl&lt;T&gt;::round_style;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_iec559;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_bounded;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::is_modulo;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::digits;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::digits10;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::max_digits10;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::radix;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::min_exponent;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::min_exponent10;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::max_exponent;\ntemplate &lt;typename T&gt;\nconstexpr const int numeric_limits_half_impl&lt;T&gt;::max_exponent10;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::traps;\ntemplate &lt;typename T&gt;\nconstexpr const bool numeric_limits_half_impl&lt;T&gt;::tinyness_before;\n}  // end namespace half_impl\n}  // end namespace Eigen\n\nnamespace std {\n// If std::numeric_limits&lt;T&gt; is specialized, should also specialize\n// std::numeric_limits&lt;const T&gt;, std::numeric_limits&lt;volatile T&gt;, and\n// std::numeric_limits&lt;const volatile T&gt;\n// https://stackoverflow.com/a/16519653/\ntemplate &lt;&gt;\nclass numeric_limits&lt;Eigen::half&gt; : public Eigen::half_impl::numeric_limits_half_impl&lt;&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;const Eigen::half&gt; : public numeric_limits&lt;Eigen::half&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;volatile Eigen::half&gt; : public numeric_limits&lt;Eigen::half&gt; {};\ntemplate &lt;&gt;\nclass numeric_limits&lt;const volatile Eigen::half&gt; : public numeric_limits&lt;Eigen::half&gt; {};\n}  // end namespace std\n\nnamespace Eigen {\n\nnamespace half_impl {\n\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 530) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(HIP_DEVICE_COMPILE))\n// Note: We deliberately do *not* define this to 1 even if we have Arm&#x27;s native\n// fp16 type since GPU half types are rather different from native CPU half types.\n#define EIGEN_HAS_NATIVE_GPU_FP16\n#endif\n\n// Intrinsics for native fp16 support. Note that on current hardware,\n// these are no faster than fp32 arithmetic (you need to use the half2\n// versions to get the ALU speed increased), but you do save the\n// conversion steps back and forth.\n\n#if defined(EIGEN_HAS_NATIVE_GPU_FP16)\nEIGEN_STRONG_INLINE __device__ half operator+(const half&amp; a, const half&amp; b) {\n#if defined(EIGEN_CUDA_SDK_VER) &amp;&amp; EIGEN_CUDA_SDK_VER &gt;= 90000\n  return __hadd(::__half(a), ::__half(b));\n#else\n  return __hadd(a, b);\n#endif\n}\nEIGEN_STRONG_INLINE __device__ half operator*(const half&amp; a, const half&amp; b) { return __hmul(a, b); }\nEIGEN_STRONG_INLINE __device__ half operator-(const half&amp; a, const half&amp; b) { return __hsub(a, b); }\nEIGEN_STRONG_INLINE __device__ half operator/(const half&amp; a, const half&amp; b) {\n#if defined(EIGEN_CUDA_SDK_VER) &amp;&amp; EIGEN_CUDA_SDK_VER &gt;= 90000\n  return __hdiv(a, b);\n#else\n  float num = __half2float(a);\n  float denom = __half2float(b);\n  return __float2half(num / denom);\n#endif\n}\nEIGEN_STRONG_INLINE __device__ half operator-(const half&amp; a) { return __hneg(a); }\nEIGEN_STRONG_INLINE __device__ half&amp; operator+=(half&amp; a, const half&amp; b) {\n  a = a + b;\n  return a;\n}\nEIGEN_STRONG_INLINE __device__ half&amp; operator*=(half&amp; a, const half&amp; b) {\n  a = a * b;\n  return a;\n}\nEIGEN_STRONG_INLINE __device__ half&amp; operator-=(half&amp; a, const half&amp; b) {\n  a = a - b;\n  return a;\n}\nEIGEN_STRONG_INLINE __device__ half&amp; operator/=(half&amp; a, const half&amp; b) {\n  a = a / b;\n  return a;\n}\nEIGEN_STRONG_INLINE __device__ bool operator==(const half&amp; a, const half&amp; b) { return __heq(a, b); }\nEIGEN_STRONG_INLINE __device__ bool operator!=(const half&amp; a, const half&amp; b) { return __hne(a, b); }\nEIGEN_STRONG_INLINE __device__ bool operator&lt;(const half&amp; a, const half&amp; b) { return __hlt(a, b); }\nEIGEN_STRONG_INLINE __device__ bool operator&lt;=(const half&amp; a, const half&amp; b) { return __hle(a, b); }\nEIGEN_STRONG_INLINE __device__ bool operator&gt;(const half&amp; a, const half&amp; b) { return __hgt(a, b); }\nEIGEN_STRONG_INLINE __device__ bool operator&gt;=(const half&amp; a, const half&amp; b) { return __hge(a, b); }\n\n#endif  // EIGEN_HAS_NATIVE_GPU_FP16\n\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator+(const half&amp; a, const half&amp; b) { return half(vaddh_f16(a.x, b.x)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator*(const half&amp; a, const half&amp; b) { return half(vmulh_f16(a.x, b.x)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a, const half&amp; b) { return half(vsubh_f16(a.x, b.x)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half&amp; a, const half&amp; b) { return half(vdivh_f16(a.x, b.x)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a) { return half(vnegh_f16(a.x)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator+=(half&amp; a, const half&amp; b) {\n  a = half(vaddh_f16(a.x, b.x));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator*=(half&amp; a, const half&amp; b) {\n  a = half(vmulh_f16(a.x, b.x));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator-=(half&amp; a, const half&amp; b) {\n  a = half(vsubh_f16(a.x, b.x));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator/=(half&amp; a, const half&amp; b) {\n  a = half(vdivh_f16(a.x, b.x));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const half&amp; a, const half&amp; b) { return vceqh_f16(a.x, b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const half&amp; a, const half&amp; b) { return !vceqh_f16(a.x, b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;(const half&amp; a, const half&amp; b) { return vclth_f16(a.x, b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;=(const half&amp; a, const half&amp; b) { return vcleh_f16(a.x, b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;(const half&amp; a, const half&amp; b) { return vcgth_f16(a.x, b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;=(const half&amp; a, const half&amp; b) { return vcgeh_f16(a.x, b.x); }\n\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16) &amp;&amp; !defined(EIGEN_GPU_COMPILE_PHASE)\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator+(const half&amp; a, const half&amp; b) { return half(a.x + b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator*(const half&amp; a, const half&amp; b) { return half(a.x * b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a, const half&amp; b) { return half(a.x - b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half&amp; a, const half&amp; b) { return half(a.x / b.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a) { return half(-a.x); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator+=(half&amp; a, const half&amp; b) {\n  a = a + b;\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator*=(half&amp; a, const half&amp; b) {\n  a = a * b;\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator-=(half&amp; a, const half&amp; b) {\n  a = a - b;\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator/=(half&amp; a, const half&amp; b) {\n  a = a / b;\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const half&amp; a, const half&amp; b) { return a.x == b.x; }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const half&amp; a, const half&amp; b) { return a.x != b.x; }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;(const half&amp; a, const half&amp; b) { return a.x &lt; b.x; }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;=(const half&amp; a, const half&amp; b) { return a.x &lt;= b.x; }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;(const half&amp; a, const half&amp; b) { return a.x &gt; b.x; }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;=(const half&amp; a, const half&amp; b) { return a.x &gt;= b.x; }\n\n// We need to distinguish \u2018clang as the CUDA compiler\u2019 from \u2018clang as the host compiler,\n// invoked by NVCC\u2019 (e.g. on MacOS). The former needs to see both host and device implementation\n// of the functions, while the latter can only deal with one of them.\n#elif !defined(EIGEN_HAS_NATIVE_GPU_FP16) || (EIGEN_COMP_CLANG &amp;&amp; !EIGEN_COMP_NVCC)  // Emulate support for half floats\n\n#if EIGEN_COMP_CLANG &amp;&amp; defined(EIGEN_GPUCC)\n// We need to provide emulated *host-side* FP16 operators for clang.\n#pragma push_macro(&quot;EIGEN_DEVICE_FUNC&quot;)\n#undef EIGEN_DEVICE_FUNC\n#if defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_HAS_NATIVE_GPU_FP16)\n#define EIGEN_DEVICE_FUNC __host__\n#else  // both host and device need emulated ops.\n#define EIGEN_DEVICE_FUNC __host__ __device__\n#endif\n#endif\n\n// Definitions for CPUs and older HIP+CUDA, mostly working through conversion\n// to/from fp32.\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator+(const half&amp; a, const half&amp; b) { return half(float(a) + float(b)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator*(const half&amp; a, const half&amp; b) { return half(float(a) * float(b)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a, const half&amp; b) { return half(float(a) - float(b)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half&amp; a, const half&amp; b) { return half(float(a) / float(b)); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator-(const half&amp; a) {\n  half result;\n  result.x = a.x ^ 0x8000;\n  return result;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator+=(half&amp; a, const half&amp; b) {\n  a = half(float(a) + float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator*=(half&amp; a, const half&amp; b) {\n  a = half(float(a) * float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator-=(half&amp; a, const half&amp; b) {\n  a = half(float(a) - float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half&amp; operator/=(half&amp; a, const half&amp; b) {\n  a = half(float(a) / float(b));\n  return a;\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator==(const half&amp; a, const half&amp; b) {\n  return numext::equal_strict(float(a), float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator!=(const half&amp; a, const half&amp; b) {\n  return numext::not_equal_strict(float(a), float(b));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;(const half&amp; a, const half&amp; b) { return float(a) &lt; float(b); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&lt;=(const half&amp; a, const half&amp; b) { return float(a) &lt;= float(b); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;(const half&amp; a, const half&amp; b) { return float(a) &gt; float(b); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool operator&gt;=(const half&amp; a, const half&amp; b) { return float(a) &gt;= float(b); }\n\n#if EIGEN_COMP_CLANG &amp;&amp; defined(EIGEN_GPUCC)\n#pragma pop_macro(&quot;EIGEN_DEVICE_FUNC&quot;)\n#endif\n\n#endif  // Emulate support for half floats\n\n// Division by an index. Do it in full float precision to avoid accuracy\n// issues in converting the denominator to half.\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator/(const half&amp; a, Index b) {\n  return half(static_cast&lt;float&gt;(a) / static_cast&lt;float&gt;(b));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator++(half&amp; a) {\n  a += half(1);\n  return a;\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator--(half&amp; a) {\n  a -= half(1);\n  return a;\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator++(half&amp; a, int) {\n  half original_value = a;\n  ++a;\n  return original_value;\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half operator--(half&amp; a, int) {\n  half original_value = a;\n  --a;\n  return original_value;\n}\n\n// Conversion routines, including fallbacks for the host or older CUDA.\n// Note that newer Intel CPUs (Haswell or newer) have vectorized versions of\n// these in hardware. If we need more performance on older/other CPUs, they are\n// also possible to vectorize directly.\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR __half_raw raw_uint16_to_half(numext::uint16_t x) {\n  // We cannot simply do a &quot;return __half_raw(x)&quot; here, because __half_raw is union type\n  // in the hip_fp16 header file, and that will trigger a compile error\n  // On the other hand, having anything but a return statement also triggers a compile error\n  // because this is constexpr function.\n  // Fortunately, since we need to disable EIGEN_CONSTEXPR for GPU anyway, we can get out\n  // of this catch22 by having separate bodies for GPU / non GPU\n#if defined(EIGEN_HAS_GPU_FP16)\n  __half_raw h;\n  h.x = x;\n  return h;\n#else\n  return __half_raw(x);\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC numext::uint16_t raw_half_as_uint16(const __half_raw&amp; h) {\n  // HIP/CUDA/Default have a member &#x27;x&#x27; of type uint16_t.\n  // For ARM64 native half, the member &#x27;x&#x27; is of type __fp16, so we need to bit-cast.\n  // For SYCL, cl::sycl::half is _Float16, so cast directly.\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  return numext::bit_cast&lt;numext::uint16_t&gt;(h.x);\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  return numext::bit_cast&lt;numext::uint16_t&gt;(h.x);\n#elif defined(SYCL_DEVICE_ONLY)\n  return numext::bit_cast&lt;numext::uint16_t&gt;(h);\n#else\n  return h.x;\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __half_raw float_to_half_rtne(float ff) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n  __half tmp_ff = __float2half(ff);\n  return *(__half_raw*)&amp;tmp_ff;\n\n#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  __half_raw h;\n  h.x = static_cast&lt;__fp16&gt;(ff);\n  return h;\n\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  __half_raw h;\n  h.x = static_cast&lt;_Float16&gt;(ff);\n  return h;\n\n#elif defined(EIGEN_HAS_FP16_C)\n  __half_raw h;\n#if EIGEN_COMP_MSVC\n  // MSVC does not have scalar instructions.\n  h.x = _mm_extract_epi16(_mm_cvtps_ph(_mm_set_ss(ff), 0), 0);\n#else\n  h.x = _cvtss_sh(ff, 0);\n#endif\n  return h;\n\n#else\n  uint32_t f_bits = Eigen::numext::bit_cast&lt;uint32_t&gt;(ff);\n  const uint32_t f32infty_bits = {255 &lt;&lt; 23};\n  const uint32_t f16max_bits = {(127 + 16) &lt;&lt; 23};\n  const uint32_t denorm_magic_bits = {((127 - 15) + (23 - 10) + 1) &lt;&lt; 23};\n  const uint32_t sign_mask = 0x80000000u;\n  __half_raw o;\n  o.x = static_cast&lt;uint16_t&gt;(0x0u);\n\n  const uint32_t sign = f_bits &amp; sign_mask;\n  f_bits ^= sign;\n\n  // NOTE all the integer compares in this function can be safely\n  // compiled into signed compares since all operands are below\n  // 0x80000000. Important if you want fast straight SSE2 code\n  // (since there&#x27;s no unsigned PCMPGTD).\n\n  if (f_bits &gt;= f16max_bits) {                         // result is Inf or NaN (all exponent bits set)\n    o.x = (f_bits &gt; f32infty_bits) ? 0x7e00 : 0x7c00;  // NaN-&gt;qNaN and Inf-&gt;Inf\n  } else {                                             // (De)normalized number or zero\n    if (f_bits &lt; (113 &lt;&lt; 23)) {                        // resulting FP16 is subnormal or zero\n      // use a magic value to align our 10 mantissa bits at the bottom of\n      // the float. as long as FP addition is round-to-nearest-even this\n      // just works.\n      f_bits = Eigen::numext::bit_cast&lt;uint32_t&gt;(Eigen::numext::bit_cast&lt;float&gt;(f_bits) +\n                                                 Eigen::numext::bit_cast&lt;float&gt;(denorm_magic_bits));\n\n      // and one integer subtract of the bias later, we have our final float!\n      o.x = static_cast&lt;numext::uint16_t&gt;(f_bits - denorm_magic_bits);\n    } else {\n      const uint32_t mant_odd = (f_bits &gt;&gt; 13) &amp; 1;  // resulting mantissa is odd\n\n      // update exponent, rounding bias part 1\n      // Equivalent to `f.u += ((unsigned int)(15 - 127) &lt;&lt; 23) + 0xfff`, but\n      // without arithmetic overflow.\n      f_bits += 0xc8000fffU;\n      // rounding bias part 2\n      f_bits += mant_odd;\n      // take the bits!\n      o.x = static_cast&lt;numext::uint16_t&gt;(f_bits &gt;&gt; 13);\n    }\n  }\n\n  o.x |= static_cast&lt;numext::uint16_t&gt;(sign &gt;&gt; 16);\n  return o;\n#endif\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float half_to_float(__half_raw h) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n  return __half2float(h);\n#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) || defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  return static_cast&lt;float&gt;(h.x);\n#elif defined(EIGEN_HAS_FP16_C)\n#if EIGEN_COMP_MSVC\n  // MSVC does not have scalar instructions.\n  return _mm_cvtss_f32(_mm_cvtph_ps(_mm_set1_epi16(h.x)));\n#else\n  return _cvtsh_ss(h.x);\n#endif\n#else\n  const float magic = Eigen::numext::bit_cast&lt;float&gt;(static_cast&lt;uint32_t&gt;(113 &lt;&lt; 23));\n  const uint32_t shifted_exp = 0x7c00 &lt;&lt; 13;  // exponent mask after shift\n  uint32_t o_bits = (h.x &amp; 0x7fff) &lt;&lt; 13;     // exponent/mantissa bits\n  const uint32_t exp = shifted_exp &amp; o_bits;  // just the exponent\n  o_bits += (127 - 15) &lt;&lt; 23;                 // exponent adjust\n\n  // handle exponent special cases\n  if (exp == shifted_exp) {      // Inf/NaN?\n    o_bits += (128 - 16) &lt;&lt; 23;  // extra exp adjust\n  } else if (exp == 0) {         // Zero/Denormal?\n    o_bits += 1 &lt;&lt; 23;           // extra exp adjust\n    // renormalize\n    o_bits = Eigen::numext::bit_cast&lt;uint32_t&gt;(Eigen::numext::bit_cast&lt;float&gt;(o_bits) - magic);\n  }\n\n  o_bits |= (h.x &amp; 0x8000) &lt;&lt; 16;  // sign bit\n  return Eigen::numext::bit_cast&lt;float&gt;(o_bits);\n#endif\n}\n\n// --- standard functions ---\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isinf)(const half&amp; a) {\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) || defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  return (numext::bit_cast&lt;numext::uint16_t&gt;(a.x) &amp; 0x7fff) == 0x7c00;\n#else\n  return (a.x &amp; 0x7fff) == 0x7c00;\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isnan)(const half&amp; a) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 530) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n  return __hisnan(a);\n#elif defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC) || defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  return (numext::bit_cast&lt;numext::uint16_t&gt;(a.x) &amp; 0x7fff) &gt; 0x7c00;\n#else\n  return (a.x &amp; 0x7fff) &gt; 0x7c00;\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool(isfinite)(const half&amp; a) {\n  return !(isinf EIGEN_NOT_A_MACRO(a)) &amp;&amp; !(isnan EIGEN_NOT_A_MACRO(a));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half abs(const half&amp; a) {\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  return half(vabsh_f16(a.x));\n#elif defined(EIGEN_HAS_BUILTIN_FLOAT16)\n  half result;\n  result.x =\n      numext::bit_cast&lt;_Float16&gt;(static_cast&lt;numext::uint16_t&gt;(numext::bit_cast&lt;numext::uint16_t&gt;(a.x) &amp; 0x7FFF));\n  return result;\n#else\n  half result;\n  result.x = a.x &amp; 0x7FFF;\n  return result;\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half exp(const half&amp; a) {\n#if (EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined EIGEN_CUDA_ARCH &amp;&amp; EIGEN_CUDA_ARCH &gt;= 530) || \\\n    defined(EIGEN_HIP_DEVICE_COMPILE)\n  return half(hexp(a));\n#else\n  return half(::expf(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half exp2(const half&amp; a) {\n#if (EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined EIGEN_CUDA_ARCH &amp;&amp; EIGEN_CUDA_ARCH &gt;= 530) || \\\n    defined(EIGEN_HIP_DEVICE_COMPILE)\n  return half(hexp2(a));\n#else\n  return half(::exp2f(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half expm1(const half&amp; a) { return half(numext::expm1(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log(const half&amp; a) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; \\\n     EIGEN_CUDA_ARCH &gt;= 530) ||                                                                 \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n  return half(hlog(a));\n#else\n  return half(::logf(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log1p(const half&amp; a) { return half(numext::log1p(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log10(const half&amp; a) { return half(::log10f(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half log2(const half&amp; a) {\n  return half(static_cast&lt;float&gt;(EIGEN_LOG2E) * ::logf(float(a)));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half sqrt(const half&amp; a) {\n#if (EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined EIGEN_CUDA_ARCH &amp;&amp; EIGEN_CUDA_ARCH &gt;= 530) || \\\n    defined(EIGEN_HIP_DEVICE_COMPILE)\n  return half(hsqrt(a));\n#else\n  return half(::sqrtf(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half pow(const half&amp; a, const half&amp; b) {\n  return half(::powf(float(a), float(b)));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atan2(const half&amp; a, const half&amp; b) {\n  return half(::atan2f(float(a), float(b)));\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half sin(const half&amp; a) { return half(::sinf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half cos(const half&amp; a) { return half(::cosf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half tan(const half&amp; a) { return half(::tanf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half tanh(const half&amp; a) { return half(::tanhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half asin(const half&amp; a) { return half(::asinf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half acos(const half&amp; a) { return half(::acosf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atan(const half&amp; a) { return half(::atanf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half atanh(const half&amp; a) { return half(::atanhf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half floor(const half&amp; a) {\n#if (EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined EIGEN_CUDA_ARCH &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    defined(EIGEN_HIP_DEVICE_COMPILE)\n  return half(hfloor(a));\n#else\n  return half(::floorf(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half ceil(const half&amp; a) {\n#if (EIGEN_CUDA_SDK_VER &gt;= 80000 &amp;&amp; defined EIGEN_CUDA_ARCH &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    defined(EIGEN_HIP_DEVICE_COMPILE)\n  return half(hceil(a));\n#else\n  return half(::ceilf(float(a)));\n#endif\n}\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half rint(const half&amp; a) { return half(::rintf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half round(const half&amp; a) { return half(::roundf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half trunc(const half&amp; a) { return half(::truncf(float(a))); }\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half fmod(const half&amp; a, const half&amp; b) {\n  return half(::fmodf(float(a), float(b)));\n}\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half(min)(const half&amp; a, const half&amp; b) { return b &lt; a ? b : a; }\n\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC half(max)(const half&amp; a, const half&amp; b) { return a &lt; b ? b : a; }\n\nEIGEN_DEVICE_FUNC inline half fma(const half&amp; a, const half&amp; b, const half&amp; c) {\n#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)\n  return half(vfmah_f16(c.x, a.x, b.x));\n#elif defined(EIGEN_VECTORIZE_AVX512FP16)\n  // Reduces to vfmadd213sh.\n  return half(_mm_cvtsh_h(_mm_fmadd_ph(_mm_set_sh(a.x), _mm_set_sh(b.x), _mm_set_sh(c.x))));\n#else\n  // Emulate FMA via float.\n  return half(numext::fma(static_cast&lt;float&gt;(a), static_cast&lt;float&gt;(b), static_cast&lt;float&gt;(c)));\n#endif\n}\n\n#ifndef EIGEN_NO_IO\nEIGEN_ALWAYS_INLINE std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const half&amp; v) {\n  os &lt;&lt; static_cast&lt;float&gt;(v);\n  return os;\n}\n#endif\n\n}  // end namespace half_impl\n\n// import Eigen::half_impl::half into Eigen namespace\n// using half_impl::half;\n\nnamespace internal {\n\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;half&gt; {\n  enum { value = true };\n};\n\ntemplate &lt;&gt;\nstruct random_impl&lt;half&gt; {\n  enum : int { MantissaBits = 10 };\n  using Impl = random_impl&lt;float&gt;;\n  static EIGEN_DEVICE_FUNC inline half run(const half&amp; x, const half&amp; y) {\n    float result = Impl::run(x, y, MantissaBits);\n    return half(result);\n  }\n  static EIGEN_DEVICE_FUNC inline half run() {\n    float result = Impl::run(MantissaBits);\n    return half(result);\n  }\n};\n\n}  // end namespace internal\n\ntemplate &lt;&gt;\nstruct NumTraits&lt;Eigen::half&gt; : GenericNumTraits&lt;Eigen::half&gt; {\n  enum { IsSigned = true, IsInteger = false, IsComplex = false, RequireInitialization = false };\n\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half epsilon() {\n    return half_impl::raw_uint16_to_half(0x0800);\n  }\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half dummy_precision() {\n    return half_impl::raw_uint16_to_half(0x211f);  //  Eigen::half(1e-2f);\n  }\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half highest() {\n    return half_impl::raw_uint16_to_half(0x7bff);\n  }\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half lowest() {\n    return half_impl::raw_uint16_to_half(0xfbff);\n  }\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half infinity() {\n    return half_impl::raw_uint16_to_half(0x7c00);\n  }\n  EIGEN_DEVICE_FUNC _EIGEN_MAYBE_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::half quiet_NaN() {\n    return half_impl::raw_uint16_to_half(0x7e00);\n  }\n};\n\n}  // end namespace Eigen\n\n#undef _EIGEN_MAYBE_CONSTEXPR\n\nnamespace Eigen {\nnamespace numext {\n\n#if defined(EIGEN_GPU_COMPILE_PHASE)\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isnan)(const Eigen::half&amp; h) {\n  return (half_impl::isnan)(h);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isinf)(const Eigen::half&amp; h) {\n  return (half_impl::isinf)(h);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE bool(isfinite)(const Eigen::half&amp; h) {\n  return (half_impl::isfinite)(h);\n}\n\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::half bit_cast&lt;Eigen::half, uint16_t&gt;(const uint16_t&amp; src) {\n  return Eigen::half(Eigen::half_impl::raw_uint16_to_half(src));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast&lt;uint16_t, Eigen::half&gt;(const Eigen::half&amp; src) {\n  return Eigen::half_impl::raw_half_as_uint16(src);\n}\n\n}  // namespace numext\n}  // namespace Eigen\n\n// Add the missing shfl* intrinsics.\n// The __shfl* functions are only valid on HIP or _CUDA_ARCH_ &gt;= 300.\n//   CUDA defines them for (__CUDA_ARCH__ &gt;= 300 || !defined(__CUDA_ARCH__))\n//\n// HIP and CUDA prior to SDK 9.0 define\n//    __shfl, __shfl_up, __shfl_down, __shfl_xor for int and float\n// CUDA since 9.0 deprecates those and instead defines\n//    __shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync,\n//    with native support for __half and __nv_bfloat16\n//\n// Note that the following are __device__ - only functions.\n#if (defined(EIGEN_CUDACC) &amp;&amp; (!defined(EIGEN_CUDA_ARCH) || EIGEN_CUDA_ARCH &gt;= 300)) || defined(EIGEN_HIPCC)\n\n#if defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; EIGEN_CUDA_SDK_VER &gt;= 90000\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_sync(unsigned mask, Eigen::half var, int srcLane,\n                                                       int width = warpSize) {\n  const __half h = var;\n  return static_cast&lt;Eigen::half&gt;(__shfl_sync(mask, h, srcLane, width));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_up_sync(unsigned mask, Eigen::half var, unsigned int delta,\n                                                          int width = warpSize) {\n  const __half h = var;\n  return static_cast&lt;Eigen::half&gt;(__shfl_up_sync(mask, h, delta, width));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_down_sync(unsigned mask, Eigen::half var, unsigned int delta,\n                                                            int width = warpSize) {\n  const __half h = var;\n  return static_cast&lt;Eigen::half&gt;(__shfl_down_sync(mask, h, delta, width));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_xor_sync(unsigned mask, Eigen::half var, int laneMask,\n                                                           int width = warpSize) {\n  const __half h = var;\n  return static_cast&lt;Eigen::half&gt;(__shfl_xor_sync(mask, h, laneMask, width));\n}\n\n#else  // HIP or CUDA SDK &lt; 9.0\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl(Eigen::half var, int srcLane, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::half&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl(ivar, srcLane, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_up(Eigen::half var, unsigned int delta, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::half&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_up(ivar, delta, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_down(Eigen::half var, unsigned int delta, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::half&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_down(ivar, delta, width)));\n}\n\n__device__ EIGEN_STRONG_INLINE Eigen::half __shfl_xor(Eigen::half var, int laneMask, int width = warpSize) {\n  const int ivar = static_cast&lt;int&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(var));\n  return Eigen::numext::bit_cast&lt;Eigen::half&gt;(static_cast&lt;Eigen::numext::uint16_t&gt;(__shfl_xor(ivar, laneMask, width)));\n}\n\n#endif  // HIP vs CUDA\n#endif  // __shfl*\n\n// ldg() has an overload for __half_raw, but we also need one for Eigen::half.\n#if (defined(EIGEN_CUDACC) &amp;&amp; (!defined(EIGEN_CUDA_ARCH) || EIGEN_CUDA_ARCH &gt;= 350)) || defined(EIGEN_HIPCC)\nEIGEN_STRONG_INLINE __device__ Eigen::half __ldg(const Eigen::half* ptr) {\n  return Eigen::half_impl::raw_uint16_to_half(__ldg(reinterpret_cast&lt;const Eigen::numext::uint16_t*&gt;(ptr)));\n}\n#endif  // __ldg\n\n#if EIGEN_HAS_STD_HASH\nnamespace std {\ntemplate &lt;&gt;\nstruct hash&lt;Eigen::half&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::half&amp; a) const {\n    return static_cast&lt;std::size_t&gt;(Eigen::numext::bit_cast&lt;Eigen::numext::uint16_t&gt;(a));\n  }\n};\n}  // end namespace std\n#endif\n\nnamespace Eigen {\nnamespace internal {\n\ntemplate &lt;&gt;\nstruct cast_impl&lt;float, half&gt; {\n  EIGEN_DEVICE_FUNC static inline half run(const float&amp; a) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n    return __float2half(a);\n#else\n    return half(a);\n#endif\n  }\n};\n\ntemplate &lt;&gt;\nstruct cast_impl&lt;int, half&gt; {\n  EIGEN_DEVICE_FUNC static inline half run(const int&amp; a) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n    return __float2half(static_cast&lt;float&gt;(a));\n#else\n    return half(static_cast&lt;float&gt;(a));\n#endif\n  }\n};\n\ntemplate &lt;&gt;\nstruct cast_impl&lt;half, float&gt; {\n  EIGEN_DEVICE_FUNC static inline float run(const half&amp; a) {\n#if (defined(EIGEN_HAS_CUDA_FP16) &amp;&amp; defined(EIGEN_CUDA_ARCH) &amp;&amp; EIGEN_CUDA_ARCH &gt;= 300) || \\\n    (defined(EIGEN_HAS_HIP_FP16) &amp;&amp; defined(EIGEN_HIP_DEVICE_COMPILE))\n    return __half2float(a);\n#else\n    return static_cast&lt;float&gt;(a);\n#endif\n  }\n};\n\n}  // namespace internal\n}  // namespace Eigen\n\n#endif  // EIGEN_HALF_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2009 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_PACKET_MATH_SSE_H\n#define EIGEN_PACKET_MATH_SSE_H\n\n#include &lt;cstdint&gt;\n// IWYU pragma: private\n#include &quot;../../InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n#ifndef EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD\n#define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8\n#endif\n\n#if !defined(EIGEN_VECTORIZE_AVX) &amp;&amp; !defined(EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS)\n// 32 bits =&gt;  8 registers\n// 64 bits =&gt; 16 registers\n#define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS (2 * sizeof(void*))\n#endif\n\n#ifdef EIGEN_VECTORIZE_FMA\n#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD\n#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD\n#endif\n#endif\n\n#if ((defined EIGEN_VECTORIZE_AVX) &amp;&amp; (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_MINGW || EIGEN_COMP_LCC) &amp;&amp; \\\n     (__GXX_ABI_VERSION &lt; 1004)) ||                                                                     \\\n    EIGEN_OS_QNX\n// With GCC&#x27;s default ABI version, a __m128 or __m256 are the same types and therefore we cannot\n// have overloads for both types without linking error.\n// One solution is to increase ABI version using -fabi-version=4 (or greater).\n// Otherwise, we workaround this inconvenience by wrapping 128bit types into the following helper\n// structure:\ntypedef eigen_packet_wrapper&lt;__m128&gt; Packet4f;\ntypedef eigen_packet_wrapper&lt;__m128d&gt; Packet2d;\n#else\ntypedef __m128 Packet4f;\ntypedef __m128d Packet2d;\n#endif\n\ntypedef eigen_packet_wrapper&lt;__m128i, 0&gt; Packet4i;\ntypedef eigen_packet_wrapper&lt;__m128i, 1&gt; Packet16b;\ntypedef eigen_packet_wrapper&lt;__m128i, 4&gt; Packet4ui;\ntypedef eigen_packet_wrapper&lt;__m128i, 5&gt; Packet2l;\n\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;__m128&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;__m128i&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;__m128d&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;Packet4i&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;Packet2l&gt; {\n  enum { value = true };\n};\n// Note that `Packet4ui` uses the underlying type `__m128i`, which is\n// interpreted as a vector of _signed_ `int32`s, which breaks some arithmetic\n// operations used in `GenericPacketMath.h`.\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;Packet4ui&gt; {\n  enum { value = false };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;Packet16b&gt; {\n  enum { value = true };\n};\n\ntemplate &lt;int p, int q, int r, int s&gt;\nstruct shuffle_mask {\n  enum { mask = (s) &lt;&lt; 6 | (r) &lt;&lt; 4 | (q) &lt;&lt; 2 | (p) };\n};\n\n// TODO: change the implementation of all swizzle* ops from macro to template,\n#define vec4f_swizzle1(v, p, q, r, s) \\\n  Packet4f(_mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(v), (shuffle_mask&lt;p, q, r, s&gt;::mask))))\n\n#define vec4i_swizzle1(v, p, q, r, s) Packet4i(_mm_shuffle_epi32(v, (shuffle_mask&lt;p, q, r, s&gt;::mask)))\n\n#define vec4ui_swizzle1(v, p, q, r, s) Packet4ui(vec4i_swizzle1(v, p, q, r, s))\n\n#define vec2d_swizzle1(v, p, q) \\\n  Packet2d(_mm_castsi128_pd(    \\\n      _mm_shuffle_epi32(_mm_castpd_si128(v), (shuffle_mask&lt;2 * p, 2 * p + 1, 2 * q, 2 * q + 1&gt;::mask))))\n\n#define vec4f_swizzle2(a, b, p, q, r, s) Packet4f(_mm_shuffle_ps((a), (b), (shuffle_mask&lt;p, q, r, s&gt;::mask)))\n\n#define vec4i_swizzle2(a, b, p, q, r, s) \\\n  Packet4i(                              \\\n      _mm_castps_si128((_mm_shuffle_ps(_mm_castsi128_ps(a), _mm_castsi128_ps(b), (shuffle_mask&lt;p, q, r, s&gt;::mask)))))\n\n#define vec4ui_swizzle2(a, b, p, q, r, s) Packet4i(vec4i_swizzle2(a, b, p, q, r, s))\n\nEIGEN_STRONG_INLINE Packet4f vec4f_movelh(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return Packet4f(_mm_movelh_ps(a, b));\n}\nEIGEN_STRONG_INLINE Packet4f vec4f_movehl(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return Packet4f(_mm_movehl_ps(a, b));\n}\nEIGEN_STRONG_INLINE Packet4f vec4f_unpacklo(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return Packet4f(_mm_unpacklo_ps(a, b));\n}\nEIGEN_STRONG_INLINE Packet4f vec4f_unpackhi(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return Packet4f(_mm_unpackhi_ps(a, b));\n}\n#define vec4f_duplane(a, p) vec4f_swizzle2(a, a, p, p, p, p)\n\n#define vec2d_swizzle2(a, b, mask) Packet2d(_mm_shuffle_pd(a, b, mask))\n\nEIGEN_STRONG_INLINE Packet2d vec2d_unpacklo(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return Packet2d(_mm_unpacklo_pd(a, b));\n}\nEIGEN_STRONG_INLINE Packet2d vec2d_unpackhi(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return Packet2d(_mm_unpackhi_pd(a, b));\n}\n#define vec2d_duplane(a, p) vec2d_swizzle2(a, a, (p &lt;&lt; 1) | p)\n\n#define EIGEN_DECLARE_CONST_Packet4f(NAME, X) const Packet4f p4f_##NAME = pset1&lt;Packet4f&gt;(X)\n\n#define EIGEN_DECLARE_CONST_Packet2d(NAME, X) const Packet2d p2d_##NAME = pset1&lt;Packet2d&gt;(X)\n\n#define EIGEN_DECLARE_CONST_Packet4f_FROM_INT(NAME, X) const Packet4f p4f_##NAME = pset1frombits&lt;Packet4f&gt;(X)\n\n#define EIGEN_DECLARE_CONST_Packet4i(NAME, X) const Packet4i p4i_##NAME = pset1&lt;Packet4i&gt;(X)\n\n#define EIGEN_DECLARE_CONST_Packet4ui(NAME, X) const Packet4ui p4ui_##NAME = pset1&lt;Packet4ui&gt;(X)\n\n// Work around lack of extract/cvt for epi64 when compiling for 32-bit.\n#if EIGEN_ARCH_x86_64\nEIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_0(const __m128i&amp; a) { return _mm_cvtsi128_si64(a); }\n#ifdef EIGEN_VECTORIZE_SSE4_1\nEIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i&amp; a) { return _mm_extract_epi64(a, 1); }\n#else\nEIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i&amp; a) {\n  return _mm_cvtsi128_si64(_mm_castpd_si128(_mm_shuffle_pd(_mm_castsi128_pd(a), _mm_castsi128_pd(a), 0x1)));\n}\n#endif\n#else\n// epi64 instructions are not available.  The following seems to generate the same instructions\n// with -O2 in GCC/Clang.\nEIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_0(const __m128i&amp; a) {\n  return numext::bit_cast&lt;int64_t&gt;(_mm_cvtsd_f64(_mm_castsi128_pd(a)));\n}\nEIGEN_ALWAYS_INLINE int64_t _mm_extract_epi64_1(const __m128i&amp; a) {\n  return numext::bit_cast&lt;int64_t&gt;(_mm_cvtsd_f64(_mm_shuffle_pd(_mm_castsi128_pd(a), _mm_castsi128_pd(a), 0x1)));\n}\n#endif\n\n// Use the packet_traits defined in AVX/PacketMath.h instead if we&#x27;re going\n// to leverage AVX instructions.\n#ifndef EIGEN_VECTORIZE_AVX\ntemplate &lt;&gt;\nstruct packet_traits&lt;float&gt; : default_packet_traits {\n  typedef Packet4f type;\n  typedef Packet4f half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 4,\n\n    HasCmp = 1,\n    HasDiv = 1,\n    HasReciprocal = EIGEN_FAST_MATH,\n    HasSin = EIGEN_FAST_MATH,\n    HasCos = EIGEN_FAST_MATH,\n    HasACos = 1,\n    HasASin = 1,\n    HasATan = 1,\n    HasATanh = 1,\n    HasLog = 1,\n    HasLog1p = 1,\n    HasExpm1 = 1,\n    HasNdtri = 1,\n    HasExp = 1,\n    HasBessel = 1,\n    HasSqrt = 1,\n    HasRsqrt = 1,\n    HasTanh = EIGEN_FAST_MATH,\n    HasErf = EIGEN_FAST_MATH,\n    HasErfc = EIGEN_FAST_MATH,\n    HasBlend = 1,\n    HasSign = 0  // The manually vectorized version is slightly slower for SSE.\n  };\n};\ntemplate &lt;&gt;\nstruct packet_traits&lt;double&gt; : default_packet_traits {\n  typedef Packet2d type;\n  typedef Packet2d half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 2,\n\n    HasCmp = 1,\n    HasDiv = 1,\n    HasSin = EIGEN_FAST_MATH,\n    HasCos = EIGEN_FAST_MATH,\n    HasTanh = EIGEN_FAST_MATH,\n    HasLog = 1,\n    HasErf = EIGEN_FAST_MATH,\n    HasErfc = EIGEN_FAST_MATH,\n    HasExp = 1,\n    HasSqrt = 1,\n    HasRsqrt = 1,\n    HasATan = 1,\n    HasATanh = 1,\n    HasBlend = 1\n  };\n};\ntemplate &lt;&gt;\nstruct packet_traits&lt;int&gt; : default_packet_traits {\n  typedef Packet4i type;\n  typedef Packet4i half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 4,\n\n    HasCmp = 1,\n    HasDiv = 1,\n    HasShift = 1,\n    HasBlend = 1\n  };\n};\ntemplate &lt;&gt;\nstruct packet_traits&lt;uint32_t&gt; : default_packet_traits {\n  typedef Packet4ui type;\n  typedef Packet4ui half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 4,\n\n    HasDiv = 0,\n    HasNegate = 0,\n    HasCmp = 1,\n    HasShift = 1,\n    HasBlend = 1\n  };\n};\ntemplate &lt;&gt;\nstruct packet_traits&lt;int64_t&gt; : default_packet_traits {\n  typedef Packet2l type;\n  typedef Packet2l half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 2,\n\n    HasDiv = 0,\n    HasCmp = 1,\n    HasShift = 1,\n    HasBlend = 1\n  };\n};\n#endif\ntemplate &lt;&gt;\nstruct packet_traits&lt;bool&gt; : default_packet_traits {\n  typedef Packet16b type;\n  typedef Packet16b half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 16,\n\n    HasCmp = 1,  // note -- only pcmp_eq is defined\n    HasShift = 0,\n    HasAbs = 0,\n    HasAbs2 = 0,\n    HasMin = 0,\n    HasMax = 0,\n    HasConj = 0,\n    HasSqrt = 1,\n    HasNegate = 0,\n    HasSign = 0  // Don&#x27;t try to vectorize psign&lt;bool&gt; = identity.\n  };\n};\n\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet4f&gt; {\n  typedef float type;\n  typedef Packet4f half;\n  typedef Packet4i integer_packet;\n  enum {\n    size = 4,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet2d&gt; {\n  typedef double type;\n  typedef Packet2d half;\n  typedef Packet2l integer_packet;\n  enum {\n    size = 2,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet2l&gt; {\n  typedef int64_t type;\n  typedef Packet2l half;\n  enum {\n    size = 2,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet4i&gt; {\n  typedef int type;\n  typedef Packet4i half;\n  enum {\n    size = 4,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet4ui&gt; {\n  typedef uint32_t type;\n  typedef Packet4ui half;\n  enum {\n    size = 4,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\ntemplate &lt;&gt;\nstruct unpacket_traits&lt;Packet16b&gt; {\n  typedef bool type;\n  typedef Packet16b half;\n  enum {\n    size = 16,\n    alignment = Aligned16,\n    vectorizable = true,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\n\n#ifndef EIGEN_VECTORIZE_AVX\ntemplate &lt;&gt;\nstruct scalar_div_cost&lt;float, true&gt; {\n  enum { value = 7 };\n};\ntemplate &lt;&gt;\nstruct scalar_div_cost&lt;double, true&gt; {\n  enum { value = 8 };\n};\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pset1&lt;Packet4f&gt;(const float&amp; from) {\n  return _mm_set_ps1(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pset1&lt;Packet2d&gt;(const double&amp; from) {\n  return _mm_set1_pd(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pset1&lt;Packet2l&gt;(const int64_t&amp; from) {\n  return _mm_set1_epi64x(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pset1&lt;Packet4i&gt;(const int&amp; from) {\n  return _mm_set1_epi32(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pset1&lt;Packet4ui&gt;(const uint32_t&amp; from) {\n  return _mm_set1_epi32(numext::bit_cast&lt;int32_t&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pset1&lt;Packet16b&gt;(const bool&amp; from) {\n  return _mm_set1_epi8(static_cast&lt;char&gt;(from));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pset1frombits&lt;Packet4f&gt;(unsigned int from) {\n  return _mm_castsi128_ps(pset1&lt;Packet4i&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pset1frombits&lt;Packet2d&gt;(uint64_t from) {\n  return _mm_castsi128_pd(_mm_set1_epi64x(from));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f peven_mask(const Packet4f&amp; /*a*/) {\n  return _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l peven_mask(const Packet2l&amp; /*a*/) {\n  return _mm_set_epi32(0, 0, -1, -1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i peven_mask(const Packet4i&amp; /*a*/) {\n  return _mm_set_epi32(0, -1, 0, -1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui peven_mask(const Packet4ui&amp; /*a*/) {\n  return _mm_set_epi32(0, -1, 0, -1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d peven_mask(const Packet2d&amp; /*a*/) {\n  return _mm_castsi128_pd(_mm_set_epi32(0, 0, -1, -1));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pzero(const Packet4f&amp; /*a*/) {\n  return _mm_setzero_ps();\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pzero(const Packet2d&amp; /*a*/) {\n  return _mm_setzero_pd();\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pzero(const Packet2l&amp; /*a*/) {\n  return _mm_setzero_si128();\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pzero(const Packet4i&amp; /*a*/) {\n  return _mm_setzero_si128();\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pzero(const Packet4ui&amp; /*a*/) {\n  return _mm_setzero_si128();\n}\n\n// GCC generates a shufps instruction for _mm_set1_ps/_mm_load1_ps instead of the more efficient pshufd instruction.\n// However, using inrinsics for pset1 makes gcc to generate crappy code in some cases (see bug 203)\n// Using inline assembly is also not an option because then gcc fails to reorder properly the instructions.\n// Therefore, we introduced the pload1 functions to be used in product kernels for which bug 203 does not apply.\n// Also note that with AVX, we want it to generate a vbroadcastss.\n#if EIGEN_COMP_GNUC_STRICT &amp;&amp; (!defined __AVX__)\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pload1&lt;Packet4f&gt;(const float* from) {\n  return vec4f_swizzle1(_mm_load_ss(from), 0, 0, 0, 0);\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f plset&lt;Packet4f&gt;(const float&amp; a) {\n  return _mm_add_ps(pset1&lt;Packet4f&gt;(a), _mm_set_ps(3, 2, 1, 0));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d plset&lt;Packet2d&gt;(const double&amp; a) {\n  return _mm_add_pd(pset1&lt;Packet2d&gt;(a), _mm_set_pd(1, 0));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l plset&lt;Packet2l&gt;(const int64_t&amp; a) {\n  return _mm_add_epi32(pset1&lt;Packet2l&gt;(a), _mm_set_epi64x(1, 0));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i plset&lt;Packet4i&gt;(const int&amp; a) {\n  return _mm_add_epi32(pset1&lt;Packet4i&gt;(a), _mm_set_epi32(3, 2, 1, 0));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui plset&lt;Packet4ui&gt;(const uint32_t&amp; a) {\n  return _mm_add_epi32(pset1&lt;Packet4ui&gt;(a), _mm_set_epi32(3, 2, 1, 0));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f padd&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_add_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d padd&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_add_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l padd&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_add_epi64(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i padd&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_add_epi32(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui padd&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_add_epi32(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b padd&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_or_si128(a, b);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE Packet padds(const Packet&amp; a, const Packet&amp; b);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f padds&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_add_ss(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d padds&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_add_sd(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f psub&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_sub_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d psub&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_sub_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l psub&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_sub_epi64(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i psub&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_sub_epi32(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui psub&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_sub_epi32(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b psub&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_xor_si128(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pxor&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f paddsub&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE3\n  return _mm_addsub_ps(a, b);\n#else\n  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x0, 0x80000000, 0x0));\n  return padd(a, pxor(mask, b));\n#endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pxor&lt;Packet2d&gt;(const Packet2d&amp;, const Packet2d&amp;);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d paddsub&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE3\n  return _mm_addsub_pd(a, b);\n#else\n  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0, 0x80000000, 0x0, 0x0));\n  return padd(a, pxor(mask, b));\n#endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f&amp; a) {\n  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000, 0x80000000, 0x80000000, 0x80000000));\n  return _mm_xor_ps(a, mask);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d&amp; a) {\n  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0, 0x80000000, 0x0, 0x80000000));\n  return _mm_xor_pd(a, mask);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pnegate(const Packet2l&amp; a) {\n  return psub(pzero(a), a);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pnegate(const Packet4i&amp; a) {\n  return psub(pzero(a), a);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pconj(const Packet4f&amp; a) {\n  return a;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pconj(const Packet2d&amp; a) {\n  return a;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pconj(const Packet2l&amp; a) {\n  return a;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pconj(const Packet4i&amp; a) {\n  return a;\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmul&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_mul_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmul&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_mul_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pmul&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  // 64-bit mul requires avx512, so do this with 32-bit multiplication\n  __m128i upper32_a = _mm_srli_epi64(a, 32);\n  __m128i upper32_b = _mm_srli_epi64(b, 32);\n\n  // upper * lower\n  __m128i mul1 = _mm_mul_epu32(upper32_a, b);\n  __m128i mul2 = _mm_mul_epu32(upper32_b, a);\n  // Gives us both upper*upper and lower*lower\n  __m128i mul3 = _mm_mul_epu32(a, b);\n\n  __m128i high = _mm_slli_epi64(_mm_add_epi64(mul1, mul2), 32);\n  return _mm_add_epi64(high, mul3);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pmul&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_mullo_epi32(a, b);\n#else\n  // this version is slightly faster than 4 scalar products\n  return vec4i_swizzle1(\n      vec4i_swizzle2(_mm_mul_epu32(a, b), _mm_mul_epu32(vec4i_swizzle1(a, 1, 0, 3, 2), vec4i_swizzle1(b, 1, 0, 3, 2)),\n                     0, 2, 0, 2),\n      0, 2, 1, 3);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pmul&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_mullo_epi32(a, b);\n#else\n  // this version is slightly faster than 4 scalar products\n  return vec4ui_swizzle1(\n      vec4ui_swizzle2(_mm_mul_epu32(a, b),\n                      _mm_mul_epu32(vec4ui_swizzle1(a, 1, 0, 3, 2), vec4ui_swizzle1(b, 1, 0, 3, 2)), 0, 2, 0, 2),\n      0, 2, 1, 3);\n#endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pmul&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_and_si128(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pdiv&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_div_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pdiv&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_div_pd(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pdiv&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n#ifdef EIGEN_VECTORIZE_AVX\n  return _mm256_cvttpd_epi32(_mm256_div_pd(_mm256_cvtepi32_pd(a), _mm256_cvtepi32_pd(b)));\n#else\n  __m128i q_lo = _mm_cvttpd_epi32(_mm_div_pd(_mm_cvtepi32_pd(a), _mm_cvtepi32_pd(b)));\n  __m128i q_hi = _mm_cvttpd_epi32(\n      _mm_div_pd(_mm_cvtepi32_pd(vec4i_swizzle1(a, 2, 3, 0, 1)), _mm_cvtepi32_pd(vec4i_swizzle1(b, 2, 3, 0, 1))));\n  return vec4i_swizzle1(_mm_unpacklo_epi32(q_lo, q_hi), 0, 2, 1, 3);\n#endif\n}\n\n#ifdef EIGEN_VECTORIZE_FMA\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f&amp; a, const Packet4f&amp; b, const Packet4f&amp; c) {\n  return _mm_fmadd_ps(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmadd(const Packet2d&amp; a, const Packet2d&amp; b, const Packet2d&amp; c) {\n  return _mm_fmadd_pd(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmsub(const Packet4f&amp; a, const Packet4f&amp; b, const Packet4f&amp; c) {\n  return _mm_fmsub_ps(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmsub(const Packet2d&amp; a, const Packet2d&amp; b, const Packet2d&amp; c) {\n  return _mm_fmsub_pd(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pnmadd(const Packet4f&amp; a, const Packet4f&amp; b, const Packet4f&amp; c) {\n  return _mm_fnmadd_ps(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pnmadd(const Packet2d&amp; a, const Packet2d&amp; b, const Packet2d&amp; c) {\n  return _mm_fnmadd_pd(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pnmsub(const Packet4f&amp; a, const Packet4f&amp; b, const Packet4f&amp; c) {\n  return _mm_fnmsub_ps(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pnmsub(const Packet2d&amp; a, const Packet2d&amp; b, const Packet2d&amp; c) {\n  return _mm_fnmsub_pd(a, b, c);\n}\n\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE Packet pmadds(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmadds&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b, const Packet4f&amp; c) {\n  return _mm_fmadd_ss(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmadds&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b, const Packet2d&amp; c) {\n  return _mm_fmadd_sd(a, b, c);\n}\n#endif\n\n#ifdef EIGEN_VECTORIZE_SSE4_1\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pselect(const Packet4f&amp; mask, const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_blendv_ps(b, a, mask);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pselect(const Packet2l&amp; mask, const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_castpd_si128(_mm_blendv_pd(_mm_castsi128_pd(b), _mm_castsi128_pd(a), _mm_castsi128_pd(mask)));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pselect(const Packet4i&amp; mask, const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b), _mm_castsi128_ps(a), _mm_castsi128_ps(mask)));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pselect(const Packet4ui&amp; mask, const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b), _mm_castsi128_ps(a), _mm_castsi128_ps(mask)));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pselect(const Packet2d&amp; mask, const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_blendv_pd(b, a, mask);\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l ptrue&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  return _mm_cmpeq_epi32(a, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i ptrue&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  return _mm_cmpeq_epi32(a, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b ptrue&lt;Packet16b&gt;(const Packet16b&amp; /*a*/) {\n  return pset1&lt;Packet16b&gt;(true);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ptrue&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  Packet4i b = _mm_castps_si128(a);\n  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ptrue&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  Packet4i b = _mm_castpd_si128(a);\n  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pand&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_and_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pand&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_and_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pand&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_and_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pand&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_and_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pand&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_and_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pand&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_and_si128(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f por&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_or_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d por&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_or_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l por&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_or_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i por&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_or_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui por&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_or_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b por&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_or_si128(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pxor&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_xor_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pxor&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_xor_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pxor&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_xor_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pxor&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_xor_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pxor&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_xor_si128(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pxor&lt;Packet16b&gt;(const Packet16b&amp; a, const Packet16b&amp; b) {\n  return _mm_xor_si128(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pandnot&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_andnot_ps(b, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pandnot&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_andnot_pd(b, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pandnot&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return _mm_andnot_si128(b, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pandnot&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_andnot_si128(b, a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pandnot&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_andnot_si128(b, a);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_cmple_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_cmplt_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_cmpnge_ps(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return _mm_cmpeq_ps(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_cmple_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_cmplt_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_cmpnge_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return _mm_cmpeq_pd(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_cmplt_epi32(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return _mm_cmpeq_epi32(a, b);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pcmp_le(const Packet4i&amp; a, const Packet4i&amp; b) {\n  return por(pcmp_lt(a, b), pcmp_eq(a, b));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pcmp_lt(const Packet2l&amp; a, const Packet2l&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_2\n  return _mm_cmpgt_epi64(b, a);\n#else\n  Packet4i eq = pcmp_eq&lt;Packet4i&gt;(Packet4i(a), Packet4i(b));\n  Packet2l hi_eq = Packet2l(_mm_shuffle_epi32(eq, (shuffle_mask&lt;1, 1, 3, 3&gt;::mask)));\n  Packet4i lt = pcmp_lt&lt;Packet4i&gt;(Packet4i(a), Packet4i(b));\n  Packet2l hi_lt = Packet2l(_mm_shuffle_epi32(lt, (shuffle_mask&lt;1, 1, 3, 3&gt;::mask)));\n  Packet2l lo_lt = Packet2l(_mm_shuffle_epi32(lt, (shuffle_mask&lt;0, 0, 2, 2&gt;::mask)));\n  // return hi(a) &lt; hi(b) || (hi(a) == hi(b) &amp;&amp; lo(a) &lt; lo(b))\n  return por(hi_lt, pand(hi_eq, lo_lt));\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pcmp_eq(const Packet2l&amp; a, const Packet2l&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_cmpeq_epi64(a, b);\n#else\n  Packet4i tmp = pcmp_eq&lt;Packet4i&gt;(Packet4i(a), Packet4i(b));\n  return Packet2l(pand&lt;Packet4i&gt;(tmp, _mm_shuffle_epi32(tmp, (shuffle_mask&lt;1, 0, 3, 2&gt;::mask))));\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pcmp_le(const Packet2l&amp; a, const Packet2l&amp; b) {\n  return por(pcmp_lt(a, b), pcmp_eq(a, b));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pcmp_eq(const Packet16b&amp; a, const Packet16b&amp; b) {\n  // Mask out invalid bool bits to avoid UB.\n  const Packet16b kBoolMask = pset1&lt;Packet16b&gt;(true);\n  return _mm_and_si128(_mm_cmpeq_epi8(a, b), kBoolMask);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pcmp_eq(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n  return _mm_cmpeq_epi32(a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmin&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)\n// There appears to be a bug in GCC, by which the optimizer may\n// flip the argument order in calls to _mm_min_ps, so we have to\n// resort to inline ASM here. This is supposed to be fixed in gcc6.3,\n// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867\n#ifdef EIGEN_VECTORIZE_AVX\n  Packet4f res;\n  asm(&quot;vminps %[a], %[b], %[res]&quot; : [res] &quot;=x&quot;(res) : [a] &quot;x&quot;(a), [b] &quot;x&quot;(b));\n#else\n  Packet4f res = b;\n  asm(&quot;minps %[a], %[res]&quot; : [res] &quot;+x&quot;(res) : [a] &quot;x&quot;(a));\n#endif\n  return res;\n#else\n  // Arguments are reversed to match NaN propagation behavior of std::min.\n  return _mm_min_ps(b, a);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmin&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)\n// There appears to be a bug in GCC, by which the optimizer may\n// flip the argument order in calls to _mm_min_pd, so we have to\n// resort to inline ASM here. This is supposed to be fixed in gcc6.3,\n// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867\n#ifdef EIGEN_VECTORIZE_AVX\n  Packet2d res;\n  asm(&quot;vminpd %[a], %[b], %[res]&quot; : [res] &quot;=x&quot;(res) : [a] &quot;x&quot;(a), [b] &quot;x&quot;(b));\n#else\n  Packet2d res = b;\n  asm(&quot;minpd %[a], %[res]&quot; : [res] &quot;+x&quot;(res) : [a] &quot;x&quot;(a));\n#endif\n  return res;\n#else\n  // Arguments are reversed to match NaN propagation behavior of std::min.\n  return _mm_min_pd(b, a);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pmin&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  Packet2l a_lt_mask = pcmp_lt(a, b);\n  return por(pandnot(b, a_lt_mask), pand(a, a_lt_mask));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pmin&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_min_epi32(a, b);\n#else\n  // after some bench, this version *is* faster than a scalar implementation\n  Packet4i mask = _mm_cmplt_epi32(a, b);\n  return _mm_or_si128(_mm_and_si128(mask, a), _mm_andnot_si128(mask, b));\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pmin&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_min_epu32(a, b);\n#else\n  return padd((Packet4ui)pmin((Packet4i)psub(a, pset1&lt;Packet4ui&gt;(0x80000000UL)),\n                              (Packet4i)psub(b, pset1&lt;Packet4ui&gt;(0x80000000UL))),\n              pset1&lt;Packet4ui&gt;(0x80000000UL));\n#endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmax&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)\n// There appears to be a bug in GCC, by which the optimizer may\n// flip the argument order in calls to _mm_max_ps, so we have to\n// resort to inline ASM here. This is supposed to be fixed in gcc6.3,\n// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867\n#ifdef EIGEN_VECTORIZE_AVX\n  Packet4f res;\n  asm(&quot;vmaxps %[a], %[b], %[res]&quot; : [res] &quot;=x&quot;(res) : [a] &quot;x&quot;(a), [b] &quot;x&quot;(b));\n#else\n  Packet4f res = b;\n  asm(&quot;maxps %[a], %[res]&quot; : [res] &quot;+x&quot;(res) : [a] &quot;x&quot;(a));\n#endif\n  return res;\n#else\n  // Arguments are reversed to match NaN propagation behavior of std::max.\n  return _mm_max_ps(b, a);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmax&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n#if EIGEN_GNUC_STRICT_LESS_THAN(6, 3, 0)\n// There appears to be a bug in GCC, by which the optimizer may\n// flip the argument order in calls to _mm_max_pd, so we have to\n// resort to inline ASM here. This is supposed to be fixed in gcc6.3,\n// see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867\n#ifdef EIGEN_VECTORIZE_AVX\n  Packet2d res;\n  asm(&quot;vmaxpd %[a], %[b], %[res]&quot; : [res] &quot;=x&quot;(res) : [a] &quot;x&quot;(a), [b] &quot;x&quot;(b));\n#else\n  Packet2d res = b;\n  asm(&quot;maxpd %[a], %[res]&quot; : [res] &quot;+x&quot;(res) : [a] &quot;x&quot;(a));\n#endif\n  return res;\n#else\n  // Arguments are reversed to match NaN propagation behavior of std::max.\n  return _mm_max_pd(b, a);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pmax&lt;Packet2l&gt;(const Packet2l&amp; a, const Packet2l&amp; b) {\n  Packet2l a_lt_mask = pcmp_lt(a, b);\n  return por(pandnot(a, a_lt_mask), pand(b, a_lt_mask));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pmax&lt;Packet4i&gt;(const Packet4i&amp; a, const Packet4i&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_max_epi32(a, b);\n#else\n  // after some bench, this version *is* faster than a scalar implementation\n  Packet4i mask = _mm_cmpgt_epi32(a, b);\n  return _mm_or_si128(_mm_and_si128(mask, a), _mm_andnot_si128(mask, b));\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pmax&lt;Packet4ui&gt;(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return _mm_max_epu32(a, b);\n#else\n  return padd((Packet4ui)pmax((Packet4i)psub(a, pset1&lt;Packet4ui&gt;(0x80000000UL)),\n                              (Packet4i)psub(b, pset1&lt;Packet4ui&gt;(0x80000000UL))),\n              pset1&lt;Packet4ui&gt;(0x80000000UL));\n#endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pcmp_lt(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return pxor(pcmp_eq(a, pmax(a, b)), ptrue(a));\n#else\n  return (Packet4ui)pcmp_lt((Packet4i)psub(a, pset1&lt;Packet4ui&gt;(0x80000000UL)),\n                            (Packet4i)psub(b, pset1&lt;Packet4ui&gt;(0x80000000UL)));\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pcmp_le(const Packet4ui&amp; a, const Packet4ui&amp; b) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  return pcmp_eq(a, pmin(a, b));\n#else\n  return (Packet4ui)pcmp_le((Packet4i)psub(a, pset1&lt;Packet4ui&gt;(0x80000000UL)),\n                            (Packet4i)psub(b, pset1&lt;Packet4ui&gt;(0x80000000UL)));\n#endif\n}\n\ntemplate &lt;typename Packet, typename Op&gt;\nEIGEN_STRONG_INLINE Packet pminmax_propagate_numbers(const Packet&amp; a, const Packet&amp; b, Op op) {\n  // In this implementation, we take advantage of the fact that pmin/pmax for SSE\n  // always return a if either a or b is NaN.\n  Packet not_nan_mask_a = pcmp_eq(a, a);\n  Packet m = op(a, b);\n  return pselect&lt;Packet&gt;(not_nan_mask_a, m, b);\n}\n\ntemplate &lt;typename Packet, typename Op&gt;\nEIGEN_STRONG_INLINE Packet pminmax_propagate_nan(const Packet&amp; a, const Packet&amp; b, Op op) {\n  // In this implementation, we take advantage of the fact that pmin/pmax for SSE\n  // always return a if either a or b is NaN.\n  Packet not_nan_mask_a = pcmp_eq(a, a);\n  Packet m = op(b, a);\n  return pselect&lt;Packet&gt;(not_nan_mask_a, m, a);\n}\n\n// Add specializations for min/max with prescribed NaN propagation.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmin&lt;PropagateNumbers, Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return pminmax_propagate_numbers(a, b, pmin&lt;Packet4f&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmin&lt;PropagateNumbers, Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return pminmax_propagate_numbers(a, b, pmin&lt;Packet2d&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmax&lt;PropagateNumbers, Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return pminmax_propagate_numbers(a, b, pmax&lt;Packet4f&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmax&lt;PropagateNumbers, Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return pminmax_propagate_numbers(a, b, pmax&lt;Packet2d&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmin&lt;PropagateNaN, Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return pminmax_propagate_nan(a, b, pmin&lt;Packet4f&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmin&lt;PropagateNaN, Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return pminmax_propagate_nan(a, b, pmin&lt;Packet2d&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pmax&lt;PropagateNaN, Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; b) {\n  return pminmax_propagate_nan(a, b, pmax&lt;Packet4f&gt;);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pmax&lt;PropagateNaN, Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; b) {\n  return pminmax_propagate_nan(a, b, pmax&lt;Packet2d&gt;);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f psignbit(const Packet4f&amp; a) {\n  return _mm_castsi128_ps(_mm_srai_epi32(_mm_castps_si128(a), 31));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d psignbit(const Packet2d&amp; a) {\n  Packet4f tmp = psignbit&lt;Packet4f&gt;(_mm_castpd_ps(a));\n#ifdef EIGEN_VECTORIZE_AVX\n  return _mm_castps_pd(_mm_permute_ps(tmp, (shuffle_mask&lt;1, 1, 3, 3&gt;::mask)));\n#else\n  return _mm_castps_pd(_mm_shuffle_ps(tmp, tmp, (shuffle_mask&lt;1, 1, 3, 3&gt;::mask)));\n#endif  // EIGEN_VECTORIZE_AVX\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i psignbit(const Packet4i&amp; a) {\n  return _mm_srai_epi32(a, 31);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui psignbit(const Packet4ui&amp; a) {\n  return pzero(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l psignbit(const Packet2l&amp; a) {\n  Packet4i tmp = psignbit&lt;Packet4i&gt;(Packet4i(a));\n  return Packet2l(_mm_shuffle_epi32(tmp, (shuffle_mask&lt;1, 1, 3, 3&gt;::mask)));\n}\n\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet2l parithmetic_shift_right(const Packet2l&amp; a) {\n  Packet2l signbit = psignbit(a);\n  return por(_mm_slli_epi64(signbit, 64 - N), _mm_srli_epi64(a, N));\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet2l plogical_shift_right(const Packet2l&amp; a) {\n  return _mm_srli_epi64(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet2l plogical_shift_left(const Packet2l&amp; a) {\n  return _mm_slli_epi64(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(const Packet4i&amp; a) {\n  return _mm_srai_epi32(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4i plogical_shift_right(const Packet4i&amp; a) {\n  return _mm_srli_epi32(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4i plogical_shift_left(const Packet4i&amp; a) {\n  return _mm_slli_epi32(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4ui parithmetic_shift_right(const Packet4ui&amp; a) {\n  return _mm_srli_epi32(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4ui plogical_shift_right(const Packet4ui&amp; a) {\n  return _mm_srli_epi32(a, N);\n}\ntemplate &lt;int N&gt;\nEIGEN_STRONG_INLINE Packet4ui plogical_shift_left(const Packet4ui&amp; a) {\n  return _mm_slli_epi32(a, N);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pabs(const Packet4f&amp; a) {\n  const __m128i mask = _mm_setr_epi32(0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF, 0x7FFFFFFF);\n  return _mm_castsi128_ps(_mm_and_si128(mask, _mm_castps_si128(a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pabs(const Packet2d&amp; a) {\n  const __m128i mask = _mm_setr_epi32(0xFFFFFFFF, 0x7FFFFFFF, 0xFFFFFFFF, 0x7FFFFFFF);\n  return _mm_castsi128_pd(_mm_and_si128(mask, _mm_castpd_si128(a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pabs(const Packet2l&amp; a) {\n  Packet2l signbit = psignbit(a);\n  return _mm_sub_epi64(_mm_xor_si128(a, signbit), signbit);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pabs(const Packet4i&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSSE3\n  return _mm_abs_epi32(a);\n#else\n  Packet4i signbit = psignbit(a);\n  return _mm_sub_epi32(_mm_xor_si128(a, signbit), signbit);\n#endif\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pabs(const Packet4ui&amp; a) {\n  return a;\n}\n\n#ifdef EIGEN_VECTORIZE_SSE4_1\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pround&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  // Unfortunately _mm_round_ps doesn&#x27;t have a rounding mode to implement numext::round.\n  const Packet4f mask = pset1frombits&lt;Packet4f&gt;(0x80000000u);\n  const Packet4f prev0dot5 = pset1frombits&lt;Packet4f&gt;(0x3EFFFFFFu);\n  return _mm_round_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pround&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  const Packet2d mask = _mm_castsi128_pd(_mm_set_epi64x(0x8000000000000000ull, 0x8000000000000000ull));\n  const Packet2d prev0dot5 = _mm_castsi128_pd(_mm_set_epi64x(0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull));\n  return _mm_round_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f print&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return _mm_round_ps(a, _MM_FROUND_CUR_DIRECTION);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d print&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return _mm_round_pd(a, _MM_FROUND_CUR_DIRECTION);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pceil&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return _mm_ceil_ps(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pceil&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return _mm_ceil_pd(a);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pfloor&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return _mm_floor_ps(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pfloor&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return _mm_floor_pd(a);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ptrunc&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return _mm_round_ps(a, _MM_FROUND_TRUNC);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ptrunc&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return _mm_round_pd(a, _MM_FROUND_TRUNC);\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pload&lt;Packet4f&gt;(const float* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_ps(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pload&lt;Packet2d&gt;(const double* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_pd(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pload&lt;Packet2l&gt;(const int64_t* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pload&lt;Packet4i&gt;(const int* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pload&lt;Packet4ui&gt;(const uint32_t* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pload&lt;Packet16b&gt;(const bool* from) {\n  EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\n\n#if EIGEN_COMP_MSVC\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ploadu&lt;Packet4f&gt;(const float* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_ps(from);\n}\n#else\n// NOTE: with the code below, MSVC&#x27;s compiler crashes!\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ploadu&lt;Packet4f&gt;(const float* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_ps(from);\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ploadu&lt;Packet2d&gt;(const double* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_pd(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l ploadu&lt;Packet2l&gt;(const int64_t* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i ploadu&lt;Packet4i&gt;(const int* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui ploadu&lt;Packet4ui&gt;(const uint32_t* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b ploadu&lt;Packet16b&gt;(const bool* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD\n  return _mm_loadu_si128(reinterpret_cast&lt;const __m128i*&gt;(from));\n}\n\n// Load lower part of packet zero extending.\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE Packet ploadl(const typename unpacket_traits&lt;Packet&gt;::type* from);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ploadl&lt;Packet4f&gt;(const float* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_castpd_ps(_mm_load_sd(reinterpret_cast&lt;const double*&gt;(from)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ploadl&lt;Packet2d&gt;(const double* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_sd(from);\n}\n\n// Load scalar\ntemplate &lt;typename Packet&gt;\nEIGEN_STRONG_INLINE Packet ploads(const typename unpacket_traits&lt;Packet&gt;::type* from);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ploads&lt;Packet4f&gt;(const float* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_ss(from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ploads&lt;Packet2d&gt;(const double* from) {\n  EIGEN_DEBUG_UNALIGNED_LOAD return _mm_load_sd(from);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f ploaddup&lt;Packet4f&gt;(const float* from) {\n  return vec4f_swizzle1(_mm_castpd_ps(_mm_load_sd(reinterpret_cast&lt;const double*&gt;(from))), 0, 0, 1, 1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d ploaddup&lt;Packet2d&gt;(const double* from) {\n  return pset1&lt;Packet2d&gt;(from[0]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l ploaddup&lt;Packet2l&gt;(const int64_t* from) {\n  return pset1&lt;Packet2l&gt;(from[0]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i ploaddup&lt;Packet4i&gt;(const int* from) {\n  Packet4i tmp;\n  tmp = _mm_loadl_epi64(reinterpret_cast&lt;const __m128i*&gt;(from));\n  return vec4i_swizzle1(tmp, 0, 0, 1, 1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui ploaddup&lt;Packet4ui&gt;(const uint32_t* from) {\n  Packet4ui tmp;\n  tmp = _mm_loadl_epi64(reinterpret_cast&lt;const __m128i*&gt;(from));\n  return vec4ui_swizzle1(tmp, 0, 0, 1, 1);\n}\n\n// Loads 8 bools from memory and returns the packet\n// {b0, b0, b1, b1, b2, b2, b3, b3, b4, b4, b5, b5, b6, b6, b7, b7}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b ploaddup&lt;Packet16b&gt;(const bool* from) {\n  __m128i tmp = _mm_castpd_si128(pload1&lt;Packet2d&gt;(reinterpret_cast&lt;const double*&gt;(from)));\n  return _mm_unpacklo_epi8(tmp, tmp);\n}\n\n// Loads 4 bools from memory and returns the packet\n// {b0, b0  b0, b0, b1, b1, b1, b1, b2, b2, b2, b2, b3, b3, b3, b3}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b ploadquad&lt;Packet16b&gt;(const bool* from) {\n  __m128i tmp = _mm_castps_si128(pload1&lt;Packet4f&gt;(reinterpret_cast&lt;const float*&gt;(from)));\n  tmp = _mm_unpacklo_epi8(tmp, tmp);\n  return _mm_unpacklo_epi16(tmp, tmp);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;float&gt;(float* to, const Packet4f&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_ps(to, from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;double&gt;(double* to, const Packet2d&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_pd(to, from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;int64_t&gt;(int64_t* to, const Packet2l&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;int&gt;(int* to, const Packet4i&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;uint32_t&gt;(uint32_t* to, const Packet4ui&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore&lt;bool&gt;(bool* to, const Packet16b&amp; from) {\n  EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;double&gt;(double* to, const Packet2d&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_pd(to, from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;float&gt;(float* to, const Packet4f&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_ps(to, from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;int64_t&gt;(int64_t* to, const Packet2l&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;int&gt;(int* to, const Packet4i&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;uint32_t&gt;(uint32_t* to, const Packet4ui&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstoreu&lt;bool&gt;(bool* to, const Packet16b&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast&lt;__m128i*&gt;(to), from);\n}\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_STRONG_INLINE void pstorel(Scalar* to, const Packet&amp; from);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstorel(float* to, const Packet4f&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storel_pi(reinterpret_cast&lt;__m64*&gt;(to), from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstorel(double* to, const Packet2d&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_storel_pd(to, from);\n}\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_STRONG_INLINE void pstores(Scalar* to, const Packet&amp; from);\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstores(float* to, const Packet4f&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_store_ss(to, from);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstores(double* to, const Packet2d&amp; from) {\n  EIGEN_DEBUG_UNALIGNED_STORE _mm_store_sd(to, from);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f preverse(const Packet4f&amp; a) {\n  return _mm_shuffle_ps(a, a, 0x1B);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d preverse(const Packet2d&amp; a) {\n  return _mm_shuffle_pd(a, a, 0x1);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l preverse(const Packet2l&amp; a) {\n  return _mm_castpd_si128(preverse(_mm_castsi128_pd(a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i preverse(const Packet4i&amp; a) {\n  return _mm_shuffle_epi32(a, 0x1B);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui preverse(const Packet4ui&amp; a) {\n  return _mm_shuffle_epi32(a, 0x1B);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b preverse(const Packet16b&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSSE3\n  __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n  return _mm_shuffle_epi8(a, mask);\n#else\n  Packet16b tmp = _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 1, 2, 3));\n  tmp = _mm_shufflehi_epi16(_mm_shufflelo_epi16(tmp, _MM_SHUFFLE(2, 3, 0, 1)), _MM_SHUFFLE(2, 3, 0, 1));\n  return _mm_or_si128(_mm_slli_epi16(tmp, 8), _mm_srli_epi16(tmp, 8));\n#endif\n}\n\n#if EIGEN_COMP_MSVC_STRICT &amp;&amp; EIGEN_OS_WIN64\n// The temporary variable fixes an internal compilation error in vs &lt;= 2008 and a wrong-result bug in vs 2010\n// Direct of the struct members fixed bug #62.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pfirst&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return a.m128_f32[0];\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pfirst&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return a.m128d_f64[0];\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int64_t pfirst&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  int64_t x = _mm_extract_epi64_0(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int pfirst&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  int x = _mm_cvtsi128_si32(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t pfirst&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  uint32_t x = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(a));\n  return x;\n}\n#elif EIGEN_COMP_MSVC_STRICT\n// The temporary variable fixes an internal compilation error in vs &lt;= 2008 and a wrong-result bug in vs 2010\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pfirst&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  float x = _mm_cvtss_f32(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pfirst&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  double x = _mm_cvtsd_f64(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int64_t pfirst&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  int64_t x = _mm_extract_epi64_0(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int pfirst&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  int x = _mm_cvtsi128_si32(a);\n  return x;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t pfirst&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  uint32_t x = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(a));\n  return x;\n}\n#else\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pfirst&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  return _mm_cvtss_f32(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pfirst&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return _mm_cvtsd_f64(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int64_t pfirst&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  return _mm_extract_epi64_0(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int pfirst&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  return _mm_cvtsi128_si32(a);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t pfirst&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  return numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(a));\n}\n#endif\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool pfirst&lt;Packet16b&gt;(const Packet16b&amp; a) {\n  int x = _mm_cvtsi128_si32(a);\n  return static_cast&lt;bool&gt;(x &amp; 1);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pgather&lt;float, Packet4f&gt;(const float* from, Index stride) {\n  return _mm_set_ps(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pgather&lt;double, Packet2d&gt;(const double* from, Index stride) {\n  return _mm_set_pd(from[1 * stride], from[0 * stride]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pgather&lt;int64_t, Packet2l&gt;(const int64_t* from, Index stride) {\n  return _mm_set_epi64x(from[1 * stride], from[0 * stride]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pgather&lt;int, Packet4i&gt;(const int* from, Index stride) {\n  return _mm_set_epi32(from[3 * stride], from[2 * stride], from[1 * stride], from[0 * stride]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pgather&lt;uint32_t, Packet4ui&gt;(const uint32_t* from, Index stride) {\n  return _mm_set_epi32(numext::bit_cast&lt;int32_t&gt;(from[3 * stride]), numext::bit_cast&lt;int32_t&gt;(from[2 * stride]),\n                       numext::bit_cast&lt;int32_t&gt;(from[1 * stride]), numext::bit_cast&lt;int32_t&gt;(from[0 * stride]));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet16b pgather&lt;bool, Packet16b&gt;(const bool* from, Index stride) {\n  return _mm_set_epi8(from[15 * stride], from[14 * stride], from[13 * stride], from[12 * stride], from[11 * stride],\n                      from[10 * stride], from[9 * stride], from[8 * stride], from[7 * stride], from[6 * stride],\n                      from[5 * stride], from[4 * stride], from[3 * stride], from[2 * stride], from[1 * stride],\n                      from[0 * stride]);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;float, Packet4f&gt;(float* to, const Packet4f&amp; from, Index stride) {\n  to[stride * 0] = pfirst(from);\n  to[stride * 1] = pfirst(_mm_shuffle_ps(from, from, 1));\n  to[stride * 2] = pfirst(_mm_shuffle_ps(from, from, 2));\n  to[stride * 3] = pfirst(_mm_shuffle_ps(from, from, 3));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;double, Packet2d&gt;(double* to, const Packet2d&amp; from, Index stride) {\n  to[stride * 0] = pfirst(from);\n  to[stride * 1] = pfirst(preverse(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;int64_t, Packet2l&gt;(int64_t* to, const Packet2l&amp; from, Index stride) {\n  to[stride * 0] = pfirst(from);\n  to[stride * 1] = pfirst(preverse(from));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;int, Packet4i&gt;(int* to, const Packet4i&amp; from, Index stride) {\n  to[stride * 0] = _mm_cvtsi128_si32(from);\n  to[stride * 1] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1));\n  to[stride * 2] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2));\n  to[stride * 3] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;uint32_t, Packet4ui&gt;(uint32_t* to, const Packet4ui&amp; from, Index stride) {\n  to[stride * 0] = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(from));\n  to[stride * 1] = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1)));\n  to[stride * 2] = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2)));\n  to[stride * 3] = numext::bit_cast&lt;uint32_t&gt;(_mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pscatter&lt;bool, Packet16b&gt;(bool* to, const Packet16b&amp; from, Index stride) {\n  EIGEN_ALIGN16 bool tmp[16];\n  pstore(tmp, from);\n  to[stride * 0] = tmp[0];\n  to[stride * 1] = tmp[1];\n  to[stride * 2] = tmp[2];\n  to[stride * 3] = tmp[3];\n  to[stride * 4] = tmp[4];\n  to[stride * 5] = tmp[5];\n  to[stride * 6] = tmp[6];\n  to[stride * 7] = tmp[7];\n  to[stride * 8] = tmp[8];\n  to[stride * 9] = tmp[9];\n  to[stride * 10] = tmp[10];\n  to[stride * 11] = tmp[11];\n  to[stride * 12] = tmp[12];\n  to[stride * 13] = tmp[13];\n  to[stride * 14] = tmp[14];\n  to[stride * 15] = tmp[15];\n}\n\n// some compilers might be tempted to perform multiple moves instead of using a vector path.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore1&lt;Packet4f&gt;(float* to, const float&amp; a) {\n  Packet4f pa = _mm_set_ss(a);\n  pstore(to, Packet4f(vec4f_swizzle1(pa, 0, 0, 0, 0)));\n}\n// some compilers might be tempted to perform multiple moves instead of using a vector path.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pstore1&lt;Packet2d&gt;(double* to, const double&amp; a) {\n  Packet2d pa = _mm_set_sd(a);\n  pstore(to, Packet2d(vec2d_swizzle1(pa, 0, 0)));\n}\n\n#if EIGEN_COMP_PGI &amp;&amp; EIGEN_COMP_PGI &lt; 1900\ntypedef const void* SsePrefetchPtrType;\n#else\ntypedef const char* SsePrefetchPtrType;\n#endif\n\n#ifndef EIGEN_VECTORIZE_AVX\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void prefetch&lt;float&gt;(const float* addr) {\n  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void prefetch&lt;double&gt;(const double* addr) {\n  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void prefetch&lt;int&gt;(const int* addr) {\n  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void prefetch&lt;int64_t&gt;(const int64_t* addr) {\n  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void prefetch&lt;uint32_t&gt;(const uint32_t* addr) {\n  _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0);\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pfrexp&lt;Packet4f&gt;(const Packet4f&amp; a, Packet4f&amp; exponent) {\n  return pfrexp_generic(a, exponent);\n}\n\n// Extract exponent without existence of Packet2l.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pfrexp_generic_get_biased_exponent(const Packet2d&amp; a) {\n  const Packet2d cst_exp_mask = pset1frombits&lt;Packet2d&gt;(static_cast&lt;uint64_t&gt;(0x7ff0000000000000ull));\n  __m128i a_expo = _mm_srli_epi64(_mm_castpd_si128(pand(a, cst_exp_mask)), 52);\n  return _mm_cvtepi32_pd(vec4i_swizzle1(a_expo, 0, 2, 1, 3));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pfrexp&lt;Packet2d&gt;(const Packet2d&amp; a, Packet2d&amp; exponent) {\n  return pfrexp_generic(a, exponent);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pldexp&lt;Packet4f&gt;(const Packet4f&amp; a, const Packet4f&amp; exponent) {\n  return pldexp_generic(a, exponent);\n}\n\n// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well\n// supported by SSE, and has more range than is needed for exponents.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pldexp&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; exponent) {\n  // Clamp exponent to [-2099, 2099]\n  const Packet2d max_exponent = pset1&lt;Packet2d&gt;(2099.0);\n  const Packet2d e = pmin(pmax(exponent, pnegate(max_exponent)), max_exponent);\n\n  // Convert e to integer and swizzle to low-order bits.\n  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);\n\n  // Split 2^e into four factors and multiply:\n  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);\n  Packet4i b = parithmetic_shift_right&lt;2&gt;(ei);                       // floor(e/4)\n  Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^b\n  Packet2d out = pmul(pmul(pmul(a, c), c), c);                       // a * 2^(3b)\n  b = psub(psub(psub(ei, b), b), b);                                 // e - 3b\n  c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));           // 2^(e - 3b)\n  out = pmul(out, c);                                                // a * 2^e\n  return out;\n}\n\n// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well\n// supported by SSE, and has more range than is needed for exponents.\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pldexp_fast&lt;Packet2d&gt;(const Packet2d&amp; a, const Packet2d&amp; exponent) {\n  // Clamp exponent to [-1023, 1024]\n  const Packet2d min_exponent = pset1&lt;Packet2d&gt;(-1023.0);\n  const Packet2d max_exponent = pset1&lt;Packet2d&gt;(1024.0);\n  const Packet2d e = pmin(pmax(exponent, min_exponent), max_exponent);\n\n  // Convert e to integer and swizzle to low-order bits.\n  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);\n\n  // Compute 2^e multiply:\n  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);\n  const Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(ei, bias), 52));  // 2^e\n  return pmul(a, c);\n}\n\n// with AVX, the default implementations based on pload1 are faster\n#ifndef __AVX__\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pbroadcast4&lt;Packet4f&gt;(const float* a, Packet4f&amp; a0, Packet4f&amp; a1, Packet4f&amp; a2, Packet4f&amp; a3) {\n  a3 = pload&lt;Packet4f&gt;(a);\n  a0 = vec4f_swizzle1(a3, 0, 0, 0, 0);\n  a1 = vec4f_swizzle1(a3, 1, 1, 1, 1);\n  a2 = vec4f_swizzle1(a3, 2, 2, 2, 2);\n  a3 = vec4f_swizzle1(a3, 3, 3, 3, 3);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE void pbroadcast4&lt;Packet2d&gt;(const double* a, Packet2d&amp; a0, Packet2d&amp; a1, Packet2d&amp; a2,\n                                               Packet2d&amp; a3) {\n#ifdef EIGEN_VECTORIZE_SSE3\n  a0 = _mm_loaddup_pd(a + 0);\n  a1 = _mm_loaddup_pd(a + 1);\n  a2 = _mm_loaddup_pd(a + 2);\n  a3 = _mm_loaddup_pd(a + 3);\n#else\n  a1 = pload&lt;Packet2d&gt;(a);\n  a0 = vec2d_swizzle1(a1, 0, 0);\n  a1 = vec2d_swizzle1(a1, 1, 1);\n  a3 = pload&lt;Packet2d&gt;(a + 2);\n  a2 = vec2d_swizzle1(a3, 0, 0);\n  a3 = vec2d_swizzle1(a3, 1, 1);\n#endif\n}\n#endif\n\nEIGEN_STRONG_INLINE void punpackp(Packet4f* vecs) {\n  vecs[1] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x55));\n  vecs[2] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xAA));\n  vecs[3] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xFF));\n  vecs[0] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x00));\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float predux&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  // Disable SSE3 _mm_hadd_pd that is extremely slow on all existing Intel&#x27;s architectures\n  // (from Nehalem to Haswell)\n  // #ifdef EIGEN_VECTORIZE_SSE3\n  //   Packet4f tmp = _mm_add_ps(a, vec4f_swizzle1(a,2,3,2,3));\n  //   return pfirst&lt;Packet4f&gt;(_mm_hadd_ps(tmp, tmp));\n  // #else\n  Packet4f tmp = _mm_add_ps(a, _mm_movehl_ps(a, a));\n  return pfirst&lt;Packet4f&gt;(_mm_add_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));\n  // #endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double predux&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  // Disable SSE3 _mm_hadd_pd that is extremely slow on all existing Intel&#x27;s architectures\n  // (from Nehalem to Haswell)\n  // #ifdef EIGEN_VECTORIZE_SSE3\n  //   return pfirst&lt;Packet2d&gt;(_mm_hadd_pd(a, a));\n  // #else\n  return pfirst&lt;Packet2d&gt;(_mm_add_sd(a, _mm_unpackhi_pd(a, a)));\n  // #endif\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int64_t predux&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  return pfirst&lt;Packet2l&gt;(_mm_add_epi64(a, _mm_unpackhi_epi64(a, a)));\n}\n\n#ifdef EIGEN_VECTORIZE_SSSE3\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int predux&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  Packet4i tmp0 = _mm_hadd_epi32(a, a);\n  return pfirst&lt;Packet4i&gt;(_mm_hadd_epi32(tmp0, tmp0));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t predux&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  Packet4ui tmp0 = _mm_hadd_epi32(a, a);\n  return pfirst&lt;Packet4ui&gt;(_mm_hadd_epi32(tmp0, tmp0));\n}\n#else\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int predux&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  Packet4i tmp = _mm_add_epi32(a, _mm_unpackhi_epi64(a, a));\n  return pfirst(tmp) + pfirst&lt;Packet4i&gt;(_mm_shuffle_epi32(tmp, 1));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t predux&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  Packet4ui tmp = _mm_add_epi32(a, _mm_unpackhi_epi64(a, a));\n  return pfirst(tmp) + pfirst&lt;Packet4ui&gt;(_mm_shuffle_epi32(tmp, 1));\n}\n#endif\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux&lt;Packet16b&gt;(const Packet16b&amp; a) {\n  Packet4i tmp = _mm_or_si128(a, _mm_unpackhi_epi64(a, a));\n  return (pfirst(tmp) != 0) || (pfirst&lt;Packet4i&gt;(_mm_shuffle_epi32(tmp, 1)) != 0);\n}\n\n// Other reduction functions:\n\n// mul\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float predux_mul&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  Packet4f tmp = _mm_mul_ps(a, _mm_movehl_ps(a, a));\n  return pfirst&lt;Packet4f&gt;(_mm_mul_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double predux_mul&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return pfirst&lt;Packet2d&gt;(_mm_mul_sd(a, _mm_unpackhi_pd(a, a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int64_t predux_mul&lt;Packet2l&gt;(const Packet2l&amp; a) {\n  EIGEN_ALIGN16 int64_t aux[2];\n  pstore(aux, a);\n  return aux[0] * aux[1];\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int predux_mul&lt;Packet4i&gt;(const Packet4i&amp; a) {\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (e.g., reusing pmul is very slow!)\n  // TODO try to call _mm_mul_epu32 directly\n  EIGEN_ALIGN16 int aux[4];\n  pstore(aux, a);\n  return (aux[0] * aux[1]) * (aux[2] * aux[3]);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t predux_mul&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (eg., reusing pmul is very slow !)\n  // TODO try to call _mm_mul_epu32 directly\n  EIGEN_ALIGN16 uint32_t aux[4];\n  pstore(aux, a);\n  return (aux[0] * aux[1]) * (aux[2] * aux[3]);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_mul&lt;Packet16b&gt;(const Packet16b&amp; a) {\n  Packet4i tmp = _mm_and_si128(a, _mm_unpackhi_epi64(a, a));\n  return ((pfirst&lt;Packet4i&gt;(tmp) == 0x01010101) &amp;&amp; (pfirst&lt;Packet4i&gt;(_mm_shuffle_epi32(tmp, 1)) == 0x01010101));\n}\n\n// min\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float predux_min&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  Packet4f tmp = _mm_min_ps(a, _mm_movehl_ps(a, a));\n  return pfirst&lt;Packet4f&gt;(_mm_min_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double predux_min&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return pfirst&lt;Packet2d&gt;(_mm_min_sd(a, _mm_unpackhi_pd(a, a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int predux_min&lt;Packet4i&gt;(const Packet4i&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  Packet4i tmp = _mm_min_epi32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));\n  return pfirst&lt;Packet4i&gt;(_mm_min_epi32(tmp, _mm_shuffle_epi32(tmp, 1)));\n#else\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (eg., it does not like using std::min after the pstore !!)\n  EIGEN_ALIGN16 int aux[4];\n  pstore(aux, a);\n  int aux0 = aux[0] &lt; aux[1] ? aux[0] : aux[1];\n  int aux2 = aux[2] &lt; aux[3] ? aux[2] : aux[3];\n  return aux0 &lt; aux2 ? aux0 : aux2;\n#endif  // EIGEN_VECTORIZE_SSE4_1\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t predux_min&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  Packet4ui tmp = _mm_min_epu32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));\n  return pfirst&lt;Packet4ui&gt;(_mm_min_epu32(tmp, _mm_shuffle_epi32(tmp, 1)));\n#else\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (eg., it does not like using std::min after the pstore !!)\n  EIGEN_ALIGN16 uint32_t aux[4];\n  pstore(aux, a);\n  uint32_t aux0 = aux[0] &lt; aux[1] ? aux[0] : aux[1];\n  uint32_t aux2 = aux[2] &lt; aux[3] ? aux[2] : aux[3];\n  return aux0 &lt; aux2 ? aux0 : aux2;\n#endif  // EIGEN_VECTORIZE_SSE4_1\n}\n\n// max\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float predux_max&lt;Packet4f&gt;(const Packet4f&amp; a) {\n  Packet4f tmp = _mm_max_ps(a, _mm_movehl_ps(a, a));\n  return pfirst&lt;Packet4f&gt;(_mm_max_ss(tmp, _mm_shuffle_ps(tmp, tmp, 1)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double predux_max&lt;Packet2d&gt;(const Packet2d&amp; a) {\n  return pfirst&lt;Packet2d&gt;(_mm_max_sd(a, _mm_unpackhi_pd(a, a)));\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE int predux_max&lt;Packet4i&gt;(const Packet4i&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  Packet4i tmp = _mm_max_epi32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));\n  return pfirst&lt;Packet4i&gt;(_mm_max_epi32(tmp, _mm_shuffle_epi32(tmp, 1)));\n#else\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (eg., it does not like using std::min after the pstore !!)\n  EIGEN_ALIGN16 int aux[4];\n  pstore(aux, a);\n  int aux0 = aux[0] &gt; aux[1] ? aux[0] : aux[1];\n  int aux2 = aux[2] &gt; aux[3] ? aux[2] : aux[3];\n  return aux0 &gt; aux2 ? aux0 : aux2;\n#endif  // EIGEN_VECTORIZE_SSE4_1\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE uint32_t predux_max&lt;Packet4ui&gt;(const Packet4ui&amp; a) {\n#ifdef EIGEN_VECTORIZE_SSE4_1\n  Packet4ui tmp = _mm_max_epu32(a, _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 0, 3, 2)));\n  return pfirst&lt;Packet4ui&gt;(_mm_max_epu32(tmp, _mm_shuffle_epi32(tmp, 1)));\n#else\n  // after some experiments, it is seems this is the fastest way to implement it\n  // for GCC (eg., it does not like using std::min after the pstore !!)\n  EIGEN_ALIGN16 uint32_t aux[4];\n  pstore(aux, a);\n  uint32_t aux0 = aux[0] &gt; aux[1] ? aux[0] : aux[1];\n  uint32_t aux2 = aux[2] &gt; aux[3] ? aux[2] : aux[3];\n  return aux0 &gt; aux2 ? aux0 : aux2;\n#endif  // EIGEN_VECTORIZE_SSE4_1\n}\n\n// not needed yet\n// template&lt;&gt; EIGEN_STRONG_INLINE bool predux_all(const Packet4f&amp; x)\n// {\n//   return _mm_movemask_ps(x) == 0xF;\n// }\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_any(const Packet2d&amp; x) {\n  return _mm_movemask_pd(x) != 0x0;\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_any(const Packet4f&amp; x) {\n  return _mm_movemask_ps(x) != 0x0;\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_any(const Packet2l&amp; x) {\n  return _mm_movemask_pd(_mm_castsi128_pd(x)) != 0x0;\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_any(const Packet4i&amp; x) {\n  return _mm_movemask_ps(_mm_castsi128_ps(x)) != 0x0;\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE bool predux_any(const Packet4ui&amp; x) {\n  return _mm_movemask_ps(_mm_castsi128_ps(x)) != 0x0;\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet4f, 4&gt;&amp; kernel) {\n  _MM_TRANSPOSE4_PS(kernel.packet[0], kernel.packet[1], kernel.packet[2], kernel.packet[3]);\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet2d, 2&gt;&amp; kernel) {\n  __m128d tmp = _mm_unpackhi_pd(kernel.packet[0], kernel.packet[1]);\n  kernel.packet[0] = _mm_unpacklo_pd(kernel.packet[0], kernel.packet[1]);\n  kernel.packet[1] = tmp;\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet2l, 2&gt;&amp; kernel) {\n  __m128i tmp = _mm_unpackhi_epi64(kernel.packet[0], kernel.packet[1]);\n  kernel.packet[0] = _mm_unpacklo_epi64(kernel.packet[0], kernel.packet[1]);\n  kernel.packet[1] = tmp;\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet4i, 4&gt;&amp; kernel) {\n  __m128i T0 = _mm_unpacklo_epi32(kernel.packet[0], kernel.packet[1]);\n  __m128i T1 = _mm_unpacklo_epi32(kernel.packet[2], kernel.packet[3]);\n  __m128i T2 = _mm_unpackhi_epi32(kernel.packet[0], kernel.packet[1]);\n  __m128i T3 = _mm_unpackhi_epi32(kernel.packet[2], kernel.packet[3]);\n\n  kernel.packet[0] = _mm_unpacklo_epi64(T0, T1);\n  kernel.packet[1] = _mm_unpackhi_epi64(T0, T1);\n  kernel.packet[2] = _mm_unpacklo_epi64(T2, T3);\n  kernel.packet[3] = _mm_unpackhi_epi64(T2, T3);\n}\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet4ui, 4&gt;&amp; kernel) {\n  ptranspose((PacketBlock&lt;Packet4i, 4&gt;&amp;)kernel);\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet16b, 4&gt;&amp; kernel) {\n  __m128i T0 = _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);\n  __m128i T1 = _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);\n  __m128i T2 = _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);\n  __m128i T3 = _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);\n  kernel.packet[0] = _mm_unpacklo_epi16(T0, T2);\n  kernel.packet[1] = _mm_unpackhi_epi16(T0, T2);\n  kernel.packet[2] = _mm_unpacklo_epi16(T1, T3);\n  kernel.packet[3] = _mm_unpackhi_epi16(T1, T3);\n}\n\nEIGEN_STRONG_INLINE void ptranspose(PacketBlock&lt;Packet16b, 16&gt;&amp; kernel) {\n  // If we number the elements in the input thus:\n  // kernel.packet[ 0] = {00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 0a, 0b, 0c, 0d, 0e, 0f}\n  // kernel.packet[ 1] = {10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1a, 1b, 1c, 1d, 1e, 1f}\n  // ...\n  // kernel.packet[15] = {f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, fa, fb, fc, fd, fe, ff},\n  //\n  // the desired output is:\n  // kernel.packet[ 0] = {00, 10, 20, 30, 40, 50, 60, 70, 80, 90, a0, b0, c0, d0, e0, f0}\n  // kernel.packet[ 1] = {01, 11, 21, 31, 41, 51, 61, 71, 81, 91, a1, b1, c1, d1, e1, f1}\n  // ...\n  // kernel.packet[15] = {0f, 1f, 2f, 3f, 4f, 5f, 6f, 7f, 8f, 9f, af, bf, cf, df, ef, ff},\n  __m128i t0 =\n      _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);  // 00 10 01 11 02 12 03 13 04 14 05 15 06 16 07 17\n  __m128i t1 =\n      _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);  // 08 18 09 19 0a 1a 0b 1b 0c 1c 0d 1d 0e 1e 0f 1f\n  __m128i t2 =\n      _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);  // 20 30 21 31 22 32 ...                     27 37\n  __m128i t3 =\n      _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);  // 28 38 29 39 2a 3a ...                     2f 3f\n  __m128i t4 =\n      _mm_unpacklo_epi8(kernel.packet[4], kernel.packet[5]);  // 40 50 41 51 42 52                         47 57\n  __m128i t5 = _mm_unpackhi_epi8(kernel.packet[4], kernel.packet[5]);  // 48 58 49 59 4a 5a\n  __m128i t6 = _mm_unpacklo_epi8(kernel.packet[6], kernel.packet[7]);\n  __m128i t7 = _mm_unpackhi_epi8(kernel.packet[6], kernel.packet[7]);\n  __m128i t8 = _mm_unpacklo_epi8(kernel.packet[8], kernel.packet[9]);\n  __m128i t9 = _mm_unpackhi_epi8(kernel.packet[8], kernel.packet[9]);\n  __m128i ta = _mm_unpacklo_epi8(kernel.packet[10], kernel.packet[11]);\n  __m128i tb = _mm_unpackhi_epi8(kernel.packet[10], kernel.packet[11]);\n  __m128i tc = _mm_unpacklo_epi8(kernel.packet[12], kernel.packet[13]);\n  __m128i td = _mm_unpackhi_epi8(kernel.packet[12], kernel.packet[13]);\n  __m128i te = _mm_unpacklo_epi8(kernel.packet[14], kernel.packet[15]);\n  __m128i tf = _mm_unpackhi_epi8(kernel.packet[14], kernel.packet[15]);\n\n  __m128i s0 = _mm_unpacklo_epi16(t0, t2);  // 00 10 20 30 01 11 21 31 02 12 22 32 03 13 23 33\n  __m128i s1 = _mm_unpackhi_epi16(t0, t2);  // 04 14 24 34\n  __m128i s2 = _mm_unpacklo_epi16(t1, t3);  // 08 18 28 38 ...\n  __m128i s3 = _mm_unpackhi_epi16(t1, t3);  // 0c 1c 2c 3c ...\n  __m128i s4 = _mm_unpacklo_epi16(t4, t6);  // 40 50 60 70 41 51 61 71 42 52 62 72 43 53 63 73\n  __m128i s5 = _mm_unpackhi_epi16(t4, t6);  // 44 54 64 74 ...\n  __m128i s6 = _mm_unpacklo_epi16(t5, t7);\n  __m128i s7 = _mm_unpackhi_epi16(t5, t7);\n  __m128i s8 = _mm_unpacklo_epi16(t8, ta);\n  __m128i s9 = _mm_unpackhi_epi16(t8, ta);\n  __m128i sa = _mm_unpacklo_epi16(t9, tb);\n  __m128i sb = _mm_unpackhi_epi16(t9, tb);\n  __m128i sc = _mm_unpacklo_epi16(tc, te);\n  __m128i sd = _mm_unpackhi_epi16(tc, te);\n  __m128i se = _mm_unpacklo_epi16(td, tf);\n  __m128i sf = _mm_unpackhi_epi16(td, tf);\n\n  __m128i u0 = _mm_unpacklo_epi32(s0, s4);  // 00 10 20 30 40 50 60 70 01 11 21 31 41 51 61 71\n  __m128i u1 = _mm_unpackhi_epi32(s0, s4);  // 02 12 22 32 42 52 62 72 03 13 23 33 43 53 63 73\n  __m128i u2 = _mm_unpacklo_epi32(s1, s5);\n  __m128i u3 = _mm_unpackhi_epi32(s1, s5);\n  __m128i u4 = _mm_unpacklo_epi32(s2, s6);\n  __m128i u5 = _mm_unpackhi_epi32(s2, s6);\n  __m128i u6 = _mm_unpacklo_epi32(s3, s7);\n  __m128i u7 = _mm_unpackhi_epi32(s3, s7);\n  __m128i u8 = _mm_unpacklo_epi32(s8, sc);\n  __m128i u9 = _mm_unpackhi_epi32(s8, sc);\n  __m128i ua = _mm_unpacklo_epi32(s9, sd);\n  __m128i ub = _mm_unpackhi_epi32(s9, sd);\n  __m128i uc = _mm_unpacklo_epi32(sa, se);\n  __m128i ud = _mm_unpackhi_epi32(sa, se);\n  __m128i ue = _mm_unpacklo_epi32(sb, sf);\n  __m128i uf = _mm_unpackhi_epi32(sb, sf);\n\n  kernel.packet[0] = _mm_unpacklo_epi64(u0, u8);\n  kernel.packet[1] = _mm_unpackhi_epi64(u0, u8);\n  kernel.packet[2] = _mm_unpacklo_epi64(u1, u9);\n  kernel.packet[3] = _mm_unpackhi_epi64(u1, u9);\n  kernel.packet[4] = _mm_unpacklo_epi64(u2, ua);\n  kernel.packet[5] = _mm_unpackhi_epi64(u2, ua);\n  kernel.packet[6] = _mm_unpacklo_epi64(u3, ub);\n  kernel.packet[7] = _mm_unpackhi_epi64(u3, ub);\n  kernel.packet[8] = _mm_unpacklo_epi64(u4, uc);\n  kernel.packet[9] = _mm_unpackhi_epi64(u4, uc);\n  kernel.packet[10] = _mm_unpacklo_epi64(u5, ud);\n  kernel.packet[11] = _mm_unpackhi_epi64(u5, ud);\n  kernel.packet[12] = _mm_unpacklo_epi64(u6, ue);\n  kernel.packet[13] = _mm_unpackhi_epi64(u6, ue);\n  kernel.packet[14] = _mm_unpacklo_epi64(u7, uf);\n  kernel.packet[15] = _mm_unpackhi_epi64(u7, uf);\n}\n\nEIGEN_STRONG_INLINE __m128i sse_blend_mask(const Selector&lt;2&gt;&amp; ifPacket) {\n  return _mm_set_epi64x(0 - ifPacket.select[1], 0 - ifPacket.select[0]);\n}\n\nEIGEN_STRONG_INLINE __m128i sse_blend_mask(const Selector&lt;4&gt;&amp; ifPacket) {\n  return _mm_set_epi32(0 - ifPacket.select[3], 0 - ifPacket.select[2], 0 - ifPacket.select[1], 0 - ifPacket.select[0]);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2l pblend(const Selector&lt;2&gt;&amp; ifPacket, const Packet2l&amp; thenPacket,\n                                    const Packet2l&amp; elsePacket) {\n  const __m128i true_mask = sse_blend_mask(ifPacket);\n  return pselect&lt;Packet2l&gt;(true_mask, thenPacket, elsePacket);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4i pblend(const Selector&lt;4&gt;&amp; ifPacket, const Packet4i&amp; thenPacket,\n                                    const Packet4i&amp; elsePacket) {\n  const __m128i true_mask = sse_blend_mask(ifPacket);\n  return pselect&lt;Packet4i&gt;(true_mask, thenPacket, elsePacket);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4ui pblend(const Selector&lt;4&gt;&amp; ifPacket, const Packet4ui&amp; thenPacket,\n                                     const Packet4ui&amp; elsePacket) {\n  return (Packet4ui)pblend(ifPacket, (Packet4i)thenPacket, (Packet4i)elsePacket);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet4f pblend(const Selector&lt;4&gt;&amp; ifPacket, const Packet4f&amp; thenPacket,\n                                    const Packet4f&amp; elsePacket) {\n  const __m128i true_mask = sse_blend_mask(ifPacket);\n  return pselect&lt;Packet4f&gt;(_mm_castsi128_ps(true_mask), thenPacket, elsePacket);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE Packet2d pblend(const Selector&lt;2&gt;&amp; ifPacket, const Packet2d&amp; thenPacket,\n                                    const Packet2d&amp; elsePacket) {\n  const __m128i true_mask = sse_blend_mask(ifPacket);\n  return pselect&lt;Packet2d&gt;(_mm_castsi128_pd(true_mask), thenPacket, elsePacket);\n}\n\n// Scalar path for pmadd with FMA to ensure consistency with vectorized path.\n#ifdef EIGEN_VECTORIZE_FMA\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pmadd(const float&amp; a, const float&amp; b, const float&amp; c) {\n  return ::fmaf(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pmadd(const double&amp; a, const double&amp; b, const double&amp; c) {\n  return ::fma(a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pmsub(const float&amp; a, const float&amp; b, const float&amp; c) {\n  return ::fmaf(a, b, -c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pmsub(const double&amp; a, const double&amp; b, const double&amp; c) {\n  return ::fma(a, b, -c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pnmadd(const float&amp; a, const float&amp; b, const float&amp; c) {\n  return ::fmaf(-a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pnmadd(const double&amp; a, const double&amp; b, const double&amp; c) {\n  return ::fma(-a, b, c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE float pnmsub(const float&amp; a, const float&amp; b, const float&amp; c) {\n  return ::fmaf(-a, b, -c);\n}\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE double pnmsub(const double&amp; a, const double&amp; b, const double&amp; c) {\n  return ::fma(-a, b, -c);\n}\n#endif\n\n#ifdef EIGEN_VECTORIZE_SSE4_1\n// Helpers for half-&gt;float and float-&gt;half conversions.\n// Currently only used by the AVX code.\nEIGEN_STRONG_INLINE __m128i half2floatsse(__m128i h) {\n  __m128i input = _mm_cvtepu16_epi32(h);\n\n  // Direct vectorization of half_to_float, C parts in the comments.\n  __m128i shifted_exp = _mm_set1_epi32(0x7c00 &lt;&lt; 13);\n  // o.u = (h.x &amp; 0x7fff) &lt;&lt; 13; // exponent/mantissa bits\n  __m128i ou = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x7fff)), 13);\n  // exp = shifted_exp &amp; o.u;   // just the exponent\n  __m128i exp = _mm_and_si128(ou, shifted_exp);\n  // o.u += (127 - 15) &lt;&lt; 23;\n  ou = _mm_add_epi32(ou, _mm_set1_epi32((127 - 15) &lt;&lt; 23));\n\n  // Inf/NaN?\n  __m128i naninf_mask = _mm_cmpeq_epi32(exp, shifted_exp);\n  // Inf/NaN adjust\n  __m128i naninf_adj = _mm_and_si128(_mm_set1_epi32((128 - 16) &lt;&lt; 23), naninf_mask);\n  // extra exp adjust for  Inf/NaN\n  ou = _mm_add_epi32(ou, naninf_adj);\n\n  // Zero/Denormal?\n  __m128i zeroden_mask = _mm_cmpeq_epi32(exp, _mm_setzero_si128());\n  __m128i zeroden_adj = _mm_and_si128(zeroden_mask, _mm_set1_epi32(1 &lt;&lt; 23));\n  // o.u += 1 &lt;&lt; 23;\n  ou = _mm_add_epi32(ou, zeroden_adj);\n  // magic.u = 113 &lt;&lt; 23\n  __m128i magic = _mm_and_si128(zeroden_mask, _mm_set1_epi32(113 &lt;&lt; 23));\n  // o.f -= magic.f\n  ou = _mm_castps_si128(_mm_sub_ps(_mm_castsi128_ps(ou), _mm_castsi128_ps(magic)));\n\n  __m128i sign = _mm_slli_epi32(_mm_and_si128(input, _mm_set1_epi32(0x8000)), 16);\n  // o.u |= (h.x &amp; 0x8000) &lt;&lt; 16;    // sign bit\n  ou = _mm_or_si128(ou, sign);\n  // return o.f;\n  // We are actually returning uint version, to make\n  // _mm256_insertf128_si256 work.\n  return ou;\n}\n\nEIGEN_STRONG_INLINE __m128i float2half(__m128 f) {\n  // unsigned int sign_mask = 0x80000000u;\n  __m128i sign = _mm_set1_epi32(0x80000000u);\n  // unsigned int sign = f.u &amp; sign_mask;\n  sign = _mm_and_si128(sign, _mm_castps_si128(f));\n  // f.u ^= sign;\n  f = _mm_xor_ps(f, _mm_castsi128_ps(sign));\n\n  __m128i fu = _mm_castps_si128(f);\n\n  __m128i f16max = _mm_set1_epi32((127 + 16) &lt;&lt; 23);\n  __m128i f32infty = _mm_set1_epi32(255 &lt;&lt; 23);\n  // if (f.u &gt;= f16max.u) // result is Inf or NaN (all exponent bits set)\n  // there is no _mm_cmpge_epi32, so use lt and swap operands\n  __m128i infnan_mask = _mm_cmplt_epi32(f16max, _mm_castps_si128(f));\n  __m128i inf_mask = _mm_cmpgt_epi32(_mm_castps_si128(f), f32infty);\n  __m128i nan_mask = _mm_andnot_si128(inf_mask, infnan_mask);\n  __m128i inf_value = _mm_and_si128(inf_mask, _mm_set1_epi32(0x7e00));\n  __m128i nan_value = _mm_and_si128(nan_mask, _mm_set1_epi32(0x7c00));\n  // o.x = (f.u &gt; f32infty.u) ? 0x7e00 : 0x7c00; // NaN-&gt;qNaN and Inf-&gt;Inf\n  __m128i naninf_value = _mm_or_si128(inf_value, nan_value);\n\n  __m128i denorm_magic = _mm_set1_epi32(((127 - 15) + (23 - 10) + 1) &lt;&lt; 23);\n  __m128i subnorm_mask = _mm_cmplt_epi32(_mm_castps_si128(f), _mm_set1_epi32(113 &lt;&lt; 23));\n  //  f.f += denorm_magic.f;\n  f = _mm_add_ps(f, _mm_castsi128_ps(denorm_magic));\n  // f.u - denorm_magic.u\n  __m128i o = _mm_sub_epi32(_mm_castps_si128(f), denorm_magic);\n  o = _mm_and_si128(o, subnorm_mask);\n  // Correct result for inf/nan/zero/subnormal, 0 otherwise\n  o = _mm_or_si128(o, naninf_value);\n\n  __m128i mask = _mm_or_si128(infnan_mask, subnorm_mask);\n  o = _mm_and_si128(o, mask);\n\n  // mant_odd = (f.u &gt;&gt; 13) &amp; 1;\n  __m128i mand_odd = _mm_and_si128(_mm_srli_epi32(fu, 13), _mm_set1_epi32(0x1));\n  // f.u += 0xc8000fffU;\n  fu = _mm_add_epi32(fu, _mm_set1_epi32(0xc8000fffU));\n  // f.u += mant_odd;\n  fu = _mm_add_epi32(fu, mand_odd);\n  fu = _mm_andnot_si128(mask, fu);\n  // f.u &gt;&gt; 13\n  fu = _mm_srli_epi32(fu, 13);\n  o = _mm_or_si128(fu, o);\n\n  // o.x |= static_cast&lt;numext::uint16_t&gt;(sign &gt;&gt; 16);\n  o = _mm_or_si128(o, _mm_srli_epi32(sign, 16));\n\n  // 16 bit values\n  return _mm_and_si128(o, _mm_set1_epi32(0xffff));\n}\n#endif\n\n// Packet math for Eigen::half\n// Disable the following code since it&#x27;s broken on too many platforms / compilers.\n// #elif defined(EIGEN_VECTORIZE_SSE) &amp;&amp; (!EIGEN_ARCH_x86_64) &amp;&amp; (!EIGEN_COMP_MSVC)\n#if 0\n\ntypedef struct {\n  __m64 x;\n} Packet4h;\n\n\ntemplate&lt;&gt; struct is_arithmetic&lt;Packet4h&gt; { enum { value = true }; };\n\ntemplate &lt;&gt;\nstruct packet_traits&lt;Eigen::half&gt; : default_packet_traits {\n  typedef Packet4h type;\n  // There is no half-size packet for Packet4h.\n  typedef Packet4h half;\n  enum {\n    Vectorizable = 1,\n    AlignedOnScalar = 1,\n    size = 4,\n    HasAdd    = 1,\n    HasSub    = 1,\n    HasMul    = 1,\n    HasDiv    = 1,\n    HasNegate = 0,\n    HasAbs    = 0,\n    HasAbs2   = 0,\n    HasMin    = 0,\n    HasMax    = 0,\n    HasConj   = 0,\n    HasSetLinear = 0,\n  };\n};\n\n\ntemplate&lt;&gt; struct unpacket_traits&lt;Packet4h&gt; { typedef Eigen::half type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h half; };\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pset1&lt;Packet4h&gt;(const Eigen::half&amp; from) {\n  Packet4h result;\n  result.x = _mm_set1_pi16(from.x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Eigen::half pfirst&lt;Packet4h&gt;(const Packet4h&amp; from) {\n  return half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(_mm_cvtsi64_si32(from.x)));\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pconj(const Packet4h&amp; a) { return a; }\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h padd&lt;Packet4h&gt;(const Packet4h&amp; a, const Packet4h&amp; b) {\n  __int64_t a64 = _mm_cvtm64_si64(a.x);\n  __int64_t b64 = _mm_cvtm64_si64(b.x);\n\n  Eigen::half h[4];\n\n  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64));\n  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64));\n  h[0] = ha + hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 16));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 16));\n  h[1] = ha + hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 32));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 32));\n  h[2] = ha + hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 48));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 48));\n  h[3] = ha + hb;\n  Packet4h result;\n  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h psub&lt;Packet4h&gt;(const Packet4h&amp; a, const Packet4h&amp; b) {\n  __int64_t a64 = _mm_cvtm64_si64(a.x);\n  __int64_t b64 = _mm_cvtm64_si64(b.x);\n\n  Eigen::half h[4];\n\n  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64));\n  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64));\n  h[0] = ha - hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 16));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 16));\n  h[1] = ha - hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 32));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 32));\n  h[2] = ha - hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 48));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 48));\n  h[3] = ha - hb;\n  Packet4h result;\n  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pmul&lt;Packet4h&gt;(const Packet4h&amp; a, const Packet4h&amp; b) {\n  __int64_t a64 = _mm_cvtm64_si64(a.x);\n  __int64_t b64 = _mm_cvtm64_si64(b.x);\n\n  Eigen::half h[4];\n\n  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64));\n  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64));\n  h[0] = ha * hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 16));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 16));\n  h[1] = ha * hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 32));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 32));\n  h[2] = ha * hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 48));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 48));\n  h[3] = ha * hb;\n  Packet4h result;\n  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pdiv&lt;Packet4h&gt;(const Packet4h&amp; a, const Packet4h&amp; b) {\n  __int64_t a64 = _mm_cvtm64_si64(a.x);\n  __int64_t b64 = _mm_cvtm64_si64(b.x);\n\n  Eigen::half h[4];\n\n  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64));\n  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64));\n  h[0] = ha / hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 16));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 16));\n  h[1] = ha / hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 32));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 32));\n  h[2] = ha / hb;\n  ha = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(a64 &gt;&gt; 48));\n  hb = half_impl::raw_uint16_to_half(static_cast&lt;unsigned short&gt;(b64 &gt;&gt; 48));\n  h[3] = ha / hb;\n  Packet4h result;\n  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pload&lt;Packet4h&gt;(const Eigen::half* from) {\n  Packet4h result;\n  result.x = _mm_cvtsi64_m64(*reinterpret_cast&lt;const __int64_t*&gt;(from));\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h ploadu&lt;Packet4h&gt;(const Eigen::half* from) {\n  Packet4h result;\n  result.x = _mm_cvtsi64_m64(*reinterpret_cast&lt;const __int64_t*&gt;(from));\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE void pstore&lt;Eigen::half&gt;(Eigen::half* to, const Packet4h&amp; from) {\n  __int64_t r = _mm_cvtm64_si64(from.x);\n  *(reinterpret_cast&lt;__int64_t*&gt;(to)) = r;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE void pstoreu&lt;Eigen::half&gt;(Eigen::half* to, const Packet4h&amp; from) {\n  __int64_t r = _mm_cvtm64_si64(from.x);\n  *(reinterpret_cast&lt;__int64_t*&gt;(to)) = r;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h\nploadquad&lt;Packet4h&gt;(const Eigen::half* from) {\n  return pset1&lt;Packet4h&gt;(*from);\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE Packet4h pgather&lt;Eigen::half, Packet4h&gt;(const Eigen::half* from, Index stride)\n{\n  Packet4h result;\n  result.x = _mm_set_pi16(from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);\n  return result;\n}\n\ntemplate&lt;&gt; EIGEN_STRONG_INLINE void pscatter&lt;Eigen::half, Packet4h&gt;(Eigen::half* to, const Packet4h&amp; from, Index stride)\n{\n  __int64_t a = _mm_cvtm64_si64(from.x);\n  to[stride*0].x = static_cast&lt;unsigned short&gt;(a);\n  to[stride*1].x = static_cast&lt;unsigned short&gt;(a &gt;&gt; 16);\n  to[stride*2].x = static_cast&lt;unsigned short&gt;(a &gt;&gt; 32);\n  to[stride*3].x = static_cast&lt;unsigned short&gt;(a &gt;&gt; 48);\n}\n\nEIGEN_STRONG_INLINE void\nptranspose(PacketBlock&lt;Packet4h,4&gt;&amp; kernel) {\n  __m64 T0 = _mm_unpacklo_pi16(kernel.packet[0].x, kernel.packet[1].x);\n  __m64 T1 = _mm_unpacklo_pi16(kernel.packet[2].x, kernel.packet[3].x);\n  __m64 T2 = _mm_unpackhi_pi16(kernel.packet[0].x, kernel.packet[1].x);\n  __m64 T3 = _mm_unpackhi_pi16(kernel.packet[2].x, kernel.packet[3].x);\n\n  kernel.packet[0].x = _mm_unpacklo_pi32(T0, T1);\n  kernel.packet[1].x = _mm_unpackhi_pi32(T0, T1);\n  kernel.packet[2].x = _mm_unpacklo_pi32(T2, T3);\n  kernel.packet[3].x = _mm_unpackhi_pi32(T2, T3);\n}\n\n#endif\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#if EIGEN_COMP_PGI &amp;&amp; EIGEN_COMP_PGI &lt; 1900\n// PGI++ does not define the following intrinsics in C++ mode.\nstatic inline __m128 _mm_castpd_ps(__m128d x) { return reinterpret_cast&lt;__m128&amp;&gt;(x); }\nstatic inline __m128i _mm_castpd_si128(__m128d x) { return reinterpret_cast&lt;__m128i&amp;&gt;(x); }\nstatic inline __m128d _mm_castps_pd(__m128 x) { return reinterpret_cast&lt;__m128d&amp;&gt;(x); }\nstatic inline __m128i _mm_castps_si128(__m128 x) { return reinterpret_cast&lt;__m128i&amp;&gt;(x); }\nstatic inline __m128 _mm_castsi128_ps(__m128i x) { return reinterpret_cast&lt;__m128&amp;&gt;(x); }\nstatic inline __m128d _mm_castsi128_pd(__m128i x) { return reinterpret_cast&lt;__m128d&amp;&gt;(x); }\n#endif\n\n#endif  // EIGEN_PACKET_MATH_SSE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_GENERIC_PACKET_MATH_H\n#define EIGEN_GENERIC_PACKET_MATH_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n/** \\internal\n * \\file GenericPacketMath.h\n *\n * Default implementation for types not supported by the vectorization.\n * In practice these functions are provided to make easier the writing\n * of generic vectorized code.\n */\n\n#ifndef EIGEN_DEBUG_ALIGNED_LOAD\n#define EIGEN_DEBUG_ALIGNED_LOAD\n#endif\n\n#ifndef EIGEN_DEBUG_UNALIGNED_LOAD\n#define EIGEN_DEBUG_UNALIGNED_LOAD\n#endif\n\n#ifndef EIGEN_DEBUG_ALIGNED_STORE\n#define EIGEN_DEBUG_ALIGNED_STORE\n#endif\n\n#ifndef EIGEN_DEBUG_UNALIGNED_STORE\n#define EIGEN_DEBUG_UNALIGNED_STORE\n#endif\n\nstruct default_packet_traits {\n  enum {\n    // Ops that are implemented for most types.\n    HasAdd = 1,\n    HasSub = 1,\n    HasShift = 1,\n    HasMul = 1,\n    HasNegate = 1,\n    HasAbs = 1,\n    HasAbs2 = 1,\n    HasMin = 1,\n    HasMax = 1,\n    HasConj = 1,\n    HasSetLinear = 1,\n    HasSign = 1,\n    // By default, the nearest integer functions (rint, round, floor, ceil, trunc) are enabled for all scalar and packet\n    // types\n    HasRound = 1,\n\n    HasArg = 0,\n    HasAbsDiff = 0,\n    HasBlend = 0,\n    // This flag is used to indicate whether packet comparison is supported.\n    // pcmp_eq, pcmp_lt and pcmp_le should be defined for it to be true.\n    HasCmp = 0,\n\n    HasDiv = 0,\n    HasReciprocal = 0,\n    HasSqrt = 0,\n    HasRsqrt = 0,\n    HasExp = 0,\n    HasExpm1 = 0,\n    HasLog = 0,\n    HasLog1p = 0,\n    HasLog10 = 0,\n    HasPow = 0,\n    HasSin = 0,\n    HasCos = 0,\n    HasTan = 0,\n    HasASin = 0,\n    HasACos = 0,\n    HasATan = 0,\n    HasATanh = 0,\n    HasSinh = 0,\n    HasCosh = 0,\n    HasTanh = 0,\n    HasLGamma = 0,\n    HasDiGamma = 0,\n    HasZeta = 0,\n    HasPolygamma = 0,\n    HasErf = 0,\n    HasErfc = 0,\n    HasNdtri = 0,\n    HasBessel = 0,\n    HasIGamma = 0,\n    HasIGammaDerA = 0,\n    HasGammaSampleDerAlpha = 0,\n    HasIGammac = 0,\n    HasBetaInc = 0\n  };\n};\n\ntemplate &lt;typename T&gt;\nstruct packet_traits : default_packet_traits {\n  typedef T type;\n  typedef T half;\n  enum {\n    Vectorizable = 0,\n    size = 1,\n    AlignedOnScalar = 0,\n  };\n  enum {\n    HasAdd = 0,\n    HasSub = 0,\n    HasMul = 0,\n    HasNegate = 0,\n    HasAbs = 0,\n    HasAbs2 = 0,\n    HasMin = 0,\n    HasMax = 0,\n    HasConj = 0,\n    HasSetLinear = 0\n  };\n};\n\ntemplate &lt;typename T&gt;\nstruct packet_traits&lt;const T&gt; : packet_traits&lt;T&gt; {};\n\ntemplate &lt;typename T&gt;\nstruct unpacket_traits {\n  typedef T type;\n  typedef T half;\n  typedef typename numext::get_integer_by_size&lt;sizeof(T)&gt;::signed_type integer_packet;\n  enum {\n    size = 1,\n    alignment = alignof(T),\n    vectorizable = false,\n    masked_load_available = false,\n    masked_store_available = false\n  };\n};\n\ntemplate &lt;typename T&gt;\nstruct unpacket_traits&lt;const T&gt; : unpacket_traits&lt;T&gt; {};\n\n/** \\internal A convenience utility for determining if the type is a scalar.\n * This is used to enable some generic packet implementations.\n */\ntemplate &lt;typename Packet&gt;\nstruct is_scalar {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  enum { value = internal::is_same&lt;Packet, Scalar&gt;::value };\n};\n\n// automatically and succinctly define combinations of pcast&lt;SrcPacket,TgtPacket&gt; when\n// 1) the packets are the same type, or\n// 2) the packets differ only in sign.\n// In both of these cases, preinterpret (bit_cast) is equivalent to pcast (static_cast)\ntemplate &lt;typename SrcPacket, typename TgtPacket,\n          bool Scalar = is_scalar&lt;SrcPacket&gt;::value &amp;&amp; is_scalar&lt;TgtPacket&gt;::value&gt;\nstruct is_degenerate_helper : is_same&lt;SrcPacket, TgtPacket&gt; {};\ntemplate &lt;&gt;\nstruct is_degenerate_helper&lt;int8_t, uint8_t, true&gt; : std::true_type {};\ntemplate &lt;&gt;\nstruct is_degenerate_helper&lt;int16_t, uint16_t, true&gt; : std::true_type {};\ntemplate &lt;&gt;\nstruct is_degenerate_helper&lt;int32_t, uint32_t, true&gt; : std::true_type {};\ntemplate &lt;&gt;\nstruct is_degenerate_helper&lt;int64_t, uint64_t, true&gt; : std::true_type {};\n\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nstruct is_degenerate_helper&lt;SrcPacket, TgtPacket, false&gt; {\n  using SrcScalar = typename unpacket_traits&lt;SrcPacket&gt;::type;\n  static constexpr int SrcSize = unpacket_traits&lt;SrcPacket&gt;::size;\n  using TgtScalar = typename unpacket_traits&lt;TgtPacket&gt;::type;\n  static constexpr int TgtSize = unpacket_traits&lt;TgtPacket&gt;::size;\n  static constexpr bool value = is_degenerate_helper&lt;SrcScalar, TgtScalar, true&gt;::value &amp;&amp; (SrcSize == TgtSize);\n};\n\n// is_degenerate&lt;T1,T2&gt;::value == is_degenerate&lt;T2,T1&gt;::value\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nstruct is_degenerate {\n  static constexpr bool value =\n      is_degenerate_helper&lt;SrcPacket, TgtPacket&gt;::value || is_degenerate_helper&lt;TgtPacket, SrcPacket&gt;::value;\n};\n\ntemplate &lt;typename Packet&gt;\nstruct is_half {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  static constexpr int Size = unpacket_traits&lt;Packet&gt;::size;\n  using DefaultPacket = typename packet_traits&lt;Scalar&gt;::type;\n  static constexpr int DefaultSize = unpacket_traits&lt;DefaultPacket&gt;::size;\n  static constexpr bool value = Size != 1 &amp;&amp; Size &lt; DefaultSize;\n};\n\ntemplate &lt;typename Src, typename Tgt&gt;\nstruct type_casting_traits {\n  enum {\n    VectorizedCast =\n        is_degenerate&lt;Src, Tgt&gt;::value &amp;&amp; packet_traits&lt;Src&gt;::Vectorizable &amp;&amp; packet_traits&lt;Tgt&gt;::Vectorizable,\n    SrcCoeffRatio = 1,\n    TgtCoeffRatio = 1\n  };\n};\n\n// provides a succinct template to define vectorized casting traits with respect to the largest accessible packet types\ntemplate &lt;typename Src, typename Tgt&gt;\nstruct vectorized_type_casting_traits {\n  enum : int {\n    DefaultSrcPacketSize = packet_traits&lt;Src&gt;::size,\n    DefaultTgtPacketSize = packet_traits&lt;Tgt&gt;::size,\n    VectorizedCast = 1,\n    SrcCoeffRatio = plain_enum_max(DefaultTgtPacketSize / DefaultSrcPacketSize, 1),\n    TgtCoeffRatio = plain_enum_max(DefaultSrcPacketSize / DefaultTgtPacketSize, 1)\n  };\n};\n\n/** \\internal Wrapper to ensure that multiple packet types can map to the same\n    same underlying vector type. */\ntemplate &lt;typename T, int unique_id = 0&gt;\nstruct eigen_packet_wrapper {\n  EIGEN_ALWAYS_INLINE operator T&amp;() { return m_val; }\n  EIGEN_ALWAYS_INLINE operator const T&amp;() const { return m_val; }\n  EIGEN_ALWAYS_INLINE eigen_packet_wrapper() = default;\n  EIGEN_ALWAYS_INLINE eigen_packet_wrapper(const T&amp; v) : m_val(v) {}\n  EIGEN_ALWAYS_INLINE eigen_packet_wrapper&amp; operator=(const T&amp; v) {\n    m_val = v;\n    return *this;\n  }\n\n  T m_val;\n};\n\ntemplate &lt;typename Target, typename Packet, bool IsSame = is_same&lt;Target, Packet&gt;::value&gt;\nstruct preinterpret_generic;\n\ntemplate &lt;typename Target, typename Packet&gt;\nstruct preinterpret_generic&lt;Target, Packet, false&gt; {\n  // the packets are not the same, attempt scalar bit_cast\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Target run(const Packet&amp; a) {\n    return numext::bit_cast&lt;Target, Packet&gt;(a);\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct preinterpret_generic&lt;Packet, Packet, true&gt; {\n  // the packets are the same type: do nothing\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; a) { return a; }\n};\n\n/** \\internal \\returns reinterpret_cast&lt;Target&gt;(a) */\ntemplate &lt;typename Target, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Target preinterpret(const Packet&amp; a) {\n  return preinterpret_generic&lt;Target, Packet&gt;::run(a);\n}\n\ntemplate &lt;typename SrcPacket, typename TgtPacket, bool Degenerate = is_degenerate&lt;SrcPacket, TgtPacket&gt;::value,\n          bool TgtIsHalf = is_half&lt;TgtPacket&gt;::value&gt;\nstruct pcast_generic;\n\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nstruct pcast_generic&lt;SrcPacket, TgtPacket, false, false&gt; {\n  // the packets are not degenerate: attempt scalar static_cast\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket&amp; a) {\n    return cast_impl&lt;SrcPacket, TgtPacket&gt;::run(a);\n  }\n};\n\ntemplate &lt;typename Packet&gt;\nstruct pcast_generic&lt;Packet, Packet, true, false&gt; {\n  // the packets are the same: do nothing\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run(const Packet&amp; a) { return a; }\n};\n\ntemplate &lt;typename SrcPacket, typename TgtPacket, bool TgtIsHalf&gt;\nstruct pcast_generic&lt;SrcPacket, TgtPacket, true, TgtIsHalf&gt; {\n  // the packets are degenerate: preinterpret is equivalent to pcast\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket&amp; a) { return preinterpret&lt;TgtPacket&gt;(a); }\n};\n\n/** \\internal \\returns static_cast&lt;TgtType&gt;(a) (coeff-wise) */\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nEIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket&amp; a) {\n  return pcast_generic&lt;SrcPacket, TgtPacket&gt;::run(a);\n}\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nEIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket&amp; a, const SrcPacket&amp; b) {\n  return pcast_generic&lt;SrcPacket, TgtPacket&gt;::run(a, b);\n}\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nEIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket&amp; a, const SrcPacket&amp; b, const SrcPacket&amp; c,\n                                         const SrcPacket&amp; d) {\n  return pcast_generic&lt;SrcPacket, TgtPacket&gt;::run(a, b, c, d);\n}\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nEIGEN_DEVICE_FUNC inline TgtPacket pcast(const SrcPacket&amp; a, const SrcPacket&amp; b, const SrcPacket&amp; c, const SrcPacket&amp; d,\n                                         const SrcPacket&amp; e, const SrcPacket&amp; f, const SrcPacket&amp; g,\n                                         const SrcPacket&amp; h) {\n  return pcast_generic&lt;SrcPacket, TgtPacket&gt;::run(a, b, c, d, e, f, g, h);\n}\n\ntemplate &lt;typename SrcPacket, typename TgtPacket&gt;\nstruct pcast_generic&lt;SrcPacket, TgtPacket, false, true&gt; {\n  // TgtPacket is a half packet of some other type\n  // perform cast and truncate result\n  using DefaultTgtPacket = typename is_half&lt;TgtPacket&gt;::DefaultPacket;\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TgtPacket run(const SrcPacket&amp; a) {\n    return preinterpret&lt;TgtPacket&gt;(pcast&lt;SrcPacket, DefaultTgtPacket&gt;(a));\n  }\n};\n\n/** \\internal \\returns a + b (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet padd(const Packet&amp; a, const Packet&amp; b) {\n  return a + b;\n}\n// Avoid compiler warning for boolean algebra.\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline bool padd(const bool&amp; a, const bool&amp; b) {\n  return a || b;\n}\n\n/** \\internal \\returns a packet version of \\a *from, (un-aligned masked add)\n * There is no generic implementation. We only have implementations for specialized\n * cases. Generic case should not be called.\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline std::enable_if_t&lt;unpacket_traits&lt;Packet&gt;::masked_fpops_available, Packet&gt; padd(\n    const Packet&amp; a, const Packet&amp; b, typename unpacket_traits&lt;Packet&gt;::mask_t umask);\n\n/** \\internal \\returns a - b (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet psub(const Packet&amp; a, const Packet&amp; b) {\n  return a - b;\n}\n\n/** \\internal \\returns -a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pnegate(const Packet&amp; a) {\n  EIGEN_STATIC_ASSERT((!is_same&lt;typename unpacket_traits&lt;Packet&gt;::type, bool&gt;::value),\n                      NEGATE IS NOT DEFINED FOR BOOLEAN TYPES)\n  return numext::negate(a);\n}\n\n/** \\internal \\returns conj(a) (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pconj(const Packet&amp; a) {\n  return numext::conj(a);\n}\n\n/** \\internal \\returns a * b (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmul(const Packet&amp; a, const Packet&amp; b) {\n  return a * b;\n}\n// Avoid compiler warning for boolean algebra.\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline bool pmul(const bool&amp; a, const bool&amp; b) {\n  return a &amp;&amp; b;\n}\n\n/** \\internal \\returns a / b (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pdiv(const Packet&amp; a, const Packet&amp; b) {\n  return a / b;\n}\n// Avoid compiler warning for boolean algebra.\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline bool pdiv(const bool&amp; a, const bool&amp; b) {\n  return a &amp;&amp; b;\n}\n\n// In the generic case, memset to all one bits.\ntemplate &lt;typename Packet, typename EnableIf = void&gt;\nstruct ptrue_impl {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; /*a*/) {\n    Packet b;\n    memset(static_cast&lt;void*&gt;(&amp;b), 0xff, sizeof(Packet));\n    return b;\n  }\n};\n\n// For booleans, we can only directly set a valid `bool` value to avoid UB.\ntemplate &lt;&gt;\nstruct ptrue_impl&lt;bool, void&gt; {\n  static EIGEN_DEVICE_FUNC inline bool run(const bool&amp; /*a*/) { return true; }\n};\n\n// For non-trivial scalars, set to Scalar(1) (i.e. a non-zero value).\n// Although this is technically not a valid bitmask, the scalar path for pselect\n// uses a comparison to zero, so this should still work in most cases. We don&#x27;t\n// have another option, since the scalar type requires initialization.\ntemplate &lt;typename T&gt;\nstruct ptrue_impl&lt;T, std::enable_if_t&lt;is_scalar&lt;T&gt;::value &amp;&amp; NumTraits&lt;T&gt;::RequireInitialization&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline T run(const T&amp; /*a*/) { return T(1); }\n};\n\n/** \\internal \\returns one bits. */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ptrue(const Packet&amp; a) {\n  return ptrue_impl&lt;Packet&gt;::run(a);\n}\n\n// In the general case, memset to zero.\ntemplate &lt;typename Packet, typename EnableIf = void&gt;\nstruct pzero_impl {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; /*a*/) {\n    Packet b;\n    memset(static_cast&lt;void*&gt;(&amp;b), 0x00, sizeof(Packet));\n    return b;\n  }\n};\n\n// For scalars, explicitly set to Scalar(0), since the underlying representation\n// for zero may not consist of all-zero bits.\ntemplate &lt;typename T&gt;\nstruct pzero_impl&lt;T, std::enable_if_t&lt;is_scalar&lt;T&gt;::value&gt;&gt; {\n  static EIGEN_DEVICE_FUNC inline T run(const T&amp; /*a*/) { return T(0); }\n};\n\n/** \\internal \\returns packet of zeros */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pzero(const Packet&amp; a) {\n  return pzero_impl&lt;Packet&gt;::run(a);\n}\n\n/** \\internal \\returns a &lt;= b as a bit mask */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pcmp_le(const Packet&amp; a, const Packet&amp; b) {\n  return a &lt;= b ? ptrue(a) : pzero(a);\n}\n\n/** \\internal \\returns a &lt; b as a bit mask */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pcmp_lt(const Packet&amp; a, const Packet&amp; b) {\n  return a &lt; b ? ptrue(a) : pzero(a);\n}\n\n/** \\internal \\returns a == b as a bit mask */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pcmp_eq(const Packet&amp; a, const Packet&amp; b) {\n  return a == b ? ptrue(a) : pzero(a);\n}\n\n/** \\internal \\returns a &lt; b or a==NaN or b==NaN as a bit mask */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pcmp_lt_or_nan(const Packet&amp; a, const Packet&amp; b) {\n  return a &gt;= b ? pzero(a) : ptrue(a);\n}\n\ntemplate &lt;typename T&gt;\nstruct bit_and {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T&amp; a, const T&amp; b) const { return a &amp; b; }\n};\n\ntemplate &lt;typename T&gt;\nstruct bit_or {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T&amp; a, const T&amp; b) const { return a | b; }\n};\n\ntemplate &lt;typename T&gt;\nstruct bit_xor {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T&amp; a, const T&amp; b) const { return a ^ b; }\n};\n\ntemplate &lt;typename T&gt;\nstruct bit_not {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T&amp; a) const { return ~a; }\n};\n\ntemplate &lt;&gt;\nstruct bit_and&lt;bool&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool&amp; a, const bool&amp; b) const {\n    return a &amp;&amp; b;\n  }\n};\n\ntemplate &lt;&gt;\nstruct bit_or&lt;bool&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool&amp; a, const bool&amp; b) const {\n    return a || b;\n  }\n};\n\ntemplate &lt;&gt;\nstruct bit_xor&lt;bool&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool&amp; a, const bool&amp; b) const {\n    return a != b;\n  }\n};\n\ntemplate &lt;&gt;\nstruct bit_not&lt;bool&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE bool operator()(const bool&amp; a) const { return !a; }\n};\n\n// Use operators &amp;, |, ^, ~.\ntemplate &lt;typename T&gt;\nstruct operator_bitwise_helper {\n  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T&amp; a, const T&amp; b) { return bit_and&lt;T&gt;()(a, b); }\n  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T&amp; a, const T&amp; b) { return bit_or&lt;T&gt;()(a, b); }\n  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T&amp; a, const T&amp; b) { return bit_xor&lt;T&gt;()(a, b); }\n  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T&amp; a) { return bit_not&lt;T&gt;()(a); }\n};\n\n// Apply binary operations byte-by-byte\ntemplate &lt;typename T&gt;\nstruct bytewise_bitwise_helper {\n  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T&amp; a, const T&amp; b) {\n    return binary(a, b, bit_and&lt;unsigned char&gt;());\n  }\n  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T&amp; a, const T&amp; b) { return binary(a, b, bit_or&lt;unsigned char&gt;()); }\n  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T&amp; a, const T&amp; b) {\n    return binary(a, b, bit_xor&lt;unsigned char&gt;());\n  }\n  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T&amp; a) { return unary(a, bit_not&lt;unsigned char&gt;()); }\n\n private:\n  template &lt;typename Op&gt;\n  EIGEN_DEVICE_FUNC static inline T unary(const T&amp; a, Op op) {\n    const unsigned char* a_ptr = reinterpret_cast&lt;const unsigned char*&gt;(&amp;a);\n    T c;\n    unsigned char* c_ptr = reinterpret_cast&lt;unsigned char*&gt;(&amp;c);\n    for (size_t i = 0; i &lt; sizeof(T); ++i) {\n      *c_ptr++ = op(*a_ptr++);\n    }\n    return c;\n  }\n\n  template &lt;typename Op&gt;\n  EIGEN_DEVICE_FUNC static inline T binary(const T&amp; a, const T&amp; b, Op op) {\n    const unsigned char* a_ptr = reinterpret_cast&lt;const unsigned char*&gt;(&amp;a);\n    const unsigned char* b_ptr = reinterpret_cast&lt;const unsigned char*&gt;(&amp;b);\n    T c;\n    unsigned char* c_ptr = reinterpret_cast&lt;unsigned char*&gt;(&amp;c);\n    for (size_t i = 0; i &lt; sizeof(T); ++i) {\n      *c_ptr++ = op(*a_ptr++, *b_ptr++);\n    }\n    return c;\n  }\n};\n\n// In the general case, use byte-by-byte manipulation.\ntemplate &lt;typename T, typename EnableIf = void&gt;\nstruct bitwise_helper : public bytewise_bitwise_helper&lt;T&gt; {};\n\n// For integers or non-trivial scalars, use binary operators.\ntemplate &lt;typename T&gt;\nstruct bitwise_helper&lt;T, typename std::enable_if_t&lt;is_scalar&lt;T&gt;::value &amp;&amp;\n                                                   (NumTraits&lt;T&gt;::IsInteger || NumTraits&lt;T&gt;::RequireInitialization)&gt;&gt;\n    : public operator_bitwise_helper&lt;T&gt; {};\n\n/** \\internal \\returns the bitwise and of \\a a and \\a b */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pand(const Packet&amp; a, const Packet&amp; b) {\n  return bitwise_helper&lt;Packet&gt;::bitwise_and(a, b);\n}\n\n/** \\internal \\returns the bitwise or of \\a a and \\a b */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet por(const Packet&amp; a, const Packet&amp; b) {\n  return bitwise_helper&lt;Packet&gt;::bitwise_or(a, b);\n}\n\n/** \\internal \\returns the bitwise xor of \\a a and \\a b */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pxor(const Packet&amp; a, const Packet&amp; b) {\n  return bitwise_helper&lt;Packet&gt;::bitwise_xor(a, b);\n}\n\n/** \\internal \\returns the bitwise not of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pnot(const Packet&amp; a) {\n  return bitwise_helper&lt;Packet&gt;::bitwise_not(a);\n}\n\n/** \\internal \\returns the bitwise and of \\a a and not \\a b */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pandnot(const Packet&amp; a, const Packet&amp; b) {\n  return pand(a, pnot(b));\n}\n\n// In the general case, use bitwise select.\ntemplate &lt;typename Packet, bool is_scalar = is_scalar&lt;Packet&gt;::value&gt;\nstruct pselect_impl {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; mask, const Packet&amp; a, const Packet&amp; b) {\n    return por(pand(a, mask), pandnot(b, mask));\n  }\n};\n\n// For scalars, use ternary select.\ntemplate &lt;typename Packet&gt;\nstruct pselect_impl&lt;Packet, true&gt; {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; mask, const Packet&amp; a, const Packet&amp; b) {\n    return numext::select(mask, a, b);\n  }\n};\n\n/** \\internal \\returns \\a or \\b for each field in packet according to \\mask */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pselect(const Packet&amp; mask, const Packet&amp; a, const Packet&amp; b) {\n  return pselect_impl&lt;Packet&gt;::run(mask, a, b);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline bool pselect&lt;bool&gt;(const bool&amp; cond, const bool&amp; a, const bool&amp; b) {\n  return cond ? a : b;\n}\n\n/** \\internal \\returns the min or of \\a a and \\a b (coeff-wise)\n    If either \\a a or \\a b are NaN, the result is implementation defined. */\ntemplate &lt;int NaNPropagation&gt;\nstruct pminmax_impl {\n  template &lt;typename Packet, typename Op&gt;\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a, const Packet&amp; b, Op op) {\n    return op(a, b);\n  }\n};\n\n/** \\internal \\returns the min or max of \\a a and \\a b (coeff-wise)\n    If either \\a a or \\a b are NaN, NaN is returned. */\ntemplate &lt;&gt;\nstruct pminmax_impl&lt;PropagateNaN&gt; {\n  template &lt;typename Packet, typename Op&gt;\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a, const Packet&amp; b, Op op) {\n    Packet not_nan_mask_a = pcmp_eq(a, a);\n    Packet not_nan_mask_b = pcmp_eq(b, b);\n    return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), b), a);\n  }\n};\n\n/** \\internal \\returns the min or max of \\a a and \\a b (coeff-wise)\n    If both \\a a and \\a b are NaN, NaN is returned.\n    Equivalent to std::fmin(a, b).  */\ntemplate &lt;&gt;\nstruct pminmax_impl&lt;PropagateNumbers&gt; {\n  template &lt;typename Packet, typename Op&gt;\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a, const Packet&amp; b, Op op) {\n    Packet not_nan_mask_a = pcmp_eq(a, a);\n    Packet not_nan_mask_b = pcmp_eq(b, b);\n    return pselect(not_nan_mask_a, pselect(not_nan_mask_b, op(a, b), a), b);\n  }\n};\n\n#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) [](const Type&amp; a, const Type&amp; b) { return Func(a, b); }\n\n/** \\internal \\returns the min of \\a a and \\a b  (coeff-wise).\n    If \\a a or \\b b is NaN, the return value is implementation defined. */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmin(const Packet&amp; a, const Packet&amp; b) {\n  return numext::mini(a, b);\n}\n\n/** \\internal \\returns the min of \\a a and \\a b  (coeff-wise).\n    NaNPropagation determines the NaN propagation semantics. */\ntemplate &lt;int NaNPropagation, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmin(const Packet&amp; a, const Packet&amp; b) {\n  return pminmax_impl&lt;NaNPropagation&gt;::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmin&lt;Packet&gt;)));\n}\n\n/** \\internal \\returns the max of \\a a and \\a b  (coeff-wise)\n    If \\a a or \\b b is NaN, the return value is implementation defined. */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmax(const Packet&amp; a, const Packet&amp; b) {\n  return numext::maxi(a, b);\n}\n\n/** \\internal \\returns the max of \\a a and \\a b  (coeff-wise).\n    NaNPropagation determines the NaN propagation semantics. */\ntemplate &lt;int NaNPropagation, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmax(const Packet&amp; a, const Packet&amp; b) {\n  return pminmax_impl&lt;NaNPropagation&gt;::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmax&lt;Packet&gt;)));\n}\n\n/** \\internal \\returns the absolute value of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pabs(const Packet&amp; a) {\n  return numext::abs(a);\n}\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline unsigned int pabs(const unsigned int&amp; a) {\n  return a;\n}\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline unsigned long pabs(const unsigned long&amp; a) {\n  return a;\n}\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline unsigned long long pabs(const unsigned long long&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns the addsub value of \\a a,b */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet paddsub(const Packet&amp; a, const Packet&amp; b) {\n  return pselect(peven_mask(a), padd(a, b), psub(a, b));\n}\n\n/** \\internal \\returns the phase angle of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet parg(const Packet&amp; a) {\n  using numext::arg;\n  return arg(a);\n}\n\n/** \\internal \\returns \\a a arithmetically shifted by N bits to the right */\ntemplate &lt;int N, typename T&gt;\nEIGEN_DEVICE_FUNC inline T parithmetic_shift_right(const T&amp; a) {\n  return numext::arithmetic_shift_right(a, N);\n}\n\n/** \\internal \\returns \\a a logically shifted by N bits to the right */\ntemplate &lt;int N, typename T&gt;\nEIGEN_DEVICE_FUNC inline T plogical_shift_right(const T&amp; a) {\n  return numext::logical_shift_right(a, N);\n}\n\n/** \\internal \\returns \\a a shifted by N bits to the left */\ntemplate &lt;int N, typename T&gt;\nEIGEN_DEVICE_FUNC inline T plogical_shift_left(const T&amp; a) {\n  return numext::logical_shift_left(a, N);\n}\n\n/** \\internal \\returns the significant and exponent of the underlying floating point numbers\n * See https://en.cppreference.com/w/cpp/numeric/math/frexp\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pfrexp(const Packet&amp; a, Packet&amp; exponent) {\n  int exp;\n  EIGEN_USING_STD(frexp);\n  Packet result = static_cast&lt;Packet&gt;(frexp(a, &amp;exp));\n  exponent = static_cast&lt;Packet&gt;(exp);\n  return result;\n}\n\n/** \\internal \\returns a * 2^((int)exponent)\n * See https://en.cppreference.com/w/cpp/numeric/math/ldexp\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pldexp(const Packet&amp; a, const Packet&amp; exponent) {\n  EIGEN_USING_STD(ldexp)\n  return static_cast&lt;Packet&gt;(ldexp(a, static_cast&lt;int&gt;(exponent)));\n}\n\n/** \\internal \\returns the min of \\a a and \\a b  (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pabsdiff(const Packet&amp; a, const Packet&amp; b) {\n  return pselect(pcmp_lt(a, b), psub(b, a), psub(a, b));\n}\n\n/** \\internal \\returns a packet version of \\a *from, from must be properly aligned */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pload(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  return *from;\n}\n\n/** \\internal \\returns n elements of a packet version of \\a *from, from must be properly aligned\n * offset indicates the starting element in which to load and\n * offset + n &lt;= unpacket_traits::size\n * All elements before offset and after the last element loaded will initialized with zero */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pload_partial(const typename unpacket_traits&lt;Packet&gt;::type* from, const Index n,\n                                              const Index offset = 0) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert(n + offset &lt;= packet_size &amp;&amp; &quot;number of elements plus offset will read past end of packet&quot;);\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};\n  for (Index i = offset; i &lt; numext::mini(n + offset, packet_size); i++) {\n    elements[i] = from[i - offset];\n  }\n  return pload&lt;Packet&gt;(elements);\n}\n\n/** \\internal \\returns a packet version of \\a *from, (un-aligned load) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ploadu(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  return *from;\n}\n\n/** \\internal \\returns n elements of a packet version of \\a *from, (un-aligned load)\n * All elements after the last element loaded will initialized with zero */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ploadu_partial(const typename unpacket_traits&lt;Packet&gt;::type* from, const Index n,\n                                               const Index offset = 0) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert(n + offset &lt;= packet_size &amp;&amp; &quot;number of elements plus offset will read past end of packet&quot;);\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};\n  for (Index i = offset; i &lt; numext::mini(n + offset, packet_size); i++) {\n    elements[i] = from[i - offset];\n  }\n  return pload&lt;Packet&gt;(elements);\n}\n\n/** \\internal \\returns a packet version of \\a *from, (un-aligned masked load)\n * There is no generic implementation. We only have implementations for specialized\n * cases. Generic case should not be called.\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline std::enable_if_t&lt;unpacket_traits&lt;Packet&gt;::masked_load_available, Packet&gt; ploadu(\n    const typename unpacket_traits&lt;Packet&gt;::type* from, typename unpacket_traits&lt;Packet&gt;::mask_t umask);\n\n/** \\internal \\returns a packet with constant coefficients \\a a, e.g.: (a,a,a,a) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pset1(const typename unpacket_traits&lt;Packet&gt;::type&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns a packet with constant coefficients set from bits */\ntemplate &lt;typename Packet, typename BitsType&gt;\nEIGEN_DEVICE_FUNC inline Packet pset1frombits(BitsType a);\n\n/** \\internal \\returns a packet with constant coefficients \\a a[0], e.g.: (a[0],a[0],a[0],a[0]) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pload1(const typename unpacket_traits&lt;Packet&gt;::type* a) {\n  return pset1&lt;Packet&gt;(*a);\n}\n\n/** \\internal \\returns a packet with elements of \\a *from duplicated.\n * For instance, for a packet of 8 elements, 4 scalars will be read from \\a *from and\n * duplicated to form: {from[0],from[0],from[1],from[1],from[2],from[2],from[3],from[3]}\n * Currently, this function is only used for scalar * complex products.\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet ploaddup(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  return *from;\n}\n\n/** \\internal \\returns a packet with elements of \\a *from quadrupled.\n * For instance, for a packet of 8 elements, 2 scalars will be read from \\a *from and\n * replicated to form: {from[0],from[0],from[0],from[0],from[1],from[1],from[1],from[1]}\n * Currently, this function is only used in matrix products.\n * For packet-size smaller or equal to 4, this function is equivalent to pload1\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ploadquad(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  return pload1&lt;Packet&gt;(from);\n}\n\n/** \\internal equivalent to\n * \\code\n * a0 = pload1(a+0);\n * a1 = pload1(a+1);\n * a2 = pload1(a+2);\n * a3 = pload1(a+3);\n * \\endcode\n * \\sa pset1, pload1, ploaddup, pbroadcast2\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pbroadcast4(const typename unpacket_traits&lt;Packet&gt;::type* a, Packet&amp; a0, Packet&amp; a1,\n                                          Packet&amp; a2, Packet&amp; a3) {\n  a0 = pload1&lt;Packet&gt;(a + 0);\n  a1 = pload1&lt;Packet&gt;(a + 1);\n  a2 = pload1&lt;Packet&gt;(a + 2);\n  a3 = pload1&lt;Packet&gt;(a + 3);\n}\n\n/** \\internal equivalent to\n * \\code\n * a0 = pload1(a+0);\n * a1 = pload1(a+1);\n * \\endcode\n * \\sa pset1, pload1, ploaddup, pbroadcast4\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pbroadcast2(const typename unpacket_traits&lt;Packet&gt;::type* a, Packet&amp; a0, Packet&amp; a1) {\n  a0 = pload1&lt;Packet&gt;(a + 0);\n  a1 = pload1&lt;Packet&gt;(a + 1);\n}\n\n/** \\internal \\brief Returns a packet with coefficients (a,a+1,...,a+packet_size-1). */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet plset(const typename unpacket_traits&lt;Packet&gt;::type&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns a packet with constant coefficients \\a a, e.g.: (x, 0, x, 0),\n     where x is the value of all 1-bits. */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet peven_mask(const Packet&amp; /*a*/) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  const size_t n = unpacket_traits&lt;Packet&gt;::size;\n  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];\n  for (size_t i = 0; i &lt; n; ++i) {\n    memset(elements + i, ((i &amp; 1) == 0 ? 0xff : 0), sizeof(Scalar));\n  }\n  return ploadu&lt;Packet&gt;(elements);\n}\n\n/** \\internal copy the packet \\a from to \\a *to, \\a to must be properly aligned */\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet&amp; from) {\n  (*to) = from;\n}\n\n/** \\internal copy n elements of the packet \\a from to \\a *to, \\a to must be properly aligned\n * offset indicates the starting element in which to store and\n * offset + n &lt;= unpacket_traits::size */\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstore_partial(Scalar* to, const Packet&amp; from, const Index n, const Index offset = 0) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert(n + offset &lt;= packet_size &amp;&amp; &quot;number of elements plus offset will write past end of packet&quot;);\n  EIGEN_ALIGN_MAX Scalar elements[packet_size];\n  pstore&lt;Scalar&gt;(elements, from);\n  for (Index i = 0; i &lt; numext::mini(n, packet_size - offset); i++) {\n    to[i] = elements[i + offset];\n  }\n}\n\n/** \\internal copy the packet \\a from to \\a *to, (un-aligned store) */\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet&amp; from) {\n  (*to) = from;\n}\n\n/** \\internal copy n elements of the packet \\a from to \\a *to, (un-aligned store) */\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstoreu_partial(Scalar* to, const Packet&amp; from, const Index n, const Index offset = 0) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert(n + offset &lt;= packet_size &amp;&amp; &quot;number of elements plus offset will write past end of packet&quot;);\n  EIGEN_ALIGN_MAX Scalar elements[packet_size];\n  pstore&lt;Scalar&gt;(elements, from);\n  for (Index i = 0; i &lt; numext::mini(n, packet_size - offset); i++) {\n    to[i] = elements[i + offset];\n  }\n}\n\n/** \\internal copy the packet \\a from to \\a *to, (un-aligned store with a mask)\n * There is no generic implementation. We only have implementations for specialized\n * cases. Generic case should not be called.\n */\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline std::enable_if_t&lt;unpacket_traits&lt;Packet&gt;::masked_store_available, void&gt; pstoreu(\n    Scalar* to, const Packet&amp; from, typename unpacket_traits&lt;Packet&gt;::mask_t umask);\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pgather(const Scalar* from, Index /*stride*/) {\n  return ploadu&lt;Packet&gt;(from);\n}\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pgather_partial(const Scalar* from, Index stride, const Index n) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  EIGEN_ALIGN_MAX Scalar elements[packet_size] = {Scalar(0)};\n  for (Index i = 0; i &lt; numext::mini(n, packet_size); i++) {\n    elements[i] = from[i * stride];\n  }\n  return pload&lt;Packet&gt;(elements);\n}\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pscatter(Scalar* to, const Packet&amp; from, Index /*stride*/) {\n  pstore(to, from);\n}\n\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pscatter_partial(Scalar* to, const Packet&amp; from, Index stride, const Index n) {\n  const Index packet_size = unpacket_traits&lt;Packet&gt;::size;\n  EIGEN_ALIGN_MAX Scalar elements[packet_size];\n  pstore&lt;Scalar&gt;(elements, from);\n  for (Index i = 0; i &lt; numext::mini(n, packet_size); i++) {\n    to[i * stride] = elements[i];\n  }\n}\n\n/** \\internal tries to do cache prefetching of \\a addr */\ntemplate &lt;typename Scalar&gt;\nEIGEN_DEVICE_FUNC inline void prefetch(const Scalar* addr) {\n#if defined(EIGEN_HIP_DEVICE_COMPILE)\n  // do nothing\n#elif defined(EIGEN_CUDA_ARCH)\n#if defined(__LP64__) || EIGEN_OS_WIN64\n  // 64-bit pointer operand constraint for inlined asm\n  asm(&quot; prefetch.L1 [ %1 ];&quot; : &quot;=l&quot;(addr) : &quot;l&quot;(addr));\n#else\n  // 32-bit pointer operand constraint for inlined asm\n  asm(&quot; prefetch.L1 [ %1 ];&quot; : &quot;=r&quot;(addr) : &quot;r&quot;(addr));\n#endif\n#elif (!EIGEN_COMP_MSVC) &amp;&amp; (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)\n  __builtin_prefetch(addr);\n#endif\n}\n\n/** \\internal \\returns the reversed elements of \\a a*/\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet preverse(const Packet&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns \\a a with real and imaginary part flipped (for complex type only) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pcplxflip(const Packet&amp; a) {\n  return Packet(numext::imag(a), numext::real(a));\n}\n\n/**************************\n * Special math functions\n ***************************/\n\n/** \\internal \\returns isnan(a) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pisnan(const Packet&amp; a) {\n  return pandnot(ptrue(a), pcmp_eq(a, a));\n}\n\n/** \\internal \\returns isinf(a) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pisinf(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  constexpr Scalar inf = NumTraits&lt;Scalar&gt;::infinity();\n  return pcmp_eq(pabs(a), pset1&lt;Packet&gt;(inf));\n}\n\n/** \\internal \\returns the sine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psin(const Packet&amp; a) {\n  EIGEN_USING_STD(sin);\n  return sin(a);\n}\n\n/** \\internal \\returns the cosine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcos(const Packet&amp; a) {\n  EIGEN_USING_STD(cos);\n  return cos(a);\n}\n\n/** \\internal \\returns the tan of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptan(const Packet&amp; a) {\n  EIGEN_USING_STD(tan);\n  return tan(a);\n}\n\n/** \\internal \\returns the arc sine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pasin(const Packet&amp; a) {\n  EIGEN_USING_STD(asin);\n  return asin(a);\n}\n\n/** \\internal \\returns the arc cosine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pacos(const Packet&amp; a) {\n  EIGEN_USING_STD(acos);\n  return acos(a);\n}\n\n/** \\internal \\returns the hyperbolic sine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psinh(const Packet&amp; a) {\n  EIGEN_USING_STD(sinh);\n  return sinh(a);\n}\n\n/** \\internal \\returns the hyperbolic cosine of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcosh(const Packet&amp; a) {\n  EIGEN_USING_STD(cosh);\n  return cosh(a);\n}\n\n/** \\internal \\returns the arc tangent of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patan(const Packet&amp; a) {\n  EIGEN_USING_STD(atan);\n  return atan(a);\n}\n\n/** \\internal \\returns the hyperbolic tan of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet ptanh(const Packet&amp; a) {\n  EIGEN_USING_STD(tanh);\n  return tanh(a);\n}\n\n/** \\internal \\returns the arc tangent of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet patanh(const Packet&amp; a) {\n  EIGEN_USING_STD(atanh);\n  return atanh(a);\n}\n\n/** \\internal \\returns the exp of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp(const Packet&amp; a) {\n  return numext::exp(a);\n}\n\n/** \\internal \\returns the exp2 of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexp2(const Packet&amp; a) {\n  return numext::exp2(a);\n}\n\n/** \\internal \\returns the expm1 of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pexpm1(const Packet&amp; a) {\n  return numext::expm1(a);\n}\n\n/** \\internal \\returns the log of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog(const Packet&amp; a) {\n  EIGEN_USING_STD(log);\n  return log(a);\n}\n\n/** \\internal \\returns the log1p of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog1p(const Packet&amp; a) {\n  return numext::log1p(a);\n}\n\n/** \\internal \\returns the log10 of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog10(const Packet&amp; a) {\n  EIGEN_USING_STD(log10);\n  return log10(a);\n}\n\n/** \\internal \\returns the log2 of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet plog2(const Packet&amp; a) {\n  using Scalar = typename internal::unpacket_traits&lt;Packet&gt;::type;\n  using RealScalar = typename NumTraits&lt;Scalar&gt;::Real;\n  return pmul(pset1&lt;Packet&gt;(Scalar(RealScalar(EIGEN_LOG2E))), plog(a));\n}\n\n/** \\internal \\returns the square-root of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet psqrt(const Packet&amp; a) {\n  return numext::sqrt(a);\n}\n\n/** \\internal \\returns the cube-root of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet pcbrt(const Packet&amp; a) {\n  return numext::cbrt(a);\n}\n\ntemplate &lt;typename Packet, bool IsScalar = is_scalar&lt;Packet&gt;::value,\n          bool IsInteger = NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger&gt;\nstruct nearest_integer_packetop_impl {\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_floor(const Packet&amp; x) { return numext::floor(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_ceil(const Packet&amp; x) { return numext::ceil(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_rint(const Packet&amp; x) { return numext::rint(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_round(const Packet&amp; x) { return numext::round(x); }\n  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet run_trunc(const Packet&amp; x) { return numext::trunc(x); }\n};\n\n/** \\internal \\returns the rounded value of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pround(const Packet&amp; a) {\n  return nearest_integer_packetop_impl&lt;Packet&gt;::run_round(a);\n}\n\n/** \\internal \\returns the floor of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pfloor(const Packet&amp; a) {\n  return nearest_integer_packetop_impl&lt;Packet&gt;::run_floor(a);\n}\n\n/** \\internal \\returns the rounded value of \\a a (coeff-wise) with current\n * rounding mode */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet print(const Packet&amp; a) {\n  return nearest_integer_packetop_impl&lt;Packet&gt;::run_rint(a);\n}\n\n/** \\internal \\returns the ceil of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet pceil(const Packet&amp; a) {\n  return nearest_integer_packetop_impl&lt;Packet&gt;::run_ceil(a);\n}\n\n/** \\internal \\returns the truncation of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet ptrunc(const Packet&amp; a) {\n  return nearest_integer_packetop_impl&lt;Packet&gt;::run_trunc(a);\n}\n\ntemplate &lt;typename Packet, typename EnableIf = void&gt;\nstruct psign_impl {\n  static EIGEN_DEVICE_FUNC inline Packet run(const Packet&amp; a) { return numext::sign(a); }\n};\n\n/** \\internal \\returns the sign of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet psign(const Packet&amp; a) {\n  return psign_impl&lt;Packet&gt;::run(a);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline bool psign(const bool&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns the first element of a packet */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type pfirst(const Packet&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns the sum of the elements of upper and lower half of \\a a if \\a a is larger than 4.\n * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}\n * For packet-size smaller or equal to 4, this boils down to a noop.\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline std::conditional_t&lt;(unpacket_traits&lt;Packet&gt;::size % 8) == 0,\n                                            typename unpacket_traits&lt;Packet&gt;::half, Packet&gt;\npredux_half_dowto4(const Packet&amp; a) {\n  return a;\n}\n\n// Slow generic implementation of Packet reduction.\ntemplate &lt;typename Packet, typename Op&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_helper(const Packet&amp; a, Op op) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  const size_t n = unpacket_traits&lt;Packet&gt;::size;\n  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];\n  pstoreu&lt;Scalar&gt;(elements, a);\n  for (size_t k = n / 2; k &gt; 0; k /= 2) {\n    for (size_t i = 0; i &lt; k; ++i) {\n      elements[i] = op(elements[i], elements[i + k]);\n    }\n  }\n  return elements[0];\n}\n\n/** \\internal \\returns the sum of the elements of \\a a*/\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux(const Packet&amp; a) {\n  return a;\n}\n\n/** \\internal \\returns the product of the elements of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_mul(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmul&lt;Scalar&gt;)));\n}\n\n/** \\internal \\returns the min of the elements of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_min(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin&lt;PropagateFast, Scalar&gt;)));\n}\n\ntemplate &lt;int NaNPropagation, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_min(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin&lt;NaNPropagation, Scalar&gt;)));\n}\n\n/** \\internal \\returns the min of the elements of \\a a */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_max(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax&lt;PropagateFast, Scalar&gt;)));\n}\n\ntemplate &lt;int NaNPropagation, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline typename unpacket_traits&lt;Packet&gt;::type predux_max(const Packet&amp; a) {\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax&lt;NaNPropagation, Scalar&gt;)));\n}\n\n#undef EIGEN_BINARY_OP_NAN_PROPAGATION\n\n/** \\internal \\returns true if all coeffs of \\a a means &quot;true&quot;\n * It is supposed to be called on values returned by pcmp_*.\n */\n// not needed yet\n// template&lt;typename Packet&gt; EIGEN_DEVICE_FUNC inline bool predux_all(const Packet&amp; a)\n// { return bool(a); }\n\n/** \\internal \\returns true if any coeffs of \\a a means &quot;true&quot;\n * It is supposed to be called on values returned by pcmp_*.\n */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline bool predux_any(const Packet&amp; a) {\n  // Dirty but generic implementation where &quot;true&quot; is assumed to be non 0 and all the sames.\n  // It is expected that &quot;true&quot; is either:\n  //  - Scalar(1)\n  //  - bits full of ones (NaN for floats),\n  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).\n  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  return numext::not_equal_strict(predux(a), Scalar(0));\n}\n\n/***************************************************************************\n * The following functions might not have to be overwritten for vectorized types\n ***************************************************************************/\n\ntemplate &lt;typename Packet, typename EnableIf = void&gt;\nstruct pmadd_impl {\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pmadd(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n    return padd(pmul(a, b), c);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pmsub(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n    return psub(pmul(a, b), c);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pnmadd(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n    return psub(c, pmul(a, b));\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pnmsub(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n    return pnegate(pmadd(a, b, c));\n  }\n};\n\ntemplate &lt;typename Scalar&gt;\nstruct pmadd_impl&lt;Scalar, std::enable_if_t&lt;is_scalar&lt;Scalar&gt;::value &amp;&amp; NumTraits&lt;Scalar&gt;::IsSigned&gt;&gt; {\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar pmadd(const Scalar&amp; a, const Scalar&amp; b, const Scalar&amp; c) {\n    return numext::fma(a, b, c);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar pmsub(const Scalar&amp; a, const Scalar&amp; b, const Scalar&amp; c) {\n    return numext::fma(a, b, Scalar(-c));\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar pnmadd(const Scalar&amp; a, const Scalar&amp; b, const Scalar&amp; c) {\n    return numext::fma(Scalar(-a), b, c);\n  }\n  static EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar pnmsub(const Scalar&amp; a, const Scalar&amp; b, const Scalar&amp; c) {\n    return -Scalar(numext::fma(a, b, c));\n  }\n};\n\n// FMA instructions.\n/** \\internal \\returns a * b + c (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmadd(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n  return pmadd_impl&lt;Packet&gt;::pmadd(a, b, c);\n}\n\n/** \\internal \\returns a * b - c (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pmsub(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n  return pmadd_impl&lt;Packet&gt;::pmsub(a, b, c);\n}\n\n/** \\internal \\returns -(a * b) + c (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pnmadd(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n  return pmadd_impl&lt;Packet&gt;::pnmadd(a, b, c);\n}\n\n/** \\internal \\returns -((a * b + c) (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pnmsub(const Packet&amp; a, const Packet&amp; b, const Packet&amp; c) {\n  return pmadd_impl&lt;Packet&gt;::pnmsub(a, b, c);\n}\n\n/** \\internal copy a packet with constant coefficient \\a a (e.g., [a,a,a,a]) to \\a *to. \\a to must be 16 bytes aligned\n */\n// NOTE: this function must really be templated on the packet type (think about different packet types for the same\n// scalar type)\ntemplate &lt;typename Packet&gt;\ninline void pstore1(typename unpacket_traits&lt;Packet&gt;::type* to, const typename unpacket_traits&lt;Packet&gt;::type&amp; a) {\n  pstore(to, pset1&lt;Packet&gt;(a));\n}\n\n/** \\internal \\returns a packet version of \\a *from.\n * The pointer \\a from must be aligned on a \\a Alignment bytes boundary. */\ntemplate &lt;typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  if (Alignment &gt;= unpacket_traits&lt;Packet&gt;::alignment)\n    return pload&lt;Packet&gt;(from);\n  else\n    return ploadu&lt;Packet&gt;(from);\n}\n\n/** \\internal \\returns n elements of a packet version of \\a *from.\n * The pointer \\a from must be aligned on a \\a Alignment bytes boundary. */\ntemplate &lt;typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt_partial(const typename unpacket_traits&lt;Packet&gt;::type* from,\n                                                            const Index n, const Index offset = 0) {\n  if (Alignment &gt;= unpacket_traits&lt;Packet&gt;::alignment)\n    return pload_partial&lt;Packet&gt;(from, n, offset);\n  else\n    return ploadu_partial&lt;Packet&gt;(from, n, offset);\n}\n\n/** \\internal copy the packet \\a from to \\a *to.\n * The pointer \\a from must be aligned on a \\a Alignment bytes boundary. */\ntemplate &lt;typename Scalar, typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void pstoret(Scalar* to, const Packet&amp; from) {\n  if (Alignment &gt;= unpacket_traits&lt;Packet&gt;::alignment)\n    pstore(to, from);\n  else\n    pstoreu(to, from);\n}\n\n/** \\internal copy n elements of the packet \\a from to \\a *to.\n * The pointer \\a from must be aligned on a \\a Alignment bytes boundary. */\ntemplate &lt;typename Scalar, typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void pstoret_partial(Scalar* to, const Packet&amp; from, const Index n,\n                                                           const Index offset = 0) {\n  if (Alignment &gt;= unpacket_traits&lt;Packet&gt;::alignment)\n    pstore_partial(to, from, n, offset);\n  else\n    pstoreu_partial(to, from, n, offset);\n}\n\n/** \\internal \\returns a packet version of \\a *from.\n * Unlike ploadt, ploadt_ro takes advantage of the read-only memory path on the\n * hardware if available to speedup the loading of data that won&#x27;t be modified\n * by the current computation.\n */\ntemplate &lt;typename Packet, int LoadMode&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt_ro(const typename unpacket_traits&lt;Packet&gt;::type* from) {\n  return ploadt&lt;Packet, LoadMode&gt;(from);\n}\n\n/***************************************************************************\n * Fast complex products (GCC generates a function call which is very slow)\n ***************************************************************************/\n\n// Eigen+CUDA does not support complexes.\n#if !defined(EIGEN_GPUCC)\n\ntemplate &lt;&gt;\ninline std::complex&lt;float&gt; pmul(const std::complex&lt;float&gt;&amp; a, const std::complex&lt;float&gt;&amp; b) {\n  return std::complex&lt;float&gt;(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());\n}\n\ntemplate &lt;&gt;\ninline std::complex&lt;double&gt; pmul(const std::complex&lt;double&gt;&amp; a, const std::complex&lt;double&gt;&amp; b) {\n  return std::complex&lt;double&gt;(a.real() * b.real() - a.imag() * b.imag(), a.imag() * b.real() + a.real() * b.imag());\n}\n\n#endif\n\n/***************************************************************************\n * PacketBlock, that is a collection of N packets where the number of words\n * in the packet is a multiple of N.\n ***************************************************************************/\ntemplate &lt;typename Packet, int N = unpacket_traits&lt;Packet&gt;::size&gt;\nstruct PacketBlock {\n  Packet packet[N];\n};\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock&lt;Packet, 1&gt;&amp; /*kernel*/) {\n  // Nothing to do in the scalar case, i.e. a 1x1 matrix.\n}\n\n/***************************************************************************\n * Selector, i.e. vector of N boolean values used to select (i.e. blend)\n * words from 2 packets.\n ***************************************************************************/\ntemplate &lt;size_t N&gt;\nstruct Selector {\n  bool select[N];\n};\n\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet pblend(const Selector&lt;unpacket_traits&lt;Packet&gt;::size&gt;&amp; ifPacket,\n                                       const Packet&amp; thenPacket, const Packet&amp; elsePacket) {\n  return ifPacket.select[0] ? thenPacket : elsePacket;\n}\n\n/** \\internal \\returns 1 / a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet preciprocal(const Packet&amp; a) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  return pdiv(pset1&lt;Packet&gt;(Scalar(1)), a);\n}\n\n/** \\internal \\returns the reciprocal square-root of \\a a (coeff-wise) */\ntemplate &lt;typename Packet&gt;\nEIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS Packet prsqrt(const Packet&amp; a) {\n  return preciprocal&lt;Packet&gt;(psqrt(a));\n}\n\ntemplate &lt;typename Packet, bool IsScalar = is_scalar&lt;Packet&gt;::value,\n          bool IsInteger = NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsInteger&gt;\nstruct psignbit_impl;\ntemplate &lt;typename Packet, bool IsInteger&gt;\nstruct psignbit_impl&lt;Packet, true, IsInteger&gt; {\n  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Packet run(const Packet&amp; a) { return numext::signbit(a); }\n};\ntemplate &lt;typename Packet&gt;\nstruct psignbit_impl&lt;Packet, false, false&gt; {\n  // generic implementation if not specialized in PacketMath.h\n  // slower than arithmetic shift\n  typedef typename unpacket_traits&lt;Packet&gt;::type Scalar;\n  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static Packet run(const Packet&amp; a) {\n    const Packet cst_pos_one = pset1&lt;Packet&gt;(Scalar(1));\n    const Packet cst_neg_one = pset1&lt;Packet&gt;(Scalar(-1));\n    return pcmp_eq(por(pand(a, cst_neg_one), cst_pos_one), cst_neg_one);\n  }\n};\ntemplate &lt;typename Packet&gt;\nstruct psignbit_impl&lt;Packet, false, true&gt; {\n  // generic implementation for integer packets\n  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static constexpr Packet run(const Packet&amp; a) { return pcmp_lt(a, pzero(a)); }\n};\n/** \\internal \\returns the sign bit of \\a a as a bitmask*/\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE constexpr Packet psignbit(const Packet&amp; a) {\n  return psignbit_impl&lt;Packet&gt;::run(a);\n}\n\n/** \\internal \\returns the 2-argument arc tangent of \\a y and \\a x (coeff-wise) */\ntemplate &lt;typename Packet, std::enable_if_t&lt;is_scalar&lt;Packet&gt;::value, int&gt; = 0&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet patan2(const Packet&amp; y, const Packet&amp; x) {\n  return numext::atan2(y, x);\n}\n\n/** \\internal \\returns the 2-argument arc tangent of \\a y and \\a x (coeff-wise) */\ntemplate &lt;typename Packet, std::enable_if_t&lt;!is_scalar&lt;Packet&gt;::value, int&gt; = 0&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet patan2(const Packet&amp; y, const Packet&amp; x) {\n  typedef typename internal::unpacket_traits&lt;Packet&gt;::type Scalar;\n\n  // See https://en.cppreference.com/w/cpp/numeric/math/atan2\n  // for how corner cases are supposed to be handled according to the\n  // IEEE floating-point standard (IEC 60559).\n  const Packet kSignMask = pset1&lt;Packet&gt;(-Scalar(0));\n  const Packet kZero = pzero(x);\n  const Packet kOne = pset1&lt;Packet&gt;(Scalar(1));\n  const Packet kPi = pset1&lt;Packet&gt;(Scalar(EIGEN_PI));\n\n  const Packet x_has_signbit = psignbit(x);\n  const Packet y_signmask = pand(y, kSignMask);\n  const Packet x_signmask = pand(x, kSignMask);\n  const Packet result_signmask = pxor(y_signmask, x_signmask);\n  const Packet shift = por(pand(x_has_signbit, kPi), y_signmask);\n\n  const Packet x_and_y_are_same = pcmp_eq(pabs(x), pabs(y));\n  const Packet x_and_y_are_zero = pcmp_eq(por(x, y), kZero);\n\n  Packet arg = pdiv(y, x);\n  arg = pselect(x_and_y_are_same, por(kOne, result_signmask), arg);\n  arg = pselect(x_and_y_are_zero, result_signmask, arg);\n\n  Packet result = patan(arg);\n  result = padd(result, shift);\n  return result;\n}\n\n/** \\internal \\returns the argument of \\a a as a complex number */\ntemplate &lt;typename Packet, std::enable_if_t&lt;is_scalar&lt;Packet&gt;::value, int&gt; = 0&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pcarg(const Packet&amp; a) {\n  return Packet(numext::arg(a));\n}\n\n/** \\internal \\returns the argument of \\a a as a complex number */\ntemplate &lt;typename Packet, std::enable_if_t&lt;!is_scalar&lt;Packet&gt;::value, int&gt; = 0&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet pcarg(const Packet&amp; a) {\n  EIGEN_STATIC_ASSERT(NumTraits&lt;typename unpacket_traits&lt;Packet&gt;::type&gt;::IsComplex,\n                      THIS METHOD IS FOR COMPLEX TYPES ONLY)\n  using RealPacket = typename unpacket_traits&lt;Packet&gt;::as_real;\n  // a                                              // r     i    r     i    ...\n  RealPacket aflip = pcplxflip(a).v;                // i     r    i     r    ...\n  RealPacket result = patan2(aflip, a.v);           // atan2 crap atan2 crap ...\n  return (Packet)pand(result, peven_mask(result));  // atan2 0    atan2 0    ...\n}\n\n/** \\internal \\returns a packet populated with values in the range [begin, begin + count). Elements\n * outside this range are not defined. \\a *from does not need to be aligned, and can be null if \\a count is zero.*/\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ploaduSegment(const typename unpacket_traits&lt;Packet&gt;::type* from, Index begin,\n                                              Index count) {\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  constexpr Index PacketSize = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert((begin &gt;= 0 &amp;&amp; count &gt;= 0 &amp;&amp; begin + count &lt;= PacketSize) &amp;&amp; &quot;invalid range&quot;);\n  Scalar aux[PacketSize];\n  smart_copy(from + begin, from + begin + count, aux + begin);\n  return ploadu&lt;Packet&gt;(aux);\n}\n\n/** \\internal \\returns a packet populated with values in the range [begin, begin + count). Elements\n * outside this range are not defined. \\a *from must be aligned, and cannot be null.*/\ntemplate &lt;typename Packet&gt;\nEIGEN_DEVICE_FUNC inline Packet ploadSegment(const typename unpacket_traits&lt;Packet&gt;::type* from, Index begin,\n                                             Index count) {\n  return ploaduSegment&lt;Packet&gt;(from, begin, count);\n}\n\n/** \\internal copy the packet \\a from in the range [begin, begin + count) to \\a *to.\nElements outside of the range [begin, begin + count) are not defined. \\a *to does not need to be aligned, and can be\nnull if \\a count is zero.*/\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstoreuSegment(Scalar* to, const Packet&amp; from, Index begin, Index count) {\n  constexpr Index PacketSize = unpacket_traits&lt;Packet&gt;::size;\n  eigen_assert((begin &gt;= 0 &amp;&amp; count &gt;= 0 &amp;&amp; begin + count &lt;= PacketSize) &amp;&amp; &quot;invalid range&quot;);\n  Scalar aux[PacketSize];\n  pstoreu&lt;Scalar, Packet&gt;(aux, from);\n  smart_copy(aux + begin, aux + begin + count, to + begin);\n}\n\n/** \\internal copy the packet \\a from in the range [begin, begin + count) to \\a *to.\nElements outside of the range [begin, begin + count) are not defined. \\a *to must be aligned, and cannot be\nnull.*/\ntemplate &lt;typename Scalar, typename Packet&gt;\nEIGEN_DEVICE_FUNC inline void pstoreSegment(Scalar* to, const Packet&amp; from, Index begin, Index count) {\n  return pstoreuSegment(to, from, begin, count);\n}\n\n/** \\internal \\returns a packet populated with values in the range [begin, begin + count). Elements\n * outside this range are not defined.*/\ntemplate &lt;typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC inline Packet ploadtSegment(const typename unpacket_traits&lt;Packet&gt;::type* from, Index begin,\n                                              Index count) {\n  constexpr int RequiredAlignment = unpacket_traits&lt;Packet&gt;::alignment;\n  if (Alignment &gt;= RequiredAlignment) {\n    return ploadSegment&lt;Packet&gt;(from, begin, count);\n  } else {\n    return ploaduSegment&lt;Packet&gt;(from, begin, count);\n  }\n}\n\n/** \\internal copy the packet \\a from in the range [begin, begin + count) to \\a *to.\nElements outside of the range [begin, begin + count) are not defined.*/\ntemplate &lt;typename Scalar, typename Packet, int Alignment&gt;\nEIGEN_DEVICE_FUNC inline void pstoretSegment(Scalar* to, const Packet&amp; from, Index begin, Index count) {\n  constexpr int RequiredAlignment = unpacket_traits&lt;Packet&gt;::alignment;\n  if (Alignment &gt;= RequiredAlignment) {\n    pstoreSegment&lt;Scalar, Packet&gt;(to, from, begin, count);\n  } else {\n    pstoreuSegment&lt;Scalar, Packet&gt;(to, from, begin, count);\n  }\n}\n\n#ifndef EIGEN_NO_IO\n\ntemplate &lt;typename Packet&gt;\nclass StreamablePacket {\n public:\n  using Scalar = typename unpacket_traits&lt;Packet&gt;::type;\n  StreamablePacket(const Packet&amp; packet) { pstoreu(v_, packet); }\n\n  friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const StreamablePacket&amp; packet) {\n    os &lt;&lt; &quot;{&quot; &lt;&lt; packet.v_[0];\n    for (int i = 1; i &lt; unpacket_traits&lt;Packet&gt;::size; ++i) {\n      os &lt;&lt; &quot;,&quot; &lt;&lt; packet.v_[i];\n    }\n    os &lt;&lt; &quot;}&quot;;\n    return os;\n  }\n\n private:\n  Scalar v_[unpacket_traits&lt;Packet&gt;::size];\n};\n\n/**\n * \\internal \\returns an intermediary that can be used to ostream packets, e.g. for debugging.\n */\ntemplate &lt;typename Packet&gt;\nStreamablePacket&lt;Packet&gt; postream(const Packet&amp; packet) {\n  return StreamablePacket&lt;Packet&gt;(packet);\n}\n\n#endif  // EIGEN_NO_IO\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_GENERIC_PACKET_MATH_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2015 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2008-2009 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2009 Kenneth Riddile &lt;kfriddile@yahoo.com&gt;\n// Copyright (C) 2010 Hauke Heibel &lt;hauke.heibel@gmail.com&gt;\n// Copyright (C) 2010 Thomas Capricelli &lt;orzel@freehackers.org&gt;\n// Copyright (C) 2013 Pavel Holoborodko &lt;pavel@holoborodko.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n/*****************************************************************************\n*** Platform checks for aligned malloc functions                           ***\n*****************************************************************************/\n\n#ifndef EIGEN_MEMORY_H\n#define EIGEN_MEMORY_H\n\n#ifndef EIGEN_MALLOC_ALREADY_ALIGNED\n\n// Try to determine automatically if malloc is already aligned.\n\n// On 64-bit systems, glibc&#x27;s malloc returns 16-byte-aligned pointers, see:\n//   http://www.gnu.org/s/libc/manual/html_node/Aligned-Memory-Blocks.html\n// This is true at least since glibc 2.8.\n// This leaves the question how to detect 64-bit. According to this document,\n//   http://gcc.fyxm.net/summit/2003/Porting%20to%2064%20bit.pdf\n// page 114, &quot;[The] LP64 model [...] is used by all 64-bit UNIX ports&quot; so it&#x27;s indeed\n// quite safe, at least within the context of glibc, to equate 64-bit with LP64.\n#if defined(__GLIBC__) &amp;&amp; ((__GLIBC__ &gt;= 2 &amp;&amp; __GLIBC_MINOR__ &gt;= 8) || __GLIBC__ &gt; 2) &amp;&amp; defined(__LP64__) &amp;&amp; \\\n    !defined(__SANITIZE_ADDRESS__) &amp;&amp; (EIGEN_DEFAULT_ALIGN_BYTES == 16)\n#define EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED 1\n#else\n#define EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED 0\n#endif\n\n// FreeBSD 6 seems to have 16-byte aligned malloc\n//   See http://svn.freebsd.org/viewvc/base/stable/6/lib/libc/stdlib/malloc.c?view=markup\n// FreeBSD 7 seems to have 16-byte aligned malloc except on ARM and MIPS architectures\n//   See http://svn.freebsd.org/viewvc/base/stable/7/lib/libc/stdlib/malloc.c?view=markup\n#if defined(__FreeBSD__) &amp;&amp; !(EIGEN_ARCH_ARM || EIGEN_ARCH_MIPS) &amp;&amp; (EIGEN_DEFAULT_ALIGN_BYTES == 16)\n#define EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED 1\n#else\n#define EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED 0\n#endif\n\n#if (EIGEN_OS_MAC &amp;&amp; (EIGEN_DEFAULT_ALIGN_BYTES == 16)) || (EIGEN_OS_WIN64 &amp;&amp; (EIGEN_DEFAULT_ALIGN_BYTES == 16)) || \\\n    EIGEN_GLIBC_MALLOC_ALREADY_ALIGNED || EIGEN_FREEBSD_MALLOC_ALREADY_ALIGNED\n#define EIGEN_MALLOC_ALREADY_ALIGNED 1\n#else\n#define EIGEN_MALLOC_ALREADY_ALIGNED 0\n#endif\n\n#endif\n\n#ifndef EIGEN_MALLOC_CHECK_THREAD_LOCAL\n\n// Check whether we can use the thread_local keyword to allow or disallow\n// allocating memory with per-thread granularity, by means of the\n// set_is_malloc_allowed() function.\n#ifndef EIGEN_AVOID_THREAD_LOCAL\n\n#if ((EIGEN_COMP_GNUC) || __has_feature(cxx_thread_local) || EIGEN_COMP_MSVC &gt;= 1900) &amp;&amp; \\\n    !defined(EIGEN_GPU_COMPILE_PHASE)\n#define EIGEN_MALLOC_CHECK_THREAD_LOCAL thread_local\n#else\n#define EIGEN_MALLOC_CHECK_THREAD_LOCAL\n#endif\n\n#else  // EIGEN_AVOID_THREAD_LOCAL\n#define EIGEN_MALLOC_CHECK_THREAD_LOCAL\n#endif  // EIGEN_AVOID_THREAD_LOCAL\n\n#endif\n\n// IWYU pragma: private\n#include &quot;../InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n/*****************************************************************************\n*** Implementation of portable aligned versions of malloc/free/realloc     ***\n*****************************************************************************/\n\n#ifdef EIGEN_NO_MALLOC\nEIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {\n  eigen_assert(false &amp;&amp; &quot;heap allocation is forbidden (EIGEN_NO_MALLOC is defined)&quot;);\n}\n#elif defined EIGEN_RUNTIME_NO_MALLOC\nEIGEN_DEVICE_FUNC inline bool is_malloc_allowed_impl(bool update, bool new_value = false) {\n  EIGEN_MALLOC_CHECK_THREAD_LOCAL static bool value = true;\n  if (update == 1) value = new_value;\n  return value;\n}\nEIGEN_DEVICE_FUNC inline bool is_malloc_allowed() { return is_malloc_allowed_impl(false); }\nEIGEN_DEVICE_FUNC inline bool set_is_malloc_allowed(bool new_value) { return is_malloc_allowed_impl(true, new_value); }\nEIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {\n  eigen_assert(is_malloc_allowed() &amp;&amp;\n               &quot;heap allocation is forbidden (EIGEN_RUNTIME_NO_MALLOC is defined and g_is_malloc_allowed is false)&quot;);\n}\n#else\nEIGEN_DEVICE_FUNC inline void check_that_malloc_is_allowed() {}\n#endif\n\nEIGEN_DEVICE_FUNC inline void throw_std_bad_alloc() {\n#ifdef EIGEN_EXCEPTIONS\n  throw std::bad_alloc();\n#else\n  std::size_t huge = static_cast&lt;std::size_t&gt;(-1);\n#if defined(EIGEN_HIPCC)\n  //\n  // calls to &quot;::operator new&quot; are to be treated as opaque function calls (i.e no inlining),\n  // and as a consequence the code in the #else block triggers the hipcc warning :\n  // &quot;no overloaded function has restriction specifiers that are compatible with the ambient context&quot;\n  //\n  // &quot;throw_std_bad_alloc&quot; has the EIGEN_DEVICE_FUNC attribute, so it seems that hipcc expects\n  // the same on &quot;operator new&quot;\n  // Reverting code back to the old version in this #if block for the hipcc compiler\n  //\n  new int[huge];\n#else\n  void* unused = ::operator new(huge);\n  EIGEN_UNUSED_VARIABLE(unused);\n#endif\n#endif\n}\n\n/*****************************************************************************\n*** Implementation of handmade aligned functions                           ***\n*****************************************************************************/\n\n/* ----- Hand made implementations of aligned malloc/free and realloc ----- */\n\n/** \\internal Like malloc, but the returned pointer is guaranteed to be aligned to `alignment`.\n * Fast, but wastes `alignment` additional bytes of memory. Does not throw any exception.\n */\nEIGEN_DEVICE_FUNC inline void* handmade_aligned_malloc(std::size_t size,\n                                                       std::size_t alignment = EIGEN_DEFAULT_ALIGN_BYTES) {\n  eigen_assert(alignment &gt;= sizeof(void*) &amp;&amp; alignment &lt;= 256 &amp;&amp; (alignment &amp; (alignment - 1)) == 0 &amp;&amp;\n               &quot;Alignment must be at least sizeof(void*), less than or equal to 256, and a power of 2&quot;);\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(malloc)\n  void* original = malloc(size + alignment);\n  if (original == nullptr) return nullptr;\n  std::size_t offset = alignment - (reinterpret_cast&lt;std::size_t&gt;(original) &amp; (alignment - 1));\n  void* aligned = static_cast&lt;void*&gt;(static_cast&lt;uint8_t*&gt;(original) + offset);\n  // Store offset - 1, since it is guaranteed to be at least 1.\n  *(static_cast&lt;uint8_t*&gt;(aligned) - 1) = static_cast&lt;uint8_t&gt;(offset - 1);\n  return aligned;\n}\n\n/** \\internal Frees memory allocated with handmade_aligned_malloc */\nEIGEN_DEVICE_FUNC inline void handmade_aligned_free(void* ptr) {\n  if (ptr != nullptr) {\n    std::size_t offset = static_cast&lt;std::size_t&gt;(*(static_cast&lt;uint8_t*&gt;(ptr) - 1)) + 1;\n    void* original = static_cast&lt;void*&gt;(static_cast&lt;uint8_t*&gt;(ptr) - offset);\n\n    check_that_malloc_is_allowed();\n    EIGEN_USING_STD(free)\n    free(original);\n  }\n}\n\n/** \\internal\n * \\brief Reallocates aligned memory.\n * Since we know that our handmade version is based on std::malloc\n * we can use std::realloc to implement efficient reallocation.\n */\nEIGEN_DEVICE_FUNC inline void* handmade_aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size,\n                                                        std::size_t alignment = EIGEN_DEFAULT_ALIGN_BYTES) {\n  if (ptr == nullptr) return handmade_aligned_malloc(new_size, alignment);\n  std::size_t old_offset = static_cast&lt;std::size_t&gt;(*(static_cast&lt;uint8_t*&gt;(ptr) - 1)) + 1;\n  void* old_original = static_cast&lt;uint8_t*&gt;(ptr) - old_offset;\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(realloc)\n  void* original = realloc(old_original, new_size + alignment);\n  if (original == nullptr) return nullptr;\n  if (original == old_original) return ptr;\n  std::size_t offset = alignment - (reinterpret_cast&lt;std::size_t&gt;(original) &amp; (alignment - 1));\n  void* aligned = static_cast&lt;void*&gt;(static_cast&lt;uint8_t*&gt;(original) + offset);\n  if (offset != old_offset) {\n    const void* src = static_cast&lt;const void*&gt;(static_cast&lt;uint8_t*&gt;(original) + old_offset);\n    std::size_t count = (std::min)(new_size, old_size);\n    std::memmove(aligned, src, count);\n  }\n  // Store offset - 1, since it is guaranteed to be at least 1.\n  *(static_cast&lt;uint8_t*&gt;(aligned) - 1) = static_cast&lt;uint8_t&gt;(offset - 1);\n  return aligned;\n}\n\n/** \\internal Allocates \\a size bytes. The returned pointer is guaranteed to have 16 or 32 bytes alignment depending on\n * the requirements. On allocation error, the returned pointer is null, and std::bad_alloc is thrown.\n */\nEIGEN_DEVICE_FUNC inline void* aligned_malloc(std::size_t size) {\n  if (size == 0) return nullptr;\n\n  void* result;\n#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(malloc)\n  result = malloc(size);\n\n#if EIGEN_DEFAULT_ALIGN_BYTES == 16\n  eigen_assert((size &lt; 16 || (std::size_t(result) % 16) == 0) &amp;&amp;\n               &quot;System&#x27;s malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback &quot;\n               &quot;to handmade aligned memory allocator.&quot;);\n#endif\n#else\n  result = handmade_aligned_malloc(size);\n#endif\n\n  if (!result &amp;&amp; size) throw_std_bad_alloc();\n\n  return result;\n}\n\n/** \\internal Frees memory allocated with aligned_malloc. */\nEIGEN_DEVICE_FUNC inline void aligned_free(void* ptr) {\n#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED\n\n  if (ptr != nullptr) {\n    check_that_malloc_is_allowed();\n    EIGEN_USING_STD(free)\n    free(ptr);\n  }\n\n#else\n  handmade_aligned_free(ptr);\n#endif\n}\n\n/**\n * \\internal\n * \\brief Reallocates an aligned block of memory.\n * \\throws std::bad_alloc on allocation failure\n */\nEIGEN_DEVICE_FUNC inline void* aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {\n  if (ptr == nullptr) return aligned_malloc(new_size);\n  if (old_size == new_size) return ptr;\n  if (new_size == 0) {\n    aligned_free(ptr);\n    return nullptr;\n  }\n\n  void* result;\n#if (EIGEN_DEFAULT_ALIGN_BYTES == 0) || EIGEN_MALLOC_ALREADY_ALIGNED\n  EIGEN_UNUSED_VARIABLE(old_size)\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(realloc)\n  result = realloc(ptr, new_size);\n#else\n  result = handmade_aligned_realloc(ptr, new_size, old_size);\n#endif\n\n  if (!result &amp;&amp; new_size) throw_std_bad_alloc();\n\n  return result;\n}\n\n/*****************************************************************************\n*** Implementation of conditionally aligned functions                      ***\n*****************************************************************************/\n\n/** \\internal Allocates \\a size bytes. If Align is true, then the returned ptr is 16-byte-aligned.\n * On allocation error, the returned pointer is null, and a std::bad_alloc is thrown.\n */\ntemplate &lt;bool Align&gt;\nEIGEN_DEVICE_FUNC inline void* conditional_aligned_malloc(std::size_t size) {\n  return aligned_malloc(size);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline void* conditional_aligned_malloc&lt;false&gt;(std::size_t size) {\n  if (size == 0) return nullptr;\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(malloc)\n  void* result = malloc(size);\n\n  if (!result &amp;&amp; size) throw_std_bad_alloc();\n  return result;\n}\n\n/** \\internal Frees memory allocated with conditional_aligned_malloc */\ntemplate &lt;bool Align&gt;\nEIGEN_DEVICE_FUNC inline void conditional_aligned_free(void* ptr) {\n  aligned_free(ptr);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline void conditional_aligned_free&lt;false&gt;(void* ptr) {\n  if (ptr != nullptr) {\n    check_that_malloc_is_allowed();\n    EIGEN_USING_STD(free)\n    free(ptr);\n  }\n}\n\ntemplate &lt;bool Align&gt;\nEIGEN_DEVICE_FUNC inline void* conditional_aligned_realloc(void* ptr, std::size_t new_size, std::size_t old_size) {\n  return aligned_realloc(ptr, new_size, old_size);\n}\n\ntemplate &lt;&gt;\nEIGEN_DEVICE_FUNC inline void* conditional_aligned_realloc&lt;false&gt;(void* ptr, std::size_t new_size,\n                                                                  std::size_t old_size) {\n  if (ptr == nullptr) return conditional_aligned_malloc&lt;false&gt;(new_size);\n  if (old_size == new_size) return ptr;\n  if (new_size == 0) {\n    conditional_aligned_free&lt;false&gt;(ptr);\n    return nullptr;\n  }\n\n  check_that_malloc_is_allowed();\n  EIGEN_USING_STD(realloc)\n  return realloc(ptr, new_size);\n}\n\n/*****************************************************************************\n*** Construction/destruction of array elements                             ***\n*****************************************************************************/\n\n/** \\internal Destructs the elements of an array.\n * The \\a size parameters tells on how many objects to call the destructor of T.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline void destruct_elements_of_array(T* ptr, std::size_t size) {\n  // always destruct an array starting from the end.\n  if (ptr)\n    while (size) ptr[--size].~T();\n}\n\n/** \\internal Constructs the elements of an array.\n * The \\a size parameter tells on how many objects to call the constructor of T.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline T* default_construct_elements_of_array(T* ptr, std::size_t size) {\n  std::size_t i = 0;\n  EIGEN_TRY {\n    for (i = 0; i &lt; size; ++i) ::new (ptr + i) T;\n  }\n  EIGEN_CATCH(...) {\n    destruct_elements_of_array(ptr, i);\n    EIGEN_THROW;\n  }\n  return ptr;\n}\n\n/** \\internal Copy-constructs the elements of an array.\n * The \\a size parameter tells on how many objects to copy.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline T* copy_construct_elements_of_array(T* ptr, const T* src, std::size_t size) {\n  std::size_t i = 0;\n  EIGEN_TRY {\n    for (i = 0; i &lt; size; ++i) ::new (ptr + i) T(*(src + i));\n  }\n  EIGEN_CATCH(...) {\n    destruct_elements_of_array(ptr, i);\n    EIGEN_THROW;\n  }\n  return ptr;\n}\n\n/** \\internal Move-constructs the elements of an array.\n * The \\a size parameter tells on how many objects to move.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline T* move_construct_elements_of_array(T* ptr, T* src, std::size_t size) {\n  std::size_t i = 0;\n  EIGEN_TRY {\n    for (i = 0; i &lt; size; ++i) ::new (ptr + i) T(std::move(*(src + i)));\n  }\n  EIGEN_CATCH(...) {\n    destruct_elements_of_array(ptr, i);\n    EIGEN_THROW;\n  }\n  return ptr;\n}\n\n/*****************************************************************************\n*** Implementation of aligned new/delete-like functions                    ***\n*****************************************************************************/\n\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size) {\n  constexpr std::size_t max_elements = (std::numeric_limits&lt;std::ptrdiff_t&gt;::max)() / sizeof(T);\n  if (size &gt; max_elements) throw_std_bad_alloc();\n}\n\n/** \\internal Allocates \\a size objects of type T. The returned pointer is guaranteed to have 16 bytes alignment.\n * On allocation error, the returned pointer is undefined, but a std::bad_alloc is thrown.\n * The default constructor of T is called.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline T* aligned_new(std::size_t size) {\n  check_size_for_overflow&lt;T&gt;(size);\n  T* result = static_cast&lt;T*&gt;(aligned_malloc(sizeof(T) * size));\n  EIGEN_TRY { return default_construct_elements_of_array(result, size); }\n  EIGEN_CATCH(...) {\n    aligned_free(result);\n    EIGEN_THROW;\n  }\n  return result;\n}\n\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline T* conditional_aligned_new(std::size_t size) {\n  check_size_for_overflow&lt;T&gt;(size);\n  T* result = static_cast&lt;T*&gt;(conditional_aligned_malloc&lt;Align&gt;(sizeof(T) * size));\n  EIGEN_TRY { return default_construct_elements_of_array(result, size); }\n  EIGEN_CATCH(...) {\n    conditional_aligned_free&lt;Align&gt;(result);\n    EIGEN_THROW;\n  }\n  return result;\n}\n\n/** \\internal Deletes objects constructed with aligned_new\n * The \\a size parameters tells on how many objects to call the destructor of T.\n */\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC inline void aligned_delete(T* ptr, std::size_t size) {\n  destruct_elements_of_array&lt;T&gt;(ptr, size);\n  aligned_free(ptr);\n}\n\n/** \\internal Deletes objects constructed with conditional_aligned_new\n * The \\a size parameters tells on how many objects to call the destructor of T.\n */\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline void conditional_aligned_delete(T* ptr, std::size_t size) {\n  destruct_elements_of_array&lt;T&gt;(ptr, size);\n  conditional_aligned_free&lt;Align&gt;(ptr);\n}\n\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline T* conditional_aligned_realloc_new(T* pts, std::size_t new_size, std::size_t old_size) {\n  check_size_for_overflow&lt;T&gt;(new_size);\n  check_size_for_overflow&lt;T&gt;(old_size);\n\n  // If elements need to be explicitly initialized, we cannot simply realloc\n  // (or memcpy) the memory block - each element needs to be reconstructed.\n  // Otherwise, objects that contain internal pointers like mpfr or\n  // AnnoyingScalar can be pointing to the wrong thing.\n  T* result = static_cast&lt;T*&gt;(conditional_aligned_malloc&lt;Align&gt;(sizeof(T) * new_size));\n  EIGEN_TRY {\n    // Move-construct initial elements.\n    std::size_t copy_size = (std::min)(old_size, new_size);\n    move_construct_elements_of_array(result, pts, copy_size);\n\n    // Default-construct remaining elements.\n    if (new_size &gt; old_size) {\n      default_construct_elements_of_array(result + copy_size, new_size - old_size);\n    }\n\n    // Delete old elements.\n    conditional_aligned_delete&lt;T, Align&gt;(pts, old_size);\n  }\n  EIGEN_CATCH(...) {\n    conditional_aligned_free&lt;Align&gt;(result);\n    EIGEN_THROW;\n  }\n\n  return result;\n}\n\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size) {\n  if (size == 0) return nullptr;  // short-cut. Also fixes Bug 884\n  check_size_for_overflow&lt;T&gt;(size);\n  T* result = static_cast&lt;T*&gt;(conditional_aligned_malloc&lt;Align&gt;(sizeof(T) * size));\n  if (NumTraits&lt;T&gt;::RequireInitialization) {\n    EIGEN_TRY { default_construct_elements_of_array(result, size); }\n    EIGEN_CATCH(...) {\n      conditional_aligned_free&lt;Align&gt;(result);\n      EIGEN_THROW;\n    }\n  }\n  return result;\n}\n\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline T* conditional_aligned_realloc_new_auto(T* pts, std::size_t new_size, std::size_t old_size) {\n  if (NumTraits&lt;T&gt;::RequireInitialization) {\n    return conditional_aligned_realloc_new&lt;T, Align&gt;(pts, new_size, old_size);\n  }\n\n  check_size_for_overflow&lt;T&gt;(new_size);\n  check_size_for_overflow&lt;T&gt;(old_size);\n  return static_cast&lt;T*&gt;(\n      conditional_aligned_realloc&lt;Align&gt;(static_cast&lt;void*&gt;(pts), sizeof(T) * new_size, sizeof(T) * old_size));\n}\n\ntemplate &lt;typename T, bool Align&gt;\nEIGEN_DEVICE_FUNC inline void conditional_aligned_delete_auto(T* ptr, std::size_t size) {\n  if (NumTraits&lt;T&gt;::RequireInitialization) destruct_elements_of_array&lt;T&gt;(ptr, size);\n  conditional_aligned_free&lt;Align&gt;(ptr);\n}\n\n/****************************************************************************/\n\n/** \\internal Returns the index of the first element of the array that is well aligned with respect to the requested \\a\n * Alignment.\n *\n * \\tparam Alignment requested alignment in Bytes.\n * \\param array the address of the start of the array\n * \\param size the size of the array\n *\n * \\note If no element of the array is well aligned or the requested alignment is not a multiple of a scalar,\n * the size of the array is returned. For example with SSE, the requested alignment is typically 16-bytes. If\n * packet size for the given scalar type is 1, then everything is considered well-aligned.\n *\n * \\note Otherwise, if the Alignment is larger that the scalar size, we rely on the assumptions that sizeof(Scalar) is a\n * power of 2. On the other hand, we do not assume that the array address is a multiple of sizeof(Scalar), as that fails\n * for example with Scalar=double on certain 32-bit platforms, see bug #79.\n *\n * There is also the variant first_aligned(const MatrixBase&amp;) defined in DenseCoeffsBase.h.\n * \\sa first_default_aligned()\n */\ntemplate &lt;int Alignment, typename Scalar, typename Index&gt;\nEIGEN_DEVICE_FUNC inline Index first_aligned(const Scalar* array, Index size) {\n  const Index ScalarSize = sizeof(Scalar);\n  const Index AlignmentSize = Alignment / ScalarSize;\n  const Index AlignmentMask = AlignmentSize - 1;\n\n  if (AlignmentSize &lt;= 1) {\n    // Either the requested alignment if smaller than a scalar, or it exactly match a 1 scalar\n    // so that all elements of the array have the same alignment.\n    return 0;\n  } else if ((std::uintptr_t(array) &amp; (sizeof(Scalar) - 1)) || (Alignment % ScalarSize) != 0) {\n    // The array is not aligned to the size of a single scalar, or the requested alignment is not a multiple of the\n    // scalar size. Consequently, no element of the array is well aligned.\n    return size;\n  } else {\n    Index first = (AlignmentSize - (Index((std::uintptr_t(array) / sizeof(Scalar))) &amp; AlignmentMask)) &amp; AlignmentMask;\n    return (first &lt; size) ? first : size;\n  }\n}\n\n/** \\internal Returns the index of the first element of the array that is well aligned with respect the largest packet\n * requirement. \\sa first_aligned(Scalar*,Index) and first_default_aligned(DenseBase&lt;Derived&gt;) */\ntemplate &lt;typename Scalar, typename Index&gt;\nEIGEN_DEVICE_FUNC inline Index first_default_aligned(const Scalar* array, Index size) {\n  typedef typename packet_traits&lt;Scalar&gt;::type DefaultPacketType;\n  return first_aligned&lt;unpacket_traits&lt;DefaultPacketType&gt;::alignment&gt;(array, size);\n}\n\n/** \\internal Returns the smallest integer multiple of \\a base and greater or equal to \\a size\n */\ntemplate &lt;typename Index&gt;\ninline Index first_multiple(Index size, Index base) {\n  return ((size + base - 1) / base) * base;\n}\n\n// std::copy is much slower than memcpy, so let&#x27;s introduce a smart_copy which\n// use memcpy on trivial types, i.e., on types that does not require an initialization ctor.\ntemplate &lt;typename T, bool UseMemcpy&gt;\nstruct smart_copy_helper;\n\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC void smart_copy(const T* start, const T* end, T* target) {\n  smart_copy_helper&lt;T, !NumTraits&lt;T&gt;::RequireInitialization&gt;::run(start, end, target);\n}\n\ntemplate &lt;typename T&gt;\nstruct smart_copy_helper&lt;T, true&gt; {\n  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target) {\n    std::intptr_t size = std::intptr_t(end) - std::intptr_t(start);\n    if (size == 0) return;\n    eigen_internal_assert(start != 0 &amp;&amp; end != 0 &amp;&amp; target != 0);\n    EIGEN_USING_STD(memcpy)\n    memcpy(target, start, size);\n  }\n};\n\ntemplate &lt;typename T&gt;\nstruct smart_copy_helper&lt;T, false&gt; {\n  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target) { std::copy(start, end, target); }\n};\n\n// intelligent memmove. falls back to std::memmove for POD types, uses std::copy otherwise.\ntemplate &lt;typename T, bool UseMemmove&gt;\nstruct smart_memmove_helper;\n\ntemplate &lt;typename T&gt;\nvoid smart_memmove(const T* start, const T* end, T* target) {\n  smart_memmove_helper&lt;T, !NumTraits&lt;T&gt;::RequireInitialization&gt;::run(start, end, target);\n}\n\ntemplate &lt;typename T&gt;\nstruct smart_memmove_helper&lt;T, true&gt; {\n  static inline void run(const T* start, const T* end, T* target) {\n    std::intptr_t size = std::intptr_t(end) - std::intptr_t(start);\n    if (size == 0) return;\n    eigen_internal_assert(start != 0 &amp;&amp; end != 0 &amp;&amp; target != 0);\n    std::memmove(target, start, size);\n  }\n};\n\ntemplate &lt;typename T&gt;\nstruct smart_memmove_helper&lt;T, false&gt; {\n  static inline void run(const T* start, const T* end, T* target) {\n    if (std::uintptr_t(target) &lt; std::uintptr_t(start)) {\n      std::copy(start, end, target);\n    } else {\n      std::ptrdiff_t count = (std::ptrdiff_t(end) - std::ptrdiff_t(start)) / sizeof(T);\n      std::copy_backward(start, end, target + count);\n    }\n  }\n};\n\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target) {\n  return std::move(start, end, target);\n}\n\n/*****************************************************************************\n*** Implementation of runtime stack allocation (falling back to malloc)    ***\n*****************************************************************************/\n\n// you can overwrite Eigen&#x27;s default behavior regarding alloca by defining EIGEN_ALLOCA\n// to the appropriate stack allocation function\n#if !defined EIGEN_ALLOCA &amp;&amp; !defined EIGEN_GPU_COMPILE_PHASE\n#if EIGEN_OS_LINUX || EIGEN_OS_MAC || (defined alloca)\n#define EIGEN_ALLOCA alloca\n#elif EIGEN_COMP_MSVC\n#define EIGEN_ALLOCA _alloca\n#endif\n#endif\n\n// With clang -Oz -mthumb, alloca changes the stack pointer in a way that is\n// not allowed in Thumb2. -DEIGEN_STACK_ALLOCATION_LIMIT=0 doesn&#x27;t work because\n// the compiler still emits bad code because stack allocation checks use &quot;&lt;=&quot;.\n// TODO: Eliminate after https://bugs.llvm.org/show_bug.cgi?id=23772\n// is fixed.\n#if defined(__clang__) &amp;&amp; defined(__thumb__)\n#undef EIGEN_ALLOCA\n#endif\n\n// This helper class construct the allocated memory, and takes care of destructing and freeing the handled data\n// at destruction time. In practice this helper class is mainly useful to avoid memory leak in case of exceptions.\ntemplate &lt;typename T&gt;\nclass aligned_stack_memory_handler : noncopyable {\n public:\n  /* Creates a stack_memory_handler responsible for the buffer \\a ptr of size \\a size.\n   * Note that \\a ptr can be 0 regardless of the other parameters.\n   * This constructor takes care of constructing/initializing the elements of the buffer if required by the scalar type\n   *T (see NumTraits&lt;T&gt;::RequireInitialization). In this case, the buffer elements will also be destructed when this\n   *handler will be destructed. Finally, if \\a dealloc is true, then the pointer \\a ptr is freed.\n   **/\n  EIGEN_DEVICE_FUNC aligned_stack_memory_handler(T* ptr, std::size_t size, bool dealloc)\n      : m_ptr(ptr), m_size(size), m_deallocate(dealloc) {\n    if (NumTraits&lt;T&gt;::RequireInitialization &amp;&amp; m_ptr) Eigen::internal::default_construct_elements_of_array(m_ptr, size);\n  }\n  EIGEN_DEVICE_FUNC ~aligned_stack_memory_handler() {\n    if (NumTraits&lt;T&gt;::RequireInitialization &amp;&amp; m_ptr) Eigen::internal::destruct_elements_of_array&lt;T&gt;(m_ptr, m_size);\n    if (m_deallocate) Eigen::internal::aligned_free(m_ptr);\n  }\n\n protected:\n  T* m_ptr;\n  std::size_t m_size;\n  bool m_deallocate;\n};\n\n#ifdef EIGEN_ALLOCA\n\ntemplate &lt;typename Xpr, int NbEvaluations,\n          bool MapExternalBuffer = nested_eval&lt;Xpr, NbEvaluations&gt;::Evaluate &amp;&amp; Xpr::MaxSizeAtCompileTime == Dynamic&gt;\nstruct local_nested_eval_wrapper {\n  static constexpr bool NeedExternalBuffer = false;\n  typedef typename Xpr::Scalar Scalar;\n  typedef typename nested_eval&lt;Xpr, NbEvaluations&gt;::type ObjectType;\n  ObjectType object;\n\n  EIGEN_DEVICE_FUNC local_nested_eval_wrapper(const Xpr&amp; xpr, Scalar* ptr) : object(xpr) {\n    EIGEN_UNUSED_VARIABLE(ptr);\n    eigen_internal_assert(ptr == 0);\n  }\n};\n\ntemplate &lt;typename Xpr, int NbEvaluations&gt;\nstruct local_nested_eval_wrapper&lt;Xpr, NbEvaluations, true&gt; {\n  static constexpr bool NeedExternalBuffer = true;\n  typedef typename Xpr::Scalar Scalar;\n  typedef typename plain_object_eval&lt;Xpr&gt;::type PlainObject;\n  typedef Map&lt;PlainObject, EIGEN_DEFAULT_ALIGN_BYTES&gt; ObjectType;\n  ObjectType object;\n\n  EIGEN_DEVICE_FUNC local_nested_eval_wrapper(const Xpr&amp; xpr, Scalar* ptr)\n      : object(ptr == 0 ? reinterpret_cast&lt;Scalar*&gt;(Eigen::internal::aligned_malloc(sizeof(Scalar) * xpr.size())) : ptr,\n               xpr.rows(), xpr.cols()),\n        m_deallocate(ptr == 0) {\n    if (NumTraits&lt;Scalar&gt;::RequireInitialization &amp;&amp; object.data())\n      Eigen::internal::default_construct_elements_of_array(object.data(), object.size());\n    object = xpr;\n  }\n\n  EIGEN_DEVICE_FUNC ~local_nested_eval_wrapper() {\n    if (NumTraits&lt;Scalar&gt;::RequireInitialization &amp;&amp; object.data())\n      Eigen::internal::destruct_elements_of_array(object.data(), object.size());\n    if (m_deallocate) Eigen::internal::aligned_free(object.data());\n  }\n\n private:\n  bool m_deallocate;\n};\n\n#endif  // EIGEN_ALLOCA\n\ntemplate &lt;typename T&gt;\nclass scoped_array : noncopyable {\n  T* m_ptr;\n\n public:\n  explicit scoped_array(std::ptrdiff_t size) { m_ptr = new T[size]; }\n  ~scoped_array() { delete[] m_ptr; }\n  T&amp; operator[](std::ptrdiff_t i) { return m_ptr[i]; }\n  const T&amp; operator[](std::ptrdiff_t i) const { return m_ptr[i]; }\n  T*&amp; ptr() { return m_ptr; }\n  const T* ptr() const { return m_ptr; }\n  operator const T*() const { return m_ptr; }\n};\n\ntemplate &lt;typename T&gt;\nvoid swap(scoped_array&lt;T&gt;&amp; a, scoped_array&lt;T&gt;&amp; b) {\n  std::swap(a.ptr(), b.ptr());\n}\n\n}  // end namespace internal\n\n/** \\internal\n *\n * The macro ei_declare_aligned_stack_constructed_variable(TYPE,NAME,SIZE,BUFFER) declares, allocates,\n * and construct an aligned buffer named NAME of SIZE elements of type TYPE on the stack\n * if the size in bytes is smaller than EIGEN_STACK_ALLOCATION_LIMIT, and if stack allocation is supported by the\n * platform (currently, this is Linux, OSX and Visual Studio only). Otherwise the memory is allocated on the heap. The\n * allocated buffer is automatically deleted when exiting the scope of this declaration. If BUFFER is non null, then the\n * declared variable is simply an alias for BUFFER, and no allocation/deletion occurs. Here is an example: \\code\n * {\n *   ei_declare_aligned_stack_constructed_variable(float,data,size,0);\n *   // use data[0] to data[size-1]\n * }\n * \\endcode\n * The underlying stack allocation function can controlled with the EIGEN_ALLOCA preprocessor token.\n *\n * The macro ei_declare_local_nested_eval(XPR_T,XPR,N,NAME) is analogue to\n * \\code\n *   typename internal::nested_eval&lt;XPRT_T,N&gt;::type NAME(XPR);\n * \\endcode\n * with the advantage of using aligned stack allocation even if the maximal size of XPR at compile time is unknown.\n * This is accomplished through alloca if this later is supported and if the required number of bytes\n * is below EIGEN_STACK_ALLOCATION_LIMIT.\n */\n#ifdef EIGEN_ALLOCA\n\n#if EIGEN_DEFAULT_ALIGN_BYTES &gt; 0\n// We always manually re-align the result of EIGEN_ALLOCA.\n// If alloca is already aligned, the compiler should be smart enough to optimize away the re-alignment.\n\n#if ((EIGEN_COMP_GNUC || EIGEN_COMP_CLANG) &amp;&amp; !EIGEN_COMP_NVHPC)\n#define EIGEN_ALIGNED_ALLOCA(SIZE) __builtin_alloca_with_align(SIZE, CHAR_BIT* EIGEN_DEFAULT_ALIGN_BYTES)\n#else\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void* eigen_aligned_alloca_helper(void* ptr) {\n  constexpr std::uintptr_t mask = EIGEN_DEFAULT_ALIGN_BYTES - 1;\n  std::uintptr_t ptr_int = std::uintptr_t(ptr);\n  std::uintptr_t aligned_ptr_int = (ptr_int + mask) &amp; ~mask;\n  std::uintptr_t offset = aligned_ptr_int - ptr_int;\n  return static_cast&lt;void*&gt;(static_cast&lt;uint8_t*&gt;(ptr) + offset);\n}\n#define EIGEN_ALIGNED_ALLOCA(SIZE) eigen_aligned_alloca_helper(EIGEN_ALLOCA(SIZE + EIGEN_DEFAULT_ALIGN_BYTES - 1))\n#endif\n\n#else\n#define EIGEN_ALIGNED_ALLOCA(SIZE) EIGEN_ALLOCA(SIZE)\n#endif\n\n#define ei_declare_aligned_stack_constructed_variable(TYPE, NAME, SIZE, BUFFER)                                     \\\n  Eigen::internal::check_size_for_overflow&lt;TYPE&gt;(SIZE);                                                             \\\n  TYPE* NAME = (BUFFER) != 0 ? (BUFFER)                                                                             \\\n                             : reinterpret_cast&lt;TYPE*&gt;((sizeof(TYPE) * SIZE &lt;= EIGEN_STACK_ALLOCATION_LIMIT)        \\\n                                                           ? EIGEN_ALIGNED_ALLOCA(sizeof(TYPE) * SIZE)              \\\n                                                           : Eigen::internal::aligned_malloc(sizeof(TYPE) * SIZE)); \\\n  Eigen::internal::aligned_stack_memory_handler&lt;TYPE&gt; EIGEN_CAT(NAME, _stack_memory_destructor)(                    \\\n      (BUFFER) == 0 ? NAME : 0, SIZE, sizeof(TYPE) * SIZE &gt; EIGEN_STACK_ALLOCATION_LIMIT)\n\n#define ei_declare_local_nested_eval(XPR_T, XPR, N, NAME)                                        \\\n  Eigen::internal::local_nested_eval_wrapper&lt;XPR_T, N&gt; EIGEN_CAT(NAME, _wrapper)(                \\\n      XPR, reinterpret_cast&lt;typename XPR_T::Scalar*&gt;(                                            \\\n               ((Eigen::internal::local_nested_eval_wrapper&lt;XPR_T, N&gt;::NeedExternalBuffer) &amp;&amp;    \\\n                ((sizeof(typename XPR_T::Scalar) * XPR.size()) &lt;= EIGEN_STACK_ALLOCATION_LIMIT)) \\\n                   ? EIGEN_ALIGNED_ALLOCA(sizeof(typename XPR_T::Scalar) * XPR.size())           \\\n                   : 0));                                                                        \\\n  typename Eigen::internal::local_nested_eval_wrapper&lt;XPR_T, N&gt;::ObjectType NAME(EIGEN_CAT(NAME, _wrapper).object)\n\n#else\n\n#define ei_declare_aligned_stack_constructed_variable(TYPE, NAME, SIZE, BUFFER)                                        \\\n  Eigen::internal::check_size_for_overflow&lt;TYPE&gt;(SIZE);                                                                \\\n  TYPE* NAME = (BUFFER) != 0 ? BUFFER : reinterpret_cast&lt;TYPE*&gt;(Eigen::internal::aligned_malloc(sizeof(TYPE) * SIZE)); \\\n  Eigen::internal::aligned_stack_memory_handler&lt;TYPE&gt; EIGEN_CAT(NAME, _stack_memory_destructor)(                       \\\n      (BUFFER) == 0 ? NAME : 0, SIZE, true)\n\n#define ei_declare_local_nested_eval(XPR_T, XPR, N, NAME) \\\n  typename Eigen::internal::nested_eval&lt;XPR_T, N&gt;::type NAME(XPR)\n\n#endif\n\n/*****************************************************************************\n*** Implementation of EIGEN_MAKE_ALIGNED_OPERATOR_NEW [_IF]                ***\n*****************************************************************************/\n\n#if EIGEN_HAS_CXX17_OVERALIGN\n\n// C++17 -&gt; no need to bother about alignment anymore :)\n\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar, Size)\n\n#else\n\n// HIP does not support new/delete on device.\n#if EIGEN_MAX_ALIGN_BYTES != 0 &amp;&amp; !defined(EIGEN_HIP_DEVICE_COMPILE)\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)                                    \\\n  EIGEN_DEVICE_FUNC void* operator new(std::size_t size, const std::nothrow_t&amp;) EIGEN_NO_THROW { \\\n    EIGEN_TRY { return Eigen::internal::conditional_aligned_malloc&lt;NeedsToAlign&gt;(size); }        \\\n    EIGEN_CATCH(...) { return 0; }                                                               \\\n  }\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)                                                             \\\n  EIGEN_DEVICE_FUNC void* operator new(std::size_t size) {                                                           \\\n    return Eigen::internal::conditional_aligned_malloc&lt;NeedsToAlign&gt;(size);                                          \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void* operator new[](std::size_t size) {                                                         \\\n    return Eigen::internal::conditional_aligned_malloc&lt;NeedsToAlign&gt;(size);                                          \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void operator delete(void* ptr) EIGEN_NO_THROW {                                                 \\\n    Eigen::internal::conditional_aligned_free&lt;NeedsToAlign&gt;(ptr);                                                    \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void operator delete[](void* ptr) EIGEN_NO_THROW {                                               \\\n    Eigen::internal::conditional_aligned_free&lt;NeedsToAlign&gt;(ptr);                                                    \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void operator delete(void* ptr, std::size_t /* sz */) EIGEN_NO_THROW {                           \\\n    Eigen::internal::conditional_aligned_free&lt;NeedsToAlign&gt;(ptr);                                                    \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void operator delete[](void* ptr, std::size_t /* sz */) EIGEN_NO_THROW {                         \\\n    Eigen::internal::conditional_aligned_free&lt;NeedsToAlign&gt;(ptr);                                                    \\\n  }                                                                                                                  \\\n  /* in-place new and delete. since (at least afaik) there is no actual   */                                         \\\n  /* memory allocated we can safely let the default implementation handle */                                         \\\n  /* this particular case. */                                                                                        \\\n  EIGEN_DEVICE_FUNC static void* operator new(std::size_t size, void* ptr) { return ::operator new(size, ptr); }     \\\n  EIGEN_DEVICE_FUNC static void* operator new[](std::size_t size, void* ptr) { return ::operator new[](size, ptr); } \\\n  EIGEN_DEVICE_FUNC void operator delete(void* memory, void* ptr) EIGEN_NO_THROW {                                   \\\n    return ::operator delete(memory, ptr);                                                                           \\\n  }                                                                                                                  \\\n  EIGEN_DEVICE_FUNC void operator delete[](void* memory, void* ptr) EIGEN_NO_THROW {                                 \\\n    return ::operator delete[](memory, ptr);                                                                         \\\n  }                                                                                                                  \\\n  /* nothrow-new (returns zero instead of std::bad_alloc) */                                                         \\\n  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)                                                              \\\n  EIGEN_DEVICE_FUNC void operator delete(void* ptr, const std::nothrow_t&amp;) EIGEN_NO_THROW {                          \\\n    Eigen::internal::conditional_aligned_free&lt;NeedsToAlign&gt;(ptr);                                                    \\\n  }                                                                                                                  \\\n  typedef void eigen_aligned_operator_new_marker_type;\n#else\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)\n#endif\n\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(true)\n#define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar, Size)                                 \\\n  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(                                                                            \\\n      bool(((Size) != Eigen::Dynamic) &amp;&amp;                                                                         \\\n           (((EIGEN_MAX_ALIGN_BYTES &gt;= 16) &amp;&amp; ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES) == 0)) ||     \\\n            ((EIGEN_MAX_ALIGN_BYTES &gt;= 32) &amp;&amp; ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES / 2) == 0)) || \\\n            ((EIGEN_MAX_ALIGN_BYTES &gt;= 64) &amp;&amp; ((sizeof(Scalar) * (Size)) % (EIGEN_MAX_ALIGN_BYTES / 4) == 0)))))\n\n#endif\n\n/****************************************************************************/\n\n/** \\class aligned_allocator\n * \\ingroup Core_Module\n *\n * \\brief STL compatible allocator to use with types requiring a non-standard alignment.\n *\n * The memory is aligned as for dynamically aligned matrix/array types such as MatrixXd.\n * By default, it will thus provide at least 16 bytes alignment and more in following cases:\n *  - 32 bytes alignment if AVX is enabled.\n *  - 64 bytes alignment if AVX512 is enabled.\n *\n * This can be controlled using the \\c EIGEN_MAX_ALIGN_BYTES macro as documented\n * \\link TopicPreprocessorDirectivesPerformance there \\endlink.\n *\n * Example:\n * \\code\n * // Matrix4f requires 16 bytes alignment:\n * std::map&lt; int, Matrix4f, std::less&lt;int&gt;,\n *           aligned_allocator&lt;std::pair&lt;const int, Matrix4f&gt; &gt; &gt; my_map_mat4;\n * // Vector3f does not require 16 bytes alignment, no need to use Eigen&#x27;s allocator:\n * std::map&lt; int, Vector3f &gt; my_map_vec3;\n * \\endcode\n *\n * \\sa \\blank \\ref TopicStlContainers.\n */\ntemplate &lt;class T&gt;\nclass aligned_allocator {\n public:\n  typedef std::size_t size_type;\n  typedef std::ptrdiff_t difference_type;\n  typedef T* pointer;\n  typedef const T* const_pointer;\n  typedef T&amp; reference;\n  typedef const T&amp; const_reference;\n  typedef T value_type;\n\n  template &lt;class U&gt;\n  struct rebind {\n    typedef aligned_allocator&lt;U&gt; other;\n  };\n\n  aligned_allocator() = default;\n\n  aligned_allocator(const aligned_allocator&amp;) = default;\n\n  template &lt;class U&gt;\n  aligned_allocator(const aligned_allocator&lt;U&gt;&amp;) {}\n\n  template &lt;class U&gt;\n  constexpr bool operator==(const aligned_allocator&lt;U&gt;&amp;) const noexcept {\n    return true;\n  }\n  template &lt;class U&gt;\n  constexpr bool operator!=(const aligned_allocator&lt;U&gt;&amp;) const noexcept {\n    return false;\n  }\n\n#if EIGEN_COMP_GNUC_STRICT &amp;&amp; EIGEN_GNUC_STRICT_AT_LEAST(7, 0, 0)\n  // In gcc std::allocator::max_size() is bugged making gcc triggers a warning:\n  // eigen/Eigen/src/Core/util/Memory.h:189:12: warning: argument 1 value &#x27;18446744073709551612&#x27; exceeds maximum object\n  // size 9223372036854775807 See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=87544\n  size_type max_size() const { return (std::numeric_limits&lt;std::ptrdiff_t&gt;::max)() / sizeof(T); }\n#endif\n\n  pointer allocate(size_type num, const void* /*hint*/ = 0) {\n    internal::check_size_for_overflow&lt;T&gt;(num);\n    return static_cast&lt;pointer&gt;(internal::aligned_malloc(num * sizeof(T)));\n  }\n\n  void deallocate(pointer p, size_type /*num*/) { internal::aligned_free(p); }\n};\n\n//---------- Cache sizes ----------\n\n#if !defined(EIGEN_NO_CPUID)\n#if EIGEN_COMP_GNUC &amp;&amp; EIGEN_ARCH_i386_OR_x86_64\n#if defined(__PIC__) &amp;&amp; EIGEN_ARCH_i386\n// Case for x86 with PIC\n#define EIGEN_CPUID(abcd, func, id)                                                  \\\n  __asm__ __volatile__(&quot;xchgl %%ebx, %k1;cpuid; xchgl %%ebx,%k1&quot;                     \\\n                       : &quot;=a&quot;(abcd[0]), &quot;=&amp;r&quot;(abcd[1]), &quot;=c&quot;(abcd[2]), &quot;=d&quot;(abcd[3]) \\\n                       : &quot;a&quot;(func), &quot;c&quot;(id));\n#elif defined(__PIC__) &amp;&amp; EIGEN_ARCH_x86_64\n// Case for x64 with PIC. In theory this is only a problem with recent gcc and with medium or large code model, not with\n// the default small code model. However, we cannot detect which code model is used, and the xchg overhead is negligible\n// anyway.\n#define EIGEN_CPUID(abcd, func, id)                                                  \\\n  __asm__ __volatile__(&quot;xchg{q}\\t{%%}rbx, %q1; cpuid; xchg{q}\\t{%%}rbx, %q1&quot;         \\\n                       : &quot;=a&quot;(abcd[0]), &quot;=&amp;r&quot;(abcd[1]), &quot;=c&quot;(abcd[2]), &quot;=d&quot;(abcd[3]) \\\n                       : &quot;0&quot;(func), &quot;2&quot;(id));\n#else\n// Case for x86_64 or x86 w/o PIC\n#define EIGEN_CPUID(abcd, func, id) \\\n  __asm__ __volatile__(&quot;cpuid&quot; : &quot;=a&quot;(abcd[0]), &quot;=b&quot;(abcd[1]), &quot;=c&quot;(abcd[2]), &quot;=d&quot;(abcd[3]) : &quot;0&quot;(func), &quot;2&quot;(id));\n#endif\n#elif EIGEN_COMP_MSVC\n#if EIGEN_ARCH_i386_OR_x86_64\n#define EIGEN_CPUID(abcd, func, id) __cpuidex((int*)abcd, func, id)\n#endif\n#endif\n#endif\n\nnamespace internal {\n\n#ifdef EIGEN_CPUID\n\ninline bool cpuid_is_vendor(int abcd[4], const int vendor[3]) {\n  return abcd[1] == vendor[0] &amp;&amp; abcd[3] == vendor[1] &amp;&amp; abcd[2] == vendor[2];\n}\n\ninline void queryCacheSizes_intel_direct(int&amp; l1, int&amp; l2, int&amp; l3) {\n  int abcd[4];\n  l1 = l2 = l3 = 0;\n  int cache_id = 0;\n  int cache_type = 0;\n  do {\n    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;\n    EIGEN_CPUID(abcd, 0x4, cache_id);\n    cache_type = (abcd[0] &amp; 0x0F) &gt;&gt; 0;\n    if (cache_type == 1 || cache_type == 3)  // data or unified cache\n    {\n      int cache_level = (abcd[0] &amp; 0xE0) &gt;&gt; 5;        // A[7:5]\n      int ways = (abcd[1] &amp; 0xFFC00000) &gt;&gt; 22;        // B[31:22]\n      int partitions = (abcd[1] &amp; 0x003FF000) &gt;&gt; 12;  // B[21:12]\n      int line_size = (abcd[1] &amp; 0x00000FFF) &gt;&gt; 0;    // B[11:0]\n      int sets = (abcd[2]);                           // C[31:0]\n\n      int cache_size = (ways + 1) * (partitions + 1) * (line_size + 1) * (sets + 1);\n\n      switch (cache_level) {\n        case 1:\n          l1 = cache_size;\n          break;\n        case 2:\n          l2 = cache_size;\n          break;\n        case 3:\n          l3 = cache_size;\n          break;\n        default:\n          break;\n      }\n    }\n    cache_id++;\n  } while (cache_type &gt; 0 &amp;&amp; cache_id &lt; 16);\n}\n\ninline void queryCacheSizes_intel_codes(int&amp; l1, int&amp; l2, int&amp; l3) {\n  int abcd[4];\n  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;\n  l1 = l2 = l3 = 0;\n  EIGEN_CPUID(abcd, 0x00000002, 0);\n  unsigned char* bytes = reinterpret_cast&lt;unsigned char*&gt;(abcd) + 2;\n  bool check_for_p2_core2 = false;\n  for (int i = 0; i &lt; 14; ++i) {\n    switch (bytes[i]) {\n      case 0x0A:\n        l1 = 8;\n        break;  // 0Ah   data L1 cache, 8 KB, 2 ways, 32 byte lines\n      case 0x0C:\n        l1 = 16;\n        break;  // 0Ch   data L1 cache, 16 KB, 4 ways, 32 byte lines\n      case 0x0E:\n        l1 = 24;\n        break;  // 0Eh   data L1 cache, 24 KB, 6 ways, 64 byte lines\n      case 0x10:\n        l1 = 16;\n        break;  // 10h   data L1 cache, 16 KB, 4 ways, 32 byte lines (IA-64)\n      case 0x15:\n        l1 = 16;\n        break;  // 15h   code L1 cache, 16 KB, 4 ways, 32 byte lines (IA-64)\n      case 0x2C:\n        l1 = 32;\n        break;  // 2Ch   data L1 cache, 32 KB, 8 ways, 64 byte lines\n      case 0x30:\n        l1 = 32;\n        break;  // 30h   code L1 cache, 32 KB, 8 ways, 64 byte lines\n      case 0x60:\n        l1 = 16;\n        break;  // 60h   data L1 cache, 16 KB, 8 ways, 64 byte lines, sectored\n      case 0x66:\n        l1 = 8;\n        break;  // 66h   data L1 cache, 8 KB, 4 ways, 64 byte lines, sectored\n      case 0x67:\n        l1 = 16;\n        break;  // 67h   data L1 cache, 16 KB, 4 ways, 64 byte lines, sectored\n      case 0x68:\n        l1 = 32;\n        break;  // 68h   data L1 cache, 32 KB, 4 ways, 64 byte lines, sectored\n      case 0x1A:\n        l2 = 96;\n        break;  // code and data L2 cache, 96 KB, 6 ways, 64 byte lines (IA-64)\n      case 0x22:\n        l3 = 512;\n        break;  // code and data L3 cache, 512 KB, 4 ways (!), 64 byte lines, dual-sectored\n      case 0x23:\n        l3 = 1024;\n        break;  // code and data L3 cache, 1024 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x25:\n        l3 = 2048;\n        break;  // code and data L3 cache, 2048 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x29:\n        l3 = 4096;\n        break;  // code and data L3 cache, 4096 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x39:\n        l2 = 128;\n        break;  // code and data L2 cache, 128 KB, 4 ways, 64 byte lines, sectored\n      case 0x3A:\n        l2 = 192;\n        break;  // code and data L2 cache, 192 KB, 6 ways, 64 byte lines, sectored\n      case 0x3B:\n        l2 = 128;\n        break;  // code and data L2 cache, 128 KB, 2 ways, 64 byte lines, sectored\n      case 0x3C:\n        l2 = 256;\n        break;  // code and data L2 cache, 256 KB, 4 ways, 64 byte lines, sectored\n      case 0x3D:\n        l2 = 384;\n        break;  // code and data L2 cache, 384 KB, 6 ways, 64 byte lines, sectored\n      case 0x3E:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 4 ways, 64 byte lines, sectored\n      case 0x40:\n        l2 = 0;\n        break;  // no integrated L2 cache (P6 core) or L3 cache (P4 core)\n      case 0x41:\n        l2 = 128;\n        break;  // code and data L2 cache, 128 KB, 4 ways, 32 byte lines\n      case 0x42:\n        l2 = 256;\n        break;  // code and data L2 cache, 256 KB, 4 ways, 32 byte lines\n      case 0x43:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 4 ways, 32 byte lines\n      case 0x44:\n        l2 = 1024;\n        break;  // code and data L2 cache, 1024 KB, 4 ways, 32 byte lines\n      case 0x45:\n        l2 = 2048;\n        break;  // code and data L2 cache, 2048 KB, 4 ways, 32 byte lines\n      case 0x46:\n        l3 = 4096;\n        break;  // code and data L3 cache, 4096 KB, 4 ways, 64 byte lines\n      case 0x47:\n        l3 = 8192;\n        break;  // code and data L3 cache, 8192 KB, 8 ways, 64 byte lines\n      case 0x48:\n        l2 = 3072;\n        break;  // code and data L2 cache, 3072 KB, 12 ways, 64 byte lines\n      case 0x49:\n        if (l2 != 0)\n          l3 = 4096;\n        else {\n          check_for_p2_core2 = true;\n          l3 = l2 = 4096;\n        }\n        break;  // code and data L3 cache, 4096 KB, 16 ways, 64 byte lines (P4) or L2 for core2\n      case 0x4A:\n        l3 = 6144;\n        break;  // code and data L3 cache, 6144 KB, 12 ways, 64 byte lines\n      case 0x4B:\n        l3 = 8192;\n        break;  // code and data L3 cache, 8192 KB, 16 ways, 64 byte lines\n      case 0x4C:\n        l3 = 12288;\n        break;  // code and data L3 cache, 12288 KB, 12 ways, 64 byte lines\n      case 0x4D:\n        l3 = 16384;\n        break;  // code and data L3 cache, 16384 KB, 16 ways, 64 byte lines\n      case 0x4E:\n        l2 = 6144;\n        break;  // code and data L2 cache, 6144 KB, 24 ways, 64 byte lines\n      case 0x78:\n        l2 = 1024;\n        break;  // code and data L2 cache, 1024 KB, 4 ways, 64 byte lines\n      case 0x79:\n        l2 = 128;\n        break;  // code and data L2 cache, 128 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x7A:\n        l2 = 256;\n        break;  // code and data L2 cache, 256 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x7B:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x7C:\n        l2 = 1024;\n        break;  // code and data L2 cache, 1024 KB, 8 ways, 64 byte lines, dual-sectored\n      case 0x7D:\n        l2 = 2048;\n        break;  // code and data L2 cache, 2048 KB, 8 ways, 64 byte lines\n      case 0x7E:\n        l2 = 256;\n        break;  // code and data L2 cache, 256 KB, 8 ways, 128 byte lines, sect. (IA-64)\n      case 0x7F:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 2 ways, 64 byte lines\n      case 0x80:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 8 ways, 64 byte lines\n      case 0x81:\n        l2 = 128;\n        break;  // code and data L2 cache, 128 KB, 8 ways, 32 byte lines\n      case 0x82:\n        l2 = 256;\n        break;  // code and data L2 cache, 256 KB, 8 ways, 32 byte lines\n      case 0x83:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 8 ways, 32 byte lines\n      case 0x84:\n        l2 = 1024;\n        break;  // code and data L2 cache, 1024 KB, 8 ways, 32 byte lines\n      case 0x85:\n        l2 = 2048;\n        break;  // code and data L2 cache, 2048 KB, 8 ways, 32 byte lines\n      case 0x86:\n        l2 = 512;\n        break;  // code and data L2 cache, 512 KB, 4 ways, 64 byte lines\n      case 0x87:\n        l2 = 1024;\n        break;  // code and data L2 cache, 1024 KB, 8 ways, 64 byte lines\n      case 0x88:\n        l3 = 2048;\n        break;  // code and data L3 cache, 2048 KB, 4 ways, 64 byte lines (IA-64)\n      case 0x89:\n        l3 = 4096;\n        break;  // code and data L3 cache, 4096 KB, 4 ways, 64 byte lines (IA-64)\n      case 0x8A:\n        l3 = 8192;\n        break;  // code and data L3 cache, 8192 KB, 4 ways, 64 byte lines (IA-64)\n      case 0x8D:\n        l3 = 3072;\n        break;  // code and data L3 cache, 3072 KB, 12 ways, 128 byte lines (IA-64)\n\n      default:\n        break;\n    }\n  }\n  if (check_for_p2_core2 &amp;&amp; l2 == l3) l3 = 0;\n  l1 *= 1024;\n  l2 *= 1024;\n  l3 *= 1024;\n}\n\ninline void queryCacheSizes_intel(int&amp; l1, int&amp; l2, int&amp; l3, int max_std_funcs) {\n  if (max_std_funcs &gt;= 4)\n    queryCacheSizes_intel_direct(l1, l2, l3);\n  else if (max_std_funcs &gt;= 2)\n    queryCacheSizes_intel_codes(l1, l2, l3);\n  else\n    l1 = l2 = l3 = 0;\n}\n\ninline void queryCacheSizes_amd(int&amp; l1, int&amp; l2, int&amp; l3) {\n  int abcd[4];\n  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;\n\n  // First query the max supported function.\n  EIGEN_CPUID(abcd, 0x80000000, 0);\n  if (static_cast&lt;numext::uint32_t&gt;(abcd[0]) &gt;= static_cast&lt;numext::uint32_t&gt;(0x80000006)) {\n    EIGEN_CPUID(abcd, 0x80000005, 0);\n    l1 = (abcd[2] &gt;&gt; 24) * 1024;  // C[31:24] = L1 size in KB\n    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;\n    EIGEN_CPUID(abcd, 0x80000006, 0);\n    l2 = (abcd[2] &gt;&gt; 16) * 1024;                      // C[31;16] = l2 cache size in KB\n    l3 = ((abcd[3] &amp; 0xFFFC000) &gt;&gt; 18) * 512 * 1024;  // D[31;18] = l3 cache size in 512KB\n  } else {\n    l1 = l2 = l3 = 0;\n  }\n}\n#endif\n\n/** \\internal\n * Queries and returns the cache sizes in Bytes of the L1, L2, and L3 data caches respectively */\ninline void queryCacheSizes(int&amp; l1, int&amp; l2, int&amp; l3) {\n#ifdef EIGEN_CPUID\n  int abcd[4];\n  const int GenuineIntel[] = {0x756e6547, 0x49656e69, 0x6c65746e};\n  const int AuthenticAMD[] = {0x68747541, 0x69746e65, 0x444d4163};\n  const int AMDisbetter_[] = {0x69444d41, 0x74656273, 0x21726574};  // &quot;AMDisbetter!&quot;\n\n  // identify the CPU vendor\n  EIGEN_CPUID(abcd, 0x0, 0);\n  int max_std_funcs = abcd[0];\n  if (cpuid_is_vendor(abcd, GenuineIntel))\n    queryCacheSizes_intel(l1, l2, l3, max_std_funcs);\n  else if (cpuid_is_vendor(abcd, AuthenticAMD) || cpuid_is_vendor(abcd, AMDisbetter_))\n    queryCacheSizes_amd(l1, l2, l3);\n  else\n    // by default let&#x27;s use Intel&#x27;s API\n    queryCacheSizes_intel(l1, l2, l3, max_std_funcs);\n\n    // here is the list of other vendors:\n    //   ||cpuid_is_vendor(abcd,&quot;VIA VIA VIA &quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;CyrixInstead&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;CentaurHauls&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;GenuineTMx86&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;TransmetaCPU&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;RiseRiseRise&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;Geode by NSC&quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;SiS SiS SiS &quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;UMC UMC UMC &quot;)\n    //   ||cpuid_is_vendor(abcd,&quot;NexGenDriven&quot;)\n#else\n  l1 = l2 = l3 = -1;\n#endif\n}\n\n/** \\internal\n * \\returns the size in Bytes of the L1 data cache */\ninline int queryL1CacheSize() {\n  int l1(-1), l2, l3;\n  queryCacheSizes(l1, l2, l3);\n  return l1;\n}\n\n/** \\internal\n * \\returns the size in Bytes of the L2 or L3 cache if this later is present */\ninline int queryTopLevelCacheSize() {\n  int l1, l2(-1), l3(-1);\n  queryCacheSizes(l1, l2, l3);\n  return (std::max)(l2, l3);\n}\n\n/** \\internal\n * This wraps C++20&#x27;s std::construct_at, using placement new instead if it is not available.\n */\n\n#if EIGEN_COMP_CXXVER &gt;= 20 &amp;&amp; defined(__cpp_lib_constexpr_dynamic_alloc) &amp;&amp; \\\n    __cpp_lib_constexpr_dynamic_alloc &gt;= 201907L\nusing std::construct_at;\n#else\ntemplate &lt;class T, class... Args&gt;\nEIGEN_DEVICE_FUNC T* construct_at(T* p, Args&amp;&amp;... args) {\n  return ::new (const_cast&lt;void*&gt;(static_cast&lt;const volatile void*&gt;(p))) T(std::forward&lt;Args&gt;(args)...);\n}\n#endif\n\n/** \\internal\n * This wraps C++17&#x27;s std::destroy_at.  If it&#x27;s not available it calls the destructor.\n * The wrapper is not a full replacement for C++20&#x27;s std::destroy_at as it cannot\n * be applied to std::array.\n */\n#if EIGEN_COMP_CXXVER &gt;= 17\nusing std::destroy_at;\n#else\ntemplate &lt;class T&gt;\nEIGEN_DEVICE_FUNC void destroy_at(T* p) {\n  p-&gt;~T();\n}\n#endif\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_MEMORY_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2015 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2006-2008 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_META_H\n#define EIGEN_META_H\n\n// IWYU pragma: private\n#include &quot;../InternalHeaderCheck.h&quot;\n\n#if defined(EIGEN_GPU_COMPILE_PHASE)\n\n#include &lt;cfloat&gt;\n\n#if defined(EIGEN_CUDA_ARCH)\n#include &lt;math_constants.h&gt;\n#endif\n\n#if defined(EIGEN_HIP_DEVICE_COMPILE)\n#include &quot;Eigen/src/Core/arch/HIP/hcc/math_constants.h&quot;\n#endif\n\n#endif\n\n// Define portable (u)int{32,64} types\n#include &lt;cstdint&gt;\n\nnamespace Eigen {\nnamespace numext {\ntypedef std::uint8_t uint8_t;\ntypedef std::int8_t int8_t;\ntypedef std::uint16_t uint16_t;\ntypedef std::int16_t int16_t;\ntypedef std::uint32_t uint32_t;\ntypedef std::int32_t int32_t;\ntypedef std::uint64_t uint64_t;\ntypedef std::int64_t int64_t;\n\ntemplate &lt;size_t Size&gt;\nstruct get_integer_by_size {\n  typedef void signed_type;\n  typedef void unsigned_type;\n};\ntemplate &lt;&gt;\nstruct get_integer_by_size&lt;1&gt; {\n  typedef int8_t signed_type;\n  typedef uint8_t unsigned_type;\n};\ntemplate &lt;&gt;\nstruct get_integer_by_size&lt;2&gt; {\n  typedef int16_t signed_type;\n  typedef uint16_t unsigned_type;\n};\ntemplate &lt;&gt;\nstruct get_integer_by_size&lt;4&gt; {\n  typedef int32_t signed_type;\n  typedef uint32_t unsigned_type;\n};\ntemplate &lt;&gt;\nstruct get_integer_by_size&lt;8&gt; {\n  typedef int64_t signed_type;\n  typedef uint64_t unsigned_type;\n};\n}  // namespace numext\n}  // namespace Eigen\n\nnamespace Eigen {\n\ntypedef EIGEN_DEFAULT_DENSE_INDEX_TYPE DenseIndex;\n\n/**\n * \\brief The Index type as used for the API.\n * \\details To change this, \\c \\#define the preprocessor symbol \\c EIGEN_DEFAULT_DENSE_INDEX_TYPE.\n * \\sa \\blank \\ref TopicPreprocessorDirectives, StorageIndex.\n */\ntypedef EIGEN_DEFAULT_DENSE_INDEX_TYPE Index;\n\nnamespace internal {\n\n/** \\internal\n * \\file Meta.h\n * This file contains generic metaprogramming classes which are not specifically related to Eigen.\n * \\note In case you wonder, yes we&#x27;re aware that Boost already provides all these features,\n * we however don&#x27;t want to add a dependency to Boost.\n */\n\nusing std::false_type;\nusing std::true_type;\n\ntemplate &lt;bool Condition&gt;\nstruct bool_constant;\n\ntemplate &lt;&gt;\nstruct bool_constant&lt;true&gt; : true_type {};\n\ntemplate &lt;&gt;\nstruct bool_constant&lt;false&gt; : false_type {};\n\n// Third-party libraries rely on these.\nusing std::conditional;\nusing std::remove_const;\nusing std::remove_pointer;\nusing std::remove_reference;\n\ntemplate &lt;typename T&gt;\nstruct remove_all {\n  typedef T type;\n};\ntemplate &lt;typename T&gt;\nstruct remove_all&lt;const T&gt; {\n  typedef typename remove_all&lt;T&gt;::type type;\n};\ntemplate &lt;typename T&gt;\nstruct remove_all&lt;T const&amp;&gt; {\n  typedef typename remove_all&lt;T&gt;::type type;\n};\ntemplate &lt;typename T&gt;\nstruct remove_all&lt;T&amp;&gt; {\n  typedef typename remove_all&lt;T&gt;::type type;\n};\ntemplate &lt;typename T&gt;\nstruct remove_all&lt;T const*&gt; {\n  typedef typename remove_all&lt;T&gt;::type type;\n};\ntemplate &lt;typename T&gt;\nstruct remove_all&lt;T*&gt; {\n  typedef typename remove_all&lt;T&gt;::type type;\n};\n\ntemplate &lt;typename T&gt;\nusing remove_all_t = typename remove_all&lt;T&gt;::type;\n\ntemplate &lt;typename T&gt;\nstruct is_arithmetic {\n  enum { value = false };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;float&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;double&gt; {\n  enum { value = true };\n};\n// GPU devices treat `long double` as `double`.\n#ifndef EIGEN_GPU_COMPILE_PHASE\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;long double&gt; {\n  enum { value = true };\n};\n#endif\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;bool&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;char&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;signed char&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;unsigned char&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;signed short&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;unsigned short&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;signed int&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;unsigned int&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;signed long&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;unsigned long&gt; {\n  enum { value = true };\n};\n\ntemplate &lt;typename T, typename U&gt;\nstruct is_same {\n  enum { value = 0 };\n};\ntemplate &lt;typename T&gt;\nstruct is_same&lt;T, T&gt; {\n  enum { value = 1 };\n};\n\ntemplate &lt;class T&gt;\nstruct is_void : is_same&lt;void, std::remove_const_t&lt;T&gt;&gt; {};\n\n/** \\internal\n * Implementation of std::void_t for SFINAE.\n *\n * Pre C++17:\n * Custom implementation.\n *\n * Post C++17: Uses std::void_t\n */\n#if EIGEN_COMP_CXXVER &gt;= 17 &amp;&amp; defined(__cpp_lib_void_t) &amp;&amp; __cpp_lib_void_t &gt;= 201411L\nusing std::void_t;\n#else\ntemplate &lt;typename...&gt;\nusing void_t = void;\n#endif\n\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;signed long long&gt; {\n  enum { value = true };\n};\ntemplate &lt;&gt;\nstruct is_arithmetic&lt;unsigned long long&gt; {\n  enum { value = true };\n};\nusing std::is_integral;\n\nusing std::make_unsigned;\n\ntemplate &lt;typename T&gt;\nstruct is_const {\n  enum { value = 0 };\n};\ntemplate &lt;typename T&gt;\nstruct is_const&lt;T const&gt; {\n  enum { value = 1 };\n};\n\ntemplate &lt;typename T&gt;\nstruct add_const_on_value_type {\n  typedef const T type;\n};\ntemplate &lt;typename T&gt;\nstruct add_const_on_value_type&lt;T&amp;&gt; {\n  typedef T const&amp; type;\n};\ntemplate &lt;typename T&gt;\nstruct add_const_on_value_type&lt;T*&gt; {\n  typedef T const* type;\n};\ntemplate &lt;typename T&gt;\nstruct add_const_on_value_type&lt;T* const&gt; {\n  typedef T const* const type;\n};\ntemplate &lt;typename T&gt;\nstruct add_const_on_value_type&lt;T const* const&gt; {\n  typedef T const* const type;\n};\n\ntemplate &lt;typename T&gt;\nusing add_const_on_value_type_t = typename add_const_on_value_type&lt;T&gt;::type;\n\nusing std::is_convertible;\n\n/** \\internal\n * A base class do disable default copy ctor and copy assignment operator.\n */\nclass noncopyable {\n  EIGEN_DEVICE_FUNC noncopyable(const noncopyable&amp;);\n  EIGEN_DEVICE_FUNC const noncopyable&amp; operator=(const noncopyable&amp;);\n\n protected:\n  EIGEN_DEVICE_FUNC noncopyable() {}\n  EIGEN_DEVICE_FUNC ~noncopyable() {}\n};\n\n/** \\internal\n * Provides access to the number of elements in the object of as a compile-time constant expression.\n * It &quot;returns&quot; Eigen::Dynamic if the size cannot be resolved at compile-time (default).\n *\n * Similar to std::tuple_size, but more general.\n *\n * It currently supports:\n *  - any types T defining T::SizeAtCompileTime\n *  - plain C arrays as T[N]\n *  - std::array (c++11)\n *  - some internal types such as SingleRange and AllRange\n *\n * The second template parameter eases SFINAE-based specializations.\n */\ntemplate &lt;typename T, typename EnableIf = void&gt;\nstruct array_size {\n  static constexpr Index value = Dynamic;\n};\n\ntemplate &lt;typename T&gt;\nstruct array_size&lt;T, std::enable_if_t&lt;((T::SizeAtCompileTime &amp; 0) == 0)&gt;&gt; {\n  static constexpr Index value = T::SizeAtCompileTime;\n};\n\ntemplate &lt;typename T, int N&gt;\nstruct array_size&lt;const T (&amp;)[N]&gt; {\n  static constexpr Index value = N;\n};\ntemplate &lt;typename T, int N&gt;\nstruct array_size&lt;T (&amp;)[N]&gt; {\n  static constexpr Index value = N;\n};\n\ntemplate &lt;typename T, std::size_t N&gt;\nstruct array_size&lt;const std::array&lt;T, N&gt;&gt; {\n  static constexpr Index value = N;\n};\ntemplate &lt;typename T, std::size_t N&gt;\nstruct array_size&lt;std::array&lt;T, N&gt;&gt; {\n  static constexpr Index value = N;\n};\n\n/** \\internal\n * Analogue of the std::ssize free function.\n * It returns the signed size of the container or view \\a x of type \\c T\n *\n * It currently supports:\n *  - any types T defining a member T::size() const\n *  - plain C arrays as T[N]\n *\n * For C++20, this function just forwards to `std::ssize`, or any ADL discoverable `ssize` function.\n */\n#if EIGEN_COMP_CXXVER &gt;= 20 &amp;&amp; defined(__cpp_lib_ssize) &amp;&amp; __cpp_lib_ssize &gt;= 201902L\n\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR auto index_list_size(T&amp;&amp; x) {\n  using std::ssize;\n  return ssize(std::forward&lt;T&gt;(x));\n}\n\n#else\n\ntemplate &lt;typename T&gt;\nEIGEN_CONSTEXPR auto index_list_size(const T&amp; x) {\n  using R = std::common_type_t&lt;std::ptrdiff_t, std::make_signed_t&lt;decltype(x.size())&gt;&gt;;\n  return static_cast&lt;R&gt;(x.size());\n}\n\ntemplate &lt;typename T, std::ptrdiff_t N&gt;\nEIGEN_CONSTEXPR std::ptrdiff_t index_list_size(const T (&amp;)[N]) {\n  return N;\n}\n#endif\n\n/** \\internal\n * Convenient struct to get the result type of a nullary, unary, binary, or\n * ternary functor.\n *\n * Pre C++17:\n * This uses std::result_of. However, note the `type` member removes\n * const and converts references/pointers to their corresponding value type.\n *\n * Post C++17: Uses std::invoke_result\n */\n#if EIGEN_HAS_STD_INVOKE_RESULT\ntemplate &lt;typename T&gt;\nstruct result_of;\n\ntemplate &lt;typename F, typename... ArgTypes&gt;\nstruct result_of&lt;F(ArgTypes...)&gt; {\n  typedef typename std::invoke_result&lt;F, ArgTypes...&gt;::type type1;\n  typedef remove_all_t&lt;type1&gt; type;\n};\n\ntemplate &lt;typename F, typename... ArgTypes&gt;\nstruct invoke_result {\n  typedef typename std::invoke_result&lt;F, ArgTypes...&gt;::type type1;\n  typedef remove_all_t&lt;type1&gt; type;\n};\n#else\ntemplate &lt;typename T&gt;\nstruct result_of {\n  typedef typename std::result_of&lt;T&gt;::type type1;\n  typedef remove_all_t&lt;type1&gt; type;\n};\n\ntemplate &lt;typename F, typename... ArgTypes&gt;\nstruct invoke_result {\n  typedef typename result_of&lt;F(ArgTypes...)&gt;::type type1;\n  typedef remove_all_t&lt;type1&gt; type;\n};\n#endif\n\n// Reduces a sequence of bools to true if all are true, false otherwise.\ntemplate &lt;bool... values&gt;\nusing reduce_all =\n    std::is_same&lt;std::integer_sequence&lt;bool, values..., true&gt;, std::integer_sequence&lt;bool, true, values...&gt;&gt;;\n\n// Reduces a sequence of bools to true if any are true, false if all false.\ntemplate &lt;bool... values&gt;\nusing reduce_any = std::integral_constant&lt;bool, !std::is_same&lt;std::integer_sequence&lt;bool, values..., false&gt;,\n                                                              std::integer_sequence&lt;bool, false, values...&gt;&gt;::value&gt;;\n\nstruct meta_yes {\n  char a[1];\n};\nstruct meta_no {\n  char a[2];\n};\n\n// Check whether T::ReturnType does exist\ntemplate &lt;typename T&gt;\nstruct has_ReturnType {\n  template &lt;typename C&gt;\n  static meta_yes testFunctor(C const*, typename C::ReturnType const* = 0);\n  template &lt;typename C&gt;\n  static meta_no testFunctor(...);\n\n  enum { value = sizeof(testFunctor&lt;T&gt;(static_cast&lt;T*&gt;(0))) == sizeof(meta_yes) };\n};\n\ntemplate &lt;typename T&gt;\nconst T* return_ptr();\n\ntemplate &lt;typename T, typename IndexType = Index&gt;\nstruct has_nullary_operator {\n  template &lt;typename C&gt;\n  static meta_yes testFunctor(C const*, std::enable_if_t&lt;(sizeof(return_ptr&lt;C&gt;()-&gt;operator()()) &gt; 0)&gt;* = 0);\n  static meta_no testFunctor(...);\n\n  enum { value = sizeof(testFunctor(static_cast&lt;T*&gt;(0))) == sizeof(meta_yes) };\n};\n\ntemplate &lt;typename T, typename IndexType = Index&gt;\nstruct has_unary_operator {\n  template &lt;typename C&gt;\n  static meta_yes testFunctor(C const*, std::enable_if_t&lt;(sizeof(return_ptr&lt;C&gt;()-&gt;operator()(IndexType(0))) &gt; 0)&gt;* = 0);\n  static meta_no testFunctor(...);\n\n  enum { value = sizeof(testFunctor(static_cast&lt;T*&gt;(0))) == sizeof(meta_yes) };\n};\n\ntemplate &lt;typename T, typename IndexType = Index&gt;\nstruct has_binary_operator {\n  template &lt;typename C&gt;\n  static meta_yes testFunctor(\n      C const*, std::enable_if_t&lt;(sizeof(return_ptr&lt;C&gt;()-&gt;operator()(IndexType(0), IndexType(0))) &gt; 0)&gt;* = 0);\n  static meta_no testFunctor(...);\n\n  enum { value = sizeof(testFunctor(static_cast&lt;T*&gt;(0))) == sizeof(meta_yes) };\n};\n\n/** \\internal In short, it computes int(sqrt(\\a Y)) with \\a Y an integer.\n * Usage example: \\code meta_sqrt&lt;1023&gt;::ret \\endcode\n */\ntemplate &lt;int Y, int InfX = 0, int SupX = ((Y == 1) ? 1 : Y / 2),\n          bool Done = ((SupX - InfX) &lt;= 1 || ((SupX * SupX &lt;= Y) &amp;&amp; ((SupX + 1) * (SupX + 1) &gt; Y)))&gt;\nclass meta_sqrt {\n  enum {\n    MidX = (InfX + SupX) / 2,\n    TakeInf = MidX * MidX &gt; Y ? 1 : 0,\n    NewInf = int(TakeInf) ? InfX : int(MidX),\n    NewSup = int(TakeInf) ? int(MidX) : SupX\n  };\n\n public:\n  enum { ret = meta_sqrt&lt;Y, NewInf, NewSup&gt;::ret };\n};\n\ntemplate &lt;int Y, int InfX, int SupX&gt;\nclass meta_sqrt&lt;Y, InfX, SupX, true&gt; {\n public:\n  enum { ret = (SupX * SupX &lt;= Y) ? SupX : InfX };\n};\n\n/** \\internal Computes the least common multiple of two positive integer A and B\n * at compile-time.\n */\ntemplate &lt;int A, int B, int K = 1, bool Done = ((A * K) % B) == 0, bool Big = (A &gt;= B)&gt;\nstruct meta_least_common_multiple {\n  enum { ret = meta_least_common_multiple&lt;A, B, K + 1&gt;::ret };\n};\ntemplate &lt;int A, int B, int K, bool Done&gt;\nstruct meta_least_common_multiple&lt;A, B, K, Done, false&gt; {\n  enum { ret = meta_least_common_multiple&lt;B, A, K&gt;::ret };\n};\ntemplate &lt;int A, int B, int K&gt;\nstruct meta_least_common_multiple&lt;A, B, K, true, true&gt; {\n  enum { ret = A * K };\n};\n\n/** \\internal determines whether the product of two numeric types is allowed and what the return type is */\ntemplate &lt;typename T, typename U&gt;\nstruct scalar_product_traits {\n  enum { Defined = 0 };\n};\n\n// FIXME quick workaround around current limitation of result_of\n// template&lt;typename Scalar, typename ArgType0, typename ArgType1&gt;\n// struct result_of&lt;scalar_product_op&lt;Scalar&gt;(ArgType0,ArgType1)&gt; {\n// typedef typename scalar_product_traits&lt;remove_all_t&lt;ArgType0&gt;, remove_all_t&lt;ArgType1&gt;&gt;::ReturnType type;\n// };\n\n/** \\internal Obtains a POD type suitable to use as storage for an object of a size\n * of at most Len bytes, aligned as specified by \\c Align.\n */\ntemplate &lt;unsigned Len, unsigned Align&gt;\nstruct aligned_storage {\n  struct type {\n    EIGEN_ALIGN_TO_BOUNDARY(Align) unsigned char data[Len];\n  };\n};\n\n}  // end namespace internal\n\ntemplate &lt;typename T&gt;\nstruct NumTraits;\n\nnamespace numext {\n\n#if defined(EIGEN_GPU_COMPILE_PHASE)\ntemplate &lt;typename T&gt;\nEIGEN_DEVICE_FUNC void swap(T&amp; a, T&amp; b) {\n  T tmp = b;\n  b = a;\n  a = tmp;\n}\n#else\ntemplate &lt;typename T&gt;\nEIGEN_STRONG_INLINE void swap(T&amp; a, T&amp; b) {\n  std::swap(a, b);\n}\n#endif\n\nusing std::numeric_limits;\n\n// Handle integer comparisons of different signedness.\ntemplate &lt;typename X, typename Y, bool XIsInteger = NumTraits&lt;X&gt;::IsInteger, bool XIsSigned = NumTraits&lt;X&gt;::IsSigned,\n          bool YIsInteger = NumTraits&lt;Y&gt;::IsInteger, bool YIsSigned = NumTraits&lt;Y&gt;::IsSigned&gt;\nstruct equal_strict_impl {\n  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X&amp; x, const Y&amp; y) { return x == y; }\n};\ntemplate &lt;typename X, typename Y&gt;\nstruct equal_strict_impl&lt;X, Y, true, false, true, true&gt; {\n  // X is an unsigned integer\n  // Y is a signed integer\n  // if Y is non-negative, it may be represented exactly as its unsigned counterpart.\n  using UnsignedY = typename internal::make_unsigned&lt;Y&gt;::type;\n  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X&amp; x, const Y&amp; y) {\n    return y &lt; Y(0) ? false : (x == static_cast&lt;UnsignedY&gt;(y));\n  }\n};\ntemplate &lt;typename X, typename Y&gt;\nstruct equal_strict_impl&lt;X, Y, true, true, true, false&gt; {\n  // X is a signed integer\n  // Y is an unsigned integer\n  static EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool run(const X&amp; x, const Y&amp; y) {\n    return equal_strict_impl&lt;Y, X&gt;::run(y, x);\n  }\n};\n\n// The aim of the following functions is to bypass -Wfloat-equal warnings\n// when we really want a strict equality comparison on floating points.\ntemplate &lt;typename X, typename Y&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const X&amp; x, const Y&amp; y) {\n  return equal_strict_impl&lt;X, Y&gt;::run(x, y);\n}\n\n#if !defined(EIGEN_GPU_COMPILE_PHASE) || (!defined(EIGEN_CUDA_ARCH) &amp;&amp; defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const float&amp; x, const float&amp; y) {\n  return std::equal_to&lt;float&gt;()(x, y);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool equal_strict(const double&amp; x, const double&amp; y) {\n  return std::equal_to&lt;double&gt;()(x, y);\n}\n#endif\n\n/**\n * \\internal Performs an exact comparison of x to zero, e.g. to decide whether a term can be ignored.\n * Use this to to bypass -Wfloat-equal warnings when exact zero is what needs to be tested.\n */\ntemplate &lt;typename X&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool is_exactly_zero(const X&amp; x) {\n  return equal_strict(x, typename NumTraits&lt;X&gt;::Literal{0});\n}\n\n/**\n * \\internal Performs an exact comparison of x to one, e.g. to decide whether a factor needs to be multiplied.\n * Use this to to bypass -Wfloat-equal warnings when exact one is what needs to be tested.\n */\ntemplate &lt;typename X&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool is_exactly_one(const X&amp; x) {\n  return equal_strict(x, typename NumTraits&lt;X&gt;::Literal{1});\n}\n\ntemplate &lt;typename X, typename Y&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const X&amp; x, const Y&amp; y) {\n  return !equal_strict_impl&lt;X, Y&gt;::run(x, y);\n}\n\n#if !defined(EIGEN_GPU_COMPILE_PHASE) || (!defined(EIGEN_CUDA_ARCH) &amp;&amp; defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const float&amp; x, const float&amp; y) {\n  return std::not_equal_to&lt;float&gt;()(x, y);\n}\n\ntemplate &lt;&gt;\nEIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool not_equal_strict(const double&amp; x, const double&amp; y) {\n  return std::not_equal_to&lt;double&gt;()(x, y);\n}\n#endif\n\n}  // end namespace numext\n\nnamespace internal {\n\ntemplate &lt;typename Scalar&gt;\nstruct is_identically_zero_impl {\n  static inline bool run(const Scalar&amp; s) { return numext::is_exactly_zero(s); }\n};\n\ntemplate &lt;typename Scalar&gt;\nEIGEN_STRONG_INLINE bool is_identically_zero(const Scalar&amp; s) {\n  return is_identically_zero_impl&lt;Scalar&gt;::run(s);\n}\n\n/// \\internal Returns true if its argument is of integer or enum type.\n/// FIXME this has the same purpose as `is_valid_index_type` in XprHelper.h\ntemplate &lt;typename A&gt;\nconstexpr bool is_int_or_enum_v = std::is_enum&lt;A&gt;::value || std::is_integral&lt;A&gt;::value;\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr void plain_enum_asserts(A, B) {\n  static_assert(is_int_or_enum_v&lt;A&gt;, &quot;Argument a must be an integer or enum&quot;);\n  static_assert(is_int_or_enum_v&lt;B&gt;, &quot;Argument b must be an integer or enum&quot;);\n}\n\n/// \\internal Gets the minimum of two values which may be integers or enums\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int plain_enum_min(A a, B b) {\n  plain_enum_asserts(a, b);\n  return ((int)a &lt;= (int)b) ? (int)a : (int)b;\n}\n\n/// \\internal Gets the maximum of two values which may be integers or enums\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int plain_enum_max(A a, B b) {\n  plain_enum_asserts(a, b);\n  return ((int)a &gt;= (int)b) ? (int)a : (int)b;\n}\n\n/**\n * \\internal\n *  `min_size_prefer_dynamic` gives the min between compile-time sizes. 0 has absolute priority, followed by 1,\n *  followed by Dynamic, followed by other finite values. The reason for giving Dynamic the priority over\n *  finite values is that min(3, Dynamic) should be Dynamic, since that could be anything between 0 and 3.\n */\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int min_size_prefer_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == 0 || (int)b == 0) return 0;\n  if ((int)a == 1 || (int)b == 1) return 1;\n  if ((int)a == Dynamic || (int)b == Dynamic) return Dynamic;\n  return plain_enum_min(a, b);\n}\n\n/**\n * \\internal\n *  min_size_prefer_fixed is a variant of `min_size_prefer_dynamic` comparing MaxSizes. The difference is that finite\n * values now have priority over Dynamic, so that min(3, Dynamic) gives 3. Indeed, whatever the actual value is (between\n * 0 and 3), it is not more than 3.\n */\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int min_size_prefer_fixed(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == 0 || (int)b == 0) return 0;\n  if ((int)a == 1 || (int)b == 1) return 1;\n  if ((int)a == Dynamic &amp;&amp; (int)b == Dynamic) return Dynamic;\n  if ((int)a == Dynamic) return (int)b;\n  if ((int)b == Dynamic) return (int)a;\n  return plain_enum_min(a, b);\n}\n\n/// \\internal see `min_size_prefer_fixed`. No need for a separate variant for MaxSizes here.\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int max_size_prefer_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return Dynamic;\n  return plain_enum_max(a, b);\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr int size_prefer_fixed(A a, B b) {\n  plain_enum_asserts(a, b);\n  return int(a) == Dynamic ? int(b) : int(a);\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr bool enum_eq_not_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return false;\n  return (int)a == (int)b;\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr bool enum_lt_not_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return false;\n  return (int)a &lt; (int)b;\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr bool enum_le_not_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return false;\n  return (int)a &lt;= (int)b;\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr bool enum_gt_not_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return false;\n  return (int)a &gt; (int)b;\n}\n\ntemplate &lt;typename A, typename B&gt;\ninline constexpr bool enum_ge_not_dynamic(A a, B b) {\n  plain_enum_asserts(a, b);\n  if ((int)a == Dynamic || (int)b == Dynamic) return false;\n  return (int)a &gt;= (int)b;\n}\n\n/// \\internal Calculate logical XOR at compile time\ninline constexpr bool logical_xor(bool a, bool b) { return a != b; }\n\n/// \\internal Calculate logical IMPLIES at compile time\ninline constexpr bool check_implication(bool a, bool b) { return !a || b; }\n\n/// \\internal Provide fallback for std::is_constant_evaluated for pre-C++20.\n#if EIGEN_COMP_CXXVER &gt;= 20 &amp;&amp; defined(__cpp_lib_is_constant_evaluated) &amp;&amp; __cpp_lib_is_constant_evaluated &gt;= 201811L\nusing std::is_constant_evaluated;\n#else\nconstexpr bool is_constant_evaluated() { return false; }\n#endif\n\ntemplate &lt;typename Scalar&gt;\nusing make_complex_t = std::conditional_t&lt;NumTraits&lt;Scalar&gt;::IsComplex, Scalar, std::complex&lt;Scalar&gt;&gt;;\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_META_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2017 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_SYMBOLIC_INDEX_H\n#define EIGEN_SYMBOLIC_INDEX_H\n\n// IWYU pragma: private\n#include &quot;../InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\namespace Eigen::symbolic\n * \\ingroup Core_Module\n *\n * This namespace defines a set of classes and functions to build and evaluate symbolic expressions of scalar type\n * Index. Here is a simple example:\n *\n * \\code\n * // First step, defines symbols:\n * struct x_tag {};  static const symbolic::SymbolExpr&lt;x_tag&gt; x;\n * struct y_tag {};  static const symbolic::SymbolExpr&lt;y_tag&gt; y;\n * struct z_tag {};  static const symbolic::SymbolExpr&lt;z_tag&gt; z;\n *\n * // Defines an expression:\n * auto expr = (x+3)/y+z;\n *\n * // And evaluate it: (c++14)\n * std::cout &lt;&lt; expr.eval(x=6,y=3,z=-13) &lt;&lt; &quot;\\n&quot;;\n *\n * \\endcode\n *\n * It is currently only used internally to define and manipulate the\n * Eigen::placeholders::last and Eigen::placeholders::lastp1 symbols in\n * Eigen::seq and Eigen::seqN.\n *\n */\nnamespace symbolic {\n\ntemplate &lt;typename Tag&gt;\nclass Symbol;\ntemplate &lt;typename Tag, typename Type&gt;\nclass SymbolValue;\ntemplate &lt;typename Arg0&gt;\nclass NegateExpr;\ntemplate &lt;typename Arg1, typename Arg2&gt;\nclass AddExpr;\ntemplate &lt;typename Arg1, typename Arg2&gt;\nclass ProductExpr;\ntemplate &lt;typename Arg1, typename Arg2&gt;\nclass QuotientExpr;\ntemplate &lt;typename IndexType = Index&gt;\nclass ValueExpr;\n\n/** \\class BaseExpr\n * \\ingroup Core_Module\n * Common base class of any symbolic expressions\n */\ntemplate &lt;typename Derived_&gt;\nclass BaseExpr {\n public:\n  using Derived = Derived_;\n  constexpr const Derived&amp; derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n\n  /** Evaluate the expression given the \\a values of the symbols.\n   *\n   * \\param values defines the values of the symbols, as constructed by SymbolExpr::operator= operator.\n   *\n   */\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return derived().eval_impl(values...);\n  }\n\n  /** Evaluate the expression at compile time given the \\a values of the symbols.\n   *\n   * If a value is not known at compile-time, returns Eigen::Undefined.\n   *\n   */\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return Derived::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n  }\n\n  constexpr NegateExpr&lt;Derived&gt; operator-() const { return NegateExpr&lt;Derived&gt;(derived()); }\n\n  constexpr AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt; operator+(Index b) const {\n    return AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt;(derived(), b);\n  }\n  constexpr AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt; operator-(Index a) const {\n    return AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt;(derived(), -a);\n  }\n  constexpr ProductExpr&lt;Derived, ValueExpr&lt;&gt;&gt; operator*(Index a) const {\n    return ProductExpr&lt;Derived, ValueExpr&lt;&gt;&gt;(derived(), a);\n  }\n  constexpr QuotientExpr&lt;Derived, ValueExpr&lt;&gt;&gt; operator/(Index a) const {\n    return QuotientExpr&lt;Derived, ValueExpr&lt;&gt;&gt;(derived(), a);\n  }\n\n  friend constexpr AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt; operator+(Index a, const BaseExpr&amp; b) {\n    return AddExpr&lt;Derived, ValueExpr&lt;&gt;&gt;(b.derived(), a);\n  }\n  friend constexpr AddExpr&lt;NegateExpr&lt;Derived&gt;, ValueExpr&lt;&gt;&gt; operator-(Index a, const BaseExpr&amp; b) {\n    return AddExpr&lt;NegateExpr&lt;Derived&gt;, ValueExpr&lt;&gt;&gt;(-b.derived(), a);\n  }\n  friend constexpr ProductExpr&lt;ValueExpr&lt;&gt;, Derived&gt; operator*(Index a, const BaseExpr&amp; b) {\n    return ProductExpr&lt;ValueExpr&lt;&gt;, Derived&gt;(a, b.derived());\n  }\n  friend constexpr QuotientExpr&lt;ValueExpr&lt;&gt;, Derived&gt; operator/(Index a, const BaseExpr&amp; b) {\n    return QuotientExpr&lt;ValueExpr&lt;&gt;, Derived&gt;(a, b.derived());\n  }\n\n  template &lt;int N&gt;\n  constexpr AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; operator+(internal::FixedInt&lt;N&gt;) const {\n    return AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt;(derived(), ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;());\n  }\n  template &lt;int N&gt;\n  constexpr AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;-N&gt;&gt;&gt; operator-(internal::FixedInt&lt;N&gt;) const {\n    return AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;-N&gt;&gt;&gt;(derived(), ValueExpr&lt;internal::FixedInt&lt;-N&gt;&gt;());\n  }\n  template &lt;int N&gt;\n  constexpr ProductExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; operator*(internal::FixedInt&lt;N&gt;) const {\n    return ProductExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt;(derived(), ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;());\n  }\n  template &lt;int N&gt;\n  constexpr QuotientExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; operator/(internal::FixedInt&lt;N&gt;) const {\n    return QuotientExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt;(derived(), ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;());\n  }\n\n  template &lt;int N&gt;\n  friend constexpr AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; operator+(internal::FixedInt&lt;N&gt;,\n                                                                                const BaseExpr&amp; b) {\n    return AddExpr&lt;Derived, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt;(b.derived(), ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;());\n  }\n  template &lt;int N&gt;\n  friend constexpr AddExpr&lt;NegateExpr&lt;Derived&gt;, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; operator-(internal::FixedInt&lt;N&gt;,\n                                                                                            const BaseExpr&amp; b) {\n    return AddExpr&lt;NegateExpr&lt;Derived&gt;, ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt;(-b.derived(),\n                                                                          ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;());\n  }\n  template &lt;int N&gt;\n  friend constexpr ProductExpr&lt;ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;, Derived&gt; operator*(internal::FixedInt&lt;N&gt;,\n                                                                                    const BaseExpr&amp; b) {\n    return ProductExpr&lt;ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;, Derived&gt;(ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;(), b.derived());\n  }\n  template &lt;int N&gt;\n  friend constexpr QuotientExpr&lt;ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;, Derived&gt; operator/(internal::FixedInt&lt;N&gt;,\n                                                                                     const BaseExpr&amp; b) {\n    return QuotientExpr&lt;ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;, Derived&gt;(ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;(), b.derived());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  constexpr AddExpr&lt;Derived, OtherDerived&gt; operator+(const BaseExpr&lt;OtherDerived&gt;&amp; b) const {\n    return AddExpr&lt;Derived, OtherDerived&gt;(derived(), b.derived());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  constexpr AddExpr&lt;Derived, NegateExpr&lt;OtherDerived&gt;&gt; operator-(const BaseExpr&lt;OtherDerived&gt;&amp; b) const {\n    return AddExpr&lt;Derived, NegateExpr&lt;OtherDerived&gt;&gt;(derived(), -b.derived());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  constexpr ProductExpr&lt;Derived, OtherDerived&gt; operator*(const BaseExpr&lt;OtherDerived&gt;&amp; b) const {\n    return ProductExpr&lt;Derived, OtherDerived&gt;(derived(), b.derived());\n  }\n\n  template &lt;typename OtherDerived&gt;\n  constexpr QuotientExpr&lt;Derived, OtherDerived&gt; operator/(const BaseExpr&lt;OtherDerived&gt;&amp; b) const {\n    return QuotientExpr&lt;Derived, OtherDerived&gt;(derived(), b.derived());\n  }\n};\n\ntemplate &lt;typename T&gt;\nstruct is_symbolic {\n  // BaseExpr has no conversion ctor, so we only have to check whether T can be statically cast to its base class\n  // BaseExpr&lt;T&gt;.\n  enum { value = internal::is_convertible&lt;T, BaseExpr&lt;T&gt;&gt;::value };\n};\n\n// A simple wrapper around an integral value to provide the eval method.\n// We could also use a free-function symbolic_eval...\ntemplate &lt;typename IndexType&gt;\nclass ValueExpr : BaseExpr&lt;ValueExpr&lt;IndexType&gt;&gt; {\n public:\n  constexpr ValueExpr() = default;\n  constexpr ValueExpr(IndexType val) : value_(val) {}\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr IndexType eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) const {\n    return value_;\n  }\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr IndexType eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return IndexType(Undefined);\n  }\n\n protected:\n  IndexType value_;\n};\n\n// Specialization for compile-time value,\n// It is similar to ValueExpr(N) but this version helps the compiler to generate better code.\ntemplate &lt;int N&gt;\nclass ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt; : public BaseExpr&lt;ValueExpr&lt;internal::FixedInt&lt;N&gt;&gt;&gt; {\n public:\n  constexpr ValueExpr() = default;\n  constexpr ValueExpr(internal::FixedInt&lt;N&gt;) {}\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) const {\n    return Index(N);\n  }\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return Index(N);\n  }\n};\n\n/** Represents the actual value of a symbol identified by its tag\n *\n * It is the return type of SymbolValue::operator=, and most of the time this is only way it is used.\n */\ntemplate &lt;typename Tag, typename Type&gt;\nclass SymbolValue : public BaseExpr&lt;SymbolValue&lt;Tag, Type&gt;&gt; {};\n\ntemplate &lt;typename Tag&gt;\nclass SymbolValue&lt;Tag, Index&gt; : public BaseExpr&lt;SymbolValue&lt;Tag, Index&gt;&gt; {\n public:\n  constexpr SymbolValue() = default;\n\n  /** Default constructor from the value \\a val */\n  constexpr SymbolValue(Index val) : value_(val) {}\n\n  /** \\returns the stored value of the symbol */\n  constexpr Index value() const { return value_; }\n\n  /** \\returns the stored value of the symbol at compile time, or Undefined if not known. */\n  static constexpr Index value_at_compile_time() { return Index(Undefined); }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) const {\n    return value();\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return value_at_compile_time();\n  }\n\n protected:\n  Index value_;\n};\n\ntemplate &lt;typename Tag, int N&gt;\nclass SymbolValue&lt;Tag, internal::FixedInt&lt;N&gt;&gt; : public BaseExpr&lt;SymbolValue&lt;Tag, internal::FixedInt&lt;N&gt;&gt;&gt; {\n public:\n  constexpr SymbolValue() = default;\n\n  /** Default constructor from the value \\a val */\n  constexpr SymbolValue(internal::FixedInt&lt;N&gt;) {}\n\n  /** \\returns the stored value of the symbol */\n  constexpr Index value() const { return static_cast&lt;Index&gt;(N); }\n\n  /** \\returns the stored value of the symbol at compile time, or Undefined if not known. */\n  static constexpr Index value_at_compile_time() { return static_cast&lt;Index&gt;(N); }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) const {\n    return value();\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return value_at_compile_time();\n  }\n};\n\n// Find and return a symbol value based on the tag.\ntemplate &lt;typename Tag, typename... Types&gt;\nstruct EvalSymbolValueHelper;\n\n// Empty base case, symbol not found.\ntemplate &lt;typename Tag&gt;\nstruct EvalSymbolValueHelper&lt;Tag&gt; {\n  static constexpr Index eval_impl() {\n    eigen_assert(false &amp;&amp; &quot;Symbol not found.&quot;);\n    return Index(Undefined);\n  }\n  static constexpr Index eval_at_compile_time_impl() { return Index(Undefined); }\n};\n\n// We found a symbol value matching the provided Tag!\ntemplate &lt;typename Tag, typename Type, typename... OtherTypes&gt;\nstruct EvalSymbolValueHelper&lt;Tag, SymbolValue&lt;Tag, Type&gt;, OtherTypes...&gt; {\n  static constexpr Index eval_impl(const SymbolValue&lt;Tag, Type&gt;&amp; symbol, const OtherTypes&amp;...) {\n    return symbol.value();\n  }\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tag, Type&gt;&amp; symbol, const OtherTypes&amp;...) {\n    return symbol.value_at_compile_time();\n  }\n};\n\n// No symbol value in first value, recursive search starting with next.\ntemplate &lt;typename Tag, typename T1, typename... OtherTypes&gt;\nstruct EvalSymbolValueHelper&lt;Tag, T1, OtherTypes...&gt; {\n  static constexpr Index eval_impl(const T1&amp;, const OtherTypes&amp;... values) {\n    return EvalSymbolValueHelper&lt;Tag, OtherTypes...&gt;::eval_impl(values...);\n  }\n  static constexpr Index eval_at_compile_time_impl(const T1&amp;, const OtherTypes&amp;...) {\n    return EvalSymbolValueHelper&lt;Tag, OtherTypes...&gt;::eval_at_compile_time_impl(OtherTypes{}...);\n  }\n};\n\n/** Expression of a symbol uniquely identified by the template parameter type \\c tag */\ntemplate &lt;typename tag&gt;\nclass SymbolExpr : public BaseExpr&lt;SymbolExpr&lt;tag&gt;&gt; {\n public:\n  /** Alias to the template parameter \\c tag */\n  typedef tag Tag;\n\n  constexpr SymbolExpr() = default;\n\n  /** Associate the value \\a val to the given symbol \\c *this, uniquely identified by its \\c Tag.\n   *\n   * The returned object should be passed to ExprBase::eval() to evaluate a given expression with this specified\n   * runtime-time value.\n   */\n  constexpr SymbolValue&lt;Tag, Index&gt; operator=(Index val) const { return SymbolValue&lt;Tag, Index&gt;(val); }\n\n  template &lt;int N&gt;\n  constexpr SymbolValue&lt;Tag, internal::FixedInt&lt;N&gt;&gt; operator=(internal::FixedInt&lt;N&gt;) const {\n    return SymbolValue&lt;Tag, internal::FixedInt&lt;N&gt;&gt;{internal::FixedInt&lt;N&gt;{}};\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return EvalSymbolValueHelper&lt;Tag, SymbolValue&lt;Tags, Types&gt;...&gt;::eval_impl(values...);\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    return EvalSymbolValueHelper&lt;Tag, SymbolValue&lt;Tags, Types&gt;...&gt;::eval_at_compile_time_impl(\n        SymbolValue&lt;Tags, Types&gt;{}...);\n  }\n};\n\ntemplate &lt;typename Arg0&gt;\nclass NegateExpr : public BaseExpr&lt;NegateExpr&lt;Arg0&gt;&gt; {\n public:\n  constexpr NegateExpr() = default;\n  constexpr NegateExpr(const Arg0&amp; arg0) : m_arg0(arg0) {}\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return -m_arg0.eval_impl(values...);\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    constexpr Index v = Arg0::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    return (v == Undefined) ? Undefined : -v;\n  }\n\n protected:\n  Arg0 m_arg0;\n};\n\ntemplate &lt;typename Arg0, typename Arg1&gt;\nclass AddExpr : public BaseExpr&lt;AddExpr&lt;Arg0, Arg1&gt;&gt; {\n public:\n  constexpr AddExpr() = default;\n  constexpr AddExpr(const Arg0&amp; arg0, const Arg1&amp; arg1) : m_arg0(arg0), m_arg1(arg1) {}\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return m_arg0.eval_impl(values...) + m_arg1.eval_impl(values...);\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 + v1;\n  }\n\n protected:\n  Arg0 m_arg0;\n  Arg1 m_arg1;\n};\n\ntemplate &lt;typename Arg0, typename Arg1&gt;\nclass ProductExpr : public BaseExpr&lt;ProductExpr&lt;Arg0, Arg1&gt;&gt; {\n public:\n  constexpr ProductExpr() = default;\n  constexpr ProductExpr(const Arg0&amp; arg0, const Arg1&amp; arg1) : m_arg0(arg0), m_arg1(arg1) {}\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return m_arg0.eval_impl(values...) * m_arg1.eval_impl(values...);\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 * v1;\n  }\n\n protected:\n  Arg0 m_arg0;\n  Arg1 m_arg1;\n};\n\ntemplate &lt;typename Arg0, typename Arg1&gt;\nclass QuotientExpr : public BaseExpr&lt;QuotientExpr&lt;Arg0, Arg1&gt;&gt; {\n public:\n  constexpr QuotientExpr() = default;\n  constexpr QuotientExpr(const Arg0&amp; arg0, const Arg1&amp; arg1) : m_arg0(arg0), m_arg1(arg1) {}\n\n  template &lt;typename... Tags, typename... Types&gt;\n  constexpr Index eval_impl(const SymbolValue&lt;Tags, Types&gt;&amp;... values) const {\n    return m_arg0.eval_impl(values...) / m_arg1.eval_impl(values...);\n  }\n\n  template &lt;typename... Tags, typename... Types&gt;\n  static constexpr Index eval_at_compile_time_impl(const SymbolValue&lt;Tags, Types&gt;&amp;...) {\n    constexpr Index v0 = Arg0::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    constexpr Index v1 = Arg1::eval_at_compile_time_impl(SymbolValue&lt;Tags, Types&gt;{}...);\n    return (v0 == Undefined || v1 == Undefined) ? Undefined : v0 / v1;\n  }\n\n protected:\n  Arg0 m_arg0;\n  Arg1 m_arg1;\n};\n\n}  // end namespace symbolic\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_SYMBOLIC_INDEX_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ANGLEAXIS_H\n#define EIGEN_ANGLEAXIS_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\geometry_module \\ingroup Geometry_Module\n *\n * \\class AngleAxis\n *\n * \\brief Represents a 3D rotation as a rotation angle around an arbitrary 3D axis\n *\n * \\param Scalar_ the scalar type, i.e., the type of the coefficients.\n *\n * \\warning When setting up an AngleAxis object, the axis vector \\b must \\b be \\b normalized.\n *\n * The following two typedefs are provided for convenience:\n * \\li \\c AngleAxisf for \\c float\n * \\li \\c AngleAxisd for \\c double\n *\n * Combined with MatrixBase::Unit{X,Y,Z}, AngleAxis can be used to easily\n * mimic Euler-angles. Here is an example:\n * \\include AngleAxis_mimic_euler.cpp\n * Output: \\verbinclude AngleAxis_mimic_euler.out\n *\n * \\note This class is not aimed to be used to store a rotation transformation,\n * but rather to make easier the creation of other rotation (Quaternion, rotation Matrix)\n * and transformation objects.\n *\n * \\sa class Quaternion, class Transform, MatrixBase::UnitX()\n */\n\nnamespace internal {\ntemplate &lt;typename Scalar_&gt;\nstruct traits&lt;AngleAxis&lt;Scalar_&gt; &gt; {\n  typedef Scalar_ Scalar;\n};\n}  // namespace internal\n\ntemplate &lt;typename Scalar_&gt;\nclass AngleAxis : public RotationBase&lt;AngleAxis&lt;Scalar_&gt;, 3&gt; {\n  typedef RotationBase&lt;AngleAxis&lt;Scalar_&gt;, 3&gt; Base;\n\n public:\n  using Base::operator*;\n\n  enum { Dim = 3 };\n  /** the scalar type of the coefficients */\n  typedef Scalar_ Scalar;\n  typedef Matrix&lt;Scalar, 3, 3&gt; Matrix3;\n  typedef Matrix&lt;Scalar, 3, 1&gt; Vector3;\n  typedef Quaternion&lt;Scalar&gt; QuaternionType;\n\n protected:\n  Vector3 m_axis;\n  Scalar m_angle;\n\n public:\n  /** Default constructor without initialization. */\n  EIGEN_DEVICE_FUNC AngleAxis() {}\n  /** Constructs and initialize the angle-axis rotation from an \\a angle in radian\n   * and an \\a axis which \\b must \\b be \\b normalized.\n   *\n   * \\warning If the \\a axis vector is not normalized, then the angle-axis object\n   *          represents an invalid rotation. */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline AngleAxis(const Scalar&amp; angle, const MatrixBase&lt;Derived&gt;&amp; axis)\n      : m_axis(axis), m_angle(angle) {}\n  /** Constructs and initialize the angle-axis rotation from a quaternion \\a q.\n   * This function implicitly normalizes the quaternion \\a q.\n   */\n  template &lt;typename QuatDerived&gt;\n  EIGEN_DEVICE_FUNC inline explicit AngleAxis(const QuaternionBase&lt;QuatDerived&gt;&amp; q) {\n    *this = q;\n  }\n  /** Constructs and initialize the angle-axis rotation from a 3x3 rotation matrix. */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline explicit AngleAxis(const MatrixBase&lt;Derived&gt;&amp; m) {\n    *this = m;\n  }\n\n  /** \\returns the value of the rotation angle in radian */\n  EIGEN_DEVICE_FUNC Scalar angle() const { return m_angle; }\n  /** \\returns a read-write reference to the stored angle in radian */\n  EIGEN_DEVICE_FUNC Scalar&amp; angle() { return m_angle; }\n\n  /** \\returns the rotation axis */\n  EIGEN_DEVICE_FUNC const Vector3&amp; axis() const { return m_axis; }\n  /** \\returns a read-write reference to the stored rotation axis.\n   *\n   * \\warning The rotation axis must remain a \\b unit vector.\n   */\n  EIGEN_DEVICE_FUNC Vector3&amp; axis() { return m_axis; }\n\n  /** Concatenates two rotations */\n  EIGEN_DEVICE_FUNC inline QuaternionType operator*(const AngleAxis&amp; other) const {\n    return QuaternionType(*this) * QuaternionType(other);\n  }\n\n  /** Concatenates two rotations */\n  EIGEN_DEVICE_FUNC inline QuaternionType operator*(const QuaternionType&amp; other) const {\n    return QuaternionType(*this) * other;\n  }\n\n  /** Concatenates two rotations */\n  friend EIGEN_DEVICE_FUNC inline QuaternionType operator*(const QuaternionType&amp; a, const AngleAxis&amp; b) {\n    return a * QuaternionType(b);\n  }\n\n  /** \\returns the inverse rotation, i.e., an angle-axis with opposite rotation angle */\n  EIGEN_DEVICE_FUNC AngleAxis inverse() const { return AngleAxis(-m_angle, m_axis); }\n\n  template &lt;class QuatDerived&gt;\n  EIGEN_DEVICE_FUNC AngleAxis&amp; operator=(const QuaternionBase&lt;QuatDerived&gt;&amp; q);\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC AngleAxis&amp; operator=(const MatrixBase&lt;Derived&gt;&amp; m);\n\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC AngleAxis&amp; fromRotationMatrix(const MatrixBase&lt;Derived&gt;&amp; m);\n  EIGEN_DEVICE_FUNC Matrix3 toRotationMatrix(void) const;\n\n  /** \\returns \\c *this with scalar type casted to \\a NewScalarType\n   *\n   * Note that if \\a NewScalarType is equal to the current scalar type of \\c *this\n   * then this function smartly returns a const reference to \\c *this.\n   */\n  template &lt;typename NewScalarType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::cast_return_type&lt;AngleAxis, AngleAxis&lt;NewScalarType&gt; &gt;::type cast()\n      const {\n    return typename internal::cast_return_type&lt;AngleAxis, AngleAxis&lt;NewScalarType&gt; &gt;::type(*this);\n  }\n\n  /** Copy constructor with scalar type conversion */\n  template &lt;typename OtherScalarType&gt;\n  EIGEN_DEVICE_FUNC inline explicit AngleAxis(const AngleAxis&lt;OtherScalarType&gt;&amp; other) {\n    m_axis = other.axis().template cast&lt;Scalar&gt;();\n    m_angle = Scalar(other.angle());\n  }\n\n  EIGEN_DEVICE_FUNC static inline const AngleAxis Identity() { return AngleAxis(Scalar(0), Vector3::UnitX()); }\n\n  /** \\returns \\c true if \\c *this is approximately equal to \\a other, within the precision\n   * determined by \\a prec.\n   *\n   * \\sa MatrixBase::isApprox() */\n  EIGEN_DEVICE_FUNC bool isApprox(const AngleAxis&amp; other, const typename NumTraits&lt;Scalar&gt;::Real&amp; prec =\n                                                              NumTraits&lt;Scalar&gt;::dummy_precision()) const {\n    return m_axis.isApprox(other.m_axis, prec) &amp;&amp; internal::isApprox(m_angle, other.m_angle, prec);\n  }\n};\n\n/** \\ingroup Geometry_Module\n * single precision angle-axis type */\ntypedef AngleAxis&lt;float&gt; AngleAxisf;\n/** \\ingroup Geometry_Module\n * double precision angle-axis type */\ntypedef AngleAxis&lt;double&gt; AngleAxisd;\n\n/** Set \\c *this from a \\b unit quaternion.\n *\n * The resulting axis is normalized, and the computed angle is in the [0,pi] range.\n *\n * This function implicitly normalizes the quaternion \\a q.\n */\ntemplate &lt;typename Scalar&gt;\ntemplate &lt;typename QuatDerived&gt;\nEIGEN_DEVICE_FUNC AngleAxis&lt;Scalar&gt;&amp; AngleAxis&lt;Scalar&gt;::operator=(const QuaternionBase&lt;QuatDerived&gt;&amp; q) {\n  EIGEN_USING_STD(atan2)\n  EIGEN_USING_STD(abs)\n  Scalar n = q.vec().norm();\n  if (n &lt; NumTraits&lt;Scalar&gt;::epsilon()) n = q.vec().stableNorm();\n\n  if (n != Scalar(0)) {\n    m_angle = Scalar(2) * atan2(n, abs(q.w()));\n    if (q.w() &lt; Scalar(0)) n = -n;\n    m_axis = q.vec() / n;\n  } else {\n    m_angle = Scalar(0);\n    m_axis &lt;&lt; Scalar(1), Scalar(0), Scalar(0);\n  }\n  return *this;\n}\n\n/** Set \\c *this from a 3x3 rotation matrix \\a mat.\n */\ntemplate &lt;typename Scalar&gt;\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC AngleAxis&lt;Scalar&gt;&amp; AngleAxis&lt;Scalar&gt;::operator=(const MatrixBase&lt;Derived&gt;&amp; mat) {\n  // Since a direct conversion would not be really faster,\n  // let&#x27;s use the robust Quaternion implementation:\n  return *this = QuaternionType(mat);\n}\n\n/**\n * \\brief Sets \\c *this from a 3x3 rotation matrix.\n **/\ntemplate &lt;typename Scalar&gt;\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC AngleAxis&lt;Scalar&gt;&amp; AngleAxis&lt;Scalar&gt;::fromRotationMatrix(const MatrixBase&lt;Derived&gt;&amp; mat) {\n  return *this = QuaternionType(mat);\n}\n\n/** Constructs and \\returns an equivalent 3x3 rotation matrix.\n */\ntemplate &lt;typename Scalar&gt;\ntypename AngleAxis&lt;Scalar&gt;::Matrix3 EIGEN_DEVICE_FUNC AngleAxis&lt;Scalar&gt;::toRotationMatrix(void) const {\n  EIGEN_USING_STD(sin)\n  EIGEN_USING_STD(cos)\n  Matrix3 res;\n  Vector3 sin_axis = sin(m_angle) * m_axis;\n  Scalar c = cos(m_angle);\n  Vector3 cos1_axis = (Scalar(1) - c) * m_axis;\n\n  Scalar tmp;\n  tmp = cos1_axis.x() * m_axis.y();\n  res.coeffRef(0, 1) = tmp - sin_axis.z();\n  res.coeffRef(1, 0) = tmp + sin_axis.z();\n\n  tmp = cos1_axis.x() * m_axis.z();\n  res.coeffRef(0, 2) = tmp + sin_axis.y();\n  res.coeffRef(2, 0) = tmp - sin_axis.y();\n\n  tmp = cos1_axis.y() * m_axis.z();\n  res.coeffRef(1, 2) = tmp - sin_axis.x();\n  res.coeffRef(2, 1) = tmp + sin_axis.x();\n\n  res.diagonal() = (cos1_axis.cwiseProduct(m_axis)).array() + c;\n\n  return res;\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ANGLEAXIS_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008-2010 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n// Copyright (C) 2009 Mathieu Gautier &lt;mathieu.gautier@cea.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_QUATERNION_H\n#define EIGEN_QUATERNION_H\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/***************************************************************************\n * Definition of QuaternionBase&lt;Derived&gt;\n * The implementation is at the end of the file\n ***************************************************************************/\n\nnamespace internal {\ntemplate &lt;typename Other, int OtherRows = Other::RowsAtCompileTime, int OtherCols = Other::ColsAtCompileTime&gt;\nstruct quaternionbase_assign_impl;\n}\n\n/** \\geometry_module \\ingroup Geometry_Module\n * \\class QuaternionBase\n * \\brief Base class for quaternion expressions\n * \\tparam Derived derived type (CRTP)\n * \\sa class Quaternion\n */\ntemplate &lt;class Derived&gt;\nclass QuaternionBase : public RotationBase&lt;Derived, 3&gt; {\n public:\n  typedef RotationBase&lt;Derived, 3&gt; Base;\n\n  using Base::operator*;\n  using Base::derived;\n\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n  typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar;\n  typedef typename internal::traits&lt;Derived&gt;::Coefficients Coefficients;\n  typedef typename Coefficients::CoeffReturnType CoeffReturnType;\n  typedef std::conditional_t&lt;bool(internal::traits&lt;Derived&gt;::Flags&amp; LvalueBit), Scalar&amp;, CoeffReturnType&gt;\n      NonConstCoeffReturnType;\n\n  enum { Flags = Eigen::internal::traits&lt;Derived&gt;::Flags };\n\n  // typedef typename Matrix&lt;Scalar,4,1&gt; Coefficients;\n  /** the type of a 3D vector */\n  typedef Matrix&lt;Scalar, 3, 1&gt; Vector3;\n  /** the equivalent rotation matrix type */\n  typedef Matrix&lt;Scalar, 3, 3&gt; Matrix3;\n  /** the equivalent angle-axis type */\n  typedef AngleAxis&lt;Scalar&gt; AngleAxisType;\n\n  /** \\returns the \\c x coefficient */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline CoeffReturnType x() const { return this-&gt;derived().coeffs().coeff(0); }\n  /** \\returns the \\c y coefficient */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline CoeffReturnType y() const { return this-&gt;derived().coeffs().coeff(1); }\n  /** \\returns the \\c z coefficient */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline CoeffReturnType z() const { return this-&gt;derived().coeffs().coeff(2); }\n  /** \\returns the \\c w coefficient */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline CoeffReturnType w() const { return this-&gt;derived().coeffs().coeff(3); }\n\n  /** \\returns a reference to the \\c x coefficient (if Derived is a non-const lvalue) */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline NonConstCoeffReturnType x() { return this-&gt;derived().coeffs().x(); }\n  /** \\returns a reference to the \\c y coefficient (if Derived is a non-const lvalue) */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline NonConstCoeffReturnType y() { return this-&gt;derived().coeffs().y(); }\n  /** \\returns a reference to the \\c z coefficient (if Derived is a non-const lvalue) */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline NonConstCoeffReturnType z() { return this-&gt;derived().coeffs().z(); }\n  /** \\returns a reference to the \\c w coefficient (if Derived is a non-const lvalue) */\n  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline NonConstCoeffReturnType w() { return this-&gt;derived().coeffs().w(); }\n\n  /** \\returns a read-only vector expression of the imaginary part (x,y,z) */\n  EIGEN_DEVICE_FUNC inline const VectorBlock&lt;const Coefficients, 3&gt; vec() const { return coeffs().template head&lt;3&gt;(); }\n\n  /** \\returns a vector expression of the imaginary part (x,y,z) */\n  EIGEN_DEVICE_FUNC inline VectorBlock&lt;Coefficients, 3&gt; vec() { return coeffs().template head&lt;3&gt;(); }\n\n  /** \\returns a read-only vector expression of the coefficients (x,y,z,w) */\n  EIGEN_DEVICE_FUNC inline const typename internal::traits&lt;Derived&gt;::Coefficients&amp; coeffs() const {\n    return derived().coeffs();\n  }\n\n  /** \\returns a vector expression of the coefficients (x,y,z,w) */\n  EIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Coefficients&amp; coeffs() { return derived().coeffs(); }\n\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE QuaternionBase&lt;Derived&gt;&amp; operator=(const QuaternionBase&lt;Derived&gt;&amp; other);\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator=(const QuaternionBase&lt;OtherDerived&gt;&amp; other);\n\n  // disabled this copy operator as it is giving very strange compilation errors when compiling\n  // test_stdvector with GCC 4.4.2. This looks like a GCC bug though, so feel free to re-enable it if it&#x27;s\n  // useful; however notice that we already have the templated operator= above and e.g. in MatrixBase\n  // we didn&#x27;t have to add, in addition to templated operator=, such a non-templated copy operator.\n  //  Derived&amp; operator=(const QuaternionBase&amp; other)\n  //  { return operator=&lt;Derived&gt;(other); }\n\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const AngleAxisType&amp; aa);\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; operator=(const MatrixBase&lt;OtherDerived&gt;&amp; m);\n\n  /** \\returns a quaternion representing an identity rotation\n   * \\sa MatrixBase::Identity()\n   */\n  EIGEN_DEVICE_FUNC static inline Quaternion&lt;Scalar&gt; Identity() {\n    return Quaternion&lt;Scalar&gt;(Scalar(1), Scalar(0), Scalar(0), Scalar(0));\n  }\n\n  /** \\sa QuaternionBase::Identity(), MatrixBase::setIdentity()\n   */\n  EIGEN_DEVICE_FUNC inline QuaternionBase&amp; setIdentity() {\n    coeffs() &lt;&lt; Scalar(0), Scalar(0), Scalar(0), Scalar(1);\n    return *this;\n  }\n\n  /** \\returns the squared norm of the quaternion&#x27;s coefficients\n   * \\sa QuaternionBase::norm(), MatrixBase::squaredNorm()\n   */\n  EIGEN_DEVICE_FUNC inline Scalar squaredNorm() const { return coeffs().squaredNorm(); }\n\n  /** \\returns the norm of the quaternion&#x27;s coefficients\n   * \\sa QuaternionBase::squaredNorm(), MatrixBase::norm()\n   */\n  EIGEN_DEVICE_FUNC inline Scalar norm() const { return coeffs().norm(); }\n\n  /** Normalizes the quaternion \\c *this\n   * \\sa normalized(), MatrixBase::normalize() */\n  EIGEN_DEVICE_FUNC inline void normalize() { coeffs().normalize(); }\n  /** \\returns a normalized copy of \\c *this\n   * \\sa normalize(), MatrixBase::normalized() */\n  EIGEN_DEVICE_FUNC inline Quaternion&lt;Scalar&gt; normalized() const { return Quaternion&lt;Scalar&gt;(coeffs().normalized()); }\n\n  /** \\returns the dot product of \\c *this and \\a other\n   * Geometrically speaking, the dot product of two unit quaternions\n   * corresponds to the cosine of half the angle between the two rotations.\n   * \\sa angularDistance()\n   */\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline Scalar dot(const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n    return coeffs().dot(other.coeffs());\n  }\n\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Scalar angularDistance(const QuaternionBase&lt;OtherDerived&gt;&amp; other) const;\n\n  /** \\returns an equivalent 3x3 rotation matrix */\n  EIGEN_DEVICE_FUNC inline Matrix3 toRotationMatrix() const;\n\n  /** \\returns the quaternion which transform \\a a into \\a b through a rotation */\n  template &lt;typename Derived1, typename Derived2&gt;\n  EIGEN_DEVICE_FUNC Derived&amp; setFromTwoVectors(const MatrixBase&lt;Derived1&gt;&amp; a, const MatrixBase&lt;Derived2&gt;&amp; b);\n\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Quaternion&lt;Scalar&gt; operator*(const QuaternionBase&lt;OtherDerived&gt;&amp; q) const;\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; operator*=(const QuaternionBase&lt;OtherDerived&gt;&amp; q);\n\n  /** \\returns the quaternion describing the inverse rotation */\n  EIGEN_DEVICE_FUNC Quaternion&lt;Scalar&gt; inverse() const;\n\n  /** \\returns the conjugated quaternion */\n  EIGEN_DEVICE_FUNC Quaternion&lt;Scalar&gt; conjugate() const;\n\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC Quaternion&lt;Scalar&gt; slerp(const Scalar&amp; t, const QuaternionBase&lt;OtherDerived&gt;&amp; other) const;\n\n  /** \\returns true if each coefficients of \\c *this and \\a other are all exactly equal.\n   * \\warning When using floating point scalar values you probably should rather use a\n   *          fuzzy comparison such as isApprox()\n   * \\sa isApprox(), operator!= */\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline bool operator==(const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n    return coeffs() == other.coeffs();\n  }\n\n  /** \\returns true if at least one pair of coefficients of \\c *this and \\a other are not exactly equal to each other.\n   * \\warning When using floating point scalar values you probably should rather use a\n   *          fuzzy comparison such as isApprox()\n   * \\sa isApprox(), operator== */\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC inline bool operator!=(const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n    return coeffs() != other.coeffs();\n  }\n\n  /** \\returns \\c true if \\c *this is approximately equal to \\a other, within the precision\n   * determined by \\a prec.\n   *\n   * \\sa MatrixBase::isApprox() */\n  template &lt;class OtherDerived&gt;\n  EIGEN_DEVICE_FUNC bool isApprox(const QuaternionBase&lt;OtherDerived&gt;&amp; other,\n                                  const RealScalar&amp; prec = NumTraits&lt;Scalar&gt;::dummy_precision()) const {\n    return coeffs().isApprox(other.coeffs(), prec);\n  }\n\n  /** return the result vector of \\a v through the rotation*/\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Vector3 _transformVector(const Vector3&amp; v) const;\n\n#ifdef EIGEN_PARSED_BY_DOXYGEN\n  /** \\returns \\c *this with scalar type casted to \\a NewScalarType\n   *\n   * Note that if \\a NewScalarType is equal to the current scalar type of \\c *this\n   * then this function smartly returns a const reference to \\c *this.\n   */\n  template &lt;typename NewScalarType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::cast_return_type&lt;Derived, Quaternion&lt;NewScalarType&gt; &gt;::type cast() const;\n\n#else\n\n  template &lt;typename NewScalarType&gt;\n  EIGEN_DEVICE_FUNC inline std::enable_if_t&lt;internal::is_same&lt;Scalar, NewScalarType&gt;::value, const Derived&amp;&gt; cast()\n      const {\n    return derived();\n  }\n\n  template &lt;typename NewScalarType&gt;\n  EIGEN_DEVICE_FUNC inline std::enable_if_t&lt;!internal::is_same&lt;Scalar, NewScalarType&gt;::value,\n                                            Quaternion&lt;NewScalarType&gt; &gt;\n  cast() const {\n    return Quaternion&lt;NewScalarType&gt;(coeffs().template cast&lt;NewScalarType&gt;());\n  }\n#endif\n\n#ifndef EIGEN_NO_IO\n  friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; s, const QuaternionBase&lt;Derived&gt;&amp; q) {\n    s &lt;&lt; q.x() &lt;&lt; &quot;i + &quot; &lt;&lt; q.y() &lt;&lt; &quot;j + &quot; &lt;&lt; q.z() &lt;&lt; &quot;k&quot;\n      &lt;&lt; &quot; + &quot; &lt;&lt; q.w();\n    return s;\n  }\n#endif\n\n#ifdef EIGEN_QUATERNIONBASE_PLUGIN\n#include EIGEN_QUATERNIONBASE_PLUGIN\n#endif\n protected:\n  EIGEN_DEFAULT_COPY_CONSTRUCTOR(QuaternionBase)\n  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(QuaternionBase)\n};\n\n/***************************************************************************\n * Definition/implementation of Quaternion&lt;Scalar&gt;\n ***************************************************************************/\n\n/** \\geometry_module \\ingroup Geometry_Module\n *\n * \\class Quaternion\n *\n * \\brief The quaternion class used to represent 3D orientations and rotations\n *\n * \\tparam Scalar_ the scalar type, i.e., the type of the coefficients\n * \\tparam Options_ controls the memory alignment of the coefficients. Can be \\# AutoAlign or \\# DontAlign. Default is\n * AutoAlign.\n *\n * This class represents a quaternion \\f$ w+xi+yj+zk \\f$ that is a convenient representation of\n * orientations and rotations of objects in three dimensions. Compared to other representations\n * like Euler angles or 3x3 matrices, quaternions offer the following advantages:\n * \\li \\b compact storage (4 scalars)\n * \\li \\b efficient to compose (28 flops),\n * \\li \\b stable spherical interpolation\n *\n * The following two typedefs are provided for convenience:\n * \\li \\c Quaternionf for \\c float\n * \\li \\c Quaterniond for \\c double\n *\n * \\warning Operations interpreting the quaternion as rotation have undefined behavior if the quaternion is not\n * normalized.\n *\n * \\sa  class AngleAxis, class Transform\n */\n\nnamespace internal {\ntemplate &lt;typename Scalar_, int Options_&gt;\nstruct traits&lt;Quaternion&lt;Scalar_, Options_&gt; &gt; {\n  typedef Quaternion&lt;Scalar_, Options_&gt; PlainObject;\n  typedef Scalar_ Scalar;\n  typedef Matrix&lt;Scalar_, 4, 1, Options_&gt; Coefficients;\n  enum { Alignment = internal::traits&lt;Coefficients&gt;::Alignment, Flags = LvalueBit };\n};\n}  // namespace internal\n\ntemplate &lt;typename Scalar_, int Options_&gt;\nclass Quaternion : public QuaternionBase&lt;Quaternion&lt;Scalar_, Options_&gt; &gt; {\n public:\n  typedef QuaternionBase&lt;Quaternion&lt;Scalar_, Options_&gt; &gt; Base;\n  enum { NeedsAlignment = internal::traits&lt;Quaternion&gt;::Alignment &gt; 0 };\n\n  typedef Scalar_ Scalar;\n\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Quaternion)\n  using Base::operator*=;\n\n  typedef typename internal::traits&lt;Quaternion&gt;::Coefficients Coefficients;\n  typedef typename Base::AngleAxisType AngleAxisType;\n\n  /** Default constructor leaving the quaternion uninitialized. */\n  EIGEN_DEVICE_FUNC inline Quaternion() {}\n\n  /** Constructs and initializes the quaternion \\f$ w+xi+yj+zk \\f$ from\n   * its four coefficients \\a w, \\a x, \\a y and \\a z.\n   *\n   * \\warning Note the order of the arguments: the real \\a w coefficient first,\n   * while internally the coefficients are stored in the following order:\n   * [\\c x, \\c y, \\c z, \\c w]\n   */\n  EIGEN_DEVICE_FUNC inline Quaternion(const Scalar&amp; w, const Scalar&amp; x, const Scalar&amp; y, const Scalar&amp; z)\n      : m_coeffs(x, y, z, w) {}\n\n  /** Constructs and initializes a quaternion from its real part as a scalar,\n   *  and its imaginary part as a 3-vector [\\c x, \\c y, \\c z]\n   */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC inline Quaternion(const Scalar&amp; w, const Eigen::MatrixBase&lt;Derived&gt;&amp; vec)\n      : m_coeffs(vec.x(), vec.y(), vec.z(), w) {\n    EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(Derived, 3);\n  }\n\n  /** Constructs and initialize a quaternion from the array data */\n  EIGEN_DEVICE_FUNC explicit inline Quaternion(const Scalar* data) : m_coeffs(data) {}\n\n  /** Copy constructor */\n  template &lt;class Derived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Quaternion(const QuaternionBase&lt;Derived&gt;&amp; other) {\n    this-&gt;Base::operator=(other);\n  }\n\n  /** Constructs and initializes a quaternion from the angle-axis \\a aa */\n  EIGEN_DEVICE_FUNC explicit inline Quaternion(const AngleAxisType&amp; aa) { *this = aa; }\n\n  /** Constructs and initializes a quaternion from either:\n   *  - a rotation matrix expression,\n   *  - a 4D vector expression representing quaternion coefficients in the order [\\c x, \\c y, \\c z, \\c w].\n   */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC explicit inline Quaternion(const MatrixBase&lt;Derived&gt;&amp; other) {\n    *this = other;\n  }\n\n  /** Explicit copy constructor with scalar conversion */\n  template &lt;typename OtherScalar, int OtherOptions&gt;\n  EIGEN_DEVICE_FUNC explicit inline Quaternion(const Quaternion&lt;OtherScalar, OtherOptions&gt;&amp; other) {\n    m_coeffs = other.coeffs().template cast&lt;Scalar&gt;();\n  }\n\n  // We define a copy constructor, which means we don&#x27;t get an implicit move constructor or assignment operator.\n  /** Default move constructor */\n  EIGEN_DEVICE_FUNC inline Quaternion(Quaternion&amp;&amp; other)\n      EIGEN_NOEXCEPT_IF(std::is_nothrow_move_constructible&lt;Scalar&gt;::value)\n      : m_coeffs(std::move(other.coeffs())) {}\n\n  /** Default move assignment operator */\n  EIGEN_DEVICE_FUNC Quaternion&amp; operator=(Quaternion&amp;&amp; other)\n      EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable&lt;Scalar&gt;::value) {\n    m_coeffs = std::move(other.coeffs());\n    return *this;\n  }\n\n  EIGEN_DEVICE_FUNC static Quaternion UnitRandom();\n\n  template &lt;typename Derived1, typename Derived2&gt;\n  EIGEN_DEVICE_FUNC static Quaternion FromTwoVectors(const MatrixBase&lt;Derived1&gt;&amp; a, const MatrixBase&lt;Derived2&gt;&amp; b);\n\n  EIGEN_DEVICE_FUNC inline Coefficients&amp; coeffs() { return m_coeffs; }\n  EIGEN_DEVICE_FUNC inline const Coefficients&amp; coeffs() const { return m_coeffs; }\n\n  EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(bool(NeedsAlignment))\n\n#ifdef EIGEN_QUATERNION_PLUGIN\n#include EIGEN_QUATERNION_PLUGIN\n#endif\n\n protected:\n  Coefficients m_coeffs;\n\n#ifndef EIGEN_PARSED_BY_DOXYGEN\n  EIGEN_STATIC_ASSERT((Options_ &amp; DontAlign) == Options_, INVALID_MATRIX_TEMPLATE_PARAMETERS)\n#endif\n};\n\n/** \\ingroup Geometry_Module\n * single precision quaternion type */\ntypedef Quaternion&lt;float&gt; Quaternionf;\n/** \\ingroup Geometry_Module\n * double precision quaternion type */\ntypedef Quaternion&lt;double&gt; Quaterniond;\n\n/***************************************************************************\n * Specialization of Map&lt;Quaternion&lt;Scalar&gt;&gt;\n ***************************************************************************/\n\nnamespace internal {\ntemplate &lt;typename Scalar_, int Options_&gt;\nstruct traits&lt;Map&lt;Quaternion&lt;Scalar_&gt;, Options_&gt; &gt;\n    : traits&lt;Quaternion&lt;Scalar_, (int(Options_) &amp; Aligned) == Aligned ? AutoAlign : DontAlign&gt; &gt; {\n  typedef Map&lt;Matrix&lt;Scalar_, 4, 1&gt;, Options_&gt; Coefficients;\n};\n}  // namespace internal\n\nnamespace internal {\ntemplate &lt;typename Scalar_, int Options_&gt;\nstruct traits&lt;Map&lt;const Quaternion&lt;Scalar_&gt;, Options_&gt; &gt;\n    : traits&lt;Quaternion&lt;Scalar_, (int(Options_) &amp; Aligned) == Aligned ? AutoAlign : DontAlign&gt; &gt; {\n  typedef Map&lt;const Matrix&lt;Scalar_, 4, 1&gt;, Options_&gt; Coefficients;\n  typedef traits&lt;Quaternion&lt;Scalar_, (int(Options_) &amp; Aligned) == Aligned ? AutoAlign : DontAlign&gt; &gt; TraitsBase;\n  enum { Flags = TraitsBase::Flags &amp; ~LvalueBit };\n};\n}  // namespace internal\n\n/** \\ingroup Geometry_Module\n * \\brief Quaternion expression mapping a constant memory buffer\n *\n * \\tparam Scalar_ the type of the Quaternion coefficients\n * \\tparam Options_ see class Map\n *\n * This is a specialization of class Map for Quaternion. This class allows to view\n * a 4 scalar memory buffer as an Eigen&#x27;s Quaternion object.\n *\n * \\sa class Map, class Quaternion, class QuaternionBase\n */\ntemplate &lt;typename Scalar_, int Options_&gt;\nclass Map&lt;const Quaternion&lt;Scalar_&gt;, Options_&gt; : public QuaternionBase&lt;Map&lt;const Quaternion&lt;Scalar_&gt;, Options_&gt; &gt; {\n public:\n  typedef QuaternionBase&lt;Map&lt;const Quaternion&lt;Scalar_&gt;, Options_&gt; &gt; Base;\n\n  typedef Scalar_ Scalar;\n  typedef typename internal::traits&lt;Map&gt;::Coefficients Coefficients;\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Map)\n  using Base::operator*=;\n\n  /** Constructs a Mapped Quaternion object from the pointer \\a coeffs\n   *\n   * The pointer \\a coeffs must reference the four coefficients of Quaternion in the following order:\n   * \\code *coeffs == {x, y, z, w} \\endcode\n   *\n   * If the template parameter Options_ is set to #Aligned, then the pointer coeffs must be aligned. */\n  EIGEN_DEVICE_FUNC explicit EIGEN_STRONG_INLINE Map(const Scalar* coeffs) : m_coeffs(coeffs) {}\n\n  EIGEN_DEVICE_FUNC inline const Coefficients&amp; coeffs() const { return m_coeffs; }\n\n protected:\n  const Coefficients m_coeffs;\n};\n\n/** \\ingroup Geometry_Module\n * \\brief Expression of a quaternion from a memory buffer\n *\n * \\tparam Scalar_ the type of the Quaternion coefficients\n * \\tparam Options_ see class Map\n *\n * This is a specialization of class Map for Quaternion. This class allows to view\n * a 4 scalar memory buffer as an Eigen&#x27;s  Quaternion object.\n *\n * \\sa class Map, class Quaternion, class QuaternionBase\n */\ntemplate &lt;typename Scalar_, int Options_&gt;\nclass Map&lt;Quaternion&lt;Scalar_&gt;, Options_&gt; : public QuaternionBase&lt;Map&lt;Quaternion&lt;Scalar_&gt;, Options_&gt; &gt; {\n public:\n  typedef QuaternionBase&lt;Map&lt;Quaternion&lt;Scalar_&gt;, Options_&gt; &gt; Base;\n\n  typedef Scalar_ Scalar;\n  typedef typename internal::traits&lt;Map&gt;::Coefficients Coefficients;\n  EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Map)\n  using Base::operator*=;\n\n  /** Constructs a Mapped Quaternion object from the pointer \\a coeffs\n   *\n   * The pointer \\a coeffs must reference the four coefficients of Quaternion in the following order:\n   * \\code *coeffs == {x, y, z, w} \\endcode\n   *\n   * If the template parameter Options_ is set to #Aligned, then the pointer coeffs must be aligned. */\n  EIGEN_DEVICE_FUNC explicit EIGEN_STRONG_INLINE Map(Scalar* coeffs) : m_coeffs(coeffs) {}\n\n  EIGEN_DEVICE_FUNC inline Coefficients&amp; coeffs() { return m_coeffs; }\n  EIGEN_DEVICE_FUNC inline const Coefficients&amp; coeffs() const { return m_coeffs; }\n\n protected:\n  Coefficients m_coeffs;\n};\n\n/** \\ingroup Geometry_Module\n * Map an unaligned array of single precision scalars as a quaternion */\ntypedef Map&lt;Quaternion&lt;float&gt;, 0&gt; QuaternionMapf;\n/** \\ingroup Geometry_Module\n * Map an unaligned array of double precision scalars as a quaternion */\ntypedef Map&lt;Quaternion&lt;double&gt;, 0&gt; QuaternionMapd;\n/** \\ingroup Geometry_Module\n * Map a 16-byte aligned array of single precision scalars as a quaternion */\ntypedef Map&lt;Quaternion&lt;float&gt;, Aligned&gt; QuaternionMapAlignedf;\n/** \\ingroup Geometry_Module\n * Map a 16-byte aligned array of double precision scalars as a quaternion */\ntypedef Map&lt;Quaternion&lt;double&gt;, Aligned&gt; QuaternionMapAlignedd;\n\n/***************************************************************************\n * Implementation of QuaternionBase methods\n ***************************************************************************/\n\n// Generic Quaternion * Quaternion product\n// This product can be specialized for a given architecture via the Arch template argument.\nnamespace internal {\ntemplate &lt;int Arch, class Derived1, class Derived2, typename Scalar&gt;\nstruct quat_product {\n  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Quaternion&lt;Scalar&gt; run(const QuaternionBase&lt;Derived1&gt;&amp; a,\n                                                                      const QuaternionBase&lt;Derived2&gt;&amp; b) {\n    return Quaternion&lt;Scalar&gt;(a.w() * b.w() - a.x() * b.x() - a.y() * b.y() - a.z() * b.z(),\n                              a.w() * b.x() + a.x() * b.w() + a.y() * b.z() - a.z() * b.y(),\n                              a.w() * b.y() + a.y() * b.w() + a.z() * b.x() - a.x() * b.z(),\n                              a.w() * b.z() + a.z() * b.w() + a.x() * b.y() - a.y() * b.x());\n  }\n};\n}  // namespace internal\n\n/** \\returns the concatenation of two rotations as a quaternion-quaternion product */\ntemplate &lt;class Derived&gt;\ntemplate &lt;class OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Quaternion&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt;\nQuaternionBase&lt;Derived&gt;::operator*(const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n  EIGEN_STATIC_ASSERT(\n      (internal::is_same&lt;typename Derived::Scalar, typename OtherDerived::Scalar&gt;::value),\n      YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)\n  return internal::quat_product&lt;Architecture::Target, Derived, OtherDerived,\n                                typename internal::traits&lt;Derived&gt;::Scalar&gt;::run(*this, other);\n}\n\n/** \\sa operator*(Quaternion) */\ntemplate &lt;class Derived&gt;\ntemplate &lt;class OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; QuaternionBase&lt;Derived&gt;::operator*=(\n    const QuaternionBase&lt;OtherDerived&gt;&amp; other) {\n  derived() = derived() * other.derived();\n  return derived();\n}\n\n/** Rotation of a vector by a quaternion.\n * \\remarks If the quaternion is used to rotate several points (&gt;1)\n * then it is much more efficient to first convert it to a 3x3 Matrix.\n * Comparison of the operation cost for n transformations:\n *   - Quaternion2:    30n\n *   - Via a Matrix3: 24 + 15n\n */\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename QuaternionBase&lt;Derived&gt;::Vector3\nQuaternionBase&lt;Derived&gt;::_transformVector(const Vector3&amp; v) const {\n  // Note that this algorithm comes from the optimization by hand\n  // of the conversion to a Matrix followed by a Matrix/Vector product.\n  // It appears to be much faster than the common algorithm found\n  // in the literature (30 versus 39 flops). It also requires two\n  // Vector3 as temporaries.\n  Vector3 uv = this-&gt;vec().cross(v);\n  uv += uv;\n  return v + this-&gt;w() * uv + this-&gt;vec().cross(uv);\n}\n\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE QuaternionBase&lt;Derived&gt;&amp; QuaternionBase&lt;Derived&gt;::operator=(\n    const QuaternionBase&lt;Derived&gt;&amp; other) {\n  coeffs() = other.coeffs();\n  return derived();\n}\n\ntemplate &lt;class Derived&gt;\ntemplate &lt;class OtherDerived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; QuaternionBase&lt;Derived&gt;::operator=(\n    const QuaternionBase&lt;OtherDerived&gt;&amp; other) {\n  coeffs() = other.coeffs();\n  return derived();\n}\n\n/** Set \\c *this from an angle-axis \\a aa and returns a reference to \\c *this\n */\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&amp; QuaternionBase&lt;Derived&gt;::operator=(const AngleAxisType&amp; aa) {\n  EIGEN_USING_STD(cos)\n  EIGEN_USING_STD(sin)\n  Scalar ha = Scalar(0.5) * aa.angle();  // Scalar(0.5) to suppress precision loss warnings\n  this-&gt;w() = cos(ha);\n  this-&gt;vec() = sin(ha) * aa.axis();\n  return derived();\n}\n\n/** Set \\c *this from the expression \\a xpr:\n *   - if \\a xpr is a 4x1 vector, then \\a xpr is assumed to be a quaternion\n *   - if \\a xpr is a 3x3 matrix, then \\a xpr is assumed to be rotation matrix\n *     and \\a xpr is converted to a quaternion\n */\n\ntemplate &lt;class Derived&gt;\ntemplate &lt;class MatrixDerived&gt;\nEIGEN_DEVICE_FUNC inline Derived&amp; QuaternionBase&lt;Derived&gt;::operator=(const MatrixBase&lt;MatrixDerived&gt;&amp; xpr) {\n  EIGEN_STATIC_ASSERT(\n      (internal::is_same&lt;typename Derived::Scalar, typename MatrixDerived::Scalar&gt;::value),\n      YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)\n  internal::quaternionbase_assign_impl&lt;MatrixDerived&gt;::run(*this, xpr.derived());\n  return derived();\n}\n\n/** Convert the quaternion to a 3x3 rotation matrix. The quaternion is required to\n * be normalized, otherwise the result is undefined.\n */\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC inline typename QuaternionBase&lt;Derived&gt;::Matrix3 QuaternionBase&lt;Derived&gt;::toRotationMatrix(\n    void) const {\n  // NOTE if inlined, then gcc 4.2 and 4.4 get rid of the temporary (not gcc 4.3 !!)\n  // if not inlined then the cost of the return by value is huge ~ +35%,\n  // however, not inlining this function is an order of magnitude slower, so\n  // it has to be inlined, and so the return by value is not an issue\n  Matrix3 res;\n\n  const Scalar tx = Scalar(2) * this-&gt;x();\n  const Scalar ty = Scalar(2) * this-&gt;y();\n  const Scalar tz = Scalar(2) * this-&gt;z();\n  const Scalar twx = tx * this-&gt;w();\n  const Scalar twy = ty * this-&gt;w();\n  const Scalar twz = tz * this-&gt;w();\n  const Scalar txx = tx * this-&gt;x();\n  const Scalar txy = ty * this-&gt;x();\n  const Scalar txz = tz * this-&gt;x();\n  const Scalar tyy = ty * this-&gt;y();\n  const Scalar tyz = tz * this-&gt;y();\n  const Scalar tzz = tz * this-&gt;z();\n\n  res.coeffRef(0, 0) = Scalar(1) - (tyy + tzz);\n  res.coeffRef(0, 1) = txy - twz;\n  res.coeffRef(0, 2) = txz + twy;\n  res.coeffRef(1, 0) = txy + twz;\n  res.coeffRef(1, 1) = Scalar(1) - (txx + tzz);\n  res.coeffRef(1, 2) = tyz - twx;\n  res.coeffRef(2, 0) = txz - twy;\n  res.coeffRef(2, 1) = tyz + twx;\n  res.coeffRef(2, 2) = Scalar(1) - (txx + tyy);\n\n  return res;\n}\n\n/** Sets \\c *this to be a quaternion representing a rotation between\n * the two arbitrary vectors \\a a and \\a b. In other words, the built\n * rotation represent a rotation sending the line of direction \\a a\n * to the line of direction \\a b, both lines passing through the origin.\n *\n * \\returns a reference to \\c *this.\n *\n * Note that the two input vectors do \\b not have to be normalized, and\n * do not need to have the same norm.\n */\ntemplate &lt;class Derived&gt;\ntemplate &lt;typename Derived1, typename Derived2&gt;\nEIGEN_DEVICE_FUNC inline Derived&amp; QuaternionBase&lt;Derived&gt;::setFromTwoVectors(const MatrixBase&lt;Derived1&gt;&amp; a,\n                                                                             const MatrixBase&lt;Derived2&gt;&amp; b) {\n  EIGEN_USING_STD(sqrt)\n  Vector3 v0 = a.normalized();\n  Vector3 v1 = b.normalized();\n  Scalar c = v1.dot(v0);\n\n  // if dot == -1, vectors are nearly opposites\n  // =&gt; accurately compute the rotation axis by computing the\n  //    intersection of the two planes. This is done by solving:\n  //       x^T v0 = 0\n  //       x^T v1 = 0\n  //    under the constraint:\n  //       ||x|| = 1\n  //    which yields a singular value problem\n  if (c &lt; Scalar(-1) + NumTraits&lt;Scalar&gt;::dummy_precision()) {\n    c = numext::maxi(c, Scalar(-1));\n    Matrix&lt;Scalar, 2, 3&gt; m;\n    m &lt;&lt; v0.transpose(), v1.transpose();\n    JacobiSVD&lt;Matrix&lt;Scalar, 2, 3&gt;, ComputeFullV&gt; svd(m);\n    Vector3 axis = svd.matrixV().col(2);\n\n    Scalar w2 = (Scalar(1) + c) * Scalar(0.5);\n    this-&gt;w() = sqrt(w2);\n    this-&gt;vec() = axis * sqrt(Scalar(1) - w2);\n    return derived();\n  }\n  Vector3 axis = v0.cross(v1);\n  Scalar s = sqrt((Scalar(1) + c) * Scalar(2));\n  Scalar invs = Scalar(1) / s;\n  this-&gt;vec() = axis * invs;\n  this-&gt;w() = s * Scalar(0.5);\n\n  return derived();\n}\n\n/** \\returns a random unit quaternion following a uniform distribution law on SO(3)\n *\n * \\note The implementation is based on http://planning.cs.uiuc.edu/node198.html\n */\ntemplate &lt;typename Scalar, int Options&gt;\nEIGEN_DEVICE_FUNC Quaternion&lt;Scalar, Options&gt; Quaternion&lt;Scalar, Options&gt;::UnitRandom() {\n  EIGEN_USING_STD(sqrt)\n  EIGEN_USING_STD(sin)\n  EIGEN_USING_STD(cos)\n  const Scalar u1 = internal::random&lt;Scalar&gt;(0, 1), u2 = internal::random&lt;Scalar&gt;(0, 2 * EIGEN_PI),\n               u3 = internal::random&lt;Scalar&gt;(0, 2 * EIGEN_PI);\n  const Scalar a = sqrt(Scalar(1) - u1), b = sqrt(u1);\n  return Quaternion(a * sin(u2), a * cos(u2), b * sin(u3), b * cos(u3));\n}\n\n/** Returns a quaternion representing a rotation between\n * the two arbitrary vectors \\a a and \\a b. In other words, the built\n * rotation represent a rotation sending the line of direction \\a a\n * to the line of direction \\a b, both lines passing through the origin.\n *\n * \\returns resulting quaternion\n *\n * Note that the two input vectors do \\b not have to be normalized, and\n * do not need to have the same norm.\n */\ntemplate &lt;typename Scalar, int Options&gt;\ntemplate &lt;typename Derived1, typename Derived2&gt;\nEIGEN_DEVICE_FUNC Quaternion&lt;Scalar, Options&gt; Quaternion&lt;Scalar, Options&gt;::FromTwoVectors(\n    const MatrixBase&lt;Derived1&gt;&amp; a, const MatrixBase&lt;Derived2&gt;&amp; b) {\n  Quaternion quat;\n  quat.setFromTwoVectors(a, b);\n  return quat;\n}\n\n/** \\returns the multiplicative inverse of \\c *this\n * Note that in most cases, i.e., if you simply want the opposite rotation,\n * and/or the quaternion is normalized, then it is enough to use the conjugate.\n *\n * \\sa QuaternionBase::conjugate()\n */\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC inline Quaternion&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt; QuaternionBase&lt;Derived&gt;::inverse()\n    const {\n  // FIXME should this function be called multiplicativeInverse and conjugate() be called inverse() or opposite()  ??\n  Scalar n2 = this-&gt;squaredNorm();\n  if (n2 &gt; Scalar(0))\n    return Quaternion&lt;Scalar&gt;(conjugate().coeffs() / n2);\n  else {\n    // return an invalid result to flag the error\n    return Quaternion&lt;Scalar&gt;(Coefficients::Zero());\n  }\n}\n\n// Generic conjugate of a Quaternion\nnamespace internal {\ntemplate &lt;int Arch, class Derived, typename Scalar&gt;\nstruct quat_conj {\n  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Quaternion&lt;Scalar&gt; run(const QuaternionBase&lt;Derived&gt;&amp; q) {\n    return Quaternion&lt;Scalar&gt;(q.w(), -q.x(), -q.y(), -q.z());\n  }\n};\n}  // namespace internal\n\n/** \\returns the conjugate of the \\c *this which is equal to the multiplicative inverse\n * if the quaternion is normalized.\n * The conjugate of a quaternion represents the opposite rotation.\n *\n * \\sa Quaternion2::inverse()\n */\ntemplate &lt;class Derived&gt;\nEIGEN_DEVICE_FUNC inline Quaternion&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt; QuaternionBase&lt;Derived&gt;::conjugate()\n    const {\n  return internal::quat_conj&lt;Architecture::Target, Derived, typename internal::traits&lt;Derived&gt;::Scalar&gt;::run(*this);\n}\n\n/** \\returns the angle (in radian) between two rotations\n * \\sa dot()\n */\ntemplate &lt;class Derived&gt;\ntemplate &lt;class OtherDerived&gt;\nEIGEN_DEVICE_FUNC inline typename internal::traits&lt;Derived&gt;::Scalar QuaternionBase&lt;Derived&gt;::angularDistance(\n    const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n  EIGEN_USING_STD(atan2)\n  Quaternion&lt;Scalar&gt; d = (*this) * other.conjugate();\n  return Scalar(2) * atan2(d.vec().norm(), numext::abs(d.w()));\n}\n\n/** \\returns the spherical linear interpolation between the two quaternions\n * \\c *this and \\a other at the parameter \\a t in [0;1].\n *\n * This represents an interpolation for a constant motion between \\c *this and \\a other,\n * see also http://en.wikipedia.org/wiki/Slerp.\n */\ntemplate &lt;class Derived&gt;\ntemplate &lt;class OtherDerived&gt;\nEIGEN_DEVICE_FUNC Quaternion&lt;typename internal::traits&lt;Derived&gt;::Scalar&gt; QuaternionBase&lt;Derived&gt;::slerp(\n    const Scalar&amp; t, const QuaternionBase&lt;OtherDerived&gt;&amp; other) const {\n  EIGEN_USING_STD(acos)\n  EIGEN_USING_STD(sin)\n  const Scalar one = Scalar(1) - NumTraits&lt;Scalar&gt;::epsilon();\n  Scalar d = this-&gt;dot(other);\n  Scalar absD = numext::abs(d);\n\n  Scalar scale0;\n  Scalar scale1;\n\n  if (absD &gt;= one) {\n    scale0 = Scalar(1) - t;\n    scale1 = t;\n  } else {\n    // theta is the angle between the 2 quaternions\n    Scalar theta = acos(absD);\n    Scalar sinTheta = sin(theta);\n\n    scale0 = sin((Scalar(1) - t) * theta) / sinTheta;\n    scale1 = sin((t * theta)) / sinTheta;\n  }\n  if (d &lt; Scalar(0)) scale1 = -scale1;\n\n  return Quaternion&lt;Scalar&gt;(scale0 * coeffs() + scale1 * other.coeffs());\n}\n\nnamespace internal {\n\n// set from a rotation matrix\ntemplate &lt;typename Other&gt;\nstruct quaternionbase_assign_impl&lt;Other, 3, 3&gt; {\n  typedef typename Other::Scalar Scalar;\n  template &lt;class Derived&gt;\n  EIGEN_DEVICE_FUNC static inline void run(QuaternionBase&lt;Derived&gt;&amp; q, const Other&amp; a_mat) {\n    const typename internal::nested_eval&lt;Other, 2&gt;::type mat(a_mat);\n    EIGEN_USING_STD(sqrt)\n    // This algorithm comes from  &quot;Quaternion Calculus and Fast Animation&quot;,\n    // Ken Shoemake, 1987 SIGGRAPH course notes\n    Scalar t = mat.trace();\n    if (t &gt; Scalar(0)) {\n      t = sqrt(t + Scalar(1.0));\n      q.w() = Scalar(0.5) * t;\n      t = Scalar(0.5) / t;\n      q.x() = (mat.coeff(2, 1) - mat.coeff(1, 2)) * t;\n      q.y() = (mat.coeff(0, 2) - mat.coeff(2, 0)) * t;\n      q.z() = (mat.coeff(1, 0) - mat.coeff(0, 1)) * t;\n    } else {\n      Index i = 0;\n      if (mat.coeff(1, 1) &gt; mat.coeff(0, 0)) i = 1;\n      if (mat.coeff(2, 2) &gt; mat.coeff(i, i)) i = 2;\n      Index j = (i + 1) % 3;\n      Index k = (j + 1) % 3;\n\n      t = sqrt(mat.coeff(i, i) - mat.coeff(j, j) - mat.coeff(k, k) + Scalar(1.0));\n      q.coeffs().coeffRef(i) = Scalar(0.5) * t;\n      t = Scalar(0.5) / t;\n      q.w() = (mat.coeff(k, j) - mat.coeff(j, k)) * t;\n      q.coeffs().coeffRef(j) = (mat.coeff(j, i) + mat.coeff(i, j)) * t;\n      q.coeffs().coeffRef(k) = (mat.coeff(k, i) + mat.coeff(i, k)) * t;\n    }\n  }\n};\n\n// set from a vector of coefficients assumed to be a quaternion\ntemplate &lt;typename Other&gt;\nstruct quaternionbase_assign_impl&lt;Other, 4, 1&gt; {\n  typedef typename Other::Scalar Scalar;\n  template &lt;class Derived&gt;\n  EIGEN_DEVICE_FUNC static inline void run(QuaternionBase&lt;Derived&gt;&amp; q, const Other&amp; vec) {\n    q.coeffs() = vec;\n  }\n};\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_QUATERNION_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ROTATION2D_H\n#define EIGEN_ROTATION2D_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n/** \\geometry_module \\ingroup Geometry_Module\n *\n * \\class Rotation2D\n *\n * \\brief Represents a rotation/orientation in a 2 dimensional space.\n *\n * \\tparam Scalar_ the scalar type, i.e., the type of the coefficients\n *\n * This class is equivalent to a single scalar representing a counter clock wise rotation\n * as a single angle in radian. It provides some additional features such as the automatic\n * conversion from/to a 2x2 rotation matrix. Moreover this class aims to provide a similar\n * interface to Quaternion in order to facilitate the writing of generic algorithms\n * dealing with rotations.\n *\n * \\sa class Quaternion, class Transform\n */\n\nnamespace internal {\n\ntemplate &lt;typename Scalar_&gt;\nstruct traits&lt;Rotation2D&lt;Scalar_&gt; &gt; {\n  typedef Scalar_ Scalar;\n};\n}  // end namespace internal\n\ntemplate &lt;typename Scalar_&gt;\nclass Rotation2D : public RotationBase&lt;Rotation2D&lt;Scalar_&gt;, 2&gt; {\n  typedef RotationBase&lt;Rotation2D&lt;Scalar_&gt;, 2&gt; Base;\n\n public:\n  using Base::operator*;\n\n  enum { Dim = 2 };\n  /** the scalar type of the coefficients */\n  typedef Scalar_ Scalar;\n  typedef Matrix&lt;Scalar, 2, 1&gt; Vector2;\n  typedef Matrix&lt;Scalar, 2, 2&gt; Matrix2;\n\n protected:\n  Scalar m_angle;\n\n public:\n  /** Construct a 2D counter clock wise rotation from the angle \\a a in radian. */\n  EIGEN_DEVICE_FUNC explicit inline Rotation2D(const Scalar&amp; a) : m_angle(a) {}\n\n  /** Default constructor without initialization. The represented rotation is undefined. */\n  EIGEN_DEVICE_FUNC Rotation2D() {}\n\n  /** Construct a 2D rotation from a 2x2 rotation matrix \\a mat.\n   *\n   * \\sa fromRotationMatrix()\n   */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC explicit Rotation2D(const MatrixBase&lt;Derived&gt;&amp; m) {\n    fromRotationMatrix(m.derived());\n  }\n\n  /** \\returns the rotation angle */\n  EIGEN_DEVICE_FUNC inline Scalar angle() const { return m_angle; }\n\n  /** \\returns a read-write reference to the rotation angle */\n  EIGEN_DEVICE_FUNC inline Scalar&amp; angle() { return m_angle; }\n\n  /** \\returns the rotation angle in [0,2pi] */\n  EIGEN_DEVICE_FUNC inline Scalar smallestPositiveAngle() const {\n    Scalar tmp = numext::fmod(m_angle, Scalar(2 * EIGEN_PI));\n    return tmp &lt; Scalar(0) ? tmp + Scalar(2 * EIGEN_PI) : tmp;\n  }\n\n  /** \\returns the rotation angle in [-pi,pi] */\n  EIGEN_DEVICE_FUNC inline Scalar smallestAngle() const {\n    Scalar tmp = numext::fmod(m_angle, Scalar(2 * EIGEN_PI));\n    if (tmp &gt; Scalar(EIGEN_PI))\n      tmp -= Scalar(2 * EIGEN_PI);\n    else if (tmp &lt; -Scalar(EIGEN_PI))\n      tmp += Scalar(2 * EIGEN_PI);\n    return tmp;\n  }\n\n  /** \\returns the inverse rotation */\n  EIGEN_DEVICE_FUNC inline Rotation2D inverse() const { return Rotation2D(-m_angle); }\n\n  /** Concatenates two rotations */\n  EIGEN_DEVICE_FUNC inline Rotation2D operator*(const Rotation2D&amp; other) const {\n    return Rotation2D(m_angle + other.m_angle);\n  }\n\n  /** Concatenates two rotations */\n  EIGEN_DEVICE_FUNC inline Rotation2D&amp; operator*=(const Rotation2D&amp; other) {\n    m_angle += other.m_angle;\n    return *this;\n  }\n\n  /** Applies the rotation to a 2D vector */\n  EIGEN_DEVICE_FUNC Vector2 operator*(const Vector2&amp; vec) const { return toRotationMatrix() * vec; }\n\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC Rotation2D&amp; fromRotationMatrix(const MatrixBase&lt;Derived&gt;&amp; m);\n  EIGEN_DEVICE_FUNC Matrix2 toRotationMatrix() const;\n\n  /** Set \\c *this from a 2x2 rotation matrix \\a mat.\n   * In other words, this function extract the rotation angle from the rotation matrix.\n   *\n   * This method is an alias for fromRotationMatrix()\n   *\n   * \\sa fromRotationMatrix()\n   */\n  template &lt;typename Derived&gt;\n  EIGEN_DEVICE_FUNC Rotation2D&amp; operator=(const MatrixBase&lt;Derived&gt;&amp; m) {\n    return fromRotationMatrix(m.derived());\n  }\n\n  /** \\returns the spherical interpolation between \\c *this and \\a other using\n   * parameter \\a t. It is in fact equivalent to a linear interpolation.\n   */\n  EIGEN_DEVICE_FUNC inline Rotation2D slerp(const Scalar&amp; t, const Rotation2D&amp; other) const {\n    Scalar dist = Rotation2D(other.m_angle - m_angle).smallestAngle();\n    return Rotation2D(m_angle + dist * t);\n  }\n\n  /** \\returns \\c *this with scalar type casted to \\a NewScalarType\n   *\n   * Note that if \\a NewScalarType is equal to the current scalar type of \\c *this\n   * then this function smartly returns a const reference to \\c *this.\n   */\n  template &lt;typename NewScalarType&gt;\n  EIGEN_DEVICE_FUNC inline typename internal::cast_return_type&lt;Rotation2D, Rotation2D&lt;NewScalarType&gt; &gt;::type cast()\n      const {\n    return typename internal::cast_return_type&lt;Rotation2D, Rotation2D&lt;NewScalarType&gt; &gt;::type(*this);\n  }\n\n  /** Copy constructor with scalar type conversion */\n  template &lt;typename OtherScalarType&gt;\n  EIGEN_DEVICE_FUNC inline explicit Rotation2D(const Rotation2D&lt;OtherScalarType&gt;&amp; other) {\n    m_angle = Scalar(other.angle());\n  }\n\n  EIGEN_DEVICE_FUNC static inline Rotation2D Identity() { return Rotation2D(0); }\n\n  /** \\returns \\c true if \\c *this is approximately equal to \\a other, within the precision\n   * determined by \\a prec.\n   *\n   * \\sa MatrixBase::isApprox() */\n  EIGEN_DEVICE_FUNC bool isApprox(const Rotation2D&amp; other, const typename NumTraits&lt;Scalar&gt;::Real&amp; prec =\n                                                               NumTraits&lt;Scalar&gt;::dummy_precision()) const {\n    return internal::isApprox(m_angle, other.m_angle, prec);\n  }\n};\n\n/** \\ingroup Geometry_Module\n * single precision 2D rotation type */\ntypedef Rotation2D&lt;float&gt; Rotation2Df;\n/** \\ingroup Geometry_Module\n * double precision 2D rotation type */\ntypedef Rotation2D&lt;double&gt; Rotation2Dd;\n\n/** Set \\c *this from a 2x2 rotation matrix \\a mat.\n * In other words, this function extract the rotation angle\n * from the rotation matrix.\n */\ntemplate &lt;typename Scalar&gt;\ntemplate &lt;typename Derived&gt;\nEIGEN_DEVICE_FUNC Rotation2D&lt;Scalar&gt;&amp; Rotation2D&lt;Scalar&gt;::fromRotationMatrix(const MatrixBase&lt;Derived&gt;&amp; mat) {\n  EIGEN_USING_STD(atan2)\n  EIGEN_STATIC_ASSERT(Derived::RowsAtCompileTime == 2 &amp;&amp; Derived::ColsAtCompileTime == 2,\n                      YOU_MADE_A_PROGRAMMING_MISTAKE)\n  m_angle = atan2(mat.coeff(1, 0), mat.coeff(0, 0));\n  return *this;\n}\n\n/** Constructs and \\returns an equivalent 2x2 rotation matrix.\n */\ntemplate &lt;typename Scalar&gt;\ntypename Rotation2D&lt;Scalar&gt;::Matrix2 EIGEN_DEVICE_FUNC Rotation2D&lt;Scalar&gt;::toRotationMatrix(void) const {\n  EIGEN_USING_STD(sin)\n  EIGEN_USING_STD(cos)\n  Scalar sinA = sin(m_angle);\n  Scalar cosA = cos(m_angle);\n  return (Matrix2() &lt;&lt; cosA, -sinA, sinA, cosA).finished();\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ROTATION2D_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2008 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_ROTATIONBASE_H\n#define EIGEN_ROTATIONBASE_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\n// forward declaration\nnamespace internal {\ntemplate &lt;typename RotationDerived, typename MatrixType, bool IsVector = MatrixType::IsVectorAtCompileTime&gt;\nstruct rotation_base_generic_product_selector;\n}\n\n/** \\class RotationBase\n *\n * \\brief Common base class for compact rotation representations\n *\n * \\tparam Derived is the derived type, i.e., a rotation type\n * \\tparam Dim_ the dimension of the space\n */\ntemplate &lt;typename Derived, int Dim_&gt;\nclass RotationBase {\n public:\n  enum { Dim = Dim_ };\n  /** the scalar type of the coefficients */\n  typedef typename internal::traits&lt;Derived&gt;::Scalar Scalar;\n\n  /** corresponding linear transformation matrix type */\n  typedef Matrix&lt;Scalar, Dim, Dim&gt; RotationMatrixType;\n  typedef Matrix&lt;Scalar, Dim, 1&gt; VectorType;\n\n public:\n  EIGEN_DEVICE_FUNC inline const Derived&amp; derived() const { return *static_cast&lt;const Derived*&gt;(this); }\n  EIGEN_DEVICE_FUNC inline Derived&amp; derived() { return *static_cast&lt;Derived*&gt;(this); }\n\n  /** \\returns an equivalent rotation matrix */\n  EIGEN_DEVICE_FUNC inline RotationMatrixType toRotationMatrix() const { return derived().toRotationMatrix(); }\n\n  /** \\returns an equivalent rotation matrix\n   * This function is added to be conform with the Transform class&#x27; naming scheme.\n   */\n  EIGEN_DEVICE_FUNC inline RotationMatrixType matrix() const { return derived().toRotationMatrix(); }\n\n  /** \\returns the inverse rotation */\n  EIGEN_DEVICE_FUNC inline Derived inverse() const { return derived().inverse(); }\n\n  /** \\returns the concatenation of the rotation \\c *this with a translation \\a t */\n  EIGEN_DEVICE_FUNC inline Transform&lt;Scalar, Dim, Isometry&gt; operator*(const Translation&lt;Scalar, Dim&gt;&amp; t) const {\n    return Transform&lt;Scalar, Dim, Isometry&gt;(*this) * t;\n  }\n\n  /** \\returns the concatenation of the rotation \\c *this with a uniform scaling \\a s */\n  EIGEN_DEVICE_FUNC inline RotationMatrixType operator*(const UniformScaling&lt;Scalar&gt;&amp; s) const {\n    return toRotationMatrix() * s.factor();\n  }\n\n  /** \\returns the concatenation of the rotation \\c *this with a generic expression \\a e\n   * \\a e can be:\n   *  - a DimxDim linear transformation matrix\n   *  - a DimxDim diagonal matrix (axis aligned scaling)\n   *  - a vector of size Dim\n   */\n  template &lt;typename OtherDerived&gt;\n  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE\n      typename internal::rotation_base_generic_product_selector&lt;Derived, OtherDerived,\n                                                                OtherDerived::IsVectorAtCompileTime&gt;::ReturnType\n      operator*(const EigenBase&lt;OtherDerived&gt;&amp; e) const {\n    return internal::rotation_base_generic_product_selector&lt;Derived, OtherDerived&gt;::run(derived(), e.derived());\n  }\n\n  /** \\returns the concatenation of a linear transformation \\a l with the rotation \\a r */\n  template &lt;typename OtherDerived&gt;\n  friend EIGEN_DEVICE_FUNC inline RotationMatrixType operator*(const EigenBase&lt;OtherDerived&gt;&amp; l, const Derived&amp; r) {\n    return l.derived() * r.toRotationMatrix();\n  }\n\n  /** \\returns the concatenation of a scaling \\a l with the rotation \\a r */\n  EIGEN_DEVICE_FUNC friend inline Transform&lt;Scalar, Dim, Affine&gt; operator*(const DiagonalMatrix&lt;Scalar, Dim&gt;&amp; l,\n                                                                           const Derived&amp; r) {\n    Transform&lt;Scalar, Dim, Affine&gt; res(r);\n    res.linear().applyOnTheLeft(l);\n    return res;\n  }\n\n  /** \\returns the concatenation of the rotation \\c *this with a transformation \\a t */\n  template &lt;int Mode, int Options&gt;\n  EIGEN_DEVICE_FUNC inline Transform&lt;Scalar, Dim, Mode&gt; operator*(\n      const Transform&lt;Scalar, Dim, Mode, Options&gt;&amp; t) const {\n    return toRotationMatrix() * t;\n  }\n\n  template &lt;typename OtherVectorType&gt;\n  EIGEN_DEVICE_FUNC inline VectorType _transformVector(const OtherVectorType&amp; v) const {\n    return toRotationMatrix() * v;\n  }\n};\n\nnamespace internal {\n\n// implementation of the generic product rotation * matrix\ntemplate &lt;typename RotationDerived, typename MatrixType&gt;\nstruct rotation_base_generic_product_selector&lt;RotationDerived, MatrixType, false&gt; {\n  enum { Dim = RotationDerived::Dim };\n  typedef Matrix&lt;typename RotationDerived::Scalar, Dim, Dim&gt; ReturnType;\n  EIGEN_DEVICE_FUNC static inline ReturnType run(const RotationDerived&amp; r, const MatrixType&amp; m) {\n    return r.toRotationMatrix() * m;\n  }\n};\n\ntemplate &lt;typename RotationDerived, typename Scalar, int Dim, int MaxDim&gt;\nstruct rotation_base_generic_product_selector&lt;RotationDerived, DiagonalMatrix&lt;Scalar, Dim, MaxDim&gt;, false&gt; {\n  typedef Transform&lt;Scalar, Dim, Affine&gt; ReturnType;\n  EIGEN_DEVICE_FUNC static inline ReturnType run(const RotationDerived&amp; r,\n                                                 const DiagonalMatrix&lt;Scalar, Dim, MaxDim&gt;&amp; m) {\n    ReturnType res(r);\n    res.linear() *= m;\n    return res;\n  }\n};\n\ntemplate &lt;typename RotationDerived, typename OtherVectorType&gt;\nstruct rotation_base_generic_product_selector&lt;RotationDerived, OtherVectorType, true&gt; {\n  enum { Dim = RotationDerived::Dim };\n  typedef Matrix&lt;typename RotationDerived::Scalar, Dim, 1&gt; ReturnType;\n  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE ReturnType run(const RotationDerived&amp; r, const OtherVectorType&amp; v) {\n    return r._transformVector(v);\n  }\n};\n\n}  // end namespace internal\n\n/** \\geometry_module\n *\n * \\brief Constructs a Dim x Dim rotation matrix from the rotation \\a r\n */\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Storage_, int MaxRows_, int MaxCols_&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Matrix&lt;Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_&gt;::Matrix(\n    const RotationBase&lt;OtherDerived, ColsAtCompileTime&gt;&amp; r) {\n  EIGEN_STATIC_ASSERT_MATRIX_SPECIFIC_SIZE(Matrix, int(OtherDerived::Dim), int(OtherDerived::Dim))\n  *this = r.toRotationMatrix();\n}\n\n/** \\geometry_module\n *\n * \\brief Set a Dim x Dim rotation matrix from the rotation \\a r\n */\ntemplate &lt;typename Scalar_, int Rows_, int Cols_, int Storage_, int MaxRows_, int MaxCols_&gt;\ntemplate &lt;typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC Matrix&lt;Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_&gt;&amp;\nMatrix&lt;Scalar_, Rows_, Cols_, Storage_, MaxRows_, MaxCols_&gt;::operator=(\n    const RotationBase&lt;OtherDerived, ColsAtCompileTime&gt;&amp; r) {\n  EIGEN_STATIC_ASSERT_MATRIX_SPECIFIC_SIZE(Matrix, int(OtherDerived::Dim), int(OtherDerived::Dim))\n  return *this = r.toRotationMatrix();\n}\n\nnamespace internal {\n\n/** \\internal\n *\n * Helper function to return an arbitrary rotation object to a rotation matrix.\n *\n * \\tparam Scalar the numeric type of the matrix coefficients\n * \\tparam Dim the dimension of the current space\n *\n * It returns a Dim x Dim fixed size matrix.\n *\n * Default specializations are provided for:\n *   - any scalar type (2D),\n *   - any matrix expression,\n *   - any type based on RotationBase (e.g., Quaternion, AngleAxis, Rotation2D)\n *\n * Currently toRotationMatrix is only used by Transform.\n *\n * \\sa class Transform, class Rotation2D, class Quaternion, class AngleAxis\n */\ntemplate &lt;typename Scalar, int Dim&gt;\nEIGEN_DEVICE_FUNC static inline Matrix&lt;Scalar, 2, 2&gt; toRotationMatrix(const Scalar&amp; s) {\n  EIGEN_STATIC_ASSERT(Dim == 2, YOU_MADE_A_PROGRAMMING_MISTAKE)\n  return Rotation2D&lt;Scalar&gt;(s).toRotationMatrix();\n}\n\ntemplate &lt;typename Scalar, int Dim, typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC static inline Matrix&lt;Scalar, Dim, Dim&gt; toRotationMatrix(const RotationBase&lt;OtherDerived, Dim&gt;&amp; r) {\n  return r.toRotationMatrix();\n}\n\ntemplate &lt;typename Scalar, int Dim, typename OtherDerived&gt;\nEIGEN_DEVICE_FUNC static inline const MatrixBase&lt;OtherDerived&gt;&amp; toRotationMatrix(const MatrixBase&lt;OtherDerived&gt;&amp; mat) {\n  EIGEN_STATIC_ASSERT(OtherDerived::RowsAtCompileTime == Dim &amp;&amp; OtherDerived::ColsAtCompileTime == Dim,\n                      YOU_MADE_A_PROGRAMMING_MISTAKE)\n  return mat;\n}\n\n}  // end namespace internal\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_ROTATIONBASE_H\n"}, "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h": {"id": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "filePath": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "content": "// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2009-2010 Benoit Jacob &lt;jacob.benoit.1@gmail.com&gt;\n// Copyright (C) 2013-2014 Gael Guennebaud &lt;gael.guennebaud@inria.fr&gt;\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef EIGEN_JACOBISVD_H\n#define EIGEN_JACOBISVD_H\n\n// IWYU pragma: private\n#include &quot;./InternalHeaderCheck.h&quot;\n\nnamespace Eigen {\n\nnamespace internal {\n\n// forward declaration (needed by ICC)\n// the empty body is required by MSVC\ntemplate &lt;typename MatrixType, int Options, bool IsComplex = NumTraits&lt;typename MatrixType::Scalar&gt;::IsComplex&gt;\nstruct svd_precondition_2x2_block_to_be_real {};\n\n/*** QR preconditioners (R-SVD)\n ***\n *** Their role is to reduce the problem of computing the SVD to the case of a square matrix.\n *** This approach, known as R-SVD, is an optimization for rectangular-enough matrices, and is a requirement for\n *** JacobiSVD which by itself is only able to work on square matrices.\n ***/\n\nenum { PreconditionIfMoreColsThanRows, PreconditionIfMoreRowsThanCols };\n\ntemplate &lt;typename MatrixType, int QRPreconditioner, int Case&gt;\nstruct qr_preconditioner_should_do_anything {\n  enum {\n    a = MatrixType::RowsAtCompileTime != Dynamic &amp;&amp; MatrixType::ColsAtCompileTime != Dynamic &amp;&amp;\n        MatrixType::ColsAtCompileTime &lt;= MatrixType::RowsAtCompileTime,\n    b = MatrixType::RowsAtCompileTime != Dynamic &amp;&amp; MatrixType::ColsAtCompileTime != Dynamic &amp;&amp;\n        MatrixType::RowsAtCompileTime &lt;= MatrixType::ColsAtCompileTime,\n    ret = !((QRPreconditioner == NoQRPreconditioner) || (Case == PreconditionIfMoreColsThanRows &amp;&amp; bool(a)) ||\n            (Case == PreconditionIfMoreRowsThanCols &amp;&amp; bool(b)))\n  };\n};\n\ntemplate &lt;typename MatrixType, int Options, int QRPreconditioner, int Case,\n          bool DoAnything = qr_preconditioner_should_do_anything&lt;MatrixType, QRPreconditioner, Case&gt;::ret&gt;\nstruct qr_preconditioner_impl {};\n\ntemplate &lt;typename MatrixType, int Options, int QRPreconditioner, int Case&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, QRPreconditioner, Case, false&gt; {\n public:\n  void allocate(const JacobiSVD&lt;MatrixType, Options&gt;&amp;) {}\n  template &lt;typename Xpr&gt;\n  bool run(JacobiSVD&lt;MatrixType, Options&gt;&amp;, const Xpr&amp;) {\n    return false;\n  }\n};\n\n/*** preconditioner using FullPivHouseholderQR ***/\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, FullPivHouseholderQRPreconditioner, PreconditionIfMoreRowsThanCols,\n                             true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum { WorkspaceSize = MatrixType::RowsAtCompileTime, MaxWorkspaceSize = MatrixType::MaxRowsAtCompileTime };\n\n  typedef Matrix&lt;Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize&gt; WorkspaceType;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.rows(), svd.cols());\n    }\n    if (svd.m_computeFullU) m_workspace.resize(svd.rows());\n  }\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.rows() &gt; matrix.cols()) {\n      m_qr.compute(matrix);\n      svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView&lt;Upper&gt;();\n      if (svd.m_computeFullU) m_qr.matrixQ().evalTo(svd.m_matrixU, m_workspace);\n      if (svd.computeV()) svd.m_matrixV = m_qr.colsPermutation();\n      return true;\n    }\n    return false;\n  }\n\n private:\n  typedef FullPivHouseholderQR&lt;MatrixType&gt; QRType;\n  QRType m_qr;\n  WorkspaceType m_workspace;\n};\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, FullPivHouseholderQRPreconditioner, PreconditionIfMoreColsThanRows,\n                             true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum {\n    RowsAtCompileTime = MatrixType::RowsAtCompileTime,\n    ColsAtCompileTime = MatrixType::ColsAtCompileTime,\n    MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,\n    MatrixOptions = traits&lt;MatrixType&gt;::Options\n  };\n\n  typedef typename internal::make_proper_matrix_type&lt;Scalar, ColsAtCompileTime, RowsAtCompileTime, MatrixOptions,\n                                                     MaxColsAtCompileTime, MaxRowsAtCompileTime&gt;::type\n      TransposeTypeWithSameStorageOrder;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.cols(), svd.rows());\n    }\n    if (svd.m_computeFullV) m_workspace.resize(svd.cols());\n  }\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.cols() &gt; matrix.rows()) {\n      m_qr.compute(matrix.adjoint());\n      svd.m_workMatrix =\n          m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView&lt;Upper&gt;().adjoint();\n      if (svd.m_computeFullV) m_qr.matrixQ().evalTo(svd.m_matrixV, m_workspace);\n      if (svd.computeU()) svd.m_matrixU = m_qr.colsPermutation();\n      return true;\n    } else\n      return false;\n  }\n\n private:\n  typedef FullPivHouseholderQR&lt;TransposeTypeWithSameStorageOrder&gt; QRType;\n  QRType m_qr;\n  typename plain_row_type&lt;MatrixType&gt;::type m_workspace;\n};\n\n/*** preconditioner using ColPivHouseholderQR ***/\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, ColPivHouseholderQRPreconditioner, PreconditionIfMoreRowsThanCols,\n                             true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum {\n    WorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixUColsAtCompileTime,\n    MaxWorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixUMaxColsAtCompileTime\n  };\n\n  typedef Matrix&lt;Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize&gt; WorkspaceType;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.rows(), svd.cols());\n    }\n    if (svd.m_computeFullU)\n      m_workspace.resize(svd.rows());\n    else if (svd.m_computeThinU)\n      m_workspace.resize(svd.cols());\n  }\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.rows() &gt; matrix.cols()) {\n      m_qr.compute(matrix);\n      svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView&lt;Upper&gt;();\n      if (svd.m_computeFullU)\n        m_qr.householderQ().evalTo(svd.m_matrixU, m_workspace);\n      else if (svd.m_computeThinU) {\n        svd.m_matrixU.setIdentity(matrix.rows(), matrix.cols());\n        m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixU, m_workspace);\n      }\n      if (svd.computeV()) svd.m_matrixV = m_qr.colsPermutation();\n      return true;\n    }\n    return false;\n  }\n\n private:\n  typedef ColPivHouseholderQR&lt;MatrixType&gt; QRType;\n  QRType m_qr;\n  WorkspaceType m_workspace;\n};\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, ColPivHouseholderQRPreconditioner, PreconditionIfMoreColsThanRows,\n                             true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum {\n    RowsAtCompileTime = MatrixType::RowsAtCompileTime,\n    ColsAtCompileTime = MatrixType::ColsAtCompileTime,\n    MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,\n    MatrixOptions = internal::traits&lt;MatrixType&gt;::Options,\n    WorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixVColsAtCompileTime,\n    MaxWorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixVMaxColsAtCompileTime\n  };\n\n  typedef Matrix&lt;Scalar, WorkspaceSize, 1, ColMajor, MaxWorkspaceSize, 1&gt; WorkspaceType;\n\n  typedef typename internal::make_proper_matrix_type&lt;Scalar, ColsAtCompileTime, RowsAtCompileTime, MatrixOptions,\n                                                     MaxColsAtCompileTime, MaxRowsAtCompileTime&gt;::type\n      TransposeTypeWithSameStorageOrder;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.cols(), svd.rows());\n    }\n    if (svd.m_computeFullV)\n      m_workspace.resize(svd.cols());\n    else if (svd.m_computeThinV)\n      m_workspace.resize(svd.rows());\n  }\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.cols() &gt; matrix.rows()) {\n      m_qr.compute(matrix.adjoint());\n\n      svd.m_workMatrix =\n          m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView&lt;Upper&gt;().adjoint();\n      if (svd.m_computeFullV)\n        m_qr.householderQ().evalTo(svd.m_matrixV, m_workspace);\n      else if (svd.m_computeThinV) {\n        svd.m_matrixV.setIdentity(matrix.cols(), matrix.rows());\n        m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixV, m_workspace);\n      }\n      if (svd.computeU()) svd.m_matrixU = m_qr.colsPermutation();\n      return true;\n    } else\n      return false;\n  }\n\n private:\n  typedef ColPivHouseholderQR&lt;TransposeTypeWithSameStorageOrder&gt; QRType;\n  QRType m_qr;\n  WorkspaceType m_workspace;\n};\n\n/*** preconditioner using HouseholderQR ***/\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, HouseholderQRPreconditioner, PreconditionIfMoreRowsThanCols, true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum {\n    WorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixUColsAtCompileTime,\n    MaxWorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixUMaxColsAtCompileTime\n  };\n\n  typedef Matrix&lt;Scalar, 1, WorkspaceSize, RowMajor, 1, MaxWorkspaceSize&gt; WorkspaceType;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.rows() != m_qr.rows() || svd.cols() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.rows(), svd.cols());\n    }\n    if (svd.m_computeFullU)\n      m_workspace.resize(svd.rows());\n    else if (svd.m_computeThinU)\n      m_workspace.resize(svd.cols());\n  }\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.rows() &gt; matrix.cols()) {\n      m_qr.compute(matrix);\n      svd.m_workMatrix = m_qr.matrixQR().block(0, 0, matrix.cols(), matrix.cols()).template triangularView&lt;Upper&gt;();\n      if (svd.m_computeFullU)\n        m_qr.householderQ().evalTo(svd.m_matrixU, m_workspace);\n      else if (svd.m_computeThinU) {\n        svd.m_matrixU.setIdentity(matrix.rows(), matrix.cols());\n        m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixU, m_workspace);\n      }\n      if (svd.computeV()) svd.m_matrixV.setIdentity(matrix.cols(), matrix.cols());\n      return true;\n    }\n    return false;\n  }\n\n private:\n  typedef HouseholderQR&lt;MatrixType&gt; QRType;\n  QRType m_qr;\n  WorkspaceType m_workspace;\n};\n\ntemplate &lt;typename MatrixType, int Options&gt;\nclass qr_preconditioner_impl&lt;MatrixType, Options, HouseholderQRPreconditioner, PreconditionIfMoreColsThanRows, true&gt; {\n public:\n  typedef typename MatrixType::Scalar Scalar;\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVDType;\n\n  enum {\n    RowsAtCompileTime = MatrixType::RowsAtCompileTime,\n    ColsAtCompileTime = MatrixType::ColsAtCompileTime,\n    MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,\n    MatrixOptions = internal::traits&lt;MatrixType&gt;::Options,\n    WorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixVColsAtCompileTime,\n    MaxWorkspaceSize = internal::traits&lt;SVDType&gt;::MatrixVMaxColsAtCompileTime\n  };\n\n  typedef Matrix&lt;Scalar, WorkspaceSize, 1, ColMajor, MaxWorkspaceSize, 1&gt; WorkspaceType;\n\n  typedef typename internal::make_proper_matrix_type&lt;Scalar, ColsAtCompileTime, RowsAtCompileTime, MatrixOptions,\n                                                     MaxColsAtCompileTime, MaxRowsAtCompileTime&gt;::type\n      TransposeTypeWithSameStorageOrder;\n\n  void allocate(const SVDType&amp; svd) {\n    if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols()) {\n      internal::destroy_at(&amp;m_qr);\n      internal::construct_at(&amp;m_qr, svd.cols(), svd.rows());\n    }\n    if (svd.m_computeFullV)\n      m_workspace.resize(svd.cols());\n    else if (svd.m_computeThinV)\n      m_workspace.resize(svd.rows());\n  }\n\n  template &lt;typename Xpr&gt;\n  bool run(SVDType&amp; svd, const Xpr&amp; matrix) {\n    if (matrix.cols() &gt; matrix.rows()) {\n      m_qr.compute(matrix.adjoint());\n\n      svd.m_workMatrix =\n          m_qr.matrixQR().block(0, 0, matrix.rows(), matrix.rows()).template triangularView&lt;Upper&gt;().adjoint();\n      if (svd.m_computeFullV)\n        m_qr.householderQ().evalTo(svd.m_matrixV, m_workspace);\n      else if (svd.m_computeThinV) {\n        svd.m_matrixV.setIdentity(matrix.cols(), matrix.rows());\n        m_qr.householderQ().applyThisOnTheLeft(svd.m_matrixV, m_workspace);\n      }\n      if (svd.computeU()) svd.m_matrixU.setIdentity(matrix.rows(), matrix.rows());\n      return true;\n    } else\n      return false;\n  }\n\n private:\n  typedef HouseholderQR&lt;TransposeTypeWithSameStorageOrder&gt; QRType;\n  QRType m_qr;\n  WorkspaceType m_workspace;\n};\n\n/*** 2x2 SVD implementation\n ***\n *** JacobiSVD consists in performing a series of 2x2 SVD subproblems\n ***/\n\ntemplate &lt;typename MatrixType, int Options&gt;\nstruct svd_precondition_2x2_block_to_be_real&lt;MatrixType, Options, false&gt; {\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVD;\n  typedef typename MatrixType::RealScalar RealScalar;\n  static bool run(typename SVD::WorkMatrixType&amp;, SVD&amp;, Index, Index, RealScalar&amp;) { return true; }\n};\n\ntemplate &lt;typename MatrixType, int Options&gt;\nstruct svd_precondition_2x2_block_to_be_real&lt;MatrixType, Options, true&gt; {\n  typedef JacobiSVD&lt;MatrixType, Options&gt; SVD;\n  typedef typename MatrixType::Scalar Scalar;\n  typedef typename MatrixType::RealScalar RealScalar;\n  static bool run(typename SVD::WorkMatrixType&amp; work_matrix, SVD&amp; svd, Index p, Index q, RealScalar&amp; maxDiagEntry) {\n    using std::abs;\n    using std::sqrt;\n    Scalar z;\n    JacobiRotation&lt;Scalar&gt; rot;\n    RealScalar n = sqrt(numext::abs2(work_matrix.coeff(p, p)) + numext::abs2(work_matrix.coeff(q, p)));\n\n    const RealScalar considerAsZero = (std::numeric_limits&lt;RealScalar&gt;::min)();\n    const RealScalar precision = NumTraits&lt;Scalar&gt;::epsilon();\n\n    if (numext::is_exactly_zero(n)) {\n      // make sure first column is zero\n      work_matrix.coeffRef(p, p) = work_matrix.coeffRef(q, p) = Scalar(0);\n\n      if (abs(numext::imag(work_matrix.coeff(p, q))) &gt; considerAsZero) {\n        // work_matrix.coeff(p,q) can be zero if work_matrix.coeff(q,p) is not zero but small enough to underflow when\n        // computing n\n        z = abs(work_matrix.coeff(p, q)) / work_matrix.coeff(p, q);\n        work_matrix.row(p) *= z;\n        if (svd.computeU()) svd.m_matrixU.col(p) *= conj(z);\n      }\n      if (abs(numext::imag(work_matrix.coeff(q, q))) &gt; considerAsZero) {\n        z = abs(work_matrix.coeff(q, q)) / work_matrix.coeff(q, q);\n        work_matrix.row(q) *= z;\n        if (svd.computeU()) svd.m_matrixU.col(q) *= conj(z);\n      }\n      // otherwise the second row is already zero, so we have nothing to do.\n    } else {\n      rot.c() = conj(work_matrix.coeff(p, p)) / n;\n      rot.s() = work_matrix.coeff(q, p) / n;\n      work_matrix.applyOnTheLeft(p, q, rot);\n      if (svd.computeU()) svd.m_matrixU.applyOnTheRight(p, q, rot.adjoint());\n      if (abs(numext::imag(work_matrix.coeff(p, q))) &gt; considerAsZero) {\n        z = abs(work_matrix.coeff(p, q)) / work_matrix.coeff(p, q);\n        work_matrix.col(q) *= z;\n        if (svd.computeV()) svd.m_matrixV.col(q) *= z;\n      }\n      if (abs(numext::imag(work_matrix.coeff(q, q))) &gt; considerAsZero) {\n        z = abs(work_matrix.coeff(q, q)) / work_matrix.coeff(q, q);\n        work_matrix.row(q) *= z;\n        if (svd.computeU()) svd.m_matrixU.col(q) *= conj(z);\n      }\n    }\n\n    // update largest diagonal entry\n    maxDiagEntry = numext::maxi&lt;RealScalar&gt;(\n        maxDiagEntry, numext::maxi&lt;RealScalar&gt;(abs(work_matrix.coeff(p, p)), abs(work_matrix.coeff(q, q))));\n    // and check whether the 2x2 block is already diagonal\n    RealScalar threshold = numext::maxi&lt;RealScalar&gt;(considerAsZero, precision * maxDiagEntry);\n    return abs(work_matrix.coeff(p, q)) &gt; threshold || abs(work_matrix.coeff(q, p)) &gt; threshold;\n  }\n};\n\ntemplate &lt;typename MatrixType_, int Options&gt;\nstruct traits&lt;JacobiSVD&lt;MatrixType_, Options&gt; &gt; : svd_traits&lt;MatrixType_, Options&gt; {\n  typedef MatrixType_ MatrixType;\n};\n\n}  // end namespace internal\n\n/** \\ingroup SVD_Module\n *\n *\n * \\class JacobiSVD\n *\n * \\brief Two-sided Jacobi SVD decomposition of a rectangular matrix\n *\n * \\tparam MatrixType_ the type of the matrix of which we are computing the SVD decomposition\n * \\tparam Options this optional parameter allows one to specify the type of QR decomposition that will be used\n * internally for the R-SVD step for non-square matrices. Additionally, it allows one to specify whether to compute thin\n * or full unitaries \\a U and \\a V. See discussion of possible values below.\n *\n * SVD decomposition consists in decomposing any n-by-p matrix \\a A as a product\n *   \\f[ A = U S V^* \\f]\n * where \\a U is a n-by-n unitary, \\a V is a p-by-p unitary, and \\a S is a n-by-p real positive matrix which is zero\n * outside of its main diagonal; the diagonal entries of S are known as the \\em singular \\em values of \\a A and the\n * columns of \\a U and \\a V are known as the left and right \\em singular \\em vectors of \\a A respectively.\n *\n * Singular values are always sorted in decreasing order.\n *\n * This JacobiSVD decomposition computes only the singular values by default. If you want \\a U or \\a V, you need to ask\n * for them explicitly.\n *\n * You can ask for only \\em thin \\a U or \\a V to be computed, meaning the following. In case of a rectangular n-by-p\n * matrix, letting \\a m be the smaller value among \\a n and \\a p, there are only \\a m singular vectors; the remaining\n * columns of \\a U and \\a V do not correspond to actual singular vectors. Asking for \\em thin \\a U or \\a V means asking\n * for only their \\a m first columns to be formed. So \\a U is then a n-by-m matrix, and \\a V is then a p-by-m matrix.\n * Notice that thin \\a U and \\a V are all you need for (least squares) solving.\n *\n * Here&#x27;s an example demonstrating basic usage:\n * \\include JacobiSVD_basic.cpp\n * Output: \\verbinclude JacobiSVD_basic.out\n *\n * This JacobiSVD class is a two-sided Jacobi R-SVD decomposition, ensuring optimal reliability and accuracy. The\n * downside is that it&#x27;s slower than bidiagonalizing SVD algorithms for large square matrices; however its complexity is\n * still \\f$ O(n^2p) \\f$ where \\a n is the smaller dimension and \\a p is the greater dimension, meaning that it is still\n * of the same order of complexity as the faster bidiagonalizing R-SVD algorithms. In particular, like any R-SVD, it\n * takes advantage of non-squareness in that its complexity is only linear in the greater dimension.\n *\n * If the input matrix has inf or nan coefficients, the result of the computation is undefined, but the computation is\n * guaranteed to terminate in finite (and reasonable) time.\n *\n * The possible QR preconditioners that can be set with Options template parameter are:\n * \\li ColPivHouseholderQRPreconditioner is the default. In practice it&#x27;s very safe. It uses column-pivoting QR.\n * \\li FullPivHouseholderQRPreconditioner, is the safest and slowest. It uses full-pivoting QR.\n *     Contrary to other QRs, it doesn&#x27;t allow computing thin unitaries.\n * \\li HouseholderQRPreconditioner is the fastest, and less safe and accurate than the pivoting variants. It uses\n * non-pivoting QR. This is very similar in safety and accuracy to the bidiagonalization process used by bidiagonalizing\n * SVD algorithms (since bidiagonalization is inherently non-pivoting). However the resulting SVD is still more reliable\n * than bidiagonalizing SVDs because the Jacobi-based iterarive process is more reliable than the optimized bidiagonal\n * SVD iterations. \\li NoQRPreconditioner allows not to use a QR preconditioner at all. This is useful if you know that\n * you will only be computing JacobiSVD decompositions of square matrices. Non-square matrices require a QR\n * preconditioner. Using this option will result in faster compilation and smaller executable code. It won&#x27;t\n * significantly speed up computation, since JacobiSVD is always checking if QR preconditioning is needed before\n * applying it anyway.\n *\n * One may also use the Options template parameter to specify how the unitaries should be computed. The options are\n * #ComputeThinU, #ComputeThinV, #ComputeFullU, #ComputeFullV. It is not possible to request both the thin and full\n * versions of a unitary. By default, unitaries will not be computed.\n *\n * You can set the QRPreconditioner and unitary options together: JacobiSVD&lt;MatrixType,\n * ColPivHouseholderQRPreconditioner | ComputeThinU | ComputeFullV&gt;\n *\n * \\sa MatrixBase::jacobiSvd()\n */\ntemplate &lt;typename MatrixType_, int Options_&gt;\nclass JacobiSVD : public SVDBase&lt;JacobiSVD&lt;MatrixType_, Options_&gt; &gt; {\n  typedef SVDBase&lt;JacobiSVD&gt; Base;\n\n public:\n  typedef MatrixType_ MatrixType;\n  typedef typename Base::Scalar Scalar;\n  typedef typename Base::RealScalar RealScalar;\n  enum : int {\n    Options = Options_,\n    QRPreconditioner = internal::get_qr_preconditioner(Options),\n    RowsAtCompileTime = Base::RowsAtCompileTime,\n    ColsAtCompileTime = Base::ColsAtCompileTime,\n    DiagSizeAtCompileTime = Base::DiagSizeAtCompileTime,\n    MaxRowsAtCompileTime = Base::MaxRowsAtCompileTime,\n    MaxColsAtCompileTime = Base::MaxColsAtCompileTime,\n    MaxDiagSizeAtCompileTime = Base::MaxDiagSizeAtCompileTime,\n    MatrixOptions = Base::MatrixOptions\n  };\n\n  typedef typename Base::MatrixUType MatrixUType;\n  typedef typename Base::MatrixVType MatrixVType;\n  typedef typename Base::SingularValuesType SingularValuesType;\n  typedef Matrix&lt;Scalar, DiagSizeAtCompileTime, DiagSizeAtCompileTime, MatrixOptions, MaxDiagSizeAtCompileTime,\n                 MaxDiagSizeAtCompileTime&gt;\n      WorkMatrixType;\n\n  /** \\brief Default Constructor.\n   *\n   * The default constructor is useful in cases in which the user intends to\n   * perform decompositions via JacobiSVD::compute(const MatrixType&amp;).\n   */\n  JacobiSVD() {}\n\n  /** \\brief Default Constructor with memory preallocation\n   *\n   * Like the default constructor but with preallocation of the internal data\n   * according to the specified problem size and \\a Options template parameter.\n   *\n   * \\sa JacobiSVD()\n   */\n  JacobiSVD(Index rows, Index cols) { allocate(rows, cols, internal::get_computation_options(Options)); }\n\n  /** \\brief Default Constructor with memory preallocation\n   *\n   * Like the default constructor but with preallocation of the internal data\n   * according to the specified problem size.\n   *\n   * One \\b cannot request unitaries using both the \\a Options template parameter\n   * and the constructor. If possible, prefer using the \\a Options template parameter.\n   *\n   * \\param rows number of rows for the input matrix\n   * \\param cols number of columns for the input matrix\n   * \\param computationOptions specify whether to compute Thin/Full unitaries U/V\n   * \\sa JacobiSVD()\n   *\n   * \\deprecated Will be removed in the next major Eigen version. Options should\n   * be specified in the \\a Options template parameter.\n   */\n  EIGEN_DEPRECATED JacobiSVD(Index rows, Index cols, unsigned int computationOptions) {\n    internal::check_svd_options_assertions&lt;MatrixType, Options&gt;(computationOptions, rows, cols);\n    allocate(rows, cols, computationOptions);\n  }\n\n  /** \\brief Constructor performing the decomposition of given matrix, using the custom options specified\n   *         with the \\a Options template parameter.\n   *\n   * \\param matrix the matrix to decompose\n   */\n  explicit JacobiSVD(const MatrixType&amp; matrix) { compute_impl(matrix, internal::get_computation_options(Options)); }\n\n  /** \\brief Constructor performing the decomposition of given matrix using specified options\n   *         for computing unitaries.\n   *\n   *  One \\b cannot request unitiaries using both the \\a Options template parameter\n   *  and the constructor. If possible, prefer using the \\a Options template parameter.\n   *\n   * \\param matrix the matrix to decompose\n   * \\param computationOptions specify whether to compute Thin/Full unitaries U/V\n   *\n   * \\deprecated Will be removed in the next major Eigen version. Options should\n   * be specified in the \\a Options template parameter.\n   */\n  // EIGEN_DEPRECATED // TODO(cantonios): re-enable after fixing a few 3p libraries that error on deprecation warnings.\n  JacobiSVD(const MatrixType&amp; matrix, unsigned int computationOptions) {\n    internal::check_svd_options_assertions&lt;MatrixType, Options&gt;(computationOptions, matrix.rows(), matrix.cols());\n    compute_impl(matrix, computationOptions);\n  }\n\n  /** \\brief Method performing the decomposition of given matrix. Computes Thin/Full unitaries U/V if specified\n   *         using the \\a Options template parameter or the class constructor.\n   *\n   * \\param matrix the matrix to decompose\n   */\n  JacobiSVD&amp; compute(const MatrixType&amp; matrix) { return compute_impl(matrix, m_computationOptions); }\n\n  /** \\brief Method performing the decomposition of given matrix, as specified by\n   *         the `computationOptions` parameter.\n   *\n   * \\param matrix the matrix to decompose\n   * \\param computationOptions specify whether to compute Thin/Full unitaries U/V\n   *\n   * \\deprecated Will be removed in the next major Eigen version. Options should\n   * be specified in the \\a Options template parameter.\n   */\n  EIGEN_DEPRECATED JacobiSVD&amp; compute(const MatrixType&amp; matrix, unsigned int computationOptions) {\n    internal::check_svd_options_assertions&lt;MatrixType, Options&gt;(m_computationOptions, matrix.rows(), matrix.cols());\n    return compute_impl(matrix, computationOptions);\n  }\n\n  using Base::cols;\n  using Base::computeU;\n  using Base::computeV;\n  using Base::diagSize;\n  using Base::rank;\n  using Base::rows;\n\n  void allocate(Index rows_, Index cols_, unsigned int computationOptions) {\n    if (Base::allocate(rows_, cols_, computationOptions)) return;\n    eigen_assert(!(ShouldComputeThinU &amp;&amp; int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &amp;&amp;\n                 !(ShouldComputeThinU &amp;&amp; int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &amp;&amp;\n                 &quot;JacobiSVD: can&#x27;t compute thin U or thin V with the FullPivHouseholderQR preconditioner. &quot;\n                 &quot;Use the ColPivHouseholderQR preconditioner instead.&quot;);\n\n    m_workMatrix.resize(diagSize(), diagSize());\n    if (cols() &gt; rows()) m_qr_precond_morecols.allocate(*this);\n    if (rows() &gt; cols()) m_qr_precond_morerows.allocate(*this);\n  }\n\n private:\n  JacobiSVD&amp; compute_impl(const MatrixType&amp; matrix, unsigned int computationOptions);\n\n protected:\n  using Base::m_computationOptions;\n  using Base::m_computeFullU;\n  using Base::m_computeFullV;\n  using Base::m_computeThinU;\n  using Base::m_computeThinV;\n  using Base::m_info;\n  using Base::m_isAllocated;\n  using Base::m_isInitialized;\n  using Base::m_matrixU;\n  using Base::m_matrixV;\n  using Base::m_nonzeroSingularValues;\n  using Base::m_prescribedThreshold;\n  using Base::m_singularValues;\n  using Base::m_usePrescribedThreshold;\n  using Base::ShouldComputeThinU;\n  using Base::ShouldComputeThinV;\n\n  EIGEN_STATIC_ASSERT(!(ShouldComputeThinU &amp;&amp; int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)) &amp;&amp;\n                          !(ShouldComputeThinU &amp;&amp; int(QRPreconditioner) == int(FullPivHouseholderQRPreconditioner)),\n                      &quot;JacobiSVD: can&#x27;t compute thin U or thin V with the FullPivHouseholderQR preconditioner. &quot;\n                      &quot;Use the ColPivHouseholderQR preconditioner instead.&quot;)\n\n  template &lt;typename MatrixType__, int Options__, bool IsComplex_&gt;\n  friend struct internal::svd_precondition_2x2_block_to_be_real;\n  template &lt;typename MatrixType__, int Options__, int QRPreconditioner_, int Case_, bool DoAnything_&gt;\n  friend struct internal::qr_preconditioner_impl;\n\n  internal::qr_preconditioner_impl&lt;MatrixType, Options, QRPreconditioner, internal::PreconditionIfMoreColsThanRows&gt;\n      m_qr_precond_morecols;\n  internal::qr_preconditioner_impl&lt;MatrixType, Options, QRPreconditioner, internal::PreconditionIfMoreRowsThanCols&gt;\n      m_qr_precond_morerows;\n  WorkMatrixType m_workMatrix;\n};\n\ntemplate &lt;typename MatrixType, int Options&gt;\nJacobiSVD&lt;MatrixType, Options&gt;&amp; JacobiSVD&lt;MatrixType, Options&gt;::compute_impl(const MatrixType&amp; matrix,\n                                                                             unsigned int computationOptions) {\n  using std::abs;\n\n  allocate(matrix.rows(), matrix.cols(), computationOptions);\n\n  // currently we stop when we reach precision 2*epsilon as the last bit of precision can require an unreasonable number\n  // of iterations, only worsening the precision of U and V as we accumulate more rotations\n  const RealScalar precision = RealScalar(2) * NumTraits&lt;Scalar&gt;::epsilon();\n\n  // limit for denormal numbers to be considered zero in order to avoid infinite loops (see bug 286)\n  const RealScalar considerAsZero = (std::numeric_limits&lt;RealScalar&gt;::min)();\n\n  // Scaling factor to reduce over/under-flows\n  RealScalar scale = matrix.cwiseAbs().template maxCoeff&lt;PropagateNaN&gt;();\n  if (!(numext::isfinite)(scale)) {\n    m_isInitialized = true;\n    m_info = InvalidInput;\n    m_nonzeroSingularValues = 0;\n    return *this;\n  }\n  if (numext::is_exactly_zero(scale)) scale = RealScalar(1);\n\n  /*** step 1. The R-SVD step: we use a QR decomposition to reduce to the case of a square matrix */\n\n  if (rows() != cols()) {\n    m_qr_precond_morecols.run(*this, matrix / scale);\n    m_qr_precond_morerows.run(*this, matrix / scale);\n  } else {\n    m_workMatrix =\n        matrix.template topLeftCorner&lt;DiagSizeAtCompileTime, DiagSizeAtCompileTime&gt;(diagSize(), diagSize()) / scale;\n    if (m_computeFullU) m_matrixU.setIdentity(rows(), rows());\n    if (m_computeThinU) m_matrixU.setIdentity(rows(), diagSize());\n    if (m_computeFullV) m_matrixV.setIdentity(cols(), cols());\n    if (m_computeThinV) m_matrixV.setIdentity(cols(), diagSize());\n  }\n\n  /*** step 2. The main Jacobi SVD iteration. ***/\n  RealScalar maxDiagEntry = m_workMatrix.cwiseAbs().diagonal().maxCoeff();\n\n  bool finished = false;\n  while (!finished) {\n    finished = true;\n\n    // do a sweep: for all index pairs (p,q), perform SVD of the corresponding 2x2 sub-matrix\n\n    for (Index p = 1; p &lt; diagSize(); ++p) {\n      for (Index q = 0; q &lt; p; ++q) {\n        // if this 2x2 sub-matrix is not diagonal already...\n        // notice that this comparison will evaluate to false if any NaN is involved, ensuring that NaN&#x27;s don&#x27;t\n        // keep us iterating forever. Similarly, small denormal numbers are considered zero.\n        RealScalar threshold = numext::maxi&lt;RealScalar&gt;(considerAsZero, precision * maxDiagEntry);\n        if (abs(m_workMatrix.coeff(p, q)) &gt; threshold || abs(m_workMatrix.coeff(q, p)) &gt; threshold) {\n          finished = false;\n          // perform SVD decomposition of 2x2 sub-matrix corresponding to indices p,q to make it diagonal\n          // the complex to real operation returns true if the updated 2x2 block is not already diagonal\n          if (internal::svd_precondition_2x2_block_to_be_real&lt;MatrixType, Options&gt;::run(m_workMatrix, *this, p, q,\n                                                                                        maxDiagEntry)) {\n            JacobiRotation&lt;RealScalar&gt; j_left, j_right;\n            internal::real_2x2_jacobi_svd(m_workMatrix, p, q, &amp;j_left, &amp;j_right);\n\n            // accumulate resulting Jacobi rotations\n            m_workMatrix.applyOnTheLeft(p, q, j_left);\n            if (computeU()) m_matrixU.applyOnTheRight(p, q, j_left.transpose());\n\n            m_workMatrix.applyOnTheRight(p, q, j_right);\n            if (computeV()) m_matrixV.applyOnTheRight(p, q, j_right);\n\n            // keep track of the largest diagonal coefficient\n            maxDiagEntry = numext::maxi&lt;RealScalar&gt;(\n                maxDiagEntry, numext::maxi&lt;RealScalar&gt;(abs(m_workMatrix.coeff(p, p)), abs(m_workMatrix.coeff(q, q))));\n          }\n        }\n      }\n    }\n  }\n\n  /*** step 3. The work matrix is now diagonal, so ensure it&#x27;s positive so its diagonal entries are the singular values\n   * ***/\n\n  for (Index i = 0; i &lt; diagSize(); ++i) {\n    // For a complex matrix, some diagonal coefficients might note have been\n    // treated by svd_precondition_2x2_block_to_be_real, and the imaginary part\n    // of some diagonal entry might not be null.\n    if (NumTraits&lt;Scalar&gt;::IsComplex &amp;&amp; abs(numext::imag(m_workMatrix.coeff(i, i))) &gt; considerAsZero) {\n      RealScalar a = abs(m_workMatrix.coeff(i, i));\n      m_singularValues.coeffRef(i) = abs(a);\n      if (computeU()) m_matrixU.col(i) *= m_workMatrix.coeff(i, i) / a;\n    } else {\n      // m_workMatrix.coeff(i,i) is already real, no difficulty:\n      RealScalar a = numext::real(m_workMatrix.coeff(i, i));\n      m_singularValues.coeffRef(i) = abs(a);\n      if (computeU() &amp;&amp; (a &lt; RealScalar(0))) m_matrixU.col(i) = -m_matrixU.col(i);\n    }\n  }\n\n  m_singularValues *= scale;\n\n  /*** step 4. Sort singular values in descending order and compute the number of nonzero singular values ***/\n\n  m_nonzeroSingularValues = diagSize();\n  for (Index i = 0; i &lt; diagSize(); i++) {\n    Index pos;\n    RealScalar maxRemainingSingularValue = m_singularValues.tail(diagSize() - i).maxCoeff(&amp;pos);\n    if (numext::is_exactly_zero(maxRemainingSingularValue)) {\n      m_nonzeroSingularValues = i;\n      break;\n    }\n    if (pos) {\n      pos += i;\n      std::swap(m_singularValues.coeffRef(i), m_singularValues.coeffRef(pos));\n      if (computeU()) m_matrixU.col(pos).swap(m_matrixU.col(i));\n      if (computeV()) m_matrixV.col(pos).swap(m_matrixV.col(i));\n    }\n  }\n\n  m_isInitialized = true;\n  return *this;\n}\n\n/** \\svd_module\n *\n * \\return the singular value decomposition of \\c *this computed by two-sided\n * Jacobi transformations.\n *\n * \\sa class JacobiSVD\n */\ntemplate &lt;typename Derived&gt;\ntemplate &lt;int Options&gt;\nJacobiSVD&lt;typename MatrixBase&lt;Derived&gt;::PlainObject, Options&gt; MatrixBase&lt;Derived&gt;::jacobiSvd() const {\n  return JacobiSVD&lt;PlainObject, Options&gt;(*this);\n}\n\ntemplate &lt;typename Derived&gt;\ntemplate &lt;int Options&gt;\nJacobiSVD&lt;typename MatrixBase&lt;Derived&gt;::PlainObject, Options&gt; MatrixBase&lt;Derived&gt;::jacobiSvd(\n    unsigned int computationOptions) const {\n  return JacobiSVD&lt;PlainObject, Options&gt;(*this, computationOptions);\n}\n\n}  // end namespace Eigen\n\n#endif  // EIGEN_JACOBISVD_H\n"}, "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp": {"id": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "filePath": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "content": "#include &quot;EulerBackwardStepSolver.h&quot;\n#include &lt;spdlog/spdlog.h&gt;\n#include &lt;Eigen/Dense&gt;\n\nnamespace PySysLinkBase\n{\n    std::tuple&lt;bool, std::vector&lt;double&gt;, double&gt; EulerBackwardStepSolver::SolveStep(std::function&lt;std::vector&lt;double&gt;(std::vector&lt;double&gt;, double)&gt; systemDerivatives,\n                                                                                std::function&lt;std::vector&lt;std::vector&lt;double&gt;&gt;(std::vector&lt;double&gt;, double)&gt; systemJacobian,\n                                                                                std::vector&lt;double&gt; states_0, double currentTime, double timeStep)\n    {\n        std::vector&lt;double&gt; statesEnd = states_0;\n\n        for (int i = 0; i &lt; this-&gt;maximumIterations; i++)\n        {\n            std::vector&lt;double&gt; statesEndOld = statesEnd;\n            std::vector&lt;double&gt; systemDerivativesEnd = systemDerivatives(statesEnd, currentTime + timeStep);\n            std::vector&lt;std::vector&lt;double&gt;&gt; systemJacobianEnd = systemJacobian(statesEnd, currentTime + timeStep);\n\n       \n            std::vector&lt;double&gt; delta = this-&gt;ComputeNewtonStep(systemJacobianEnd, systemDerivativesEnd, states_0, statesEnd, timeStep);\n\n            for (size_t j = 0; j &lt; statesEnd.size(); j++) {\n                statesEnd[j] += delta[j];\n            }\n\n            // Check convergence\n            double maxError = 0.0;\n            for (size_t j = 0; j &lt; statesEnd.size(); j++)\n            {\n                maxError = std::max(maxError, std::abs(statesEnd[j] - statesEndOld[j]));\n            }\n            \n            if (maxError &lt; this-&gt;tolerance)\n            {\n                systemDerivatives(states_0, currentTime);\n                return {true, statesEnd, timeStep};\n            }\n        }\n\n        systemDerivatives(states_0, currentTime);\n        return {true, statesEnd, timeStep};\n    }\n\n    std::vector&lt;double&gt; EulerBackwardStepSolver::ComputeNewtonStep(const std::vector&lt;std::vector&lt;double&gt;&gt;&amp; systemJacobianEnd,\n        const std::vector&lt;double&gt;&amp; systemDerivativesEnd, const std::vector&lt;double&gt;&amp; states_0, const std::vector&lt;double&gt;&amp; statesEnd,\n         double timeStep) \n    {\n        int rows = systemJacobianEnd.size();\n        if (rows == 0 || systemJacobianEnd[0].size() != rows) {\n            throw std::runtime_error(&quot;Jacobian must be a non-empty square matrix.&quot;);\n        }\n\n        Eigen::MatrixXd eigenJacobian(rows, rows);\n        for (int i = 0; i &lt; rows; i++) {\n            if (systemJacobianEnd[i].size() != rows) {\n                throw std::runtime_error(&quot;Jacobian must be a square matrix.&quot;);\n            }\n            for (int j = 0; j &lt; rows; j++) {\n                eigenJacobian(i, j) = systemJacobianEnd[i][j];\n            }\n        }\n\n        Eigen::VectorXd eigenDerivatives(rows);\n        for (int i = 0; i &lt; rows; i++) {\n            eigenDerivatives(i) = systemDerivativesEnd[i];\n        }\n\n        Eigen::VectorXd eigenStatesEnd(rows);\n        for (int i = 0; i &lt; rows; i++) {\n            eigenStatesEnd(i) = statesEnd[i];\n        }\n        Eigen::VectorXd eigenStates_0(rows);\n        for (int i = 0; i &lt; rows; i++) {\n            eigenStates_0(i) = states_0[i];\n        }\n\n        Eigen::VectorXd F = eigenStatesEnd - eigenStates_0 - timeStep * eigenDerivatives;\n        Eigen::MatrixXd dF = Eigen::MatrixXd::Identity(rows, rows) - timeStep * eigenJacobian;\n\n        Eigen::VectorXd delta = -dF.inverse() * F;\n\n        // Convert the result back to std::vector&lt;double&gt;\n        std::vector&lt;double&gt; deltaStd(delta.data(), delta.data() + delta.size());\n        return deltaStd;\n    }\n\n} // namespace PySysLinkBase\n"}}, "reports": [{"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc", "reportHash": "8812c4ddb6bd852200d5e824a738163f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc", "checker": {"name": "misc-header-include-cycle", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/header-include-cycle.html"}, "analyzerName": "clang-tidy", "line": 129, "column": 10, "message": "direct self-inclusion of header file 'ReshapedMethods.inc'", "events": [{"message": "direct self-inclusion of header file 'ReshapedMethods.inc'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/plugins/ReshapedMethods.inc", "line": 129, "column": 10}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "LOW", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "reportHash": "119c448d614cdd95b4fd9a8ec3786e9b", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 75, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "line": 75, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "reportHash": "afa3ef82b4673ada38fdd51c9702e1cf", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 102, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "line": 102, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "reportHash": "fdba89d09852e0e83a2801dde6fcb145", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 113, "column": 80, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Array.h", "line": 113, "column": 80}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "reportHash": "b6f78bb0ffb9f2f7cd33e8e46388bbf8", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 106, "column": 21, "message": "operator=() should return 'ArrayBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'ArrayBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "line": 106, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "reportHash": "84c7ca4ab89ec98c354e1c0b53c0ec2d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 113, "column": 21, "message": "operator=() should return 'ArrayBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'ArrayBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ArrayBase.h", "line": 113, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "2b012daeba377307f2bcd7ca75da49e3", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 37, "column": 1, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 37, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "2b012daeba377307f2bcd7ca75da49e3", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 44, "column": 1, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 44, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "94ad4a07528f9d70ecdb3e289170a63d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 50, "column": 1, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 50, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "e1f877fd42d2aadf0c8efdf747ea8692", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 51, "column": 19, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 51, "column": 19}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "94ad4a07528f9d70ecdb3e289170a63d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 56, "column": 1, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 56, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "7a2539f0a8ccad916a491d632d8dc7aa", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 58, "column": 19, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 58, "column": 19}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "94ad4a07528f9d70ecdb3e289170a63d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 63, "column": 1, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 63, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "reportHash": "94ad4a07528f9d70ecdb3e289170a63d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 70, "column": 1, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Assign.h", "line": 70, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "reportHash": "b84029e80d996e31f199083d3c55f0e7", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 263, "column": 21, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "line": 263, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "reportHash": "20489aa38e80d5a1068d6148513da41f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 268, "column": 21, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "line": 268, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "reportHash": "0b51dd985848d2e6a4d54125d3b94d37", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 271, "column": 21, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "line": 271, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "reportHash": "a88faafeb9b9c26b98ae3206d98cc969", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 280, "column": 21, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseBase.h", "line": 280, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "205b8d1ae6141e2ecb502004dc441354", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 113, "column": 56, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 113, "column": 56}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 113, "column": 88}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "205b8d1ae6141e2ecb502004dc441354", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 147, "column": 56, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 147, "column": 56}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 147, "column": 88}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "205b8d1ae6141e2ecb502004dc441354", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 185, "column": 56, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 185, "column": 56}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 185, "column": 88}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "205b8d1ae6141e2ecb502004dc441354", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 225, "column": 56, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 225, "column": 56}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 225, "column": 88}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "e603810af0e6b9e8cc88bf5f947ebcfa", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 252, "column": 56, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 252, "column": 56}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 252, "column": 82}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "ee94c90656da3bfc3971bebbd5b4d565", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-move-constructor", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-move-constructor.html"}, "analyzerName": "clang-tidy", "line": 568, "column": 51, "message": "move constructors should be marked noexcept", "events": [{"message": "move constructors should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 568, "column": 51}], "macros": [], "notes": [{"message": ": DenseStorage(static_cast<const DenseStorage&>(other)) {} (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 568, "column": 7}, {"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 568, "column": 2}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "reportHash": "be1fd3a7bc0d7c4996004ca6c488e8dd", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "checker": {"name": "performance-noexcept-move-constructor", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-move-constructor.html"}, "analyzerName": "clang-tidy", "line": 570, "column": 65, "message": "move assignment operators should be marked noexcept", "events": [{"message": "move assignment operators should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 570, "column": 65}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DenseStorage.h", "line": 570, "column": 98}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h", "reportHash": "19ff7cc16ea77fe93edd14b546941c6f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 23, "column": 21, "message": "operator=() should return 'DeviceWrapper&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'DeviceWrapper&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/DeviceWrapper.h", "line": 23, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h", "reportHash": "67cabbdd84f76f4786196a0d38c7f651", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 126, "column": 1, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/EigenBase.h", "line": 126, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h", "reportHash": "bbadc7731308c49f0d09f9cd9f157e9f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 265, "column": 21, "message": "operator=() should return 'MapBase&'", "events": [{"message": "operator=() should return 'MapBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MapBase.h", "line": 265, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "reportHash": "46f55c769be19dd42ca645b0b7e78ef8", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 210, "column": 92, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "line": 210, "column": 92}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "reportHash": "c3867f12cca5e729ae3d3c29daf8c478", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 224, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "line": 224, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "reportHash": "2525556100f8938856ea5afca0ccfd96", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 233, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "line": 233, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "reportHash": "b9720319d8d4a3fa827dcbc1c94da34a", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 238, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Matrix.h", "line": 238, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "reportHash": "9469b32ffefad72693ad9d05bb71de1e", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 139, "column": 21, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "line": 139, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "reportHash": "ed9fc0061cc76ba8014d2884fbefc147", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 145, "column": 21, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "line": 145, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "reportHash": "ae53660379fef62a1c24f24b5b03285b", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 148, "column": 21, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "line": 148, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "reportHash": "d67ddc88ec4db8781b85187951fd90d1", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 151, "column": 21, "message": "operator=() should return 'MatrixBase&'", "events": [{"message": "operator=() should return 'MatrixBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/MatrixBase.h", "line": 151, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h", "reportHash": "05108a32d97c03848e16c842fc4e5c9f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 41, "column": 21, "message": "operator=() should return 'NoAlias&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'NoAlias&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/NoAlias.h", "line": 41, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "reportHash": "5aad2cd26bf026c75c87dd665635e770", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 76, "column": 3, "message": "operator=() should return 'PermutationBase&'", "events": [{"message": "operator=() should return 'PermutationBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "line": 76, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "reportHash": "e24e357a659bb8818f969fa8f35fd1d5", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 83, "column": 3, "message": "operator=() should return 'PermutationBase&'", "events": [{"message": "operator=() should return 'PermutationBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "line": 83, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "reportHash": "f894628adaaf16cd4a6d33cbfe81233f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 330, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "line": 330, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "reportHash": "4f8568427db72da66c36980cf3d6f0a2", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 391, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "line": 391, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "reportHash": "f894628adaaf16cd4a6d33cbfe81233f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 397, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PermutationMatrix.h", "line": 397, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "reportHash": "c1dda583c5b1145ee1a414eedd183442", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 429, "column": 21, "message": "operator=() should return 'PlainObjectBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'PlainObjectBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "line": 429, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "reportHash": "a252b0a3b71f13da26aaeb8c26908c6d", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 441, "column": 21, "message": "operator=() should return 'PlainObjectBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'PlainObjectBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "line": 441, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "reportHash": "5dff21a1dc71c6e75e30a73d8eb26c97", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 551, "column": 21, "message": "operator=() should return 'PlainObjectBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'PlainObjectBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/PlainObjectBase.h", "line": 551, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "reportHash": "04fe6cad67aa45aed0aa7633e6192466", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "checker": {"name": "performance-noexcept-move-constructor", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-move-constructor.html"}, "analyzerName": "clang-tidy", "line": 345, "column": 28, "message": "move constructors should be marked noexcept", "events": [{"message": "move constructors should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "line": 345, "column": 28}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Ref.h", "line": 345, "column": 46}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h", "reportHash": "70c443cd5d338b080e8cca2d90436819", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 83, "column": 1, "message": "operator=() should return 'DenseBase&'", "events": [{"message": "operator=() should return 'DenseBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/ReturnByValue.h", "line": 83, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "reportHash": "354ee98e1765fcca410b64d036780fde", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "checker": {"name": "misc-redundant-expression", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/redundant-expression.html"}, "analyzerName": "clang-tidy", "line": 38, "column": 23, "message": "both sides of operator are equivalent", "events": [{"message": "both sides of operator are equivalent", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "line": 38, "column": 23}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "reportHash": "604f6284c6439aae1541848b46b1b2ab", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "checker": {"name": "misc-redundant-expression", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/redundant-expression.html"}, "analyzerName": "clang-tidy", "line": 145, "column": 12, "message": "both sides of operator are equivalent", "events": [{"message": "both sides of operator are equivalent", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/StableNorm.h", "line": 145, "column": 12}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "reportHash": "21f80a4c1f0a51f2059bded903eb69aa", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 32, "column": 3, "message": "operator=() should return 'TranspositionsBase&'", "events": [{"message": "operator=() should return 'TranspositionsBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "line": 32, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "reportHash": "a9142ee51d0de5267daa89beb9aeb2ea", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 162, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "line": 162, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "reportHash": "a9142ee51d0de5267daa89beb9aeb2ea", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 206, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "line": 206, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "reportHash": "a9142ee51d0de5267daa89beb9aeb2ea", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 250, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/Transpositions.h", "line": 250, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "reportHash": "48dc59801681053053f28f92254c5a75", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 377, "column": 21, "message": "operator=() should return 'TriangularViewImpl&'", "events": [{"message": "operator=() should return 'TriangularViewImpl&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "line": 377, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "reportHash": "9fd6656f881784e11b4d8cb7b011e056", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 381, "column": 21, "message": "operator=() should return 'TriangularViewImpl&'", "events": [{"message": "operator=() should return 'TriangularViewImpl&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "line": 381, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "reportHash": "32631b781211e68768336e8a32b6fcee", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 384, "column": 21, "message": "operator=() should return 'TriangularViewImpl&'", "events": [{"message": "operator=() should return 'TriangularViewImpl&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "line": 384, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "reportHash": "26d2f1372eecdc5157a97cc7dc2730f9", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 499, "column": 1, "message": "operator=() should return 'TriangularViewImpl&'", "events": [{"message": "operator=() should return 'TriangularViewImpl&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "line": 499, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "reportHash": "26d2f1372eecdc5157a97cc7dc2730f9", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 515, "column": 1, "message": "operator=() should return 'TriangularViewImpl&'", "events": [{"message": "operator=() should return 'TriangularViewImpl&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/TriangularMatrix.h", "line": 515, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h", "reportHash": "1bb53945173f16d9993b9f646367aa99", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 546, "column": 21, "message": "operator=() should return 'VectorwiseOp&'", "events": [{"message": "operator=() should return 'VectorwiseOp&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/VectorwiseOp.h", "line": 546, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "reportHash": "eb329ea09eeb30dce348e923579cc48e", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 70, "column": 8, "message": "identifier '__bfloat16_raw' is reserved because it starts with '__'", "events": [{"message": "identifier '__bfloat16_raw' is reserved because it starts with '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "line": 70, "column": 8}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "reportHash": "08d37d19b909e8d5e8118558d230f6d4", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 102, "column": 41, "message": "identifier '__bfloat16_raw' is reserved because it starts with '__'", "events": [{"message": "identifier '__bfloat16_raw' is reserved because it starts with '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/BFloat16.h", "line": 102, "column": 41}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h", "reportHash": "fbb262dd4d9f74e4fb8aed2105f1ff06", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h", "checker": {"name": "bugprone-misplaced-widening-cast", "url": "https://clang.llvm.org/extra/clang-tidy/checks/bugprone/misplaced-widening-cast.html"}, "analyzerName": "clang-tidy", "line": 199, "column": 58, "message": "either cast from 'int' to 'ScalarUI' (aka 'unsigned long') is ineffective, or there is loss of precision before the conversion", "events": [{"message": "either cast from 'int' to 'ScalarUI' (aka 'unsigned long') is ineffective, or there is loss of precision before the conversion", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h", "line": 199, "column": 58}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "HIGH", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "reportHash": "e7d2786ce7e6982c6952b5049a22ff8e", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "checker": {"name": "clang-diagnostic-reserved-macro-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-macro-identifier"}, "analyzerName": "clang-tidy", "line": 51, "column": 9, "message": "macro name is a reserved identifier", "events": [{"message": "macro name is a reserved identifier", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "line": 51, "column": 9}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "reportHash": "3d31fd265c68daa10a5c84eac1b4ed3f", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 88, "column": 8, "message": "identifier '__half_raw' is reserved because it starts with '__'", "events": [{"message": "identifier '__half_raw' is reserved because it starts with '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "line": 88, "column": 8}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "reportHash": "c24eab7bff4fcbcfbc560484b84c4ea3", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 160, "column": 33, "message": "identifier '__half_raw' is reserved because it starts with '__'", "events": [{"message": "identifier '__half_raw' is reserved because it starts with '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "line": 160, "column": 33}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "reportHash": "4c53651ddb08ff13b168d25b915c3ea5", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "checker": {"name": "clang-diagnostic-reserved-macro-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-macro-identifier"}, "analyzerName": "clang-tidy", "line": 880, "column": 8, "message": "macro name is a reserved identifier", "events": [{"message": "macro name is a reserved identifier", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/Default/Half.h", "line": 880, "column": 8}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "1093c80adf91d48b5dd3ca21e9f61054", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1385, "column": 28, "message": "'ploadl' is confusable with 'pload1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 819, "column": 33}, {"message": "'ploadl' is confusable with 'pload1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1385, "column": 28}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "54d0673875ac043e62e78929f7dfbadd", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1387, "column": 30, "message": "'ploadl<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pload1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 819, "column": 33}, {"message": "'ploadl<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pload1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1387, "column": 30}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "f40226b77d642d03956d5ce830c3e067", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1391, "column": 30, "message": "'ploadl<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pload1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 819, "column": 33}, {"message": "'ploadl<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pload1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1391, "column": 30}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "b35569aa77b9f998ee2907b443654346", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1500, "column": 26, "message": "'pstorel' is confusable with 'pstore1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 1364, "column": 13}, {"message": "'pstorel' is confusable with 'pstore1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1500, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "488c96bea5694ba2c6fa2a526c721394", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1502, "column": 26, "message": "'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstore1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 1364, "column": 13}, {"message": "'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstore1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1502, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "900e45a9a2d801516f9a0f2a513e9ca4", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1506, "column": 26, "message": "'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstore1'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/GenericPacketMath.h", "line": 1364, "column": 13}, {"message": "'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstore1'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1506, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "837f1eebf31cf891240520b77a078311", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1719, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1500, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1719, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "77c5e262695b041035720eb9e5a1f503", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1719, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1506, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1719, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "9ffe063802313d77b7231988c1c91d84", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1719, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1502, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(4 * sizeof(float)))) float>' is confusable with 'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1719, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "2af23e9521b32e2e9c57743a6a64c0a2", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1725, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1500, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1725, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "e7fa0d5de3eff67a2acecbf6917b4205", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1725, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1506, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel<double, __attribute__((__vector_size__(2 * sizeof(double)))) double>'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1725, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "reportHash": "5b14d7d63bb57e070efbc81b70b1420a", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "checker": {"name": "misc-confusable-identifiers", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/confusable-identifiers.html"}, "analyzerName": "clang-tidy", "line": 1725, "column": 26, "message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>'", "events": [{"message": "other declaration found here", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1502, "column": 26}, {"message": "'pstore1<__attribute__((__vector_size__(2 * sizeof(double)))) double>' is confusable with 'pstorel<float, __attribute__((__vector_size__(4 * sizeof(float)))) float>'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/arch/SSE/PacketMath.h", "line": 1725, "column": 26}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "reportHash": "344306f97dfa4ac2eb37aa13f70a4c35", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 736, "column": 6, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "line": 736, "column": 6}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Memory.h", "line": 736, "column": 52}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "reportHash": "04766f56ce653ad7041eed0eae33ff14", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "checker": {"name": "bugprone-sizeof-expression", "url": "https://clang.llvm.org/extra/clang-tidy/checks/bugprone/sizeof-expression.html"}, "analyzerName": "clang-tidy", "line": 432, "column": 97, "message": "suspicious comparison of 'sizeof(expr)' to a constant", "events": [{"message": "suspicious comparison of 'sizeof(expr)' to a constant", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "line": 432, "column": 97}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "HIGH", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "reportHash": "160fa0c543963d57c0f8c3fc5af0abef", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "checker": {"name": "bugprone-sizeof-expression", "url": "https://clang.llvm.org/extra/clang-tidy/checks/bugprone/sizeof-expression.html"}, "analyzerName": "clang-tidy", "line": 441, "column": 109, "message": "suspicious comparison of 'sizeof(expr)' to a constant", "events": [{"message": "suspicious comparison of 'sizeof(expr)' to a constant", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "line": 441, "column": 109}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "HIGH", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "reportHash": "f4d24eebed302fb42995bf904102c91c", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "checker": {"name": "bugprone-sizeof-expression", "url": "https://clang.llvm.org/extra/clang-tidy/checks/bugprone/sizeof-expression.html"}, "analyzerName": "clang-tidy", "line": 451, "column": 99, "message": "suspicious comparison of 'sizeof(expr)' to a constant", "events": [{"message": "suspicious comparison of 'sizeof(expr)' to a constant", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "line": 451, "column": 99}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "HIGH", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "reportHash": "50baba071a55e2c84634bf7656a5dc4b", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "checker": {"name": "performance-noexcept-swap", "url": "https://clang.llvm.org/extra/clang-tidy/checks/performance/noexcept-swap.html"}, "analyzerName": "clang-tidy", "line": 534, "column": 26, "message": "swap functions should be marked noexcept", "events": [{"message": "swap functions should be marked noexcept", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "line": 534, "column": 26}], "macros": [], "notes": [{"message": "noexcept  (fixit)", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Meta.h", "line": 534, "column": 44}], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "reportHash": "be2c6f28751073fafca9f5949c9fa4e6", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 332, "column": 3, "message": "operator=() should return 'SymbolExpr&'", "events": [{"message": "operator=() should return 'SymbolExpr&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "line": 332, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "reportHash": "35669a9e8b7b1b38876a0cef465c6900", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 335, "column": 3, "message": "operator=() should return 'SymbolExpr&'", "events": [{"message": "operator=() should return 'SymbolExpr&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/SymbolicIndex.h", "line": 335, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h", "reportHash": "dddf1bae9186ad1f71bb2d9c09a551b4", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 202, "column": 3, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/AngleAxis.h", "line": 202, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "0eb9c44d86fc985786ade33133c24d86", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 93, "column": 21, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "expanded from macro 'EIGEN_STRONG_INLINE'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Core/util/Macros.h", "line": 844, "column": 29}, {"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 93, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "575b96ef66a1a7c40318493aaa4035fc", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 102, "column": 21, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 102, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "30e2a95ba624e0e4d16180da032a4812", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 104, "column": 21, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 104, "column": 21}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "e5d34aa3ab6cdc45d11df9f78921d42b", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 559, "column": 3, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 559, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "ec5962dda542ce1af7c6e70fef9f1068", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 562, "column": 1, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 562, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "ec5962dda542ce1af7c6e70fef9f1068", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 572, "column": 1, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 572, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "reportHash": "ec5962dda542ce1af7c6e70fef9f1068", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 588, "column": 1, "message": "operator=() should return 'QuaternionBase&'", "events": [{"message": "operator=() should return 'QuaternionBase&'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Quaternion.h", "line": 588, "column": 1}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h", "reportHash": "7ec8b3c9bdfea5e2731ae8db2c84e9de", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 127, "column": 5, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/Rotation2D.h", "line": 127, "column": 5}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h", "reportHash": "6c359a992abf757aed132ca719482bfd", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h", "checker": {"name": "misc-unconventional-assign-operator", "url": "https://clang.llvm.org/extra/clang-tidy/checks/misc/unconventional-assign-operator.html"}, "analyzerName": "clang-tidy", "line": 164, "column": 3, "message": "operator=() should always return '*this'", "events": [{"message": "operator=() should always return '*this'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/Geometry/RotationBase.h", "line": 164, "column": 3}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "reportHash": "e16d141737afcb0591608dc275c9fabc", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 654, "column": 22, "message": "identifier 'MatrixType__' is reserved because it contains '__'", "events": [{"message": "identifier 'MatrixType__' is reserved because it contains '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "line": 654, "column": 22}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "reportHash": "225a099a93976fe8e42bc0ef95a4e106", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 654, "column": 40, "message": "identifier 'Options__' is reserved because it contains '__'", "events": [{"message": "identifier 'Options__' is reserved because it contains '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "line": 654, "column": 40}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "reportHash": "95d733d812ae8ba8a41b364a93dc61e9", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 656, "column": 22, "message": "identifier 'MatrixType__' is reserved because it contains '__'", "events": [{"message": "identifier 'MatrixType__' is reserved because it contains '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "line": 656, "column": 22}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "reportHash": "6150e1700b074e398b2aadc4e846b181", "path": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "checker": {"name": "clang-diagnostic-reserved-identifier", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wreserved-identifier"}, "analyzerName": "clang-tidy", "line": 656, "column": 40, "message": "identifier 'Options__' is reserved because it contains '__'", "events": [{"message": "identifier 'Options__' is reserved because it contains '__'", "fileId": "/home/pello/PySysLinkBase/.codechecker/_deps/eigen-src/Eigen/src/SVD/JacobiSVD.h", "line": 656, "column": 40}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "reportHash": "46abdd83fe0785dfbc2f506c81b6da32", "path": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "checker": {"name": "clang-diagnostic-sign-compare", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wsign-compare"}, "analyzerName": "clang-tidy", "line": 49, "column": 54, "message": "comparison of integers of different signs: 'size_type' (aka 'unsigned long') and 'int'", "events": [{"message": "comparison of integers of different signs: 'size_type' (aka 'unsigned long') and 'int'", "fileId": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "line": 49, "column": 54}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}, {"fileId": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "reportHash": "b05fc55cbdbedada70da894114be42c6", "path": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "checker": {"name": "clang-diagnostic-sign-compare", "url": "https://clang.llvm.org/docs/DiagnosticsReference.html#wsign-compare"}, "analyzerName": "clang-tidy", "line": 55, "column": 45, "message": "comparison of integers of different signs: 'size_type' (aka 'unsigned long') and 'int'", "events": [{"message": "comparison of integers of different signs: 'size_type' (aka 'unsigned long') and 'int'", "fileId": "/home/pello/PySysLinkBase/src/ContinuousAndOde/EulerBackwardStepSolver.cpp", "line": 55, "column": 45}], "macros": [], "notes": [], "reviewStatus": "Unreviewed", "severity": "MEDIUM", "testcase": null, "timestamp": null}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
